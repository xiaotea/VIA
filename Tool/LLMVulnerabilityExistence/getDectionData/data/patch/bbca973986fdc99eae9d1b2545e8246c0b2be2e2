{
    "neutron/api/v2/attributes.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 731,
                "afterPatchRowNumber": 731,
                "PatchRowcode": "                       'is_visible': True},"
            },
            "1": {
                "beforePatchRowNumber": 732,
                "afterPatchRowNumber": 732,
                "PatchRowcode": "         'device_owner': {'allow_post': True, 'allow_put': True,"
            },
            "2": {
                "beforePatchRowNumber": 733,
                "afterPatchRowNumber": 733,
                "PatchRowcode": "                          'validate': {'type:string': DEVICE_OWNER_MAX_LEN},"
            },
            "3": {
                "beforePatchRowNumber": 734,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                         'default': '',"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 734,
                "PatchRowcode": "+                         'default': '', 'enforce_policy': True,"
            },
            "5": {
                "beforePatchRowNumber": 735,
                "afterPatchRowNumber": 735,
                "PatchRowcode": "                          'is_visible': True},"
            },
            "6": {
                "beforePatchRowNumber": 736,
                "afterPatchRowNumber": 736,
                "PatchRowcode": "         'tenant_id': {'allow_post': True, 'allow_put': False,"
            },
            "7": {
                "beforePatchRowNumber": 737,
                "afterPatchRowNumber": 737,
                "PatchRowcode": "                       'validate': {'type:string': TENANT_ID_MAX_LEN},"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import re",
            "",
            "import netaddr",
            "from oslo_log import log as logging",
            "from oslo_utils import uuidutils",
            "import six",
            "import webob.exc",
            "",
            "from neutron.common import constants",
            "from neutron.common import exceptions as n_exc",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "ATTR_NOT_SPECIFIED = object()",
            "# Defining a constant to avoid repeating string literal in several modules",
            "SHARED = 'shared'",
            "",
            "# Used by range check to indicate no limit for a bound.",
            "UNLIMITED = None",
            "",
            "# TODO(watanabe.isao): A fix like in neutron/db/models_v2.py needs to be",
            "# done in other db modules, to reuse the following constants.",
            "# Common definitions for maximum string field length",
            "NAME_MAX_LEN = 255",
            "TENANT_ID_MAX_LEN = 255",
            "DESCRIPTION_MAX_LEN = 255",
            "DEVICE_ID_MAX_LEN = 255",
            "DEVICE_OWNER_MAX_LEN = 255",
            "",
            "",
            "def _verify_dict_keys(expected_keys, target_dict, strict=True):",
            "    \"\"\"Allows to verify keys in a dictionary.",
            "",
            "    :param expected_keys: A list of keys expected to be present.",
            "    :param target_dict: The dictionary which should be verified.",
            "    :param strict: Specifies whether additional keys are allowed to be present.",
            "    :return: True, if keys in the dictionary correspond to the specification.",
            "    \"\"\"",
            "    if not isinstance(target_dict, dict):",
            "        msg = (_(\"Invalid input. '%(target_dict)s' must be a dictionary \"",
            "                 \"with keys: %(expected_keys)s\") %",
            "               {'target_dict': target_dict, 'expected_keys': expected_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = set(expected_keys)",
            "    provided_keys = set(target_dict.keys())",
            "",
            "    predicate = expected_keys.__eq__ if strict else expected_keys.issubset",
            "",
            "    if not predicate(provided_keys):",
            "        msg = (_(\"Validation of dictionary's keys failed. \"",
            "                 \"Expected keys: %(expected_keys)s \"",
            "                 \"Provided keys: %(provided_keys)s\") %",
            "               {'expected_keys': expected_keys,",
            "                'provided_keys': provided_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def is_attr_set(attribute):",
            "    return not (attribute is None or attribute is ATTR_NOT_SPECIFIED)",
            "",
            "",
            "def _validate_values(data, valid_values=None):",
            "    if data not in valid_values:",
            "        msg = (_(\"'%(data)s' is not in %(valid_values)s\") %",
            "               {'data': data, 'valid_values': valid_values})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_not_empty_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_not_empty_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_not_empty_string(data, max_len=None):",
            "    msg = _validate_string(data, max_len=max_len)",
            "    if msg:",
            "        return msg",
            "    if not data.strip():",
            "        msg = _(\"'%s' Blank strings are not permitted\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_string(data, max_len=None):",
            "    if not isinstance(data, six.string_types):",
            "        msg = _(\"'%s' is not a valid string\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if max_len is not None and len(data) > max_len:",
            "        msg = (_(\"'%(data)s' exceeds maximum length of %(max_len)s\") %",
            "               {'data': data, 'max_len': max_len})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_boolean(data, valid_values=None):",
            "    try:",
            "        convert_to_boolean(data)",
            "    except n_exc.InvalidInput:",
            "        msg = _(\"'%s' is not a valid boolean value\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_range(data, valid_values=None):",
            "    \"\"\"Check that integer value is within a range provided.",
            "",
            "    Test is inclusive. Allows either limit to be ignored, to allow",
            "    checking ranges where only the lower or upper limit matter.",
            "    It is expected that the limits provided are valid integers or",
            "    the value None.",
            "    \"\"\"",
            "",
            "    min_value = valid_values[0]",
            "    max_value = valid_values[1]",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    if min_value is not UNLIMITED and data < min_value:",
            "        msg = _(\"'%(data)s' is too small - must be at least \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': min_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "    if max_value is not UNLIMITED and data > max_value:",
            "        msg = _(\"'%(data)s' is too large - must be no larger than \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': max_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_no_whitespace(data):",
            "    \"\"\"Validates that input has no whitespace.\"\"\"",
            "    if re.search(r'\\s', data):",
            "        msg = _(\"'%s' contains whitespace\") % data",
            "        LOG.debug(msg)",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return data",
            "",
            "",
            "def _validate_mac_address(data, valid_values=None):",
            "    try:",
            "        valid_mac = netaddr.valid_mac(_validate_no_whitespace(data))",
            "    except Exception:",
            "        valid_mac = False",
            "",
            "    if valid_mac:",
            "        valid_mac = not netaddr.EUI(data) in map(netaddr.EUI,",
            "                    constants.INVALID_MAC_ADDRESSES)",
            "    # TODO(arosen): The code in this file should be refactored",
            "    # so it catches the correct exceptions. _validate_no_whitespace",
            "    # raises AttributeError if data is None.",
            "    if not valid_mac:",
            "        msg = _(\"'%s' is not a valid MAC address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_mac_address_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_mac_address(data, valid_values)",
            "",
            "",
            "def _validate_ip_address(data, valid_values=None):",
            "    try:",
            "        netaddr.IPAddress(_validate_no_whitespace(data))",
            "        # The followings are quick checks for IPv6 (has ':') and",
            "        # IPv4.  (has 3 periods like 'xx.xx.xx.xx')",
            "        # NOTE(yamamoto): netaddr uses libraries provided by the underlying",
            "        # platform to convert addresses.  For example, inet_aton(3).",
            "        # Some platforms, including NetBSD and OS X, have inet_aton",
            "        # implementation which accepts more varying forms of addresses than",
            "        # we want to accept here.  The following check is to reject such",
            "        # addresses.  For Example:",
            "        #   >>> netaddr.IPAddress('1' * 59)",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>> netaddr.IPAddress(str(int('1' * 59) & 0xffffffff))",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>>",
            "        if ':' not in data and data.count('.') != 3:",
            "            raise ValueError()",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_ip_pools(data, valid_values=None):",
            "    \"\"\"Validate that start and end IP addresses are present.",
            "",
            "    In addition to this the IP addresses will also be validated",
            "    \"\"\"",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for IP pool: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['start', 'end']",
            "    for ip_pool in data:",
            "        msg = _verify_dict_keys(expected_keys, ip_pool)",
            "        if msg:",
            "            return msg",
            "        for k in expected_keys:",
            "            msg = _validate_ip_address(ip_pool[k])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_fixed_ips(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for fixed IP: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    ips = []",
            "    for fixed_ip in data:",
            "        if not isinstance(fixed_ip, dict):",
            "            msg = _(\"Invalid data format for fixed IP: '%s'\") % fixed_ip",
            "            LOG.debug(msg)",
            "            return msg",
            "        if 'ip_address' in fixed_ip:",
            "            # Ensure that duplicate entries are not set - just checking IP",
            "            # suffices. Duplicate subnet_id's are legitimate.",
            "            fixed_ip_address = fixed_ip['ip_address']",
            "            if fixed_ip_address in ips:",
            "                msg = _(\"Duplicate IP address '%s'\") % fixed_ip_address",
            "                LOG.debug(msg)",
            "            else:",
            "                msg = _validate_ip_address(fixed_ip_address)",
            "            if msg:",
            "                return msg",
            "            ips.append(fixed_ip_address)",
            "        if 'subnet_id' in fixed_ip:",
            "            msg = _validate_uuid(fixed_ip['subnet_id'])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_nameservers(data, valid_values=None):",
            "    if not hasattr(data, '__iter__'):",
            "        msg = _(\"Invalid data format for nameserver: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    hosts = []",
            "    for host in data:",
            "        # This must be an IP address only",
            "        msg = _validate_ip_address(host)",
            "        if msg:",
            "            msg = _(\"'%(host)s' is not a valid nameserver. %(msg)s\") % {",
            "                'host': host, 'msg': msg}",
            "            LOG.debug(msg)",
            "            return msg",
            "        if host in hosts:",
            "            msg = _(\"Duplicate nameserver '%s'\") % host",
            "            LOG.debug(msg)",
            "            return msg",
            "        hosts.append(host)",
            "",
            "",
            "def _validate_hostroutes(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for hostroute: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['destination', 'nexthop']",
            "    hostroutes = []",
            "    for hostroute in data:",
            "        msg = _verify_dict_keys(expected_keys, hostroute)",
            "        if msg:",
            "            return msg",
            "        msg = _validate_subnet(hostroute['destination'])",
            "        if msg:",
            "            return msg",
            "        msg = _validate_ip_address(hostroute['nexthop'])",
            "        if msg:",
            "            return msg",
            "        if hostroute in hostroutes:",
            "            msg = _(\"Duplicate hostroute '%s'\") % hostroute",
            "            LOG.debug(msg)",
            "            return msg",
            "        hostroutes.append(hostroute)",
            "",
            "",
            "def _validate_ip_address_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_ip_address(data, valid_values)",
            "",
            "",
            "def _validate_subnet(data, valid_values=None):",
            "    msg = None",
            "    try:",
            "        net = netaddr.IPNetwork(_validate_no_whitespace(data))",
            "        if '/' not in data:",
            "            msg = _(\"'%(data)s' isn't a recognized IP subnet cidr,\"",
            "                    \" '%(cidr)s' is recommended\") % {\"data\": data,",
            "                                                     \"cidr\": net.cidr}",
            "        else:",
            "            return",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP subnet\") % data",
            "    if msg:",
            "        LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_subnet_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_subnet(item)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_subnet_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_subnet(data, valid_values)",
            "",
            "",
            "def _validate_regex(data, valid_values=None):",
            "    try:",
            "        if re.match(valid_values, data):",
            "            return",
            "    except TypeError:",
            "        pass",
            "",
            "    msg = _(\"'%s' is not a valid input\") % data",
            "    LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_regex_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_regex(data, valid_values)",
            "",
            "",
            "def _validate_subnetpool_id(data, valid_values=None):",
            "    if data != constants.IPV6_PD_POOL_ID:",
            "        return _validate_uuid_or_none(data, valid_values)",
            "",
            "",
            "def _validate_subnetpool_id_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_subnetpool_id(data, valid_values)",
            "",
            "",
            "def _validate_uuid(data, valid_values=None):",
            "    if not uuidutils.is_uuid_like(data):",
            "        msg = _(\"'%s' is not a valid UUID\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_uuid_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_uuid(data)",
            "",
            "",
            "def _validate_uuid_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_uuid(item)",
            "        if msg:",
            "            return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_dict_item(key, key_validator, data):",
            "    # Find conversion function, if any, and apply it",
            "    conv_func = key_validator.get('convert_to')",
            "    if conv_func:",
            "        data[key] = conv_func(data.get(key))",
            "    # Find validator function",
            "    # TODO(salv-orlando): Structure of dict attributes should be improved",
            "    # to avoid iterating over items",
            "    val_func = val_params = None",
            "    for (k, v) in six.iteritems(key_validator):",
            "        if k.startswith('type:'):",
            "            # ask forgiveness, not permission",
            "            try:",
            "                val_func = validators[k]",
            "            except KeyError:",
            "                msg = _(\"Validator '%s' does not exist.\") % k",
            "                LOG.debug(msg)",
            "                return msg",
            "            val_params = v",
            "            break",
            "    # Process validation",
            "    if val_func:",
            "        return val_func(data.get(key), val_params)",
            "",
            "",
            "def _validate_dict(data, key_specs=None):",
            "    if not isinstance(data, dict):",
            "        msg = _(\"'%s' is not a dictionary\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    # Do not perform any further validation, if no constraints are supplied",
            "    if not key_specs:",
            "        return",
            "",
            "    # Check whether all required keys are present",
            "    required_keys = [key for key, spec in six.iteritems(key_specs)",
            "                     if spec.get('required')]",
            "",
            "    if required_keys:",
            "        msg = _verify_dict_keys(required_keys, data, False)",
            "        if msg:",
            "            return msg",
            "",
            "    # Perform validation and conversion of all values",
            "    # according to the specifications.",
            "    for key, key_validator in [(k, v) for k, v in six.iteritems(key_specs)",
            "                               if k in data]:",
            "        msg = _validate_dict_item(key, key_validator, data)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_dict_or_none(data, key_specs=None):",
            "    if data is not None:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_empty(data, key_specs=None):",
            "    if data != {}:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_nodata(data, key_specs=None):",
            "    if data:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_non_negative(data, valid_values=None):",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if data < 0:",
            "        msg = _(\"'%s' should be non-negative\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def convert_to_boolean(data):",
            "    if isinstance(data, six.string_types):",
            "        val = data.lower()",
            "        if val == \"true\" or val == \"1\":",
            "            return True",
            "        if val == \"false\" or val == \"0\":",
            "            return False",
            "    elif isinstance(data, bool):",
            "        return data",
            "    elif isinstance(data, int):",
            "        if data == 0:",
            "            return False",
            "        elif data == 1:",
            "            return True",
            "    msg = _(\"'%s' cannot be converted to boolean\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_boolean_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_boolean(data)",
            "",
            "",
            "def convert_to_int(data):",
            "    try:",
            "        return int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not a integer\") % data",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_int_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_int(data)",
            "    return data",
            "",
            "",
            "def convert_to_positive_float_or_none(val):",
            "    # NOTE(salv-orlando): This conversion function is currently used by",
            "    # a vendor specific extension only at the moment  It is used for",
            "    # port's RXTX factor in neutron.plugins.vmware.extensions.qos.",
            "    # It is deemed however generic enough to be in this module as it",
            "    # might be used in future for other API attributes.",
            "    if val is None:",
            "        return",
            "    try:",
            "        val = float(val)",
            "        if val < 0:",
            "            raise ValueError()",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' must be a non negative decimal.\") % val",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return val",
            "",
            "",
            "def convert_kvp_str_to_list(data):",
            "    \"\"\"Convert a value of the form 'key=value' to ['key', 'value'].",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key).",
            "    \"\"\"",
            "    kvp = [x.strip() for x in data.split('=', 1)]",
            "    if len(kvp) == 2 and kvp[0]:",
            "        return kvp",
            "    msg = _(\"'%s' is not of the form <key>=[value]\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_kvp_list_to_dict(kvp_list):",
            "    \"\"\"Convert a list of 'key=value' strings to a dict.",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key) or if any",
            "                                of the keys appear more than once.",
            "    \"\"\"",
            "    if kvp_list == ['True']:",
            "        # No values were provided (i.e. '--flag-name')",
            "        return {}",
            "    kvp_map = {}",
            "    for kvp_str in kvp_list:",
            "        key, value = convert_kvp_str_to_list(kvp_str)",
            "        kvp_map.setdefault(key, set())",
            "        kvp_map[key].add(value)",
            "    return dict((x, list(y)) for x, y in six.iteritems(kvp_map))",
            "",
            "",
            "def convert_none_to_empty_list(value):",
            "    return [] if value is None else value",
            "",
            "",
            "def convert_none_to_empty_dict(value):",
            "    return {} if value is None else value",
            "",
            "",
            "def convert_to_list(data):",
            "    if data is None:",
            "        return []",
            "    elif hasattr(data, '__iter__') and not isinstance(data, six.string_types):",
            "        return list(data)",
            "    else:",
            "        return [data]",
            "",
            "",
            "HEX_ELEM = '[0-9A-Fa-f]'",
            "UUID_PATTERN = '-'.join([HEX_ELEM + '{8}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{4}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{12}'])",
            "# Note: In order to ensure that the MAC address is unicast the first byte",
            "# must be even.",
            "MAC_PATTERN = \"^%s[aceACE02468](:%s{2}){5}$\" % (HEX_ELEM, HEX_ELEM)",
            "",
            "# Dictionary that maintains a list of validation functions",
            "validators = {'type:dict': _validate_dict,",
            "              'type:dict_or_none': _validate_dict_or_none,",
            "              'type:dict_or_empty': _validate_dict_or_empty,",
            "              'type:dict_or_nodata': _validate_dict_or_nodata,",
            "              'type:fixed_ips': _validate_fixed_ips,",
            "              'type:hostroutes': _validate_hostroutes,",
            "              'type:ip_address': _validate_ip_address,",
            "              'type:ip_address_or_none': _validate_ip_address_or_none,",
            "              'type:ip_pools': _validate_ip_pools,",
            "              'type:mac_address': _validate_mac_address,",
            "              'type:mac_address_or_none': _validate_mac_address_or_none,",
            "              'type:nameservers': _validate_nameservers,",
            "              'type:non_negative': _validate_non_negative,",
            "              'type:range': _validate_range,",
            "              'type:regex': _validate_regex,",
            "              'type:regex_or_none': _validate_regex_or_none,",
            "              'type:string': _validate_string,",
            "              'type:string_or_none': _validate_string_or_none,",
            "              'type:not_empty_string': _validate_not_empty_string,",
            "              'type:not_empty_string_or_none':",
            "              _validate_not_empty_string_or_none,",
            "              'type:subnet': _validate_subnet,",
            "              'type:subnet_list': _validate_subnet_list,",
            "              'type:subnet_or_none': _validate_subnet_or_none,",
            "              'type:subnetpool_id': _validate_subnetpool_id,",
            "              'type:subnetpool_id_or_none': _validate_subnetpool_id_or_none,",
            "              'type:uuid': _validate_uuid,",
            "              'type:uuid_or_none': _validate_uuid_or_none,",
            "              'type:uuid_list': _validate_uuid_list,",
            "              'type:values': _validate_values,",
            "              'type:boolean': _validate_boolean}",
            "",
            "# Define constants for base resource name",
            "NETWORK = 'network'",
            "NETWORKS = '%ss' % NETWORK",
            "PORT = 'port'",
            "PORTS = '%ss' % PORT",
            "SUBNET = 'subnet'",
            "SUBNETS = '%ss' % SUBNET",
            "SUBNETPOOL = 'subnetpool'",
            "SUBNETPOOLS = '%ss' % SUBNETPOOL",
            "# Note: a default of ATTR_NOT_SPECIFIED indicates that an",
            "# attribute is not required, but will be generated by the plugin",
            "# if it is not specified.  Particularly, a value of ATTR_NOT_SPECIFIED",
            "# is different from an attribute that has been specified with a value of",
            "# None.  For example, if 'gateway_ip' is omitted in a request to",
            "# create a subnet, the plugin will receive ATTR_NOT_SPECIFIED",
            "# and the default gateway_ip will be generated.",
            "# However, if gateway_ip is specified as None, this means that",
            "# the subnet does not have a gateway IP.",
            "# The following is a short reference for understanding attribute info:",
            "# default: default value of the attribute (if missing, the attribute",
            "# becomes mandatory.",
            "# allow_post: the attribute can be used on POST requests.",
            "# allow_put: the attribute can be used on PUT requests.",
            "# validate: specifies rules for validating data in the attribute.",
            "# convert_to: transformation to apply to the value before it is returned",
            "# is_visible: the attribute is returned in GET responses.",
            "# required_by_policy: the attribute is required by the policy engine and",
            "# should therefore be filled by the API layer even if not present in",
            "# request body.",
            "# enforce_policy: the attribute is actively part of the policy enforcing",
            "# mechanism, ie: there might be rules which refer to this attribute.",
            "",
            "RESOURCE_ATTRIBUTE_MAP = {",
            "    NETWORKS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True,",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'default': '', 'is_visible': True},",
            "        'subnets': {'allow_post': False, 'allow_put': False,",
            "                    'default': [],",
            "                    'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    PORTS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'mac_address': {'allow_post': True, 'allow_put': True,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:mac_address': None},",
            "                        'enforce_policy': True,",
            "                        'is_visible': True},",
            "        'fixed_ips': {'allow_post': True, 'allow_put': True,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'convert_list_to': convert_kvp_list_to_dict,",
            "                      'validate': {'type:fixed_ips': None},",
            "                      'enforce_policy': True,",
            "                      'is_visible': True},",
            "        'device_id': {'allow_post': True, 'allow_put': True,",
            "                      'validate': {'type:string': DEVICE_ID_MAX_LEN},",
            "                      'default': '',",
            "                      'is_visible': True},",
            "        'device_owner': {'allow_post': True, 'allow_put': True,",
            "                         'validate': {'type:string': DEVICE_OWNER_MAX_LEN},",
            "                         'default': '',",
            "                         'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "    },",
            "    SUBNETS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'ip_version': {'allow_post': True, 'allow_put': False,",
            "                       'convert_to': convert_to_int,",
            "                       'validate': {'type:values': [4, 6]},",
            "                       'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'subnetpool_id': {'allow_post': True,",
            "                          'allow_put': False,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'required_by_policy': False,",
            "                          'validate': {'type:subnetpool_id_or_none': None},",
            "                          'is_visible': True},",
            "        'prefixlen': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:non_negative': None},",
            "                      'convert_to': convert_to_int,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'required_by_policy': False,",
            "                      'is_visible': False},",
            "        'cidr': {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': ATTR_NOT_SPECIFIED,",
            "                 'validate': {'type:subnet_or_none': None},",
            "                 'required_by_policy': False,",
            "                 'is_visible': True},",
            "        'gateway_ip': {'allow_post': True, 'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:ip_address_or_none': None},",
            "                       'is_visible': True},",
            "        'allocation_pools': {'allow_post': True, 'allow_put': True,",
            "                             'default': ATTR_NOT_SPECIFIED,",
            "                             'validate': {'type:ip_pools': None},",
            "                             'is_visible': True},",
            "        'dns_nameservers': {'allow_post': True, 'allow_put': True,",
            "                            'convert_to': convert_none_to_empty_list,",
            "                            'default': ATTR_NOT_SPECIFIED,",
            "                            'validate': {'type:nameservers': None},",
            "                            'is_visible': True},",
            "        'host_routes': {'allow_post': True, 'allow_put': True,",
            "                        'convert_to': convert_none_to_empty_list,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:hostroutes': None},",
            "                        'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'enable_dhcp': {'allow_post': True, 'allow_put': True,",
            "                        'default': True,",
            "                        'convert_to': convert_to_boolean,",
            "                        'is_visible': True},",
            "        'ipv6_ra_mode': {'allow_post': True, 'allow_put': False,",
            "                         'default': ATTR_NOT_SPECIFIED,",
            "                         'validate': {'type:values': constants.IPV6_MODES},",
            "                         'is_visible': True},",
            "        'ipv6_address_mode': {'allow_post': True, 'allow_put': False,",
            "                              'default': ATTR_NOT_SPECIFIED,",
            "                              'validate': {'type:values':",
            "                                           constants.IPV6_MODES},",
            "                              'is_visible': True},",
            "        SHARED: {'allow_post': False,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': False,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    SUBNETPOOLS: {",
            "        'id': {'allow_post': False,",
            "               'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'validate': {'type:not_empty_string': None},",
            "                 'is_visible': True},",
            "        'tenant_id': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'prefixes': {'allow_post': True,",
            "                     'allow_put': True,",
            "                     'validate': {'type:subnet_list': None},",
            "                     'is_visible': True},",
            "        'default_quota': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'is_visible': True},",
            "        'ip_version': {'allow_post': False,",
            "                       'allow_put': False,",
            "                       'is_visible': True},",
            "        'default_prefixlen': {'allow_post': True,",
            "                              'allow_put': True,",
            "                              'validate': {'type:non_negative': None},",
            "                              'convert_to': convert_to_int,",
            "                              'default': ATTR_NOT_SPECIFIED,",
            "                              'is_visible': True},",
            "        'min_prefixlen': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'is_visible': True},",
            "        'max_prefixlen': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    }",
            "}",
            "",
            "# Identify the attribute used by a resource to reference another resource",
            "",
            "RESOURCE_FOREIGN_KEYS = {",
            "    NETWORKS: 'network_id'",
            "}",
            "",
            "PLURALS = {NETWORKS: NETWORK,",
            "           PORTS: PORT,",
            "           SUBNETS: SUBNET,",
            "           SUBNETPOOLS: SUBNETPOOL,",
            "           'dns_nameservers': 'dns_nameserver',",
            "           'host_routes': 'host_route',",
            "           'allocation_pools': 'allocation_pool',",
            "           'fixed_ips': 'fixed_ip',",
            "           'extensions': 'extension'}",
            "",
            "",
            "def fill_default_value(attr_info, res_dict,",
            "                       exc_cls=ValueError,",
            "                       check_allow_post=True):",
            "    for attr, attr_vals in six.iteritems(attr_info):",
            "        if attr_vals['allow_post']:",
            "            if ('default' not in attr_vals and",
            "                attr not in res_dict):",
            "                msg = _(\"Failed to parse request. Required \"",
            "                        \"attribute '%s' not specified\") % attr",
            "                raise exc_cls(msg)",
            "            res_dict[attr] = res_dict.get(attr,",
            "                                          attr_vals.get('default'))",
            "        elif check_allow_post:",
            "            if attr in res_dict:",
            "                msg = _(\"Attribute '%s' not allowed in POST\") % attr",
            "                raise exc_cls(msg)",
            "",
            "",
            "def convert_value(attr_info, res_dict, exc_cls=ValueError):",
            "    for attr, attr_vals in six.iteritems(attr_info):",
            "        if (attr not in res_dict or",
            "            res_dict[attr] is ATTR_NOT_SPECIFIED):",
            "            continue",
            "        # Convert values if necessary",
            "        if 'convert_to' in attr_vals:",
            "            res_dict[attr] = attr_vals['convert_to'](res_dict[attr])",
            "        # Check that configured values are correct",
            "        if 'validate' not in attr_vals:",
            "            continue",
            "        for rule in attr_vals['validate']:",
            "            res = validators[rule](res_dict[attr], attr_vals['validate'][rule])",
            "            if res:",
            "                msg_dict = dict(attr=attr, reason=res)",
            "                msg = _(\"Invalid input for %(attr)s. \"",
            "                        \"Reason: %(reason)s.\") % msg_dict",
            "                raise exc_cls(msg)",
            "",
            "",
            "def populate_tenant_id(context, res_dict, attr_info, is_create):",
            "    if (('tenant_id' in res_dict and",
            "         res_dict['tenant_id'] != context.tenant_id and",
            "         not context.is_admin)):",
            "        msg = _(\"Specifying 'tenant_id' other than authenticated \"",
            "                \"tenant in request requires admin privileges\")",
            "        raise webob.exc.HTTPBadRequest(msg)",
            "",
            "    if is_create and 'tenant_id' not in res_dict:",
            "        if context.tenant_id:",
            "            res_dict['tenant_id'] = context.tenant_id",
            "        elif 'tenant_id' in attr_info:",
            "            msg = _(\"Running without keystone AuthN requires \"",
            "                    \"that tenant_id is specified\")",
            "            raise webob.exc.HTTPBadRequest(msg)",
            "",
            "",
            "def verify_attributes(res_dict, attr_info):",
            "    extra_keys = set(res_dict.keys()) - set(attr_info.keys())",
            "    if extra_keys:",
            "        msg = _(\"Unrecognized attribute(s) '%s'\") % ', '.join(extra_keys)",
            "        raise webob.exc.HTTPBadRequest(msg)"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "import re",
            "",
            "import netaddr",
            "from oslo_log import log as logging",
            "from oslo_utils import uuidutils",
            "import six",
            "import webob.exc",
            "",
            "from neutron.common import constants",
            "from neutron.common import exceptions as n_exc",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "ATTR_NOT_SPECIFIED = object()",
            "# Defining a constant to avoid repeating string literal in several modules",
            "SHARED = 'shared'",
            "",
            "# Used by range check to indicate no limit for a bound.",
            "UNLIMITED = None",
            "",
            "# TODO(watanabe.isao): A fix like in neutron/db/models_v2.py needs to be",
            "# done in other db modules, to reuse the following constants.",
            "# Common definitions for maximum string field length",
            "NAME_MAX_LEN = 255",
            "TENANT_ID_MAX_LEN = 255",
            "DESCRIPTION_MAX_LEN = 255",
            "DEVICE_ID_MAX_LEN = 255",
            "DEVICE_OWNER_MAX_LEN = 255",
            "",
            "",
            "def _verify_dict_keys(expected_keys, target_dict, strict=True):",
            "    \"\"\"Allows to verify keys in a dictionary.",
            "",
            "    :param expected_keys: A list of keys expected to be present.",
            "    :param target_dict: The dictionary which should be verified.",
            "    :param strict: Specifies whether additional keys are allowed to be present.",
            "    :return: True, if keys in the dictionary correspond to the specification.",
            "    \"\"\"",
            "    if not isinstance(target_dict, dict):",
            "        msg = (_(\"Invalid input. '%(target_dict)s' must be a dictionary \"",
            "                 \"with keys: %(expected_keys)s\") %",
            "               {'target_dict': target_dict, 'expected_keys': expected_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = set(expected_keys)",
            "    provided_keys = set(target_dict.keys())",
            "",
            "    predicate = expected_keys.__eq__ if strict else expected_keys.issubset",
            "",
            "    if not predicate(provided_keys):",
            "        msg = (_(\"Validation of dictionary's keys failed. \"",
            "                 \"Expected keys: %(expected_keys)s \"",
            "                 \"Provided keys: %(provided_keys)s\") %",
            "               {'expected_keys': expected_keys,",
            "                'provided_keys': provided_keys})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def is_attr_set(attribute):",
            "    return not (attribute is None or attribute is ATTR_NOT_SPECIFIED)",
            "",
            "",
            "def _validate_values(data, valid_values=None):",
            "    if data not in valid_values:",
            "        msg = (_(\"'%(data)s' is not in %(valid_values)s\") %",
            "               {'data': data, 'valid_values': valid_values})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_not_empty_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_not_empty_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_not_empty_string(data, max_len=None):",
            "    msg = _validate_string(data, max_len=max_len)",
            "    if msg:",
            "        return msg",
            "    if not data.strip():",
            "        msg = _(\"'%s' Blank strings are not permitted\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_string_or_none(data, max_len=None):",
            "    if data is not None:",
            "        return _validate_string(data, max_len=max_len)",
            "",
            "",
            "def _validate_string(data, max_len=None):",
            "    if not isinstance(data, six.string_types):",
            "        msg = _(\"'%s' is not a valid string\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if max_len is not None and len(data) > max_len:",
            "        msg = (_(\"'%(data)s' exceeds maximum length of %(max_len)s\") %",
            "               {'data': data, 'max_len': max_len})",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_boolean(data, valid_values=None):",
            "    try:",
            "        convert_to_boolean(data)",
            "    except n_exc.InvalidInput:",
            "        msg = _(\"'%s' is not a valid boolean value\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_range(data, valid_values=None):",
            "    \"\"\"Check that integer value is within a range provided.",
            "",
            "    Test is inclusive. Allows either limit to be ignored, to allow",
            "    checking ranges where only the lower or upper limit matter.",
            "    It is expected that the limits provided are valid integers or",
            "    the value None.",
            "    \"\"\"",
            "",
            "    min_value = valid_values[0]",
            "    max_value = valid_values[1]",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    if min_value is not UNLIMITED and data < min_value:",
            "        msg = _(\"'%(data)s' is too small - must be at least \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': min_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "    if max_value is not UNLIMITED and data > max_value:",
            "        msg = _(\"'%(data)s' is too large - must be no larger than \"",
            "                \"'%(limit)d'\") % {'data': data, 'limit': max_value}",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_no_whitespace(data):",
            "    \"\"\"Validates that input has no whitespace.\"\"\"",
            "    if re.search(r'\\s', data):",
            "        msg = _(\"'%s' contains whitespace\") % data",
            "        LOG.debug(msg)",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return data",
            "",
            "",
            "def _validate_mac_address(data, valid_values=None):",
            "    try:",
            "        valid_mac = netaddr.valid_mac(_validate_no_whitespace(data))",
            "    except Exception:",
            "        valid_mac = False",
            "",
            "    if valid_mac:",
            "        valid_mac = not netaddr.EUI(data) in map(netaddr.EUI,",
            "                    constants.INVALID_MAC_ADDRESSES)",
            "    # TODO(arosen): The code in this file should be refactored",
            "    # so it catches the correct exceptions. _validate_no_whitespace",
            "    # raises AttributeError if data is None.",
            "    if not valid_mac:",
            "        msg = _(\"'%s' is not a valid MAC address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_mac_address_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_mac_address(data, valid_values)",
            "",
            "",
            "def _validate_ip_address(data, valid_values=None):",
            "    try:",
            "        netaddr.IPAddress(_validate_no_whitespace(data))",
            "        # The followings are quick checks for IPv6 (has ':') and",
            "        # IPv4.  (has 3 periods like 'xx.xx.xx.xx')",
            "        # NOTE(yamamoto): netaddr uses libraries provided by the underlying",
            "        # platform to convert addresses.  For example, inet_aton(3).",
            "        # Some platforms, including NetBSD and OS X, have inet_aton",
            "        # implementation which accepts more varying forms of addresses than",
            "        # we want to accept here.  The following check is to reject such",
            "        # addresses.  For Example:",
            "        #   >>> netaddr.IPAddress('1' * 59)",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>> netaddr.IPAddress(str(int('1' * 59) & 0xffffffff))",
            "        #   IPAddress('199.28.113.199')",
            "        #   >>>",
            "        if ':' not in data and data.count('.') != 3:",
            "            raise ValueError()",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP address\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_ip_pools(data, valid_values=None):",
            "    \"\"\"Validate that start and end IP addresses are present.",
            "",
            "    In addition to this the IP addresses will also be validated",
            "    \"\"\"",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for IP pool: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['start', 'end']",
            "    for ip_pool in data:",
            "        msg = _verify_dict_keys(expected_keys, ip_pool)",
            "        if msg:",
            "            return msg",
            "        for k in expected_keys:",
            "            msg = _validate_ip_address(ip_pool[k])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_fixed_ips(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for fixed IP: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    ips = []",
            "    for fixed_ip in data:",
            "        if not isinstance(fixed_ip, dict):",
            "            msg = _(\"Invalid data format for fixed IP: '%s'\") % fixed_ip",
            "            LOG.debug(msg)",
            "            return msg",
            "        if 'ip_address' in fixed_ip:",
            "            # Ensure that duplicate entries are not set - just checking IP",
            "            # suffices. Duplicate subnet_id's are legitimate.",
            "            fixed_ip_address = fixed_ip['ip_address']",
            "            if fixed_ip_address in ips:",
            "                msg = _(\"Duplicate IP address '%s'\") % fixed_ip_address",
            "                LOG.debug(msg)",
            "            else:",
            "                msg = _validate_ip_address(fixed_ip_address)",
            "            if msg:",
            "                return msg",
            "            ips.append(fixed_ip_address)",
            "        if 'subnet_id' in fixed_ip:",
            "            msg = _validate_uuid(fixed_ip['subnet_id'])",
            "            if msg:",
            "                return msg",
            "",
            "",
            "def _validate_nameservers(data, valid_values=None):",
            "    if not hasattr(data, '__iter__'):",
            "        msg = _(\"Invalid data format for nameserver: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    hosts = []",
            "    for host in data:",
            "        # This must be an IP address only",
            "        msg = _validate_ip_address(host)",
            "        if msg:",
            "            msg = _(\"'%(host)s' is not a valid nameserver. %(msg)s\") % {",
            "                'host': host, 'msg': msg}",
            "            LOG.debug(msg)",
            "            return msg",
            "        if host in hosts:",
            "            msg = _(\"Duplicate nameserver '%s'\") % host",
            "            LOG.debug(msg)",
            "            return msg",
            "        hosts.append(host)",
            "",
            "",
            "def _validate_hostroutes(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"Invalid data format for hostroute: '%s'\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    expected_keys = ['destination', 'nexthop']",
            "    hostroutes = []",
            "    for hostroute in data:",
            "        msg = _verify_dict_keys(expected_keys, hostroute)",
            "        if msg:",
            "            return msg",
            "        msg = _validate_subnet(hostroute['destination'])",
            "        if msg:",
            "            return msg",
            "        msg = _validate_ip_address(hostroute['nexthop'])",
            "        if msg:",
            "            return msg",
            "        if hostroute in hostroutes:",
            "            msg = _(\"Duplicate hostroute '%s'\") % hostroute",
            "            LOG.debug(msg)",
            "            return msg",
            "        hostroutes.append(hostroute)",
            "",
            "",
            "def _validate_ip_address_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_ip_address(data, valid_values)",
            "",
            "",
            "def _validate_subnet(data, valid_values=None):",
            "    msg = None",
            "    try:",
            "        net = netaddr.IPNetwork(_validate_no_whitespace(data))",
            "        if '/' not in data:",
            "            msg = _(\"'%(data)s' isn't a recognized IP subnet cidr,\"",
            "                    \" '%(cidr)s' is recommended\") % {\"data\": data,",
            "                                                     \"cidr\": net.cidr}",
            "        else:",
            "            return",
            "    except Exception:",
            "        msg = _(\"'%s' is not a valid IP subnet\") % data",
            "    if msg:",
            "        LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_subnet_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_subnet(item)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_subnet_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_subnet(data, valid_values)",
            "",
            "",
            "def _validate_regex(data, valid_values=None):",
            "    try:",
            "        if re.match(valid_values, data):",
            "            return",
            "    except TypeError:",
            "        pass",
            "",
            "    msg = _(\"'%s' is not a valid input\") % data",
            "    LOG.debug(msg)",
            "    return msg",
            "",
            "",
            "def _validate_regex_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_regex(data, valid_values)",
            "",
            "",
            "def _validate_subnetpool_id(data, valid_values=None):",
            "    if data != constants.IPV6_PD_POOL_ID:",
            "        return _validate_uuid_or_none(data, valid_values)",
            "",
            "",
            "def _validate_subnetpool_id_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_subnetpool_id(data, valid_values)",
            "",
            "",
            "def _validate_uuid(data, valid_values=None):",
            "    if not uuidutils.is_uuid_like(data):",
            "        msg = _(\"'%s' is not a valid UUID\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_uuid_or_none(data, valid_values=None):",
            "    if data is not None:",
            "        return _validate_uuid(data)",
            "",
            "",
            "def _validate_uuid_list(data, valid_values=None):",
            "    if not isinstance(data, list):",
            "        msg = _(\"'%s' is not a list\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    for item in data:",
            "        msg = _validate_uuid(item)",
            "        if msg:",
            "            return msg",
            "",
            "    if len(set(data)) != len(data):",
            "        msg = _(\"Duplicate items in the list: '%s'\") % ', '.join(data)",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def _validate_dict_item(key, key_validator, data):",
            "    # Find conversion function, if any, and apply it",
            "    conv_func = key_validator.get('convert_to')",
            "    if conv_func:",
            "        data[key] = conv_func(data.get(key))",
            "    # Find validator function",
            "    # TODO(salv-orlando): Structure of dict attributes should be improved",
            "    # to avoid iterating over items",
            "    val_func = val_params = None",
            "    for (k, v) in six.iteritems(key_validator):",
            "        if k.startswith('type:'):",
            "            # ask forgiveness, not permission",
            "            try:",
            "                val_func = validators[k]",
            "            except KeyError:",
            "                msg = _(\"Validator '%s' does not exist.\") % k",
            "                LOG.debug(msg)",
            "                return msg",
            "            val_params = v",
            "            break",
            "    # Process validation",
            "    if val_func:",
            "        return val_func(data.get(key), val_params)",
            "",
            "",
            "def _validate_dict(data, key_specs=None):",
            "    if not isinstance(data, dict):",
            "        msg = _(\"'%s' is not a dictionary\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "    # Do not perform any further validation, if no constraints are supplied",
            "    if not key_specs:",
            "        return",
            "",
            "    # Check whether all required keys are present",
            "    required_keys = [key for key, spec in six.iteritems(key_specs)",
            "                     if spec.get('required')]",
            "",
            "    if required_keys:",
            "        msg = _verify_dict_keys(required_keys, data, False)",
            "        if msg:",
            "            return msg",
            "",
            "    # Perform validation and conversion of all values",
            "    # according to the specifications.",
            "    for key, key_validator in [(k, v) for k, v in six.iteritems(key_specs)",
            "                               if k in data]:",
            "        msg = _validate_dict_item(key, key_validator, data)",
            "        if msg:",
            "            return msg",
            "",
            "",
            "def _validate_dict_or_none(data, key_specs=None):",
            "    if data is not None:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_empty(data, key_specs=None):",
            "    if data != {}:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_dict_or_nodata(data, key_specs=None):",
            "    if data:",
            "        return _validate_dict(data, key_specs)",
            "",
            "",
            "def _validate_non_negative(data, valid_values=None):",
            "    try:",
            "        data = int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not an integer\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "    if data < 0:",
            "        msg = _(\"'%s' should be non-negative\") % data",
            "        LOG.debug(msg)",
            "        return msg",
            "",
            "",
            "def convert_to_boolean(data):",
            "    if isinstance(data, six.string_types):",
            "        val = data.lower()",
            "        if val == \"true\" or val == \"1\":",
            "            return True",
            "        if val == \"false\" or val == \"0\":",
            "            return False",
            "    elif isinstance(data, bool):",
            "        return data",
            "    elif isinstance(data, int):",
            "        if data == 0:",
            "            return False",
            "        elif data == 1:",
            "            return True",
            "    msg = _(\"'%s' cannot be converted to boolean\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_boolean_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_boolean(data)",
            "",
            "",
            "def convert_to_int(data):",
            "    try:",
            "        return int(data)",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' is not a integer\") % data",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_to_int_if_not_none(data):",
            "    if data is not None:",
            "        return convert_to_int(data)",
            "    return data",
            "",
            "",
            "def convert_to_positive_float_or_none(val):",
            "    # NOTE(salv-orlando): This conversion function is currently used by",
            "    # a vendor specific extension only at the moment  It is used for",
            "    # port's RXTX factor in neutron.plugins.vmware.extensions.qos.",
            "    # It is deemed however generic enough to be in this module as it",
            "    # might be used in future for other API attributes.",
            "    if val is None:",
            "        return",
            "    try:",
            "        val = float(val)",
            "        if val < 0:",
            "            raise ValueError()",
            "    except (ValueError, TypeError):",
            "        msg = _(\"'%s' must be a non negative decimal.\") % val",
            "        raise n_exc.InvalidInput(error_message=msg)",
            "    return val",
            "",
            "",
            "def convert_kvp_str_to_list(data):",
            "    \"\"\"Convert a value of the form 'key=value' to ['key', 'value'].",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key).",
            "    \"\"\"",
            "    kvp = [x.strip() for x in data.split('=', 1)]",
            "    if len(kvp) == 2 and kvp[0]:",
            "        return kvp",
            "    msg = _(\"'%s' is not of the form <key>=[value]\") % data",
            "    raise n_exc.InvalidInput(error_message=msg)",
            "",
            "",
            "def convert_kvp_list_to_dict(kvp_list):",
            "    \"\"\"Convert a list of 'key=value' strings to a dict.",
            "",
            "    :raises: n_exc.InvalidInput if any of the strings are malformed",
            "                                (e.g. do not contain a key) or if any",
            "                                of the keys appear more than once.",
            "    \"\"\"",
            "    if kvp_list == ['True']:",
            "        # No values were provided (i.e. '--flag-name')",
            "        return {}",
            "    kvp_map = {}",
            "    for kvp_str in kvp_list:",
            "        key, value = convert_kvp_str_to_list(kvp_str)",
            "        kvp_map.setdefault(key, set())",
            "        kvp_map[key].add(value)",
            "    return dict((x, list(y)) for x, y in six.iteritems(kvp_map))",
            "",
            "",
            "def convert_none_to_empty_list(value):",
            "    return [] if value is None else value",
            "",
            "",
            "def convert_none_to_empty_dict(value):",
            "    return {} if value is None else value",
            "",
            "",
            "def convert_to_list(data):",
            "    if data is None:",
            "        return []",
            "    elif hasattr(data, '__iter__') and not isinstance(data, six.string_types):",
            "        return list(data)",
            "    else:",
            "        return [data]",
            "",
            "",
            "HEX_ELEM = '[0-9A-Fa-f]'",
            "UUID_PATTERN = '-'.join([HEX_ELEM + '{8}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{4}', HEX_ELEM + '{4}',",
            "                         HEX_ELEM + '{12}'])",
            "# Note: In order to ensure that the MAC address is unicast the first byte",
            "# must be even.",
            "MAC_PATTERN = \"^%s[aceACE02468](:%s{2}){5}$\" % (HEX_ELEM, HEX_ELEM)",
            "",
            "# Dictionary that maintains a list of validation functions",
            "validators = {'type:dict': _validate_dict,",
            "              'type:dict_or_none': _validate_dict_or_none,",
            "              'type:dict_or_empty': _validate_dict_or_empty,",
            "              'type:dict_or_nodata': _validate_dict_or_nodata,",
            "              'type:fixed_ips': _validate_fixed_ips,",
            "              'type:hostroutes': _validate_hostroutes,",
            "              'type:ip_address': _validate_ip_address,",
            "              'type:ip_address_or_none': _validate_ip_address_or_none,",
            "              'type:ip_pools': _validate_ip_pools,",
            "              'type:mac_address': _validate_mac_address,",
            "              'type:mac_address_or_none': _validate_mac_address_or_none,",
            "              'type:nameservers': _validate_nameservers,",
            "              'type:non_negative': _validate_non_negative,",
            "              'type:range': _validate_range,",
            "              'type:regex': _validate_regex,",
            "              'type:regex_or_none': _validate_regex_or_none,",
            "              'type:string': _validate_string,",
            "              'type:string_or_none': _validate_string_or_none,",
            "              'type:not_empty_string': _validate_not_empty_string,",
            "              'type:not_empty_string_or_none':",
            "              _validate_not_empty_string_or_none,",
            "              'type:subnet': _validate_subnet,",
            "              'type:subnet_list': _validate_subnet_list,",
            "              'type:subnet_or_none': _validate_subnet_or_none,",
            "              'type:subnetpool_id': _validate_subnetpool_id,",
            "              'type:subnetpool_id_or_none': _validate_subnetpool_id_or_none,",
            "              'type:uuid': _validate_uuid,",
            "              'type:uuid_or_none': _validate_uuid_or_none,",
            "              'type:uuid_list': _validate_uuid_list,",
            "              'type:values': _validate_values,",
            "              'type:boolean': _validate_boolean}",
            "",
            "# Define constants for base resource name",
            "NETWORK = 'network'",
            "NETWORKS = '%ss' % NETWORK",
            "PORT = 'port'",
            "PORTS = '%ss' % PORT",
            "SUBNET = 'subnet'",
            "SUBNETS = '%ss' % SUBNET",
            "SUBNETPOOL = 'subnetpool'",
            "SUBNETPOOLS = '%ss' % SUBNETPOOL",
            "# Note: a default of ATTR_NOT_SPECIFIED indicates that an",
            "# attribute is not required, but will be generated by the plugin",
            "# if it is not specified.  Particularly, a value of ATTR_NOT_SPECIFIED",
            "# is different from an attribute that has been specified with a value of",
            "# None.  For example, if 'gateway_ip' is omitted in a request to",
            "# create a subnet, the plugin will receive ATTR_NOT_SPECIFIED",
            "# and the default gateway_ip will be generated.",
            "# However, if gateway_ip is specified as None, this means that",
            "# the subnet does not have a gateway IP.",
            "# The following is a short reference for understanding attribute info:",
            "# default: default value of the attribute (if missing, the attribute",
            "# becomes mandatory.",
            "# allow_post: the attribute can be used on POST requests.",
            "# allow_put: the attribute can be used on PUT requests.",
            "# validate: specifies rules for validating data in the attribute.",
            "# convert_to: transformation to apply to the value before it is returned",
            "# is_visible: the attribute is returned in GET responses.",
            "# required_by_policy: the attribute is required by the policy engine and",
            "# should therefore be filled by the API layer even if not present in",
            "# request body.",
            "# enforce_policy: the attribute is actively part of the policy enforcing",
            "# mechanism, ie: there might be rules which refer to this attribute.",
            "",
            "RESOURCE_ATTRIBUTE_MAP = {",
            "    NETWORKS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True,",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'default': '', 'is_visible': True},",
            "        'subnets': {'allow_post': False, 'allow_put': False,",
            "                    'default': [],",
            "                    'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    PORTS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'admin_state_up': {'allow_post': True, 'allow_put': True,",
            "                           'default': True,",
            "                           'convert_to': convert_to_boolean,",
            "                           'is_visible': True},",
            "        'mac_address': {'allow_post': True, 'allow_put': True,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:mac_address': None},",
            "                        'enforce_policy': True,",
            "                        'is_visible': True},",
            "        'fixed_ips': {'allow_post': True, 'allow_put': True,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'convert_list_to': convert_kvp_list_to_dict,",
            "                      'validate': {'type:fixed_ips': None},",
            "                      'enforce_policy': True,",
            "                      'is_visible': True},",
            "        'device_id': {'allow_post': True, 'allow_put': True,",
            "                      'validate': {'type:string': DEVICE_ID_MAX_LEN},",
            "                      'default': '',",
            "                      'is_visible': True},",
            "        'device_owner': {'allow_post': True, 'allow_put': True,",
            "                         'validate': {'type:string': DEVICE_OWNER_MAX_LEN},",
            "                         'default': '', 'enforce_policy': True,",
            "                         'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'status': {'allow_post': False, 'allow_put': False,",
            "                   'is_visible': True},",
            "    },",
            "    SUBNETS: {",
            "        'id': {'allow_post': False, 'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True, 'allow_put': True, 'default': '',",
            "                 'validate': {'type:string': NAME_MAX_LEN},",
            "                 'is_visible': True},",
            "        'ip_version': {'allow_post': True, 'allow_put': False,",
            "                       'convert_to': convert_to_int,",
            "                       'validate': {'type:values': [4, 6]},",
            "                       'is_visible': True},",
            "        'network_id': {'allow_post': True, 'allow_put': False,",
            "                       'required_by_policy': True,",
            "                       'validate': {'type:uuid': None},",
            "                       'is_visible': True},",
            "        'subnetpool_id': {'allow_post': True,",
            "                          'allow_put': False,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'required_by_policy': False,",
            "                          'validate': {'type:subnetpool_id_or_none': None},",
            "                          'is_visible': True},",
            "        'prefixlen': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:non_negative': None},",
            "                      'convert_to': convert_to_int,",
            "                      'default': ATTR_NOT_SPECIFIED,",
            "                      'required_by_policy': False,",
            "                      'is_visible': False},",
            "        'cidr': {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': ATTR_NOT_SPECIFIED,",
            "                 'validate': {'type:subnet_or_none': None},",
            "                 'required_by_policy': False,",
            "                 'is_visible': True},",
            "        'gateway_ip': {'allow_post': True, 'allow_put': True,",
            "                       'default': ATTR_NOT_SPECIFIED,",
            "                       'validate': {'type:ip_address_or_none': None},",
            "                       'is_visible': True},",
            "        'allocation_pools': {'allow_post': True, 'allow_put': True,",
            "                             'default': ATTR_NOT_SPECIFIED,",
            "                             'validate': {'type:ip_pools': None},",
            "                             'is_visible': True},",
            "        'dns_nameservers': {'allow_post': True, 'allow_put': True,",
            "                            'convert_to': convert_none_to_empty_list,",
            "                            'default': ATTR_NOT_SPECIFIED,",
            "                            'validate': {'type:nameservers': None},",
            "                            'is_visible': True},",
            "        'host_routes': {'allow_post': True, 'allow_put': True,",
            "                        'convert_to': convert_none_to_empty_list,",
            "                        'default': ATTR_NOT_SPECIFIED,",
            "                        'validate': {'type:hostroutes': None},",
            "                        'is_visible': True},",
            "        'tenant_id': {'allow_post': True, 'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'enable_dhcp': {'allow_post': True, 'allow_put': True,",
            "                        'default': True,",
            "                        'convert_to': convert_to_boolean,",
            "                        'is_visible': True},",
            "        'ipv6_ra_mode': {'allow_post': True, 'allow_put': False,",
            "                         'default': ATTR_NOT_SPECIFIED,",
            "                         'validate': {'type:values': constants.IPV6_MODES},",
            "                         'is_visible': True},",
            "        'ipv6_address_mode': {'allow_post': True, 'allow_put': False,",
            "                              'default': ATTR_NOT_SPECIFIED,",
            "                              'validate': {'type:values':",
            "                                           constants.IPV6_MODES},",
            "                              'is_visible': True},",
            "        SHARED: {'allow_post': False,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': False,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    },",
            "    SUBNETPOOLS: {",
            "        'id': {'allow_post': False,",
            "               'allow_put': False,",
            "               'validate': {'type:uuid': None},",
            "               'is_visible': True,",
            "               'primary_key': True},",
            "        'name': {'allow_post': True,",
            "                 'allow_put': True,",
            "                 'validate': {'type:not_empty_string': None},",
            "                 'is_visible': True},",
            "        'tenant_id': {'allow_post': True,",
            "                      'allow_put': False,",
            "                      'validate': {'type:string': TENANT_ID_MAX_LEN},",
            "                      'required_by_policy': True,",
            "                      'is_visible': True},",
            "        'prefixes': {'allow_post': True,",
            "                     'allow_put': True,",
            "                     'validate': {'type:subnet_list': None},",
            "                     'is_visible': True},",
            "        'default_quota': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'is_visible': True},",
            "        'ip_version': {'allow_post': False,",
            "                       'allow_put': False,",
            "                       'is_visible': True},",
            "        'default_prefixlen': {'allow_post': True,",
            "                              'allow_put': True,",
            "                              'validate': {'type:non_negative': None},",
            "                              'convert_to': convert_to_int,",
            "                              'default': ATTR_NOT_SPECIFIED,",
            "                              'is_visible': True},",
            "        'min_prefixlen': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'is_visible': True},",
            "        'max_prefixlen': {'allow_post': True,",
            "                          'allow_put': True,",
            "                          'default': ATTR_NOT_SPECIFIED,",
            "                          'validate': {'type:non_negative': None},",
            "                          'convert_to': convert_to_int,",
            "                          'is_visible': True},",
            "        SHARED: {'allow_post': True,",
            "                 'allow_put': False,",
            "                 'default': False,",
            "                 'convert_to': convert_to_boolean,",
            "                 'is_visible': True,",
            "                 'required_by_policy': True,",
            "                 'enforce_policy': True},",
            "    }",
            "}",
            "",
            "# Identify the attribute used by a resource to reference another resource",
            "",
            "RESOURCE_FOREIGN_KEYS = {",
            "    NETWORKS: 'network_id'",
            "}",
            "",
            "PLURALS = {NETWORKS: NETWORK,",
            "           PORTS: PORT,",
            "           SUBNETS: SUBNET,",
            "           SUBNETPOOLS: SUBNETPOOL,",
            "           'dns_nameservers': 'dns_nameserver',",
            "           'host_routes': 'host_route',",
            "           'allocation_pools': 'allocation_pool',",
            "           'fixed_ips': 'fixed_ip',",
            "           'extensions': 'extension'}",
            "",
            "",
            "def fill_default_value(attr_info, res_dict,",
            "                       exc_cls=ValueError,",
            "                       check_allow_post=True):",
            "    for attr, attr_vals in six.iteritems(attr_info):",
            "        if attr_vals['allow_post']:",
            "            if ('default' not in attr_vals and",
            "                attr not in res_dict):",
            "                msg = _(\"Failed to parse request. Required \"",
            "                        \"attribute '%s' not specified\") % attr",
            "                raise exc_cls(msg)",
            "            res_dict[attr] = res_dict.get(attr,",
            "                                          attr_vals.get('default'))",
            "        elif check_allow_post:",
            "            if attr in res_dict:",
            "                msg = _(\"Attribute '%s' not allowed in POST\") % attr",
            "                raise exc_cls(msg)",
            "",
            "",
            "def convert_value(attr_info, res_dict, exc_cls=ValueError):",
            "    for attr, attr_vals in six.iteritems(attr_info):",
            "        if (attr not in res_dict or",
            "            res_dict[attr] is ATTR_NOT_SPECIFIED):",
            "            continue",
            "        # Convert values if necessary",
            "        if 'convert_to' in attr_vals:",
            "            res_dict[attr] = attr_vals['convert_to'](res_dict[attr])",
            "        # Check that configured values are correct",
            "        if 'validate' not in attr_vals:",
            "            continue",
            "        for rule in attr_vals['validate']:",
            "            res = validators[rule](res_dict[attr], attr_vals['validate'][rule])",
            "            if res:",
            "                msg_dict = dict(attr=attr, reason=res)",
            "                msg = _(\"Invalid input for %(attr)s. \"",
            "                        \"Reason: %(reason)s.\") % msg_dict",
            "                raise exc_cls(msg)",
            "",
            "",
            "def populate_tenant_id(context, res_dict, attr_info, is_create):",
            "    if (('tenant_id' in res_dict and",
            "         res_dict['tenant_id'] != context.tenant_id and",
            "         not context.is_admin)):",
            "        msg = _(\"Specifying 'tenant_id' other than authenticated \"",
            "                \"tenant in request requires admin privileges\")",
            "        raise webob.exc.HTTPBadRequest(msg)",
            "",
            "    if is_create and 'tenant_id' not in res_dict:",
            "        if context.tenant_id:",
            "            res_dict['tenant_id'] = context.tenant_id",
            "        elif 'tenant_id' in attr_info:",
            "            msg = _(\"Running without keystone AuthN requires \"",
            "                    \"that tenant_id is specified\")",
            "            raise webob.exc.HTTPBadRequest(msg)",
            "",
            "",
            "def verify_attributes(res_dict, attr_info):",
            "    extra_keys = set(res_dict.keys()) - set(attr_info.keys())",
            "    if extra_keys:",
            "        msg = _(\"Unrecognized attribute(s) '%s'\") % ', '.join(extra_keys)",
            "        raise webob.exc.HTTPBadRequest(msg)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "734": []
        },
        "addLocation": []
    },
    "neutron/policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 290,
                "afterPatchRowNumber": 290,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 291,
                "afterPatchRowNumber": 291,
                "PatchRowcode": "         self.field = field"
            },
            "2": {
                "beforePatchRowNumber": 292,
                "afterPatchRowNumber": 292,
                "PatchRowcode": "         self.value = conv_func(value)"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 293,
                "PatchRowcode": "+        self.regex = re.compile(value[1:]) if value.startswith('~') else None"
            },
            "4": {
                "beforePatchRowNumber": 293,
                "afterPatchRowNumber": 294,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 294,
                "afterPatchRowNumber": 295,
                "PatchRowcode": "     def __call__(self, target_dict, cred_dict, enforcer):"
            },
            "6": {
                "beforePatchRowNumber": 295,
                "afterPatchRowNumber": 296,
                "PatchRowcode": "         target_value = target_dict.get(self.field)"
            },
            "7": {
                "beforePatchRowNumber": 299,
                "afterPatchRowNumber": 300,
                "PatchRowcode": "                       \"%(target_dict)s\","
            },
            "8": {
                "beforePatchRowNumber": 300,
                "afterPatchRowNumber": 301,
                "PatchRowcode": "                       {'field': self.field, 'target_dict': target_dict})"
            },
            "9": {
                "beforePatchRowNumber": 301,
                "afterPatchRowNumber": 302,
                "PatchRowcode": "             return False"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 303,
                "PatchRowcode": "+        if self.regex:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+            return bool(self.regex.match(target_value))"
            },
            "12": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": 305,
                "PatchRowcode": "         return target_value == self.value"
            },
            "13": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 306,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 304,
                "afterPatchRowNumber": 307,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"",
            "Policy engine for neutron.  Largely copied from nova.",
            "\"\"\"",
            "",
            "import collections",
            "import re",
            "",
            "from oslo_config import cfg",
            "from oslo_log import log as logging",
            "from oslo_policy import policy",
            "from oslo_utils import excutils",
            "from oslo_utils import importutils",
            "import six",
            "",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron.i18n import _LE, _LW",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "_ENFORCER = None",
            "ADMIN_CTX_POLICY = 'context_is_admin'",
            "ADVSVC_CTX_POLICY = 'context_is_advsvc'",
            "",
            "",
            "def reset():",
            "    global _ENFORCER",
            "    if _ENFORCER:",
            "        _ENFORCER.clear()",
            "        _ENFORCER = None",
            "",
            "",
            "def init(conf=cfg.CONF, policy_file=None):",
            "    \"\"\"Init an instance of the Enforcer class.\"\"\"",
            "",
            "    global _ENFORCER",
            "    if not _ENFORCER:",
            "        _ENFORCER = policy.Enforcer(conf, policy_file=policy_file)",
            "        _ENFORCER.load_rules(True)",
            "",
            "",
            "def refresh(policy_file=None):",
            "    \"\"\"Reset policy and init a new instance of Enforcer.\"\"\"",
            "    reset()",
            "    init(policy_file=policy_file)",
            "",
            "",
            "def get_resource_and_action(action, pluralized=None):",
            "    \"\"\"Extract resource and action (write, read) from api operation.\"\"\"",
            "    data = action.split(':', 1)[0].split('_', 1)",
            "    resource = pluralized or (\"%ss\" % data[-1])",
            "    return (resource, data[0] != 'get')",
            "",
            "",
            "def set_rules(policies, overwrite=True):",
            "    \"\"\"Set rules based on the provided dict of rules.",
            "",
            "    :param policies: New policies to use. It should be an instance of dict.",
            "    :param overwrite: Whether to overwrite current rules or update them",
            "                          with the new rules.",
            "    \"\"\"",
            "",
            "    LOG.debug(\"Loading policies from file: %s\", _ENFORCER.policy_path)",
            "    init()",
            "    _ENFORCER.set_rules(policies, overwrite)",
            "",
            "",
            "def _is_attribute_explicitly_set(attribute_name, resource, target, action):",
            "    \"\"\"Verify that an attribute is present and is explicitly set.\"\"\"",
            "    if 'update' in action:",
            "        # In the case of update, the function should not pay attention to a",
            "        # default value of an attribute, but check whether it was explicitly",
            "        # marked as being updated instead.",
            "        return (attribute_name in target[const.ATTRIBUTES_TO_UPDATE] and",
            "                target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED)",
            "    return ('default' in resource[attribute_name] and",
            "            attribute_name in target and",
            "            target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED and",
            "            target[attribute_name] != resource[attribute_name]['default'])",
            "",
            "",
            "def _should_validate_sub_attributes(attribute, sub_attr):",
            "    \"\"\"Verify that sub-attributes are iterable and should be validated.\"\"\"",
            "    validate = attribute.get('validate')",
            "    return (validate and isinstance(sub_attr, collections.Iterable) and",
            "            any([k.startswith('type:dict') and",
            "                 v for (k, v) in six.iteritems(validate)]))",
            "",
            "",
            "def _build_subattr_match_rule(attr_name, attr, action, target):",
            "    \"\"\"Create the rule to match for sub-attribute policy checks.\"\"\"",
            "    # TODO(salv-orlando): Instead of relying on validator info, introduce",
            "    # typing for API attributes",
            "    # Expect a dict as type descriptor",
            "    validate = attr['validate']",
            "    key = list(filter(lambda k: k.startswith('type:dict'), validate.keys()))",
            "    if not key:",
            "        LOG.warn(_LW(\"Unable to find data type descriptor for attribute %s\"),",
            "                 attr_name)",
            "        return",
            "    data = validate[key[0]]",
            "    if not isinstance(data, dict):",
            "        LOG.debug(\"Attribute type descriptor is not a dict. Unable to \"",
            "                  \"generate any sub-attr policy rule for %s.\",",
            "                  attr_name)",
            "        return",
            "    sub_attr_rules = [policy.RuleCheck('rule', '%s:%s:%s' %",
            "                                       (action, attr_name,",
            "                                        sub_attr_name)) for",
            "                      sub_attr_name in data if sub_attr_name in",
            "                      target[attr_name]]",
            "    return policy.AndCheck(sub_attr_rules)",
            "",
            "",
            "def _process_rules_list(rules, match_rule):",
            "    \"\"\"Recursively walk a policy rule to extract a list of match entries.\"\"\"",
            "    if isinstance(match_rule, policy.RuleCheck):",
            "        rules.append(match_rule.match)",
            "    elif isinstance(match_rule, policy.AndCheck):",
            "        for rule in match_rule.rules:",
            "            _process_rules_list(rules, rule)",
            "    return rules",
            "",
            "",
            "def _build_match_rule(action, target, pluralized):",
            "    \"\"\"Create the rule to match for a given action.",
            "",
            "    The policy rule to be matched is built in the following way:",
            "    1) add entries for matching permission on objects",
            "    2) add an entry for the specific action (e.g.: create_network)",
            "    3) add an entry for attributes of a resource for which the action",
            "       is being executed (e.g.: create_network:shared)",
            "    4) add an entry for sub-attributes of a resource for which the",
            "       action is being executed",
            "       (e.g.: create_router:external_gateway_info:network_id)",
            "    \"\"\"",
            "    match_rule = policy.RuleCheck('rule', action)",
            "    resource, is_write = get_resource_and_action(action, pluralized)",
            "    # Attribute-based checks shall not be enforced on GETs",
            "    if is_write:",
            "        # assigning to variable with short name for improving readability",
            "        res_map = attributes.RESOURCE_ATTRIBUTE_MAP",
            "        if resource in res_map:",
            "            for attribute_name in res_map[resource]:",
            "                if _is_attribute_explicitly_set(attribute_name,",
            "                                                res_map[resource],",
            "                                                target, action):",
            "                    attribute = res_map[resource][attribute_name]",
            "                    if 'enforce_policy' in attribute:",
            "                        attr_rule = policy.RuleCheck('rule', '%s:%s' %",
            "                                                     (action, attribute_name))",
            "                        # Build match entries for sub-attributes",
            "                        if _should_validate_sub_attributes(",
            "                                attribute, target[attribute_name]):",
            "                            attr_rule = policy.AndCheck(",
            "                                [attr_rule, _build_subattr_match_rule(",
            "                                    attribute_name, attribute,",
            "                                    action, target)])",
            "                        match_rule = policy.AndCheck([match_rule, attr_rule])",
            "    return match_rule",
            "",
            "",
            "# This check is registered as 'tenant_id' so that it can override",
            "# GenericCheck which was used for validating parent resource ownership.",
            "# This will prevent us from having to handling backward compatibility",
            "# for policy.json",
            "# TODO(salv-orlando): Reinstate GenericCheck for simple tenant_id checks",
            "@policy.register('tenant_id')",
            "class OwnerCheck(policy.Check):",
            "    \"\"\"Resource ownership check.",
            "",
            "    This check verifies the owner of the current resource, or of another",
            "    resource referenced by the one under analysis.",
            "    In the former case it falls back to a regular GenericCheck, whereas",
            "    in the latter case it leverages the plugin to load the referenced",
            "    resource and perform the check.",
            "    \"\"\"",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        try:",
            "            self.target_field = re.findall(r'^\\%\\((.*)\\)s$',",
            "                                           match)[0]",
            "        except IndexError:",
            "            err_reason = (_(\"Unable to identify a target field from:%s. \"",
            "                            \"Match should be in the form %%(<field_name>)s\") %",
            "                          match)",
            "            LOG.exception(err_reason)",
            "            raise exceptions.PolicyInitError(",
            "                policy=\"%s:%s\" % (kind, match),",
            "                reason=err_reason)",
            "        super(OwnerCheck, self).__init__(kind, match)",
            "",
            "    def __call__(self, target, creds, enforcer):",
            "        if self.target_field not in target:",
            "            # policy needs a plugin check",
            "            # target field is in the form resource:field",
            "            # however if they're not separated by a colon, use an underscore",
            "            # as a separator for backward compatibility",
            "",
            "            def do_split(separator):",
            "                parent_res, parent_field = self.target_field.split(",
            "                    separator, 1)",
            "                return parent_res, parent_field",
            "",
            "            for separator in (':', '_'):",
            "                try:",
            "                    parent_res, parent_field = do_split(separator)",
            "                    break",
            "                except ValueError:",
            "                    LOG.debug(\"Unable to find ':' as separator in %s.\",",
            "                              self.target_field)",
            "            else:",
            "                # If we are here split failed with both separators",
            "                err_reason = (_(\"Unable to find resource name in %s\") %",
            "                              self.target_field)",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            parent_foreign_key = attributes.RESOURCE_FOREIGN_KEYS.get(",
            "                \"%ss\" % parent_res, None)",
            "            if not parent_foreign_key:",
            "                err_reason = (_(\"Unable to verify match:%(match)s as the \"",
            "                                \"parent resource: %(res)s was not found\") %",
            "                              {'match': self.match, 'res': parent_res})",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            # NOTE(salv-orlando): This check currently assumes the parent",
            "            # resource is handled by the core plugin. It might be worth",
            "            # having a way to map resources to plugins so to make this",
            "            # check more general",
            "            # NOTE(ihrachys): if import is put in global, circular",
            "            # import failure occurs",
            "            manager = importutils.import_module('neutron.manager')",
            "            f = getattr(manager.NeutronManager.get_instance().plugin,",
            "                        'get_%s' % parent_res)",
            "            # f *must* exist, if not found it is better to let neutron",
            "            # explode. Check will be performed with admin context",
            "            context = importutils.import_module('neutron.context')",
            "            try:",
            "                data = f(context.get_admin_context(),",
            "                         target[parent_foreign_key],",
            "                         fields=[parent_field])",
            "                target[self.target_field] = data[parent_field]",
            "            except Exception:",
            "                with excutils.save_and_reraise_exception():",
            "                    LOG.exception(_LE('Policy check error while calling %s!'),",
            "                                  f)",
            "        match = self.match % target",
            "        if self.kind in creds:",
            "            return match == six.text_type(creds[self.kind])",
            "        return False",
            "",
            "",
            "@policy.register('field')",
            "class FieldCheck(policy.Check):",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        resource, field_value = match.split(':', 1)",
            "        field, value = field_value.split('=', 1)",
            "",
            "        super(FieldCheck, self).__init__(kind, '%s:%s:%s' %",
            "                                         (resource, field, value))",
            "",
            "        # Value might need conversion - we need help from the attribute map",
            "        try:",
            "            attr = attributes.RESOURCE_ATTRIBUTE_MAP[resource][field]",
            "            conv_func = attr['convert_to']",
            "        except KeyError:",
            "            conv_func = lambda x: x",
            "",
            "        self.field = field",
            "        self.value = conv_func(value)",
            "",
            "    def __call__(self, target_dict, cred_dict, enforcer):",
            "        target_value = target_dict.get(self.field)",
            "        # target_value might be a boolean, explicitly compare with None",
            "        if target_value is None:",
            "            LOG.debug(\"Unable to find requested field: %(field)s in target: \"",
            "                      \"%(target_dict)s\",",
            "                      {'field': self.field, 'target_dict': target_dict})",
            "            return False",
            "        return target_value == self.value",
            "",
            "",
            "def _prepare_check(context, action, target, pluralized):",
            "    \"\"\"Prepare rule, target, and credentials for the policy engine.\"\"\"",
            "    # Compare with None to distinguish case in which target is {}",
            "    if target is None:",
            "        target = {}",
            "    match_rule = _build_match_rule(action, target, pluralized)",
            "    credentials = context.to_dict()",
            "    return match_rule, target, credentials",
            "",
            "",
            "def log_rule_list(match_rule):",
            "    if LOG.isEnabledFor(logging.DEBUG):",
            "        rules = _process_rules_list([], match_rule)",
            "        LOG.debug(\"Enforcing rules: %s\", rules)",
            "",
            "",
            "def check(context, action, target, plugin=None, might_not_exist=False,",
            "          pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param might_not_exist: If True the policy check is skipped (and the",
            "        function returns True) if the specified policy does not exist.",
            "        Defaults to false.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :return: Returns True if access is permitted else False.",
            "    \"\"\"",
            "    # If we already know the context has admin rights do not perform an",
            "    # additional check and authorize the operation",
            "    if context.is_admin:",
            "        return True",
            "    if might_not_exist and not (_ENFORCER.rules and action in _ENFORCER.rules):",
            "        return True",
            "    match_rule, target, credentials = _prepare_check(context,",
            "                                                     action,",
            "                                                     target,",
            "                                                     pluralized)",
            "    result = _ENFORCER.enforce(match_rule,",
            "                               target,",
            "                               credentials,",
            "                               pluralized=pluralized)",
            "    # logging applied rules in case of failure",
            "    if not result:",
            "        log_rule_list(match_rule)",
            "    return result",
            "",
            "",
            "def enforce(context, action, target, plugin=None, pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :raises oslo_policy.policy.PolicyNotAuthorized:",
            "            if verification fails.",
            "    \"\"\"",
            "    # If we already know the context has admin rights do not perform an",
            "    # additional check and authorize the operation",
            "    if context.is_admin:",
            "        return True",
            "    rule, target, credentials = _prepare_check(context,",
            "                                               action,",
            "                                               target,",
            "                                               pluralized)",
            "    try:",
            "        result = _ENFORCER.enforce(rule, target, credentials, action=action,",
            "                                   do_raise=True)",
            "    except policy.PolicyNotAuthorized:",
            "        with excutils.save_and_reraise_exception():",
            "            log_rule_list(rule)",
            "            LOG.debug(\"Failed policy check for '%s'\", action)",
            "    return result",
            "",
            "",
            "def check_is_admin(context):",
            "    \"\"\"Verify context has admin rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    if ADMIN_CTX_POLICY not in _ENFORCER.rules:",
            "        return False",
            "    return _ENFORCER.enforce(ADMIN_CTX_POLICY, credentials, credentials)",
            "",
            "",
            "def check_is_advsvc(context):",
            "    \"\"\"Verify context has advsvc rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    if ADVSVC_CTX_POLICY not in _ENFORCER.rules:",
            "        return False",
            "    return _ENFORCER.enforce(ADVSVC_CTX_POLICY, credentials, credentials)",
            "",
            "",
            "def _extract_roles(rule, roles):",
            "    if isinstance(rule, policy.RoleCheck):",
            "        roles.append(rule.match.lower())",
            "    elif isinstance(rule, policy.RuleCheck):",
            "        _extract_roles(_ENFORCER.rules[rule.match], roles)",
            "    elif hasattr(rule, 'rules'):",
            "        for rule in rule.rules:",
            "            _extract_roles(rule, roles)"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "# All Rights Reserved.",
            "#",
            "#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may",
            "#    not use this file except in compliance with the License. You may obtain",
            "#    a copy of the License at",
            "#",
            "#         http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "#    Unless required by applicable law or agreed to in writing, software",
            "#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT",
            "#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the",
            "#    License for the specific language governing permissions and limitations",
            "#    under the License.",
            "",
            "\"\"\"",
            "Policy engine for neutron.  Largely copied from nova.",
            "\"\"\"",
            "",
            "import collections",
            "import re",
            "",
            "from oslo_config import cfg",
            "from oslo_log import log as logging",
            "from oslo_policy import policy",
            "from oslo_utils import excutils",
            "from oslo_utils import importutils",
            "import six",
            "",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron.i18n import _LE, _LW",
            "",
            "",
            "LOG = logging.getLogger(__name__)",
            "",
            "_ENFORCER = None",
            "ADMIN_CTX_POLICY = 'context_is_admin'",
            "ADVSVC_CTX_POLICY = 'context_is_advsvc'",
            "",
            "",
            "def reset():",
            "    global _ENFORCER",
            "    if _ENFORCER:",
            "        _ENFORCER.clear()",
            "        _ENFORCER = None",
            "",
            "",
            "def init(conf=cfg.CONF, policy_file=None):",
            "    \"\"\"Init an instance of the Enforcer class.\"\"\"",
            "",
            "    global _ENFORCER",
            "    if not _ENFORCER:",
            "        _ENFORCER = policy.Enforcer(conf, policy_file=policy_file)",
            "        _ENFORCER.load_rules(True)",
            "",
            "",
            "def refresh(policy_file=None):",
            "    \"\"\"Reset policy and init a new instance of Enforcer.\"\"\"",
            "    reset()",
            "    init(policy_file=policy_file)",
            "",
            "",
            "def get_resource_and_action(action, pluralized=None):",
            "    \"\"\"Extract resource and action (write, read) from api operation.\"\"\"",
            "    data = action.split(':', 1)[0].split('_', 1)",
            "    resource = pluralized or (\"%ss\" % data[-1])",
            "    return (resource, data[0] != 'get')",
            "",
            "",
            "def set_rules(policies, overwrite=True):",
            "    \"\"\"Set rules based on the provided dict of rules.",
            "",
            "    :param policies: New policies to use. It should be an instance of dict.",
            "    :param overwrite: Whether to overwrite current rules or update them",
            "                          with the new rules.",
            "    \"\"\"",
            "",
            "    LOG.debug(\"Loading policies from file: %s\", _ENFORCER.policy_path)",
            "    init()",
            "    _ENFORCER.set_rules(policies, overwrite)",
            "",
            "",
            "def _is_attribute_explicitly_set(attribute_name, resource, target, action):",
            "    \"\"\"Verify that an attribute is present and is explicitly set.\"\"\"",
            "    if 'update' in action:",
            "        # In the case of update, the function should not pay attention to a",
            "        # default value of an attribute, but check whether it was explicitly",
            "        # marked as being updated instead.",
            "        return (attribute_name in target[const.ATTRIBUTES_TO_UPDATE] and",
            "                target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED)",
            "    return ('default' in resource[attribute_name] and",
            "            attribute_name in target and",
            "            target[attribute_name] is not attributes.ATTR_NOT_SPECIFIED and",
            "            target[attribute_name] != resource[attribute_name]['default'])",
            "",
            "",
            "def _should_validate_sub_attributes(attribute, sub_attr):",
            "    \"\"\"Verify that sub-attributes are iterable and should be validated.\"\"\"",
            "    validate = attribute.get('validate')",
            "    return (validate and isinstance(sub_attr, collections.Iterable) and",
            "            any([k.startswith('type:dict') and",
            "                 v for (k, v) in six.iteritems(validate)]))",
            "",
            "",
            "def _build_subattr_match_rule(attr_name, attr, action, target):",
            "    \"\"\"Create the rule to match for sub-attribute policy checks.\"\"\"",
            "    # TODO(salv-orlando): Instead of relying on validator info, introduce",
            "    # typing for API attributes",
            "    # Expect a dict as type descriptor",
            "    validate = attr['validate']",
            "    key = list(filter(lambda k: k.startswith('type:dict'), validate.keys()))",
            "    if not key:",
            "        LOG.warn(_LW(\"Unable to find data type descriptor for attribute %s\"),",
            "                 attr_name)",
            "        return",
            "    data = validate[key[0]]",
            "    if not isinstance(data, dict):",
            "        LOG.debug(\"Attribute type descriptor is not a dict. Unable to \"",
            "                  \"generate any sub-attr policy rule for %s.\",",
            "                  attr_name)",
            "        return",
            "    sub_attr_rules = [policy.RuleCheck('rule', '%s:%s:%s' %",
            "                                       (action, attr_name,",
            "                                        sub_attr_name)) for",
            "                      sub_attr_name in data if sub_attr_name in",
            "                      target[attr_name]]",
            "    return policy.AndCheck(sub_attr_rules)",
            "",
            "",
            "def _process_rules_list(rules, match_rule):",
            "    \"\"\"Recursively walk a policy rule to extract a list of match entries.\"\"\"",
            "    if isinstance(match_rule, policy.RuleCheck):",
            "        rules.append(match_rule.match)",
            "    elif isinstance(match_rule, policy.AndCheck):",
            "        for rule in match_rule.rules:",
            "            _process_rules_list(rules, rule)",
            "    return rules",
            "",
            "",
            "def _build_match_rule(action, target, pluralized):",
            "    \"\"\"Create the rule to match for a given action.",
            "",
            "    The policy rule to be matched is built in the following way:",
            "    1) add entries for matching permission on objects",
            "    2) add an entry for the specific action (e.g.: create_network)",
            "    3) add an entry for attributes of a resource for which the action",
            "       is being executed (e.g.: create_network:shared)",
            "    4) add an entry for sub-attributes of a resource for which the",
            "       action is being executed",
            "       (e.g.: create_router:external_gateway_info:network_id)",
            "    \"\"\"",
            "    match_rule = policy.RuleCheck('rule', action)",
            "    resource, is_write = get_resource_and_action(action, pluralized)",
            "    # Attribute-based checks shall not be enforced on GETs",
            "    if is_write:",
            "        # assigning to variable with short name for improving readability",
            "        res_map = attributes.RESOURCE_ATTRIBUTE_MAP",
            "        if resource in res_map:",
            "            for attribute_name in res_map[resource]:",
            "                if _is_attribute_explicitly_set(attribute_name,",
            "                                                res_map[resource],",
            "                                                target, action):",
            "                    attribute = res_map[resource][attribute_name]",
            "                    if 'enforce_policy' in attribute:",
            "                        attr_rule = policy.RuleCheck('rule', '%s:%s' %",
            "                                                     (action, attribute_name))",
            "                        # Build match entries for sub-attributes",
            "                        if _should_validate_sub_attributes(",
            "                                attribute, target[attribute_name]):",
            "                            attr_rule = policy.AndCheck(",
            "                                [attr_rule, _build_subattr_match_rule(",
            "                                    attribute_name, attribute,",
            "                                    action, target)])",
            "                        match_rule = policy.AndCheck([match_rule, attr_rule])",
            "    return match_rule",
            "",
            "",
            "# This check is registered as 'tenant_id' so that it can override",
            "# GenericCheck which was used for validating parent resource ownership.",
            "# This will prevent us from having to handling backward compatibility",
            "# for policy.json",
            "# TODO(salv-orlando): Reinstate GenericCheck for simple tenant_id checks",
            "@policy.register('tenant_id')",
            "class OwnerCheck(policy.Check):",
            "    \"\"\"Resource ownership check.",
            "",
            "    This check verifies the owner of the current resource, or of another",
            "    resource referenced by the one under analysis.",
            "    In the former case it falls back to a regular GenericCheck, whereas",
            "    in the latter case it leverages the plugin to load the referenced",
            "    resource and perform the check.",
            "    \"\"\"",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        try:",
            "            self.target_field = re.findall(r'^\\%\\((.*)\\)s$',",
            "                                           match)[0]",
            "        except IndexError:",
            "            err_reason = (_(\"Unable to identify a target field from:%s. \"",
            "                            \"Match should be in the form %%(<field_name>)s\") %",
            "                          match)",
            "            LOG.exception(err_reason)",
            "            raise exceptions.PolicyInitError(",
            "                policy=\"%s:%s\" % (kind, match),",
            "                reason=err_reason)",
            "        super(OwnerCheck, self).__init__(kind, match)",
            "",
            "    def __call__(self, target, creds, enforcer):",
            "        if self.target_field not in target:",
            "            # policy needs a plugin check",
            "            # target field is in the form resource:field",
            "            # however if they're not separated by a colon, use an underscore",
            "            # as a separator for backward compatibility",
            "",
            "            def do_split(separator):",
            "                parent_res, parent_field = self.target_field.split(",
            "                    separator, 1)",
            "                return parent_res, parent_field",
            "",
            "            for separator in (':', '_'):",
            "                try:",
            "                    parent_res, parent_field = do_split(separator)",
            "                    break",
            "                except ValueError:",
            "                    LOG.debug(\"Unable to find ':' as separator in %s.\",",
            "                              self.target_field)",
            "            else:",
            "                # If we are here split failed with both separators",
            "                err_reason = (_(\"Unable to find resource name in %s\") %",
            "                              self.target_field)",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            parent_foreign_key = attributes.RESOURCE_FOREIGN_KEYS.get(",
            "                \"%ss\" % parent_res, None)",
            "            if not parent_foreign_key:",
            "                err_reason = (_(\"Unable to verify match:%(match)s as the \"",
            "                                \"parent resource: %(res)s was not found\") %",
            "                              {'match': self.match, 'res': parent_res})",
            "                LOG.exception(err_reason)",
            "                raise exceptions.PolicyCheckError(",
            "                    policy=\"%s:%s\" % (self.kind, self.match),",
            "                    reason=err_reason)",
            "            # NOTE(salv-orlando): This check currently assumes the parent",
            "            # resource is handled by the core plugin. It might be worth",
            "            # having a way to map resources to plugins so to make this",
            "            # check more general",
            "            # NOTE(ihrachys): if import is put in global, circular",
            "            # import failure occurs",
            "            manager = importutils.import_module('neutron.manager')",
            "            f = getattr(manager.NeutronManager.get_instance().plugin,",
            "                        'get_%s' % parent_res)",
            "            # f *must* exist, if not found it is better to let neutron",
            "            # explode. Check will be performed with admin context",
            "            context = importutils.import_module('neutron.context')",
            "            try:",
            "                data = f(context.get_admin_context(),",
            "                         target[parent_foreign_key],",
            "                         fields=[parent_field])",
            "                target[self.target_field] = data[parent_field]",
            "            except Exception:",
            "                with excutils.save_and_reraise_exception():",
            "                    LOG.exception(_LE('Policy check error while calling %s!'),",
            "                                  f)",
            "        match = self.match % target",
            "        if self.kind in creds:",
            "            return match == six.text_type(creds[self.kind])",
            "        return False",
            "",
            "",
            "@policy.register('field')",
            "class FieldCheck(policy.Check):",
            "    def __init__(self, kind, match):",
            "        # Process the match",
            "        resource, field_value = match.split(':', 1)",
            "        field, value = field_value.split('=', 1)",
            "",
            "        super(FieldCheck, self).__init__(kind, '%s:%s:%s' %",
            "                                         (resource, field, value))",
            "",
            "        # Value might need conversion - we need help from the attribute map",
            "        try:",
            "            attr = attributes.RESOURCE_ATTRIBUTE_MAP[resource][field]",
            "            conv_func = attr['convert_to']",
            "        except KeyError:",
            "            conv_func = lambda x: x",
            "",
            "        self.field = field",
            "        self.value = conv_func(value)",
            "        self.regex = re.compile(value[1:]) if value.startswith('~') else None",
            "",
            "    def __call__(self, target_dict, cred_dict, enforcer):",
            "        target_value = target_dict.get(self.field)",
            "        # target_value might be a boolean, explicitly compare with None",
            "        if target_value is None:",
            "            LOG.debug(\"Unable to find requested field: %(field)s in target: \"",
            "                      \"%(target_dict)s\",",
            "                      {'field': self.field, 'target_dict': target_dict})",
            "            return False",
            "        if self.regex:",
            "            return bool(self.regex.match(target_value))",
            "        return target_value == self.value",
            "",
            "",
            "def _prepare_check(context, action, target, pluralized):",
            "    \"\"\"Prepare rule, target, and credentials for the policy engine.\"\"\"",
            "    # Compare with None to distinguish case in which target is {}",
            "    if target is None:",
            "        target = {}",
            "    match_rule = _build_match_rule(action, target, pluralized)",
            "    credentials = context.to_dict()",
            "    return match_rule, target, credentials",
            "",
            "",
            "def log_rule_list(match_rule):",
            "    if LOG.isEnabledFor(logging.DEBUG):",
            "        rules = _process_rules_list([], match_rule)",
            "        LOG.debug(\"Enforcing rules: %s\", rules)",
            "",
            "",
            "def check(context, action, target, plugin=None, might_not_exist=False,",
            "          pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param might_not_exist: If True the policy check is skipped (and the",
            "        function returns True) if the specified policy does not exist.",
            "        Defaults to false.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :return: Returns True if access is permitted else False.",
            "    \"\"\"",
            "    # If we already know the context has admin rights do not perform an",
            "    # additional check and authorize the operation",
            "    if context.is_admin:",
            "        return True",
            "    if might_not_exist and not (_ENFORCER.rules and action in _ENFORCER.rules):",
            "        return True",
            "    match_rule, target, credentials = _prepare_check(context,",
            "                                                     action,",
            "                                                     target,",
            "                                                     pluralized)",
            "    result = _ENFORCER.enforce(match_rule,",
            "                               target,",
            "                               credentials,",
            "                               pluralized=pluralized)",
            "    # logging applied rules in case of failure",
            "    if not result:",
            "        log_rule_list(match_rule)",
            "    return result",
            "",
            "",
            "def enforce(context, action, target, plugin=None, pluralized=None):",
            "    \"\"\"Verifies that the action is valid on the target in this context.",
            "",
            "    :param context: neutron context",
            "    :param action: string representing the action to be checked",
            "        this should be colon separated for clarity.",
            "    :param target: dictionary representing the object of the action",
            "        for object creation this should be a dictionary representing the",
            "        location of the object e.g. ``{'project_id': context.project_id}``",
            "    :param plugin: currently unused and deprecated.",
            "        Kept for backward compatibility.",
            "    :param pluralized: pluralized case of resource",
            "        e.g. firewall_policy -> pluralized = \"firewall_policies\"",
            "",
            "    :raises oslo_policy.policy.PolicyNotAuthorized:",
            "            if verification fails.",
            "    \"\"\"",
            "    # If we already know the context has admin rights do not perform an",
            "    # additional check and authorize the operation",
            "    if context.is_admin:",
            "        return True",
            "    rule, target, credentials = _prepare_check(context,",
            "                                               action,",
            "                                               target,",
            "                                               pluralized)",
            "    try:",
            "        result = _ENFORCER.enforce(rule, target, credentials, action=action,",
            "                                   do_raise=True)",
            "    except policy.PolicyNotAuthorized:",
            "        with excutils.save_and_reraise_exception():",
            "            log_rule_list(rule)",
            "            LOG.debug(\"Failed policy check for '%s'\", action)",
            "    return result",
            "",
            "",
            "def check_is_admin(context):",
            "    \"\"\"Verify context has admin rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    if ADMIN_CTX_POLICY not in _ENFORCER.rules:",
            "        return False",
            "    return _ENFORCER.enforce(ADMIN_CTX_POLICY, credentials, credentials)",
            "",
            "",
            "def check_is_advsvc(context):",
            "    \"\"\"Verify context has advsvc rights according to policy settings.\"\"\"",
            "    init()",
            "    # the target is user-self",
            "    credentials = context.to_dict()",
            "    if ADVSVC_CTX_POLICY not in _ENFORCER.rules:",
            "        return False",
            "    return _ENFORCER.enforce(ADVSVC_CTX_POLICY, credentials, credentials)",
            "",
            "",
            "def _extract_roles(rule, roles):",
            "    if isinstance(rule, policy.RoleCheck):",
            "        roles.append(rule.match.lower())",
            "    elif isinstance(rule, policy.RuleCheck):",
            "        _extract_roles(_ENFORCER.rules[rule.match], roles)",
            "    elif hasattr(rule, 'rules'):",
            "        for rule in rule.rules:",
            "            _extract_roles(rule, roles)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "neutron.policy.FieldCheck",
            "neutron.policy.FieldCheck.__init__.conv_func",
            "jinja2.nodes.Const.from_untrusted"
        ]
    },
    "neutron/tests/unit/test_policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 241,
                "PatchRowcode": "             \"regular_user\": \"role:user\","
            },
            "1": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "             \"shared\": \"field:networks:shared=True\","
            },
            "2": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 243,
                "PatchRowcode": "             \"external\": \"field:networks:router:external=True\","
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+            \"network_device\": \"field:port:device_owner=~^network:\","
            },
            "4": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 245,
                "PatchRowcode": "             \"default\": '@',"
            },
            "5": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 246,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 247,
                "PatchRowcode": "             \"create_network\": \"rule:admin_or_owner\","
            },
            "7": {
                "beforePatchRowNumber": 252,
                "afterPatchRowNumber": 253,
                "PatchRowcode": "             \"create_subnet\": \"rule:admin_or_network_owner\","
            },
            "8": {
                "beforePatchRowNumber": 253,
                "afterPatchRowNumber": 254,
                "PatchRowcode": "             \"create_port:mac\": \"rule:admin_or_network_owner or \""
            },
            "9": {
                "beforePatchRowNumber": 254,
                "afterPatchRowNumber": 255,
                "PatchRowcode": "                                \"rule:context_is_advsvc\","
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 256,
                "PatchRowcode": "+            \"create_port:device_owner\": \"not rule:network_device\","
            },
            "11": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": 257,
                "PatchRowcode": "             \"update_port\": \"rule:admin_or_owner or rule:context_is_advsvc\","
            },
            "12": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": 258,
                "PatchRowcode": "             \"get_port\": \"rule:admin_or_owner or rule:context_is_advsvc\","
            },
            "13": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": 259,
                "PatchRowcode": "             \"delete_port\": \"rule:admin_or_owner or rule:context_is_advsvc\","
            },
            "14": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 332,
                "PatchRowcode": "         self._test_nonadmin_action_on_attr('create', 'shared', True,"
            },
            "15": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 333,
                "PatchRowcode": "                                            oslo_policy.PolicyNotAuthorized)"
            },
            "16": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 334,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 335,
                "PatchRowcode": "+    def test_create_port_device_owner_regex(self):"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 336,
                "PatchRowcode": "+        blocked_values = ('network:', 'network:abdef', 'network:dhcp',"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 337,
                "PatchRowcode": "+                          'network:router_interface')"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+        for val in blocked_values:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+            self._test_advsvc_action_on_attr("
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 340,
                "PatchRowcode": "+                'create', 'port', 'device_owner', val,"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+                oslo_policy.PolicyNotAuthorized"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+            )"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 343,
                "PatchRowcode": "+        ok_values = ('network', 'networks', 'my_network:test', 'my_network:')"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 344,
                "PatchRowcode": "+        for val in ok_values:"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+            self._test_advsvc_action_on_attr("
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+                'create', 'port', 'device_owner', val"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+            )"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 349,
                "PatchRowcode": "     def test_advsvc_get_network_works(self):"
            },
            "32": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 350,
                "PatchRowcode": "         self._test_advsvc_action_on_attr('get', 'network', 'shared', False)"
            },
            "33": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 351,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Test of Policy Engine For Neutron\"\"\"",
            "",
            "import mock",
            "from oslo_policy import policy as oslo_policy",
            "from oslo_serialization import jsonutils",
            "from oslo_utils import importutils",
            "import six",
            "import six.moves.urllib.request as urlrequest",
            "",
            "import neutron",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron import context",
            "from neutron import manager",
            "from neutron import policy",
            "from neutron.tests import base",
            "",
            "",
            "class PolicyFileTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyFileTestCase, self).setUp()",
            "        self.context = context.Context('fake', 'fake', is_admin=False)",
            "        self.target = {'tenant_id': 'fake'}",
            "",
            "    def test_modified_policy_reloads(self):",
            "        tmpfilename = self.get_temp_file_path('policy')",
            "        action = \"example:test\"",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"\"}\"\"\")",
            "        policy.refresh(policy_file=tmpfilename)",
            "        policy.enforce(self.context, action, self.target)",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"!\"}\"\"\")",
            "        policy.refresh(policy_file=tmpfilename)",
            "        self.target = {'tenant_id': 'fake_tenant'}",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized,",
            "                          policy.enforce,",
            "                          self.context,",
            "                          action,",
            "                          self.target)",
            "",
            "",
            "class PolicyTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyTestCase, self).setUp()",
            "        # NOTE(vish): preload rules to circumvent reloading from file",
            "        rules = {",
            "            \"true\": '@',",
            "            \"example:allowed\": '@',",
            "            \"example:denied\": '!',",
            "            \"example:get_http\": \"http:http://www.example.com\",",
            "            \"example:my_file\": \"role:compute_admin or tenant_id:%(tenant_id)s\",",
            "            \"example:early_and_fail\": \"! and @\",",
            "            \"example:early_or_success\": \"@ or !\",",
            "            \"example:lowercase_admin\": \"role:admin or role:sysadmin\",",
            "            \"example:uppercase_admin\": \"role:ADMIN or role:sysadmin\",",
            "        }",
            "        policy.refresh()",
            "        # NOTE(vish): then overload underlying rules",
            "        policy.set_rules(oslo_policy.Rules.from_dict(rules))",
            "        self.context = context.Context('fake', 'fake', roles=['member'])",
            "        self.target = {}",
            "",
            "    def test_enforce_nonexistent_action_throws(self):",
            "        action = \"example:noexist\"",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_enforce_bad_action_throws(self):",
            "        action = \"example:denied\"",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_check_bad_action_noraise(self):",
            "        action = \"example:denied\"",
            "        result = policy.check(self.context, action, self.target)",
            "        self.assertEqual(result, False)",
            "",
            "    def test_check_non_existent_action(self):",
            "        action = \"example:idonotexist\"",
            "        result_1 = policy.check(self.context, action, self.target)",
            "        self.assertFalse(result_1)",
            "        result_2 = policy.check(self.context, action, self.target,",
            "                                might_not_exist=True)",
            "        self.assertTrue(result_2)",
            "",
            "    def test_enforce_good_action(self):",
            "        action = \"example:allowed\"",
            "        result = policy.enforce(self.context, action, self.target)",
            "        self.assertEqual(result, True)",
            "",
            "    @mock.patch.object(urlrequest, 'urlopen',",
            "                       return_value=six.StringIO(\"True\"))",
            "    def test_enforce_http_true(self, mock_urlrequest):",
            "        action = \"example:get_http\"",
            "        target = {}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_http_false(self):",
            "",
            "        def fakeurlopen(url, post_data):",
            "            return six.StringIO(\"False\")",
            "",
            "        with mock.patch.object(urlrequest, 'urlopen', new=fakeurlopen):",
            "            action = \"example:get_http\"",
            "            target = {}",
            "            self.assertRaises(oslo_policy.PolicyNotAuthorized,",
            "                              policy.enforce, self.context,",
            "                              action, target)",
            "",
            "    def test_templatized_enforcement(self):",
            "        target_mine = {'tenant_id': 'fake'}",
            "        target_not_mine = {'tenant_id': 'another'}",
            "        action = \"example:my_file\"",
            "        policy.enforce(self.context, action, target_mine)",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target_not_mine)",
            "",
            "    def test_early_AND_enforcement(self):",
            "        action = \"example:early_and_fail\"",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_early_OR_enforcement(self):",
            "        action = \"example:early_or_success\"",
            "        policy.enforce(self.context, action, self.target)",
            "",
            "    def test_ignore_case_role_check(self):",
            "        lowercase_action = \"example:lowercase_admin\"",
            "        uppercase_action = \"example:uppercase_admin\"",
            "        # NOTE(dprince) we mix case in the Admin role here to ensure",
            "        # case is ignored",
            "        admin_context = context.Context('admin', 'fake', roles=['AdMiN'])",
            "        policy.enforce(admin_context, lowercase_action, self.target)",
            "        policy.enforce(admin_context, uppercase_action, self.target)",
            "",
            "",
            "class DefaultPolicyTestCase(base.BaseTestCase):",
            "",
            "    def setUp(self):",
            "        super(DefaultPolicyTestCase, self).setUp()",
            "        tmpfilename = self.get_temp_file_path('policy.json')",
            "        self.rules = {",
            "            \"default\": '',",
            "            \"example:exist\": '!',",
            "        }",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            jsonutils.dump(self.rules, policyfile)",
            "        policy.refresh(policy_file=tmpfilename)",
            "",
            "        self.context = context.Context('fake', 'fake')",
            "",
            "    def test_policy_called(self):",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, \"example:exist\", {})",
            "",
            "    def test_not_found_policy_calls_default(self):",
            "        policy.enforce(self.context, \"example:noexist\", {})",
            "",
            "",
            "FAKE_RESOURCE_NAME = 'fake_resource'",
            "FAKE_SPECIAL_RESOURCE_NAME = 'fake_policy'",
            "FAKE_RESOURCES = {\"%ss\" % FAKE_RESOURCE_NAME:",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }},",
            "                  # special plural name",
            "                  \"%s\" % FAKE_SPECIAL_RESOURCE_NAME.replace('y', 'ies'):",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }}}",
            "",
            "",
            "class NeutronPolicyTestCase(base.BaseTestCase):",
            "",
            "    def fakepolicyinit(self, **kwargs):",
            "        enf = policy._ENFORCER",
            "        enf.set_rules(oslo_policy.Rules(self.rules))",
            "",
            "    def setUp(self):",
            "        super(NeutronPolicyTestCase, self).setUp()",
            "        policy.refresh()",
            "        # Add Fake resources to RESOURCE_ATTRIBUTE_MAP",
            "        attributes.RESOURCE_ATTRIBUTE_MAP.update(FAKE_RESOURCES)",
            "        self._set_rules()",
            "",
            "        def remove_fake_resource():",
            "            del attributes.RESOURCE_ATTRIBUTE_MAP[\"%ss\" % FAKE_RESOURCE_NAME]",
            "",
            "        self.patcher = mock.patch.object(neutron.policy,",
            "                                         'init',",
            "                                         new=self.fakepolicyinit)",
            "        self.patcher.start()",
            "        self.addCleanup(remove_fake_resource)",
            "        self.context = context.Context('fake', 'fake', roles=['user'])",
            "        plugin_klass = importutils.import_class(",
            "            \"neutron.db.db_base_plugin_v2.NeutronDbPluginV2\")",
            "        self.manager_patcher = mock.patch('neutron.manager.NeutronManager')",
            "        fake_manager = self.manager_patcher.start()",
            "        fake_manager_instance = fake_manager.return_value",
            "        fake_manager_instance.plugin = plugin_klass()",
            "",
            "    def _set_rules(self, **kwargs):",
            "        rules_dict = {",
            "            \"context_is_admin\": \"role:admin\",",
            "            \"context_is_advsvc\": \"role:advsvc\",",
            "            \"admin_or_network_owner\": \"rule:context_is_admin or \"",
            "                                      \"tenant_id:%(network:tenant_id)s\",",
            "            \"admin_or_owner\": (\"rule:context_is_admin or \"",
            "                               \"tenant_id:%(tenant_id)s\"),",
            "            \"admin_only\": \"rule:context_is_admin\",",
            "            \"regular_user\": \"role:user\",",
            "            \"shared\": \"field:networks:shared=True\",",
            "            \"external\": \"field:networks:router:external=True\",",
            "            \"default\": '@',",
            "",
            "            \"create_network\": \"rule:admin_or_owner\",",
            "            \"create_network:shared\": \"rule:admin_only\",",
            "            \"update_network\": '@',",
            "            \"update_network:shared\": \"rule:admin_only\",",
            "            \"get_network\": \"rule:admin_or_owner or rule:shared or \"",
            "                           \"rule:external or rule:context_is_advsvc\",",
            "            \"create_subnet\": \"rule:admin_or_network_owner\",",
            "            \"create_port:mac\": \"rule:admin_or_network_owner or \"",
            "                               \"rule:context_is_advsvc\",",
            "            \"update_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"get_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"delete_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"create_fake_resource\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_1\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_2\": \"rule:admin_only\",",
            "",
            "            \"create_fake_policy:\": \"rule:admin_or_owner\",",
            "            \"get_firewall_policy\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\",",
            "            \"get_firewall_rule\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\",",
            "",
            "            \"insert_rule\": \"rule:admin_or_owner\",",
            "            \"remove_rule\": \"rule:admin_or_owner\",",
            "        }",
            "        rules_dict.update(**kwargs)",
            "        self.rules = oslo_policy.Rules.from_dict(rules_dict)",
            "",
            "    def test_firewall_policy_insert_rule_with_admin_context(self):",
            "        action = \"insert_rule\"",
            "        target = {}",
            "        result = policy.check(context.get_admin_context(), action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_firewall_policy_insert_rule_with_owner(self):",
            "        action = \"insert_rule\"",
            "        target = {\"tenant_id\": \"own_tenant\"}",
            "        user_context = context.Context('', \"own_tenant\", roles=['user'])",
            "        result = policy.check(user_context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_firewall_policy_remove_rule_without_admin_or_owner(self):",
            "        action = \"remove_rule\"",
            "        target = {\"firewall_rule_id\": \"rule_id\", \"tenant_id\": \"tenantA\"}",
            "        user_context = context.Context('', \"another_tenant\", roles=['user'])",
            "        result = policy.check(user_context, action, target)",
            "        self.assertFalse(result)",
            "",
            "    def _test_action_on_attr(self, context, action, obj, attr, value,",
            "                             exception=None, **kwargs):",
            "        action = \"%s_%s\" % (action, obj)",
            "        target = {'tenant_id': 'the_owner', attr: value}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        if exception:",
            "            self.assertRaises(exception, policy.enforce,",
            "                              context, action, target)",
            "        else:",
            "            result = policy.enforce(context, action, target)",
            "            self.assertEqual(result, True)",
            "",
            "    def _test_nonadmin_action_on_attr(self, action, attr, value,",
            "                                      exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\", roles=['user'])",
            "        self._test_action_on_attr(user_context, action, \"network\", attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def _test_advsvc_action_on_attr(self, action, obj, attr, value,",
            "                                    exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\",",
            "                                       roles=['user', 'advsvc'])",
            "        self._test_action_on_attr(user_context, action, obj, attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def test_nonadmin_write_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', False,",
            "                                           oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', False,",
            "                                           oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_write_on_shared_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', True,",
            "                                           oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_advsvc_get_network_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'network', 'shared', False)",
            "",
            "    def test_advsvc_create_network_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'network', 'shared', False,",
            "                                         oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_advsvc_create_port_works(self):",
            "        self._test_advsvc_action_on_attr('create', 'port:mac', 'shared', False)",
            "",
            "    def test_advsvc_get_port_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'port', 'shared', False)",
            "",
            "    def test_advsvc_update_port_works(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_advsvc_action_on_attr('update', 'port', 'shared', True,",
            "                                         **kwargs)",
            "",
            "    def test_advsvc_delete_port_works(self):",
            "        self._test_advsvc_action_on_attr('delete', 'port', 'shared', False)",
            "",
            "    def test_advsvc_create_subnet_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'subnet', 'shared', False,",
            "                                         oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_shared_succeeds(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', True)",
            "",
            "    def test_check_is_admin_with_admin_context_succeeds(self):",
            "        admin_context = context.get_admin_context()",
            "        # explicitly set roles as this test verifies user credentials",
            "        # with the policy engine",
            "        admin_context.roles = ['admin']",
            "        self.assertTrue(policy.check_is_admin(admin_context))",
            "",
            "    def test_check_is_admin_with_user_context_fails(self):",
            "        self.assertFalse(policy.check_is_admin(self.context))",
            "",
            "    def test_check_is_admin_with_no_admin_policy_fails(self):",
            "        del self.rules[policy.ADMIN_CTX_POLICY]",
            "        admin_context = context.get_admin_context()",
            "        self.assertFalse(policy.check_is_admin(admin_context))",
            "",
            "    def test_check_is_advsvc_with_admin_context_fails(self):",
            "        admin_context = context.get_admin_context()",
            "        self.assertFalse(policy.check_is_advsvc(admin_context))",
            "",
            "    def test_check_is_advsvc_with_svc_context_succeeds(self):",
            "        svc_context = context.Context('', 'svc', roles=['advsvc'])",
            "        self.assertTrue(policy.check_is_advsvc(svc_context))",
            "",
            "    def test_check_is_advsvc_with_no_advsvc_policy_fails(self):",
            "        del self.rules[policy.ADVSVC_CTX_POLICY]",
            "        svc_context = context.Context('', 'svc', roles=['advsvc'])",
            "        self.assertFalse(policy.check_is_advsvc(svc_context))",
            "",
            "    def test_check_is_advsvc_with_user_context_fails(self):",
            "        self.assertFalse(policy.check_is_advsvc(self.context))",
            "",
            "    def _test_enforce_adminonly_attribute(self, action, **kwargs):",
            "        admin_context = context.get_admin_context()",
            "        target = {'shared': True}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        result = policy.enforce(admin_context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_adminonly_attribute_create(self):",
            "        self._test_enforce_adminonly_attribute('create_network')",
            "",
            "    def test_enforce_adminonly_attribute_update(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_enforce_adminonly_attribute('update_network', **kwargs)",
            "",
            "    def test_reset_adminonly_attr_to_default_fails(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_nonadmin_action_on_attr('update', 'shared', False,",
            "                                           oslo_policy.PolicyNotAuthorized,",
            "                                           **kwargs)",
            "",
            "    def test_enforce_adminonly_attribute_nonadminctx_returns_403(self):",
            "        action = \"create_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def _test_build_subattribute_match_rule(self, validate_value):",
            "        bk = FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate']",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = (",
            "            validate_value)",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        self.assertFalse(policy._build_subattr_match_rule(",
            "            'attr',",
            "            FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr'],",
            "            action,",
            "            target))",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = bk",
            "",
            "    def test_build_subattribute_match_rule_empty_dict_validator(self):",
            "        self._test_build_subattribute_match_rule({})",
            "",
            "    def test_build_subattribute_match_rule_wrong_validation_info(self):",
            "        self._test_build_subattribute_match_rule(",
            "            {'type:dict': 'wrong_stuff'})",
            "",
            "    def test_build_match_rule_special_pluralized(self):",
            "        action = \"create_\" + FAKE_SPECIAL_RESOURCE_NAME",
            "        pluralized = \"create_fake_policies\"",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, pluralized)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_build_match_rule_normal_pluralized_when_create(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, None)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_enforce_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        result = policy.enforce(self.context, action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        result = policy.enforce(context.get_admin_context(),",
            "                                action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute_nonadminctx_returns_403(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target, None)",
            "",
            "    def test_enforce_regularuser_on_read(self):",
            "        action = \"get_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_policy_shared(self):",
            "        action = \"get_firewall_policy\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_rule_shared(self):",
            "        action = \"get_firewall_rule\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check(self):",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_enforce_plugin_failure(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            raise NotImplementedError('Blast!')",
            "",
            "        # the policy check and plugin method we use in this test are irrelevant",
            "        # so long that we verify that, if *f* blows up, the behavior of the",
            "        # policy engine to propagate the exception is preserved",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            self.assertRaises(NotImplementedError,",
            "                              policy.enforce,",
            "                              self.context,",
            "                              action,",
            "                              target)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource_bw_compatibility(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        self._set_rules(",
            "            admin_or_network_owner=\"role:admin or \"",
            "                                   \"tenant_id:%(network_tenant_id)s\")",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_tenant_id_check_no_target_field_raises(self):",
            "        # Try and add a bad rule",
            "        self.assertRaises(",
            "            exceptions.PolicyInitError,",
            "            oslo_policy.Rules.from_dict,",
            "            {'test_policy': 'tenant_id:(wrong_stuff)'})",
            "",
            "    def _test_enforce_tenant_id_raises(self, bad_rule):",
            "        self._set_rules(admin_or_owner=bad_rule)",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        self.fakepolicyinit()",
            "        self.assertRaises(exceptions.PolicyCheckError,",
            "                          policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def test_enforce_tenant_id_check_malformed_target_field_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(malformed_field)s')",
            "",
            "    def test_enforce_tenant_id_check_invalid_parent_resource_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(foobaz_tenant_id)s')",
            "",
            "    def test_process_rules(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        # Construct RuleChecks for an action, attribute and subattribute",
            "        match_rule = oslo_policy.RuleCheck('rule', action)",
            "        attr_rule = oslo_policy.RuleCheck(",
            "            'rule', '%s:%ss' % (action, FAKE_RESOURCE_NAME))",
            "        sub_attr_rules = [oslo_policy.RuleCheck(",
            "            'rule', '%s:%s:%s' % (action, 'attr', 'sub_attr_1'))]",
            "        # Build an AndCheck from the given RuleChecks",
            "        # Make the checks nested to better check the recursion",
            "        sub_attr_rules = oslo_policy.AndCheck(sub_attr_rules)",
            "        attr_rule = oslo_policy.AndCheck(",
            "            [attr_rule, sub_attr_rules])",
            "",
            "        match_rule = oslo_policy.AndCheck([match_rule, attr_rule])",
            "        # Assert that the rules are correctly extracted from the match_rule",
            "        rules = policy._process_rules_list([], match_rule)",
            "        self.assertEqual(['create_fake_resource',",
            "                          'create_fake_resource:fake_resources',",
            "                          'create_fake_resource:attr:sub_attr_1'], rules)",
            "",
            "    @mock.patch.object(policy.LOG, 'isEnabledFor', return_value=True)",
            "    @mock.patch.object(policy.LOG, 'debug')",
            "    def test_log_rule_list(self, mock_debug, mock_is_e):",
            "        policy.log_rule_list(oslo_policy.RuleCheck('rule', 'create_'))",
            "        self.assertTrue(mock_is_e.called)",
            "        self.assertTrue(mock_debug.called)"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2012 OpenStack Foundation.",
            "#",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");",
            "# you may not use this file except in compliance with the License.",
            "# You may obtain a copy of the License at",
            "#",
            "#    http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing, software",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or",
            "# implied.",
            "# See the License for the specific language governing permissions and",
            "# limitations under the License.",
            "",
            "\"\"\"Test of Policy Engine For Neutron\"\"\"",
            "",
            "import mock",
            "from oslo_policy import policy as oslo_policy",
            "from oslo_serialization import jsonutils",
            "from oslo_utils import importutils",
            "import six",
            "import six.moves.urllib.request as urlrequest",
            "",
            "import neutron",
            "from neutron.api.v2 import attributes",
            "from neutron.common import constants as const",
            "from neutron.common import exceptions",
            "from neutron import context",
            "from neutron import manager",
            "from neutron import policy",
            "from neutron.tests import base",
            "",
            "",
            "class PolicyFileTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyFileTestCase, self).setUp()",
            "        self.context = context.Context('fake', 'fake', is_admin=False)",
            "        self.target = {'tenant_id': 'fake'}",
            "",
            "    def test_modified_policy_reloads(self):",
            "        tmpfilename = self.get_temp_file_path('policy')",
            "        action = \"example:test\"",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"\"}\"\"\")",
            "        policy.refresh(policy_file=tmpfilename)",
            "        policy.enforce(self.context, action, self.target)",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            policyfile.write(\"\"\"{\"example:test\": \"!\"}\"\"\")",
            "        policy.refresh(policy_file=tmpfilename)",
            "        self.target = {'tenant_id': 'fake_tenant'}",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized,",
            "                          policy.enforce,",
            "                          self.context,",
            "                          action,",
            "                          self.target)",
            "",
            "",
            "class PolicyTestCase(base.BaseTestCase):",
            "    def setUp(self):",
            "        super(PolicyTestCase, self).setUp()",
            "        # NOTE(vish): preload rules to circumvent reloading from file",
            "        rules = {",
            "            \"true\": '@',",
            "            \"example:allowed\": '@',",
            "            \"example:denied\": '!',",
            "            \"example:get_http\": \"http:http://www.example.com\",",
            "            \"example:my_file\": \"role:compute_admin or tenant_id:%(tenant_id)s\",",
            "            \"example:early_and_fail\": \"! and @\",",
            "            \"example:early_or_success\": \"@ or !\",",
            "            \"example:lowercase_admin\": \"role:admin or role:sysadmin\",",
            "            \"example:uppercase_admin\": \"role:ADMIN or role:sysadmin\",",
            "        }",
            "        policy.refresh()",
            "        # NOTE(vish): then overload underlying rules",
            "        policy.set_rules(oslo_policy.Rules.from_dict(rules))",
            "        self.context = context.Context('fake', 'fake', roles=['member'])",
            "        self.target = {}",
            "",
            "    def test_enforce_nonexistent_action_throws(self):",
            "        action = \"example:noexist\"",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_enforce_bad_action_throws(self):",
            "        action = \"example:denied\"",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_check_bad_action_noraise(self):",
            "        action = \"example:denied\"",
            "        result = policy.check(self.context, action, self.target)",
            "        self.assertEqual(result, False)",
            "",
            "    def test_check_non_existent_action(self):",
            "        action = \"example:idonotexist\"",
            "        result_1 = policy.check(self.context, action, self.target)",
            "        self.assertFalse(result_1)",
            "        result_2 = policy.check(self.context, action, self.target,",
            "                                might_not_exist=True)",
            "        self.assertTrue(result_2)",
            "",
            "    def test_enforce_good_action(self):",
            "        action = \"example:allowed\"",
            "        result = policy.enforce(self.context, action, self.target)",
            "        self.assertEqual(result, True)",
            "",
            "    @mock.patch.object(urlrequest, 'urlopen',",
            "                       return_value=six.StringIO(\"True\"))",
            "    def test_enforce_http_true(self, mock_urlrequest):",
            "        action = \"example:get_http\"",
            "        target = {}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_http_false(self):",
            "",
            "        def fakeurlopen(url, post_data):",
            "            return six.StringIO(\"False\")",
            "",
            "        with mock.patch.object(urlrequest, 'urlopen', new=fakeurlopen):",
            "            action = \"example:get_http\"",
            "            target = {}",
            "            self.assertRaises(oslo_policy.PolicyNotAuthorized,",
            "                              policy.enforce, self.context,",
            "                              action, target)",
            "",
            "    def test_templatized_enforcement(self):",
            "        target_mine = {'tenant_id': 'fake'}",
            "        target_not_mine = {'tenant_id': 'another'}",
            "        action = \"example:my_file\"",
            "        policy.enforce(self.context, action, target_mine)",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target_not_mine)",
            "",
            "    def test_early_AND_enforcement(self):",
            "        action = \"example:early_and_fail\"",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, self.target)",
            "",
            "    def test_early_OR_enforcement(self):",
            "        action = \"example:early_or_success\"",
            "        policy.enforce(self.context, action, self.target)",
            "",
            "    def test_ignore_case_role_check(self):",
            "        lowercase_action = \"example:lowercase_admin\"",
            "        uppercase_action = \"example:uppercase_admin\"",
            "        # NOTE(dprince) we mix case in the Admin role here to ensure",
            "        # case is ignored",
            "        admin_context = context.Context('admin', 'fake', roles=['AdMiN'])",
            "        policy.enforce(admin_context, lowercase_action, self.target)",
            "        policy.enforce(admin_context, uppercase_action, self.target)",
            "",
            "",
            "class DefaultPolicyTestCase(base.BaseTestCase):",
            "",
            "    def setUp(self):",
            "        super(DefaultPolicyTestCase, self).setUp()",
            "        tmpfilename = self.get_temp_file_path('policy.json')",
            "        self.rules = {",
            "            \"default\": '',",
            "            \"example:exist\": '!',",
            "        }",
            "        with open(tmpfilename, \"w\") as policyfile:",
            "            jsonutils.dump(self.rules, policyfile)",
            "        policy.refresh(policy_file=tmpfilename)",
            "",
            "        self.context = context.Context('fake', 'fake')",
            "",
            "    def test_policy_called(self):",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, \"example:exist\", {})",
            "",
            "    def test_not_found_policy_calls_default(self):",
            "        policy.enforce(self.context, \"example:noexist\", {})",
            "",
            "",
            "FAKE_RESOURCE_NAME = 'fake_resource'",
            "FAKE_SPECIAL_RESOURCE_NAME = 'fake_policy'",
            "FAKE_RESOURCES = {\"%ss\" % FAKE_RESOURCE_NAME:",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }},",
            "                  # special plural name",
            "                  \"%s\" % FAKE_SPECIAL_RESOURCE_NAME.replace('y', 'ies'):",
            "                  {'attr': {'allow_post': True,",
            "                            'allow_put': True,",
            "                            'is_visible': True,",
            "                            'default': None,",
            "                            'enforce_policy': True,",
            "                            'validate': {'type:dict':",
            "                                         {'sub_attr_1': {'type:string': None},",
            "                                          'sub_attr_2': {'type:string': None}}}",
            "                            }}}",
            "",
            "",
            "class NeutronPolicyTestCase(base.BaseTestCase):",
            "",
            "    def fakepolicyinit(self, **kwargs):",
            "        enf = policy._ENFORCER",
            "        enf.set_rules(oslo_policy.Rules(self.rules))",
            "",
            "    def setUp(self):",
            "        super(NeutronPolicyTestCase, self).setUp()",
            "        policy.refresh()",
            "        # Add Fake resources to RESOURCE_ATTRIBUTE_MAP",
            "        attributes.RESOURCE_ATTRIBUTE_MAP.update(FAKE_RESOURCES)",
            "        self._set_rules()",
            "",
            "        def remove_fake_resource():",
            "            del attributes.RESOURCE_ATTRIBUTE_MAP[\"%ss\" % FAKE_RESOURCE_NAME]",
            "",
            "        self.patcher = mock.patch.object(neutron.policy,",
            "                                         'init',",
            "                                         new=self.fakepolicyinit)",
            "        self.patcher.start()",
            "        self.addCleanup(remove_fake_resource)",
            "        self.context = context.Context('fake', 'fake', roles=['user'])",
            "        plugin_klass = importutils.import_class(",
            "            \"neutron.db.db_base_plugin_v2.NeutronDbPluginV2\")",
            "        self.manager_patcher = mock.patch('neutron.manager.NeutronManager')",
            "        fake_manager = self.manager_patcher.start()",
            "        fake_manager_instance = fake_manager.return_value",
            "        fake_manager_instance.plugin = plugin_klass()",
            "",
            "    def _set_rules(self, **kwargs):",
            "        rules_dict = {",
            "            \"context_is_admin\": \"role:admin\",",
            "            \"context_is_advsvc\": \"role:advsvc\",",
            "            \"admin_or_network_owner\": \"rule:context_is_admin or \"",
            "                                      \"tenant_id:%(network:tenant_id)s\",",
            "            \"admin_or_owner\": (\"rule:context_is_admin or \"",
            "                               \"tenant_id:%(tenant_id)s\"),",
            "            \"admin_only\": \"rule:context_is_admin\",",
            "            \"regular_user\": \"role:user\",",
            "            \"shared\": \"field:networks:shared=True\",",
            "            \"external\": \"field:networks:router:external=True\",",
            "            \"network_device\": \"field:port:device_owner=~^network:\",",
            "            \"default\": '@',",
            "",
            "            \"create_network\": \"rule:admin_or_owner\",",
            "            \"create_network:shared\": \"rule:admin_only\",",
            "            \"update_network\": '@',",
            "            \"update_network:shared\": \"rule:admin_only\",",
            "            \"get_network\": \"rule:admin_or_owner or rule:shared or \"",
            "                           \"rule:external or rule:context_is_advsvc\",",
            "            \"create_subnet\": \"rule:admin_or_network_owner\",",
            "            \"create_port:mac\": \"rule:admin_or_network_owner or \"",
            "                               \"rule:context_is_advsvc\",",
            "            \"create_port:device_owner\": \"not rule:network_device\",",
            "            \"update_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"get_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"delete_port\": \"rule:admin_or_owner or rule:context_is_advsvc\",",
            "            \"create_fake_resource\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_1\": \"rule:admin_or_owner\",",
            "            \"create_fake_resource:attr:sub_attr_2\": \"rule:admin_only\",",
            "",
            "            \"create_fake_policy:\": \"rule:admin_or_owner\",",
            "            \"get_firewall_policy\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\",",
            "            \"get_firewall_rule\": \"rule:admin_or_owner or \"",
            "                            \"rule:shared\",",
            "",
            "            \"insert_rule\": \"rule:admin_or_owner\",",
            "            \"remove_rule\": \"rule:admin_or_owner\",",
            "        }",
            "        rules_dict.update(**kwargs)",
            "        self.rules = oslo_policy.Rules.from_dict(rules_dict)",
            "",
            "    def test_firewall_policy_insert_rule_with_admin_context(self):",
            "        action = \"insert_rule\"",
            "        target = {}",
            "        result = policy.check(context.get_admin_context(), action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_firewall_policy_insert_rule_with_owner(self):",
            "        action = \"insert_rule\"",
            "        target = {\"tenant_id\": \"own_tenant\"}",
            "        user_context = context.Context('', \"own_tenant\", roles=['user'])",
            "        result = policy.check(user_context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_firewall_policy_remove_rule_without_admin_or_owner(self):",
            "        action = \"remove_rule\"",
            "        target = {\"firewall_rule_id\": \"rule_id\", \"tenant_id\": \"tenantA\"}",
            "        user_context = context.Context('', \"another_tenant\", roles=['user'])",
            "        result = policy.check(user_context, action, target)",
            "        self.assertFalse(result)",
            "",
            "    def _test_action_on_attr(self, context, action, obj, attr, value,",
            "                             exception=None, **kwargs):",
            "        action = \"%s_%s\" % (action, obj)",
            "        target = {'tenant_id': 'the_owner', attr: value}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        if exception:",
            "            self.assertRaises(exception, policy.enforce,",
            "                              context, action, target)",
            "        else:",
            "            result = policy.enforce(context, action, target)",
            "            self.assertEqual(result, True)",
            "",
            "    def _test_nonadmin_action_on_attr(self, action, attr, value,",
            "                                      exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\", roles=['user'])",
            "        self._test_action_on_attr(user_context, action, \"network\", attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def _test_advsvc_action_on_attr(self, action, obj, attr, value,",
            "                                    exception=None, **kwargs):",
            "        user_context = context.Context('', \"user\",",
            "                                       roles=['user', 'advsvc'])",
            "        self._test_action_on_attr(user_context, action, obj, attr,",
            "                                  value, exception, **kwargs)",
            "",
            "    def test_nonadmin_write_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', False,",
            "                                           oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_private_fails(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', False,",
            "                                           oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_write_on_shared_fails(self):",
            "        self._test_nonadmin_action_on_attr('create', 'shared', True,",
            "                                           oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_create_port_device_owner_regex(self):",
            "        blocked_values = ('network:', 'network:abdef', 'network:dhcp',",
            "                          'network:router_interface')",
            "        for val in blocked_values:",
            "            self._test_advsvc_action_on_attr(",
            "                'create', 'port', 'device_owner', val,",
            "                oslo_policy.PolicyNotAuthorized",
            "            )",
            "        ok_values = ('network', 'networks', 'my_network:test', 'my_network:')",
            "        for val in ok_values:",
            "            self._test_advsvc_action_on_attr(",
            "                'create', 'port', 'device_owner', val",
            "            )",
            "",
            "    def test_advsvc_get_network_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'network', 'shared', False)",
            "",
            "    def test_advsvc_create_network_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'network', 'shared', False,",
            "                                         oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_advsvc_create_port_works(self):",
            "        self._test_advsvc_action_on_attr('create', 'port:mac', 'shared', False)",
            "",
            "    def test_advsvc_get_port_works(self):",
            "        self._test_advsvc_action_on_attr('get', 'port', 'shared', False)",
            "",
            "    def test_advsvc_update_port_works(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_advsvc_action_on_attr('update', 'port', 'shared', True,",
            "                                         **kwargs)",
            "",
            "    def test_advsvc_delete_port_works(self):",
            "        self._test_advsvc_action_on_attr('delete', 'port', 'shared', False)",
            "",
            "    def test_advsvc_create_subnet_fails(self):",
            "        self._test_advsvc_action_on_attr('create', 'subnet', 'shared', False,",
            "                                         oslo_policy.PolicyNotAuthorized)",
            "",
            "    def test_nonadmin_read_on_shared_succeeds(self):",
            "        self._test_nonadmin_action_on_attr('get', 'shared', True)",
            "",
            "    def test_check_is_admin_with_admin_context_succeeds(self):",
            "        admin_context = context.get_admin_context()",
            "        # explicitly set roles as this test verifies user credentials",
            "        # with the policy engine",
            "        admin_context.roles = ['admin']",
            "        self.assertTrue(policy.check_is_admin(admin_context))",
            "",
            "    def test_check_is_admin_with_user_context_fails(self):",
            "        self.assertFalse(policy.check_is_admin(self.context))",
            "",
            "    def test_check_is_admin_with_no_admin_policy_fails(self):",
            "        del self.rules[policy.ADMIN_CTX_POLICY]",
            "        admin_context = context.get_admin_context()",
            "        self.assertFalse(policy.check_is_admin(admin_context))",
            "",
            "    def test_check_is_advsvc_with_admin_context_fails(self):",
            "        admin_context = context.get_admin_context()",
            "        self.assertFalse(policy.check_is_advsvc(admin_context))",
            "",
            "    def test_check_is_advsvc_with_svc_context_succeeds(self):",
            "        svc_context = context.Context('', 'svc', roles=['advsvc'])",
            "        self.assertTrue(policy.check_is_advsvc(svc_context))",
            "",
            "    def test_check_is_advsvc_with_no_advsvc_policy_fails(self):",
            "        del self.rules[policy.ADVSVC_CTX_POLICY]",
            "        svc_context = context.Context('', 'svc', roles=['advsvc'])",
            "        self.assertFalse(policy.check_is_advsvc(svc_context))",
            "",
            "    def test_check_is_advsvc_with_user_context_fails(self):",
            "        self.assertFalse(policy.check_is_advsvc(self.context))",
            "",
            "    def _test_enforce_adminonly_attribute(self, action, **kwargs):",
            "        admin_context = context.get_admin_context()",
            "        target = {'shared': True}",
            "        if kwargs:",
            "            target.update(kwargs)",
            "        result = policy.enforce(admin_context, action, target)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_adminonly_attribute_create(self):",
            "        self._test_enforce_adminonly_attribute('create_network')",
            "",
            "    def test_enforce_adminonly_attribute_update(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_enforce_adminonly_attribute('update_network', **kwargs)",
            "",
            "    def test_reset_adminonly_attr_to_default_fails(self):",
            "        kwargs = {const.ATTRIBUTES_TO_UPDATE: ['shared']}",
            "        self._test_nonadmin_action_on_attr('update', 'shared', False,",
            "                                           oslo_policy.PolicyNotAuthorized,",
            "                                           **kwargs)",
            "",
            "    def test_enforce_adminonly_attribute_nonadminctx_returns_403(self):",
            "        action = \"create_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def _test_build_subattribute_match_rule(self, validate_value):",
            "        bk = FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate']",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = (",
            "            validate_value)",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        self.assertFalse(policy._build_subattr_match_rule(",
            "            'attr',",
            "            FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr'],",
            "            action,",
            "            target))",
            "        FAKE_RESOURCES['%ss' % FAKE_RESOURCE_NAME]['attr']['validate'] = bk",
            "",
            "    def test_build_subattribute_match_rule_empty_dict_validator(self):",
            "        self._test_build_subattribute_match_rule({})",
            "",
            "    def test_build_subattribute_match_rule_wrong_validation_info(self):",
            "        self._test_build_subattribute_match_rule(",
            "            {'type:dict': 'wrong_stuff'})",
            "",
            "    def test_build_match_rule_special_pluralized(self):",
            "        action = \"create_\" + FAKE_SPECIAL_RESOURCE_NAME",
            "        pluralized = \"create_fake_policies\"",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, pluralized)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_build_match_rule_normal_pluralized_when_create(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {}",
            "        result = policy._build_match_rule(action, target, None)",
            "        self.assertEqual(\"rule:\" + action, str(result))",
            "",
            "    def test_enforce_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x'}}",
            "        result = policy.enforce(self.context, action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        result = policy.enforce(context.get_admin_context(),",
            "                                action, target, None)",
            "        self.assertEqual(result, True)",
            "",
            "    def test_enforce_admin_only_subattribute_nonadminctx_returns_403(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        target = {'tenant_id': 'fake', 'attr': {'sub_attr_1': 'x',",
            "                                                'sub_attr_2': 'y'}}",
            "        self.assertRaises(oslo_policy.PolicyNotAuthorized, policy.enforce,",
            "                          self.context, action, target, None)",
            "",
            "    def test_enforce_regularuser_on_read(self):",
            "        action = \"get_network\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_policy_shared(self):",
            "        action = \"get_firewall_policy\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_firewall_rule_shared(self):",
            "        action = \"get_firewall_rule\"",
            "        target = {'shared': True, 'tenant_id': 'somebody_else'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check(self):",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        result = policy.enforce(self.context, action, target)",
            "        self.assertTrue(result)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_enforce_plugin_failure(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            raise NotImplementedError('Blast!')",
            "",
            "        # the policy check and plugin method we use in this test are irrelevant",
            "        # so long that we verify that, if *f* blows up, the behavior of the",
            "        # policy engine to propagate the exception is preserved",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            self.assertRaises(NotImplementedError,",
            "                              policy.enforce,",
            "                              self.context,",
            "                              action,",
            "                              target)",
            "",
            "    def test_enforce_tenant_id_check_parent_resource_bw_compatibility(self):",
            "",
            "        def fakegetnetwork(*args, **kwargs):",
            "            return {'tenant_id': 'fake'}",
            "",
            "        self._set_rules(",
            "            admin_or_network_owner=\"role:admin or \"",
            "                                   \"tenant_id:%(network_tenant_id)s\")",
            "        action = \"create_port:mac\"",
            "        with mock.patch.object(manager.NeutronManager.get_instance().plugin,",
            "                               'get_network', new=fakegetnetwork):",
            "            target = {'network_id': 'whatever'}",
            "            result = policy.enforce(self.context, action, target)",
            "            self.assertTrue(result)",
            "",
            "    def test_tenant_id_check_no_target_field_raises(self):",
            "        # Try and add a bad rule",
            "        self.assertRaises(",
            "            exceptions.PolicyInitError,",
            "            oslo_policy.Rules.from_dict,",
            "            {'test_policy': 'tenant_id:(wrong_stuff)'})",
            "",
            "    def _test_enforce_tenant_id_raises(self, bad_rule):",
            "        self._set_rules(admin_or_owner=bad_rule)",
            "        # Trigger a policy with rule admin_or_owner",
            "        action = \"create_network\"",
            "        target = {'tenant_id': 'fake'}",
            "        self.fakepolicyinit()",
            "        self.assertRaises(exceptions.PolicyCheckError,",
            "                          policy.enforce,",
            "                          self.context, action, target)",
            "",
            "    def test_enforce_tenant_id_check_malformed_target_field_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(malformed_field)s')",
            "",
            "    def test_enforce_tenant_id_check_invalid_parent_resource_raises(self):",
            "        self._test_enforce_tenant_id_raises('tenant_id:%(foobaz_tenant_id)s')",
            "",
            "    def test_process_rules(self):",
            "        action = \"create_\" + FAKE_RESOURCE_NAME",
            "        # Construct RuleChecks for an action, attribute and subattribute",
            "        match_rule = oslo_policy.RuleCheck('rule', action)",
            "        attr_rule = oslo_policy.RuleCheck(",
            "            'rule', '%s:%ss' % (action, FAKE_RESOURCE_NAME))",
            "        sub_attr_rules = [oslo_policy.RuleCheck(",
            "            'rule', '%s:%s:%s' % (action, 'attr', 'sub_attr_1'))]",
            "        # Build an AndCheck from the given RuleChecks",
            "        # Make the checks nested to better check the recursion",
            "        sub_attr_rules = oslo_policy.AndCheck(sub_attr_rules)",
            "        attr_rule = oslo_policy.AndCheck(",
            "            [attr_rule, sub_attr_rules])",
            "",
            "        match_rule = oslo_policy.AndCheck([match_rule, attr_rule])",
            "        # Assert that the rules are correctly extracted from the match_rule",
            "        rules = policy._process_rules_list([], match_rule)",
            "        self.assertEqual(['create_fake_resource',",
            "                          'create_fake_resource:fake_resources',",
            "                          'create_fake_resource:attr:sub_attr_1'], rules)",
            "",
            "    @mock.patch.object(policy.LOG, 'isEnabledFor', return_value=True)",
            "    @mock.patch.object(policy.LOG, 'debug')",
            "    def test_log_rule_list(self, mock_debug, mock_is_e):",
            "        policy.log_rule_list(oslo_policy.RuleCheck('rule', 'create_'))",
            "        self.assertTrue(mock_is_e.called)",
            "        self.assertTrue(mock_debug.called)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "neutron.tests.unit.test_policy.NeutronPolicyTestCase.setUp",
            "neutron.tests.unit.test_policy.NeutronPolicyTestCase.self",
            "neutron.tests.unit.test_policy.NeutronPolicyTestCase._test_enforce_tenant_id_raises",
            "neutron.tests.unit.test_policy.NeutronPolicyTestCase._set_rules.rules_dict",
            "neutron.tests.unit.test_policy.NeutronPolicyTestCase.test_enforce_tenant_id_check_parent_resource_bw_compatibility",
            "jinja2.nodes.Const.from_untrusted"
        ]
    }
}