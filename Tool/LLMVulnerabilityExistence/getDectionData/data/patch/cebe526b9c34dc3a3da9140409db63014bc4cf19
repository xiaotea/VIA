{
    "aiohttp/formdata.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1,
                "afterPatchRowNumber": 1,
                "PatchRowcode": " import io"
            },
            "1": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 2,
                "PatchRowcode": "+import warnings"
            },
            "2": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from typing import Any, Iterable, List, Optional"
            },
            "3": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from urllib.parse import urlencode"
            },
            "4": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": 54,
                "PatchRowcode": "         if isinstance(value, io.IOBase):"
            },
            "6": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 55,
                "PatchRowcode": "             self._is_multipart = True"
            },
            "7": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "         elif isinstance(value, (bytes, bytearray, memoryview)):"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+            msg = ("
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 58,
                "PatchRowcode": "+                \"In v4, passing bytes will no longer create a file field. \""
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+                \"Please explicitly use the filename parameter or pass a BytesIO object.\""
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+            )"
            },
            "12": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "             if filename is None and content_transfer_encoding is None:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+                warnings.warn(msg, DeprecationWarning)"
            },
            "14": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "                 filename = name"
            },
            "15": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 64,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 65,
                "PatchRowcode": "         type_options: MultiDict[str] = MultiDict({\"name\": name})"
            },
            "17": {
                "beforePatchRowNumber": 81,
                "afterPatchRowNumber": 87,
                "PatchRowcode": "                     \"content_transfer_encoding must be an instance\""
            },
            "18": {
                "beforePatchRowNumber": 82,
                "afterPatchRowNumber": 88,
                "PatchRowcode": "                     \" of str. Got: %s\" % content_transfer_encoding"
            },
            "19": {
                "beforePatchRowNumber": 83,
                "afterPatchRowNumber": 89,
                "PatchRowcode": "                 )"
            },
            "20": {
                "beforePatchRowNumber": 84,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            headers[hdrs.CONTENT_TRANSFER_ENCODING] = content_transfer_encoding"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 90,
                "PatchRowcode": "+            msg = ("
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 91,
                "PatchRowcode": "+                \"content_transfer_encoding is deprecated. \""
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 92,
                "PatchRowcode": "+                \"To maintain compatibility with v4 please pass a BytesPayload.\""
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 93,
                "PatchRowcode": "+            )"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 94,
                "PatchRowcode": "+            warnings.warn(msg, DeprecationWarning)"
            },
            "26": {
                "beforePatchRowNumber": 85,
                "afterPatchRowNumber": 95,
                "PatchRowcode": "             self._is_multipart = True"
            },
            "27": {
                "beforePatchRowNumber": 86,
                "afterPatchRowNumber": 96,
                "PatchRowcode": " "
            },
            "28": {
                "beforePatchRowNumber": 87,
                "afterPatchRowNumber": 97,
                "PatchRowcode": "         self._fields.append((type_options, headers, value))"
            }
        },
        "frontPatchFile": [
            "import io",
            "from typing import Any, Iterable, List, Optional",
            "from urllib.parse import urlencode",
            "",
            "from multidict import MultiDict, MultiDictProxy",
            "",
            "from . import hdrs, multipart, payload",
            "from .helpers import guess_filename",
            "from .payload import Payload",
            "",
            "__all__ = (\"FormData\",)",
            "",
            "",
            "class FormData:",
            "    \"\"\"Helper class for form body generation.",
            "",
            "    Supports multipart/form-data and application/x-www-form-urlencoded.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        fields: Iterable[Any] = (),",
            "        quote_fields: bool = True,",
            "        charset: Optional[str] = None,",
            "    ) -> None:",
            "        self._writer = multipart.MultipartWriter(\"form-data\")",
            "        self._fields: List[Any] = []",
            "        self._is_multipart = False",
            "        self._is_processed = False",
            "        self._quote_fields = quote_fields",
            "        self._charset = charset",
            "",
            "        if isinstance(fields, dict):",
            "            fields = list(fields.items())",
            "        elif not isinstance(fields, (list, tuple)):",
            "            fields = (fields,)",
            "        self.add_fields(*fields)",
            "",
            "    @property",
            "    def is_multipart(self) -> bool:",
            "        return self._is_multipart",
            "",
            "    def add_field(",
            "        self,",
            "        name: str,",
            "        value: Any,",
            "        *,",
            "        content_type: Optional[str] = None,",
            "        filename: Optional[str] = None,",
            "        content_transfer_encoding: Optional[str] = None,",
            "    ) -> None:",
            "",
            "        if isinstance(value, io.IOBase):",
            "            self._is_multipart = True",
            "        elif isinstance(value, (bytes, bytearray, memoryview)):",
            "            if filename is None and content_transfer_encoding is None:",
            "                filename = name",
            "",
            "        type_options: MultiDict[str] = MultiDict({\"name\": name})",
            "        if filename is not None and not isinstance(filename, str):",
            "            raise TypeError(",
            "                \"filename must be an instance of str. \" \"Got: %s\" % filename",
            "            )",
            "        if filename is None and isinstance(value, io.IOBase):",
            "            filename = guess_filename(value, name)",
            "        if filename is not None:",
            "            type_options[\"filename\"] = filename",
            "            self._is_multipart = True",
            "",
            "        headers = {}",
            "        if content_type is not None:",
            "            if not isinstance(content_type, str):",
            "                raise TypeError(",
            "                    \"content_type must be an instance of str. \" \"Got: %s\" % content_type",
            "                )",
            "            headers[hdrs.CONTENT_TYPE] = content_type",
            "            self._is_multipart = True",
            "        if content_transfer_encoding is not None:",
            "            if not isinstance(content_transfer_encoding, str):",
            "                raise TypeError(",
            "                    \"content_transfer_encoding must be an instance\"",
            "                    \" of str. Got: %s\" % content_transfer_encoding",
            "                )",
            "            headers[hdrs.CONTENT_TRANSFER_ENCODING] = content_transfer_encoding",
            "            self._is_multipart = True",
            "",
            "        self._fields.append((type_options, headers, value))",
            "",
            "    def add_fields(self, *fields: Any) -> None:",
            "        to_add = list(fields)",
            "",
            "        while to_add:",
            "            rec = to_add.pop(0)",
            "",
            "            if isinstance(rec, io.IOBase):",
            "                k = guess_filename(rec, \"unknown\")",
            "                self.add_field(k, rec)  # type: ignore[arg-type]",
            "",
            "            elif isinstance(rec, (MultiDictProxy, MultiDict)):",
            "                to_add.extend(rec.items())",
            "",
            "            elif isinstance(rec, (list, tuple)) and len(rec) == 2:",
            "                k, fp = rec",
            "                self.add_field(k, fp)  # type: ignore[arg-type]",
            "",
            "            else:",
            "                raise TypeError(",
            "                    \"Only io.IOBase, multidict and (name, file) \"",
            "                    \"pairs allowed, use .add_field() for passing \"",
            "                    \"more complex parameters, got {!r}\".format(rec)",
            "                )",
            "",
            "    def _gen_form_urlencoded(self) -> payload.BytesPayload:",
            "        # form data (x-www-form-urlencoded)",
            "        data = []",
            "        for type_options, _, value in self._fields:",
            "            data.append((type_options[\"name\"], value))",
            "",
            "        charset = self._charset if self._charset is not None else \"utf-8\"",
            "",
            "        if charset == \"utf-8\":",
            "            content_type = \"application/x-www-form-urlencoded\"",
            "        else:",
            "            content_type = \"application/x-www-form-urlencoded; \" \"charset=%s\" % charset",
            "",
            "        return payload.BytesPayload(",
            "            urlencode(data, doseq=True, encoding=charset).encode(),",
            "            content_type=content_type,",
            "        )",
            "",
            "    def _gen_form_data(self) -> multipart.MultipartWriter:",
            "        \"\"\"Encode a list of fields using the multipart/form-data MIME format\"\"\"",
            "        if self._is_processed:",
            "            raise RuntimeError(\"Form data has been processed already\")",
            "        for dispparams, headers, value in self._fields:",
            "            try:",
            "                if hdrs.CONTENT_TYPE in headers:",
            "                    part = payload.get_payload(",
            "                        value,",
            "                        content_type=headers[hdrs.CONTENT_TYPE],",
            "                        headers=headers,",
            "                        encoding=self._charset,",
            "                    )",
            "                else:",
            "                    part = payload.get_payload(",
            "                        value, headers=headers, encoding=self._charset",
            "                    )",
            "            except Exception as exc:",
            "                raise TypeError(",
            "                    \"Can not serialize value type: %r\\n \"",
            "                    \"headers: %r\\n value: %r\" % (type(value), headers, value)",
            "                ) from exc",
            "",
            "            if dispparams:",
            "                part.set_content_disposition(",
            "                    \"form-data\", quote_fields=self._quote_fields, **dispparams",
            "                )",
            "                # FIXME cgi.FieldStorage doesn't likes body parts with",
            "                # Content-Length which were sent via chunked transfer encoding",
            "                assert part.headers is not None",
            "                part.headers.popall(hdrs.CONTENT_LENGTH, None)",
            "",
            "            self._writer.append_payload(part)",
            "",
            "        self._is_processed = True",
            "        return self._writer",
            "",
            "    def __call__(self) -> Payload:",
            "        if self._is_multipart:",
            "            return self._gen_form_data()",
            "        else:",
            "            return self._gen_form_urlencoded()"
        ],
        "afterPatchFile": [
            "import io",
            "import warnings",
            "from typing import Any, Iterable, List, Optional",
            "from urllib.parse import urlencode",
            "",
            "from multidict import MultiDict, MultiDictProxy",
            "",
            "from . import hdrs, multipart, payload",
            "from .helpers import guess_filename",
            "from .payload import Payload",
            "",
            "__all__ = (\"FormData\",)",
            "",
            "",
            "class FormData:",
            "    \"\"\"Helper class for form body generation.",
            "",
            "    Supports multipart/form-data and application/x-www-form-urlencoded.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        fields: Iterable[Any] = (),",
            "        quote_fields: bool = True,",
            "        charset: Optional[str] = None,",
            "    ) -> None:",
            "        self._writer = multipart.MultipartWriter(\"form-data\")",
            "        self._fields: List[Any] = []",
            "        self._is_multipart = False",
            "        self._is_processed = False",
            "        self._quote_fields = quote_fields",
            "        self._charset = charset",
            "",
            "        if isinstance(fields, dict):",
            "            fields = list(fields.items())",
            "        elif not isinstance(fields, (list, tuple)):",
            "            fields = (fields,)",
            "        self.add_fields(*fields)",
            "",
            "    @property",
            "    def is_multipart(self) -> bool:",
            "        return self._is_multipart",
            "",
            "    def add_field(",
            "        self,",
            "        name: str,",
            "        value: Any,",
            "        *,",
            "        content_type: Optional[str] = None,",
            "        filename: Optional[str] = None,",
            "        content_transfer_encoding: Optional[str] = None,",
            "    ) -> None:",
            "",
            "        if isinstance(value, io.IOBase):",
            "            self._is_multipart = True",
            "        elif isinstance(value, (bytes, bytearray, memoryview)):",
            "            msg = (",
            "                \"In v4, passing bytes will no longer create a file field. \"",
            "                \"Please explicitly use the filename parameter or pass a BytesIO object.\"",
            "            )",
            "            if filename is None and content_transfer_encoding is None:",
            "                warnings.warn(msg, DeprecationWarning)",
            "                filename = name",
            "",
            "        type_options: MultiDict[str] = MultiDict({\"name\": name})",
            "        if filename is not None and not isinstance(filename, str):",
            "            raise TypeError(",
            "                \"filename must be an instance of str. \" \"Got: %s\" % filename",
            "            )",
            "        if filename is None and isinstance(value, io.IOBase):",
            "            filename = guess_filename(value, name)",
            "        if filename is not None:",
            "            type_options[\"filename\"] = filename",
            "            self._is_multipart = True",
            "",
            "        headers = {}",
            "        if content_type is not None:",
            "            if not isinstance(content_type, str):",
            "                raise TypeError(",
            "                    \"content_type must be an instance of str. \" \"Got: %s\" % content_type",
            "                )",
            "            headers[hdrs.CONTENT_TYPE] = content_type",
            "            self._is_multipart = True",
            "        if content_transfer_encoding is not None:",
            "            if not isinstance(content_transfer_encoding, str):",
            "                raise TypeError(",
            "                    \"content_transfer_encoding must be an instance\"",
            "                    \" of str. Got: %s\" % content_transfer_encoding",
            "                )",
            "            msg = (",
            "                \"content_transfer_encoding is deprecated. \"",
            "                \"To maintain compatibility with v4 please pass a BytesPayload.\"",
            "            )",
            "            warnings.warn(msg, DeprecationWarning)",
            "            self._is_multipart = True",
            "",
            "        self._fields.append((type_options, headers, value))",
            "",
            "    def add_fields(self, *fields: Any) -> None:",
            "        to_add = list(fields)",
            "",
            "        while to_add:",
            "            rec = to_add.pop(0)",
            "",
            "            if isinstance(rec, io.IOBase):",
            "                k = guess_filename(rec, \"unknown\")",
            "                self.add_field(k, rec)  # type: ignore[arg-type]",
            "",
            "            elif isinstance(rec, (MultiDictProxy, MultiDict)):",
            "                to_add.extend(rec.items())",
            "",
            "            elif isinstance(rec, (list, tuple)) and len(rec) == 2:",
            "                k, fp = rec",
            "                self.add_field(k, fp)  # type: ignore[arg-type]",
            "",
            "            else:",
            "                raise TypeError(",
            "                    \"Only io.IOBase, multidict and (name, file) \"",
            "                    \"pairs allowed, use .add_field() for passing \"",
            "                    \"more complex parameters, got {!r}\".format(rec)",
            "                )",
            "",
            "    def _gen_form_urlencoded(self) -> payload.BytesPayload:",
            "        # form data (x-www-form-urlencoded)",
            "        data = []",
            "        for type_options, _, value in self._fields:",
            "            data.append((type_options[\"name\"], value))",
            "",
            "        charset = self._charset if self._charset is not None else \"utf-8\"",
            "",
            "        if charset == \"utf-8\":",
            "            content_type = \"application/x-www-form-urlencoded\"",
            "        else:",
            "            content_type = \"application/x-www-form-urlencoded; \" \"charset=%s\" % charset",
            "",
            "        return payload.BytesPayload(",
            "            urlencode(data, doseq=True, encoding=charset).encode(),",
            "            content_type=content_type,",
            "        )",
            "",
            "    def _gen_form_data(self) -> multipart.MultipartWriter:",
            "        \"\"\"Encode a list of fields using the multipart/form-data MIME format\"\"\"",
            "        if self._is_processed:",
            "            raise RuntimeError(\"Form data has been processed already\")",
            "        for dispparams, headers, value in self._fields:",
            "            try:",
            "                if hdrs.CONTENT_TYPE in headers:",
            "                    part = payload.get_payload(",
            "                        value,",
            "                        content_type=headers[hdrs.CONTENT_TYPE],",
            "                        headers=headers,",
            "                        encoding=self._charset,",
            "                    )",
            "                else:",
            "                    part = payload.get_payload(",
            "                        value, headers=headers, encoding=self._charset",
            "                    )",
            "            except Exception as exc:",
            "                raise TypeError(",
            "                    \"Can not serialize value type: %r\\n \"",
            "                    \"headers: %r\\n value: %r\" % (type(value), headers, value)",
            "                ) from exc",
            "",
            "            if dispparams:",
            "                part.set_content_disposition(",
            "                    \"form-data\", quote_fields=self._quote_fields, **dispparams",
            "                )",
            "                # FIXME cgi.FieldStorage doesn't likes body parts with",
            "                # Content-Length which were sent via chunked transfer encoding",
            "                assert part.headers is not None",
            "                part.headers.popall(hdrs.CONTENT_LENGTH, None)",
            "",
            "            self._writer.append_payload(part)",
            "",
            "        self._is_processed = True",
            "        return self._writer",
            "",
            "    def __call__(self) -> Payload:",
            "        if self._is_multipart:",
            "            return self._gen_form_data()",
            "        else:",
            "            return self._gen_form_urlencoded()"
        ],
        "action": [
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "84": [
                "FormData",
                "add_field"
            ]
        },
        "addLocation": [
            "aiohttp.formdata.FormData.add_field.headers",
            "src.saml2.sigver",
            "aiohttp.formdata.FormData.add_fields"
        ]
    },
    "aiohttp/multipart.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": 256,
                "PatchRowcode": "     chunk_size = 8192"
            },
            "1": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": 257,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": 258,
                "PatchRowcode": "     def __init__("
            },
            "3": {
                "beforePatchRowNumber": 259,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self, boundary: bytes, headers: \"CIMultiDictProxy[str]\", content: StreamReader"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+        self,"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+        boundary: bytes,"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+        headers: \"CIMultiDictProxy[str]\","
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+        content: StreamReader,"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+        *,"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 264,
                "PatchRowcode": "+        subtype: str = \"mixed\","
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 265,
                "PatchRowcode": "+        default_charset: Optional[str] = None,"
            },
            "11": {
                "beforePatchRowNumber": 260,
                "afterPatchRowNumber": 266,
                "PatchRowcode": "     ) -> None:"
            },
            "12": {
                "beforePatchRowNumber": 261,
                "afterPatchRowNumber": 267,
                "PatchRowcode": "         self.headers = headers"
            },
            "13": {
                "beforePatchRowNumber": 262,
                "afterPatchRowNumber": 268,
                "PatchRowcode": "         self._boundary = boundary"
            },
            "14": {
                "beforePatchRowNumber": 263,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "         self._content = content"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 270,
                "PatchRowcode": "+        self._default_charset = default_charset"
            },
            "16": {
                "beforePatchRowNumber": 264,
                "afterPatchRowNumber": 271,
                "PatchRowcode": "         self._at_eof = False"
            },
            "17": {
                "beforePatchRowNumber": 265,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        length = self.headers.get(CONTENT_LENGTH, None)"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+        self._is_form_data = subtype == \"form-data\""
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 273,
                "PatchRowcode": "+        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 274,
                "PatchRowcode": "+        length = None if self._is_form_data else self.headers.get(CONTENT_LENGTH, None)"
            },
            "21": {
                "beforePatchRowNumber": 266,
                "afterPatchRowNumber": 275,
                "PatchRowcode": "         self._length = int(length) if length is not None else None"
            },
            "22": {
                "beforePatchRowNumber": 267,
                "afterPatchRowNumber": 276,
                "PatchRowcode": "         self._read_bytes = 0"
            },
            "23": {
                "beforePatchRowNumber": 268,
                "afterPatchRowNumber": 277,
                "PatchRowcode": "         self._unread: Deque[bytes] = deque()"
            },
            "24": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "         assert self._length is not None, \"Content-Length required for chunked read\""
            },
            "25": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 339,
                "PatchRowcode": "         chunk_size = min(size, self._length - self._read_bytes)"
            },
            "26": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "         chunk = await self._content.read(chunk_size)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+        if self._content.at_eof():"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+            self._at_eof = True"
            },
            "29": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 343,
                "PatchRowcode": "         return chunk"
            },
            "30": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 344,
                "PatchRowcode": " "
            },
            "31": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 345,
                "PatchRowcode": "     async def _read_chunk_from_stream(self, size: int) -> bytes:"
            },
            "32": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 460,
                "PatchRowcode": "         \"\"\""
            },
            "33": {
                "beforePatchRowNumber": 450,
                "afterPatchRowNumber": 461,
                "PatchRowcode": "         if CONTENT_TRANSFER_ENCODING in self.headers:"
            },
            "34": {
                "beforePatchRowNumber": 451,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "             data = self._decode_content_transfer(data)"
            },
            "35": {
                "beforePatchRowNumber": 452,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if CONTENT_ENCODING in self.headers:"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 463,
                "PatchRowcode": "+        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 464,
                "PatchRowcode": "+        if not self._is_form_data and CONTENT_ENCODING in self.headers:"
            },
            "38": {
                "beforePatchRowNumber": 453,
                "afterPatchRowNumber": 465,
                "PatchRowcode": "             return self._decode_content(data)"
            },
            "39": {
                "beforePatchRowNumber": 454,
                "afterPatchRowNumber": 466,
                "PatchRowcode": "         return data"
            },
            "40": {
                "beforePatchRowNumber": 455,
                "afterPatchRowNumber": 467,
                "PatchRowcode": " "
            },
            "41": {
                "beforePatchRowNumber": 483,
                "afterPatchRowNumber": 495,
                "PatchRowcode": "         \"\"\"Returns charset parameter from Content-Type header or default.\"\"\""
            },
            "42": {
                "beforePatchRowNumber": 484,
                "afterPatchRowNumber": 496,
                "PatchRowcode": "         ctype = self.headers.get(CONTENT_TYPE, \"\")"
            },
            "43": {
                "beforePatchRowNumber": 485,
                "afterPatchRowNumber": 497,
                "PatchRowcode": "         mimetype = parse_mimetype(ctype)"
            },
            "44": {
                "beforePatchRowNumber": 486,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return mimetype.parameters.get(\"charset\", default)"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 498,
                "PatchRowcode": "+        return mimetype.parameters.get(\"charset\", self._default_charset or default)"
            },
            "46": {
                "beforePatchRowNumber": 487,
                "afterPatchRowNumber": 499,
                "PatchRowcode": " "
            },
            "47": {
                "beforePatchRowNumber": 488,
                "afterPatchRowNumber": 500,
                "PatchRowcode": "     @reify"
            },
            "48": {
                "beforePatchRowNumber": 489,
                "afterPatchRowNumber": 501,
                "PatchRowcode": "     def name(self) -> Optional[str]:"
            },
            "49": {
                "beforePatchRowNumber": 538,
                "afterPatchRowNumber": 550,
                "PatchRowcode": "     part_reader_cls = BodyPartReader"
            },
            "50": {
                "beforePatchRowNumber": 539,
                "afterPatchRowNumber": 551,
                "PatchRowcode": " "
            },
            "51": {
                "beforePatchRowNumber": 540,
                "afterPatchRowNumber": 552,
                "PatchRowcode": "     def __init__(self, headers: Mapping[str, str], content: StreamReader) -> None:"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 553,
                "PatchRowcode": "+        self._mimetype = parse_mimetype(headers[CONTENT_TYPE])"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 554,
                "PatchRowcode": "+        assert self._mimetype.type == \"multipart\", \"multipart/* content type expected\""
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 555,
                "PatchRowcode": "+        if \"boundary\" not in self._mimetype.parameters:"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 556,
                "PatchRowcode": "+            raise ValueError("
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 557,
                "PatchRowcode": "+                \"boundary missed for Content-Type: %s\" % headers[CONTENT_TYPE]"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 558,
                "PatchRowcode": "+            )"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 559,
                "PatchRowcode": "+"
            },
            "59": {
                "beforePatchRowNumber": 541,
                "afterPatchRowNumber": 560,
                "PatchRowcode": "         self.headers = headers"
            },
            "60": {
                "beforePatchRowNumber": 542,
                "afterPatchRowNumber": 561,
                "PatchRowcode": "         self._boundary = (\"--\" + self._get_boundary()).encode()"
            },
            "61": {
                "beforePatchRowNumber": 543,
                "afterPatchRowNumber": 562,
                "PatchRowcode": "         self._content = content"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 563,
                "PatchRowcode": "+        self._default_charset: Optional[str] = None"
            },
            "63": {
                "beforePatchRowNumber": 544,
                "afterPatchRowNumber": 564,
                "PatchRowcode": "         self._last_part: Optional[Union[\"MultipartReader\", BodyPartReader]] = None"
            },
            "64": {
                "beforePatchRowNumber": 545,
                "afterPatchRowNumber": 565,
                "PatchRowcode": "         self._at_eof = False"
            },
            "65": {
                "beforePatchRowNumber": 546,
                "afterPatchRowNumber": 566,
                "PatchRowcode": "         self._at_bof = True"
            },
            "66": {
                "beforePatchRowNumber": 592,
                "afterPatchRowNumber": 612,
                "PatchRowcode": "             await self._read_boundary()"
            },
            "67": {
                "beforePatchRowNumber": 593,
                "afterPatchRowNumber": 613,
                "PatchRowcode": "         if self._at_eof:  # we just read the last boundary, nothing to do there"
            },
            "68": {
                "beforePatchRowNumber": 594,
                "afterPatchRowNumber": 614,
                "PatchRowcode": "             return None"
            },
            "69": {
                "beforePatchRowNumber": 595,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        self._last_part = await self.fetch_next_part()"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 615,
                "PatchRowcode": "+"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 616,
                "PatchRowcode": "+        part = await self.fetch_next_part()"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 617,
                "PatchRowcode": "+        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.6"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 618,
                "PatchRowcode": "+        if ("
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 619,
                "PatchRowcode": "+            self._last_part is None"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 620,
                "PatchRowcode": "+            and self._mimetype.subtype == \"form-data\""
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 621,
                "PatchRowcode": "+            and isinstance(part, BodyPartReader)"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 622,
                "PatchRowcode": "+        ):"
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 623,
                "PatchRowcode": "+            _, params = parse_content_disposition(part.headers.get(CONTENT_DISPOSITION))"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 624,
                "PatchRowcode": "+            if params.get(\"name\") == \"_charset_\":"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 625,
                "PatchRowcode": "+                # Longest encoding in https://encoding.spec.whatwg.org/encodings.json"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 626,
                "PatchRowcode": "+                # is 19 characters, so 32 should be more than enough for any valid encoding."
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 627,
                "PatchRowcode": "+                charset = await part.read_chunk(32)"
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 628,
                "PatchRowcode": "+                if len(charset) > 31:"
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 629,
                "PatchRowcode": "+                    raise RuntimeError(\"Invalid default charset\")"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 630,
                "PatchRowcode": "+                self._default_charset = charset.strip().decode()"
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 631,
                "PatchRowcode": "+                part = await self.fetch_next_part()"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 632,
                "PatchRowcode": "+        self._last_part = part"
            },
            "88": {
                "beforePatchRowNumber": 596,
                "afterPatchRowNumber": 633,
                "PatchRowcode": "         return self._last_part"
            },
            "89": {
                "beforePatchRowNumber": 597,
                "afterPatchRowNumber": 634,
                "PatchRowcode": " "
            },
            "90": {
                "beforePatchRowNumber": 598,
                "afterPatchRowNumber": 635,
                "PatchRowcode": "     async def release(self) -> None:"
            },
            "91": {
                "beforePatchRowNumber": 628,
                "afterPatchRowNumber": 665,
                "PatchRowcode": "                 return type(self)(headers, self._content)"
            },
            "92": {
                "beforePatchRowNumber": 629,
                "afterPatchRowNumber": 666,
                "PatchRowcode": "             return self.multipart_reader_cls(headers, self._content)"
            },
            "93": {
                "beforePatchRowNumber": 630,
                "afterPatchRowNumber": 667,
                "PatchRowcode": "         else:"
            },
            "94": {
                "beforePatchRowNumber": 631,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return self.part_reader_cls(self._boundary, headers, self._content)"
            },
            "95": {
                "beforePatchRowNumber": 632,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "96": {
                "beforePatchRowNumber": 633,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def _get_boundary(self) -> str:"
            },
            "97": {
                "beforePatchRowNumber": 634,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        mimetype = parse_mimetype(self.headers[CONTENT_TYPE])"
            },
            "98": {
                "beforePatchRowNumber": 635,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "99": {
                "beforePatchRowNumber": 636,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        assert mimetype.type == \"multipart\", \"multipart/* content type expected\""
            },
            "100": {
                "beforePatchRowNumber": 637,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "101": {
                "beforePatchRowNumber": 638,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if \"boundary\" not in mimetype.parameters:"
            },
            "102": {
                "beforePatchRowNumber": 639,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise ValueError("
            },
            "103": {
                "beforePatchRowNumber": 640,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"boundary missed for Content-Type: %s\" % self.headers[CONTENT_TYPE]"
            },
            "104": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 668,
                "PatchRowcode": "+            return self.part_reader_cls("
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 669,
                "PatchRowcode": "+                self._boundary,"
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 670,
                "PatchRowcode": "+                headers,"
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 671,
                "PatchRowcode": "+                self._content,"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 672,
                "PatchRowcode": "+                subtype=self._mimetype.subtype,"
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 673,
                "PatchRowcode": "+                default_charset=self._default_charset,"
            },
            "110": {
                "beforePatchRowNumber": 641,
                "afterPatchRowNumber": 674,
                "PatchRowcode": "             )"
            },
            "111": {
                "beforePatchRowNumber": 642,
                "afterPatchRowNumber": 675,
                "PatchRowcode": " "
            },
            "112": {
                "beforePatchRowNumber": 643,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        boundary = mimetype.parameters[\"boundary\"]"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 676,
                "PatchRowcode": "+    def _get_boundary(self) -> str:"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 677,
                "PatchRowcode": "+        boundary = self._mimetype.parameters[\"boundary\"]"
            },
            "115": {
                "beforePatchRowNumber": 644,
                "afterPatchRowNumber": 678,
                "PatchRowcode": "         if len(boundary) > 70:"
            },
            "116": {
                "beforePatchRowNumber": 645,
                "afterPatchRowNumber": 679,
                "PatchRowcode": "             raise ValueError(\"boundary %r is too long (70 chars max)\" % boundary)"
            },
            "117": {
                "beforePatchRowNumber": 646,
                "afterPatchRowNumber": 680,
                "PatchRowcode": " "
            },
            "118": {
                "beforePatchRowNumber": 731,
                "afterPatchRowNumber": 765,
                "PatchRowcode": "         super().__init__(None, content_type=ctype)"
            },
            "119": {
                "beforePatchRowNumber": 732,
                "afterPatchRowNumber": 766,
                "PatchRowcode": " "
            },
            "120": {
                "beforePatchRowNumber": 733,
                "afterPatchRowNumber": 767,
                "PatchRowcode": "         self._parts: List[_Part] = []"
            },
            "121": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 768,
                "PatchRowcode": "+        self._is_form_data = subtype == \"form-data\""
            },
            "122": {
                "beforePatchRowNumber": 734,
                "afterPatchRowNumber": 769,
                "PatchRowcode": " "
            },
            "123": {
                "beforePatchRowNumber": 735,
                "afterPatchRowNumber": 770,
                "PatchRowcode": "     def __enter__(self) -> \"MultipartWriter\":"
            },
            "124": {
                "beforePatchRowNumber": 736,
                "afterPatchRowNumber": 771,
                "PatchRowcode": "         return self"
            },
            "125": {
                "beforePatchRowNumber": 808,
                "afterPatchRowNumber": 843,
                "PatchRowcode": " "
            },
            "126": {
                "beforePatchRowNumber": 809,
                "afterPatchRowNumber": 844,
                "PatchRowcode": "     def append_payload(self, payload: Payload) -> Payload:"
            },
            "127": {
                "beforePatchRowNumber": 810,
                "afterPatchRowNumber": 845,
                "PatchRowcode": "         \"\"\"Adds a new body part to multipart writer.\"\"\""
            },
            "128": {
                "beforePatchRowNumber": 811,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # compression"
            },
            "129": {
                "beforePatchRowNumber": 812,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        encoding: Optional[str] = payload.headers.get("
            },
            "130": {
                "beforePatchRowNumber": 813,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            CONTENT_ENCODING,"
            },
            "131": {
                "beforePatchRowNumber": 814,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"\","
            },
            "132": {
                "beforePatchRowNumber": 815,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ).lower()"
            },
            "133": {
                "beforePatchRowNumber": 816,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if encoding and encoding not in (\"deflate\", \"gzip\", \"identity\"):"
            },
            "134": {
                "beforePatchRowNumber": 817,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise RuntimeError(f\"unknown content encoding: {encoding}\")"
            },
            "135": {
                "beforePatchRowNumber": 818,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if encoding == \"identity\":"
            },
            "136": {
                "beforePatchRowNumber": 819,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            encoding = None"
            },
            "137": {
                "beforePatchRowNumber": 820,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "138": {
                "beforePatchRowNumber": 821,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # te encoding"
            },
            "139": {
                "beforePatchRowNumber": 822,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        te_encoding: Optional[str] = payload.headers.get("
            },
            "140": {
                "beforePatchRowNumber": 823,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            CONTENT_TRANSFER_ENCODING,"
            },
            "141": {
                "beforePatchRowNumber": 824,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            \"\","
            },
            "142": {
                "beforePatchRowNumber": 825,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ).lower()"
            },
            "143": {
                "beforePatchRowNumber": 826,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if te_encoding not in (\"\", \"base64\", \"quoted-printable\", \"binary\"):"
            },
            "144": {
                "beforePatchRowNumber": 827,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            raise RuntimeError("
            },
            "145": {
                "beforePatchRowNumber": 828,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                \"unknown content transfer encoding: {}\" \"\".format(te_encoding)"
            },
            "146": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 846,
                "PatchRowcode": "+        encoding: Optional[str] = None"
            },
            "147": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 847,
                "PatchRowcode": "+        te_encoding: Optional[str] = None"
            },
            "148": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 848,
                "PatchRowcode": "+        if self._is_form_data:"
            },
            "149": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 849,
                "PatchRowcode": "+            # https://datatracker.ietf.org/doc/html/rfc7578#section-4.7"
            },
            "150": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 850,
                "PatchRowcode": "+            # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8"
            },
            "151": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 851,
                "PatchRowcode": "+            assert CONTENT_DISPOSITION in payload.headers"
            },
            "152": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 852,
                "PatchRowcode": "+            assert \"name=\" in payload.headers[CONTENT_DISPOSITION]"
            },
            "153": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 853,
                "PatchRowcode": "+            assert ("
            },
            "154": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 854,
                "PatchRowcode": "+                not {CONTENT_ENCODING, CONTENT_LENGTH, CONTENT_TRANSFER_ENCODING}"
            },
            "155": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 855,
                "PatchRowcode": "+                & payload.headers.keys()"
            },
            "156": {
                "beforePatchRowNumber": 829,
                "afterPatchRowNumber": 856,
                "PatchRowcode": "             )"
            },
            "157": {
                "beforePatchRowNumber": 830,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if te_encoding == \"binary\":"
            },
            "158": {
                "beforePatchRowNumber": 831,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            te_encoding = None"
            },
            "159": {
                "beforePatchRowNumber": 832,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "160": {
                "beforePatchRowNumber": 833,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # size"
            },
            "161": {
                "beforePatchRowNumber": 834,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        size = payload.size"
            },
            "162": {
                "beforePatchRowNumber": 835,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if size is not None and not (encoding or te_encoding):"
            },
            "163": {
                "beforePatchRowNumber": 836,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            payload.headers[CONTENT_LENGTH] = str(size)"
            },
            "164": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 857,
                "PatchRowcode": "+        else:"
            },
            "165": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 858,
                "PatchRowcode": "+            # compression"
            },
            "166": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 859,
                "PatchRowcode": "+            encoding = payload.headers.get(CONTENT_ENCODING, \"\").lower()"
            },
            "167": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 860,
                "PatchRowcode": "+            if encoding and encoding not in (\"deflate\", \"gzip\", \"identity\"):"
            },
            "168": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 861,
                "PatchRowcode": "+                raise RuntimeError(f\"unknown content encoding: {encoding}\")"
            },
            "169": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 862,
                "PatchRowcode": "+            if encoding == \"identity\":"
            },
            "170": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 863,
                "PatchRowcode": "+                encoding = None"
            },
            "171": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 864,
                "PatchRowcode": "+"
            },
            "172": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 865,
                "PatchRowcode": "+            # te encoding"
            },
            "173": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 866,
                "PatchRowcode": "+            te_encoding = payload.headers.get(CONTENT_TRANSFER_ENCODING, \"\").lower()"
            },
            "174": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 867,
                "PatchRowcode": "+            if te_encoding not in (\"\", \"base64\", \"quoted-printable\", \"binary\"):"
            },
            "175": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 868,
                "PatchRowcode": "+                raise RuntimeError(f\"unknown content transfer encoding: {te_encoding}\")"
            },
            "176": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 869,
                "PatchRowcode": "+            if te_encoding == \"binary\":"
            },
            "177": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 870,
                "PatchRowcode": "+                te_encoding = None"
            },
            "178": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 871,
                "PatchRowcode": "+"
            },
            "179": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 872,
                "PatchRowcode": "+            # size"
            },
            "180": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 873,
                "PatchRowcode": "+            size = payload.size"
            },
            "181": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 874,
                "PatchRowcode": "+            if size is not None and not (encoding or te_encoding):"
            },
            "182": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 875,
                "PatchRowcode": "+                payload.headers[CONTENT_LENGTH] = str(size)"
            },
            "183": {
                "beforePatchRowNumber": 837,
                "afterPatchRowNumber": 876,
                "PatchRowcode": " "
            },
            "184": {
                "beforePatchRowNumber": 838,
                "afterPatchRowNumber": 877,
                "PatchRowcode": "         self._parts.append((payload, encoding, te_encoding))  # type: ignore[arg-type]"
            },
            "185": {
                "beforePatchRowNumber": 839,
                "afterPatchRowNumber": 878,
                "PatchRowcode": "         return payload"
            }
        },
        "frontPatchFile": [
            "import base64",
            "import binascii",
            "import json",
            "import re",
            "import uuid",
            "import warnings",
            "import zlib",
            "from collections import deque",
            "from types import TracebackType",
            "from typing import (",
            "    TYPE_CHECKING,",
            "    Any,",
            "    AsyncIterator,",
            "    Deque,",
            "    Dict,",
            "    Iterator,",
            "    List,",
            "    Mapping,",
            "    Optional,",
            "    Sequence,",
            "    Tuple,",
            "    Type,",
            "    Union,",
            "    cast,",
            ")",
            "from urllib.parse import parse_qsl, unquote, urlencode",
            "",
            "from multidict import CIMultiDict, CIMultiDictProxy",
            "",
            "from .compression_utils import ZLibCompressor, ZLibDecompressor",
            "from .hdrs import (",
            "    CONTENT_DISPOSITION,",
            "    CONTENT_ENCODING,",
            "    CONTENT_LENGTH,",
            "    CONTENT_TRANSFER_ENCODING,",
            "    CONTENT_TYPE,",
            ")",
            "from .helpers import CHAR, TOKEN, parse_mimetype, reify",
            "from .http import HeadersParser",
            "from .payload import (",
            "    JsonPayload,",
            "    LookupError,",
            "    Order,",
            "    Payload,",
            "    StringPayload,",
            "    get_payload,",
            "    payload_type,",
            ")",
            "from .streams import StreamReader",
            "",
            "__all__ = (",
            "    \"MultipartReader\",",
            "    \"MultipartWriter\",",
            "    \"BodyPartReader\",",
            "    \"BadContentDispositionHeader\",",
            "    \"BadContentDispositionParam\",",
            "    \"parse_content_disposition\",",
            "    \"content_disposition_filename\",",
            ")",
            "",
            "",
            "if TYPE_CHECKING:",
            "    from .client_reqrep import ClientResponse",
            "",
            "",
            "class BadContentDispositionHeader(RuntimeWarning):",
            "    pass",
            "",
            "",
            "class BadContentDispositionParam(RuntimeWarning):",
            "    pass",
            "",
            "",
            "def parse_content_disposition(",
            "    header: Optional[str],",
            ") -> Tuple[Optional[str], Dict[str, str]]:",
            "    def is_token(string: str) -> bool:",
            "        return bool(string) and TOKEN >= set(string)",
            "",
            "    def is_quoted(string: str) -> bool:",
            "        return string[0] == string[-1] == '\"'",
            "",
            "    def is_rfc5987(string: str) -> bool:",
            "        return is_token(string) and string.count(\"'\") == 2",
            "",
            "    def is_extended_param(string: str) -> bool:",
            "        return string.endswith(\"*\")",
            "",
            "    def is_continuous_param(string: str) -> bool:",
            "        pos = string.find(\"*\") + 1",
            "        if not pos:",
            "            return False",
            "        substring = string[pos:-1] if string.endswith(\"*\") else string[pos:]",
            "        return substring.isdigit()",
            "",
            "    def unescape(text: str, *, chars: str = \"\".join(map(re.escape, CHAR))) -> str:",
            "        return re.sub(f\"\\\\\\\\([{chars}])\", \"\\\\1\", text)",
            "",
            "    if not header:",
            "        return None, {}",
            "",
            "    disptype, *parts = header.split(\";\")",
            "    if not is_token(disptype):",
            "        warnings.warn(BadContentDispositionHeader(header))",
            "        return None, {}",
            "",
            "    params: Dict[str, str] = {}",
            "    while parts:",
            "        item = parts.pop(0)",
            "",
            "        if \"=\" not in item:",
            "            warnings.warn(BadContentDispositionHeader(header))",
            "            return None, {}",
            "",
            "        key, value = item.split(\"=\", 1)",
            "        key = key.lower().strip()",
            "        value = value.lstrip()",
            "",
            "        if key in params:",
            "            warnings.warn(BadContentDispositionHeader(header))",
            "            return None, {}",
            "",
            "        if not is_token(key):",
            "            warnings.warn(BadContentDispositionParam(item))",
            "            continue",
            "",
            "        elif is_continuous_param(key):",
            "            if is_quoted(value):",
            "                value = unescape(value[1:-1])",
            "            elif not is_token(value):",
            "                warnings.warn(BadContentDispositionParam(item))",
            "                continue",
            "",
            "        elif is_extended_param(key):",
            "            if is_rfc5987(value):",
            "                encoding, _, value = value.split(\"'\", 2)",
            "                encoding = encoding or \"utf-8\"",
            "            else:",
            "                warnings.warn(BadContentDispositionParam(item))",
            "                continue",
            "",
            "            try:",
            "                value = unquote(value, encoding, \"strict\")",
            "            except UnicodeDecodeError:  # pragma: nocover",
            "                warnings.warn(BadContentDispositionParam(item))",
            "                continue",
            "",
            "        else:",
            "            failed = True",
            "            if is_quoted(value):",
            "                failed = False",
            "                value = unescape(value[1:-1].lstrip(\"\\\\/\"))",
            "            elif is_token(value):",
            "                failed = False",
            "            elif parts:",
            "                # maybe just ; in filename, in any case this is just",
            "                # one case fix, for proper fix we need to redesign parser",
            "                _value = f\"{value};{parts[0]}\"",
            "                if is_quoted(_value):",
            "                    parts.pop(0)",
            "                    value = unescape(_value[1:-1].lstrip(\"\\\\/\"))",
            "                    failed = False",
            "",
            "            if failed:",
            "                warnings.warn(BadContentDispositionHeader(header))",
            "                return None, {}",
            "",
            "        params[key] = value",
            "",
            "    return disptype.lower(), params",
            "",
            "",
            "def content_disposition_filename(",
            "    params: Mapping[str, str], name: str = \"filename\"",
            ") -> Optional[str]:",
            "    name_suf = \"%s*\" % name",
            "    if not params:",
            "        return None",
            "    elif name_suf in params:",
            "        return params[name_suf]",
            "    elif name in params:",
            "        return params[name]",
            "    else:",
            "        parts = []",
            "        fnparams = sorted(",
            "            (key, value) for key, value in params.items() if key.startswith(name_suf)",
            "        )",
            "        for num, (key, value) in enumerate(fnparams):",
            "            _, tail = key.split(\"*\", 1)",
            "            if tail.endswith(\"*\"):",
            "                tail = tail[:-1]",
            "            if tail == str(num):",
            "                parts.append(value)",
            "            else:",
            "                break",
            "        if not parts:",
            "            return None",
            "        value = \"\".join(parts)",
            "        if \"'\" in value:",
            "            encoding, _, value = value.split(\"'\", 2)",
            "            encoding = encoding or \"utf-8\"",
            "            return unquote(value, encoding, \"strict\")",
            "        return value",
            "",
            "",
            "class MultipartResponseWrapper:",
            "    \"\"\"Wrapper around the MultipartReader.",
            "",
            "    It takes care about",
            "    underlying connection and close it when it needs in.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        resp: \"ClientResponse\",",
            "        stream: \"MultipartReader\",",
            "    ) -> None:",
            "        self.resp = resp",
            "        self.stream = stream",
            "",
            "    def __aiter__(self) -> \"MultipartResponseWrapper\":",
            "        return self",
            "",
            "    async def __anext__(",
            "        self,",
            "    ) -> Union[\"MultipartReader\", \"BodyPartReader\"]:",
            "        part = await self.next()",
            "        if part is None:",
            "            raise StopAsyncIteration",
            "        return part",
            "",
            "    def at_eof(self) -> bool:",
            "        \"\"\"Returns True when all response data had been read.\"\"\"",
            "        return self.resp.content.at_eof()",
            "",
            "    async def next(",
            "        self,",
            "    ) -> Optional[Union[\"MultipartReader\", \"BodyPartReader\"]]:",
            "        \"\"\"Emits next multipart reader object.\"\"\"",
            "        item = await self.stream.next()",
            "        if self.stream.at_eof():",
            "            await self.release()",
            "        return item",
            "",
            "    async def release(self) -> None:",
            "        \"\"\"Release the connection gracefully.",
            "",
            "        All remaining content is read to the void.",
            "        \"\"\"",
            "        await self.resp.release()",
            "",
            "",
            "class BodyPartReader:",
            "    \"\"\"Multipart reader for single body part.\"\"\"",
            "",
            "    chunk_size = 8192",
            "",
            "    def __init__(",
            "        self, boundary: bytes, headers: \"CIMultiDictProxy[str]\", content: StreamReader",
            "    ) -> None:",
            "        self.headers = headers",
            "        self._boundary = boundary",
            "        self._content = content",
            "        self._at_eof = False",
            "        length = self.headers.get(CONTENT_LENGTH, None)",
            "        self._length = int(length) if length is not None else None",
            "        self._read_bytes = 0",
            "        self._unread: Deque[bytes] = deque()",
            "        self._prev_chunk: Optional[bytes] = None",
            "        self._content_eof = 0",
            "        self._cache: Dict[str, Any] = {}",
            "",
            "    def __aiter__(self) -> AsyncIterator[\"BodyPartReader\"]:",
            "        return self  # type: ignore[return-value]",
            "",
            "    async def __anext__(self) -> bytes:",
            "        part = await self.next()",
            "        if part is None:",
            "            raise StopAsyncIteration",
            "        return part",
            "",
            "    async def next(self) -> Optional[bytes]:",
            "        item = await self.read()",
            "        if not item:",
            "            return None",
            "        return item",
            "",
            "    async def read(self, *, decode: bool = False) -> bytes:",
            "        \"\"\"Reads body part data.",
            "",
            "        decode: Decodes data following by encoding",
            "                method from Content-Encoding header. If it missed",
            "                data remains untouched",
            "        \"\"\"",
            "        if self._at_eof:",
            "            return b\"\"",
            "        data = bytearray()",
            "        while not self._at_eof:",
            "            data.extend(await self.read_chunk(self.chunk_size))",
            "        if decode:",
            "            return self.decode(data)",
            "        return data",
            "",
            "    async def read_chunk(self, size: int = chunk_size) -> bytes:",
            "        \"\"\"Reads body part content chunk of the specified size.",
            "",
            "        size: chunk size",
            "        \"\"\"",
            "        if self._at_eof:",
            "            return b\"\"",
            "        if self._length:",
            "            chunk = await self._read_chunk_from_length(size)",
            "        else:",
            "            chunk = await self._read_chunk_from_stream(size)",
            "",
            "        self._read_bytes += len(chunk)",
            "        if self._read_bytes == self._length:",
            "            self._at_eof = True",
            "        if self._at_eof:",
            "            clrf = await self._content.readline()",
            "            assert (",
            "                b\"\\r\\n\" == clrf",
            "            ), \"reader did not read all the data or it is malformed\"",
            "        return chunk",
            "",
            "    async def _read_chunk_from_length(self, size: int) -> bytes:",
            "        # Reads body part content chunk of the specified size.",
            "        # The body part must has Content-Length header with proper value.",
            "        assert self._length is not None, \"Content-Length required for chunked read\"",
            "        chunk_size = min(size, self._length - self._read_bytes)",
            "        chunk = await self._content.read(chunk_size)",
            "        return chunk",
            "",
            "    async def _read_chunk_from_stream(self, size: int) -> bytes:",
            "        # Reads content chunk of body part with unknown length.",
            "        # The Content-Length header for body part is not necessary.",
            "        assert (",
            "            size >= len(self._boundary) + 2",
            "        ), \"Chunk size must be greater or equal than boundary length + 2\"",
            "        first_chunk = self._prev_chunk is None",
            "        if first_chunk:",
            "            self._prev_chunk = await self._content.read(size)",
            "",
            "        chunk = await self._content.read(size)",
            "        self._content_eof += int(self._content.at_eof())",
            "        assert self._content_eof < 3, \"Reading after EOF\"",
            "        assert self._prev_chunk is not None",
            "        window = self._prev_chunk + chunk",
            "        sub = b\"\\r\\n\" + self._boundary",
            "        if first_chunk:",
            "            idx = window.find(sub)",
            "        else:",
            "            idx = window.find(sub, max(0, len(self._prev_chunk) - len(sub)))",
            "        if idx >= 0:",
            "            # pushing boundary back to content",
            "            with warnings.catch_warnings():",
            "                warnings.filterwarnings(\"ignore\", category=DeprecationWarning)",
            "                self._content.unread_data(window[idx:])",
            "            if size > idx:",
            "                self._prev_chunk = self._prev_chunk[:idx]",
            "            chunk = window[len(self._prev_chunk) : idx]",
            "            if not chunk:",
            "                self._at_eof = True",
            "        result = self._prev_chunk",
            "        self._prev_chunk = chunk",
            "        return result",
            "",
            "    async def readline(self) -> bytes:",
            "        \"\"\"Reads body part by line by line.\"\"\"",
            "        if self._at_eof:",
            "            return b\"\"",
            "",
            "        if self._unread:",
            "            line = self._unread.popleft()",
            "        else:",
            "            line = await self._content.readline()",
            "",
            "        if line.startswith(self._boundary):",
            "            # the very last boundary may not come with \\r\\n,",
            "            # so set single rules for everyone",
            "            sline = line.rstrip(b\"\\r\\n\")",
            "            boundary = self._boundary",
            "            last_boundary = self._boundary + b\"--\"",
            "            # ensure that we read exactly the boundary, not something alike",
            "            if sline == boundary or sline == last_boundary:",
            "                self._at_eof = True",
            "                self._unread.append(line)",
            "                return b\"\"",
            "        else:",
            "            next_line = await self._content.readline()",
            "            if next_line.startswith(self._boundary):",
            "                line = line[:-2]  # strip CRLF but only once",
            "            self._unread.append(next_line)",
            "",
            "        return line",
            "",
            "    async def release(self) -> None:",
            "        \"\"\"Like read(), but reads all the data to the void.\"\"\"",
            "        if self._at_eof:",
            "            return",
            "        while not self._at_eof:",
            "            await self.read_chunk(self.chunk_size)",
            "",
            "    async def text(self, *, encoding: Optional[str] = None) -> str:",
            "        \"\"\"Like read(), but assumes that body part contains text data.\"\"\"",
            "        data = await self.read(decode=True)",
            "        # see https://www.w3.org/TR/html5/forms.html#multipart/form-data-encoding-algorithm",
            "        # and https://dvcs.w3.org/hg/xhr/raw-file/tip/Overview.html#dom-xmlhttprequest-send",
            "        encoding = encoding or self.get_charset(default=\"utf-8\")",
            "        return data.decode(encoding)",
            "",
            "    async def json(self, *, encoding: Optional[str] = None) -> Optional[Dict[str, Any]]:",
            "        \"\"\"Like read(), but assumes that body parts contains JSON data.\"\"\"",
            "        data = await self.read(decode=True)",
            "        if not data:",
            "            return None",
            "        encoding = encoding or self.get_charset(default=\"utf-8\")",
            "        return cast(Dict[str, Any], json.loads(data.decode(encoding)))",
            "",
            "    async def form(self, *, encoding: Optional[str] = None) -> List[Tuple[str, str]]:",
            "        \"\"\"Like read(), but assumes that body parts contain form urlencoded data.\"\"\"",
            "        data = await self.read(decode=True)",
            "        if not data:",
            "            return []",
            "        if encoding is not None:",
            "            real_encoding = encoding",
            "        else:",
            "            real_encoding = self.get_charset(default=\"utf-8\")",
            "        try:",
            "            decoded_data = data.rstrip().decode(real_encoding)",
            "        except UnicodeDecodeError:",
            "            raise ValueError(\"data cannot be decoded with %s encoding\" % real_encoding)",
            "",
            "        return parse_qsl(",
            "            decoded_data,",
            "            keep_blank_values=True,",
            "            encoding=real_encoding,",
            "        )",
            "",
            "    def at_eof(self) -> bool:",
            "        \"\"\"Returns True if the boundary was reached or False otherwise.\"\"\"",
            "        return self._at_eof",
            "",
            "    def decode(self, data: bytes) -> bytes:",
            "        \"\"\"Decodes data.",
            "",
            "        Decoding is done according the specified Content-Encoding",
            "        or Content-Transfer-Encoding headers value.",
            "        \"\"\"",
            "        if CONTENT_TRANSFER_ENCODING in self.headers:",
            "            data = self._decode_content_transfer(data)",
            "        if CONTENT_ENCODING in self.headers:",
            "            return self._decode_content(data)",
            "        return data",
            "",
            "    def _decode_content(self, data: bytes) -> bytes:",
            "        encoding = self.headers.get(CONTENT_ENCODING, \"\").lower()",
            "        if encoding == \"identity\":",
            "            return data",
            "        if encoding in {\"deflate\", \"gzip\"}:",
            "            return ZLibDecompressor(",
            "                encoding=encoding,",
            "                suppress_deflate_header=True,",
            "            ).decompress_sync(data)",
            "",
            "        raise RuntimeError(f\"unknown content encoding: {encoding}\")",
            "",
            "    def _decode_content_transfer(self, data: bytes) -> bytes:",
            "        encoding = self.headers.get(CONTENT_TRANSFER_ENCODING, \"\").lower()",
            "",
            "        if encoding == \"base64\":",
            "            return base64.b64decode(data)",
            "        elif encoding == \"quoted-printable\":",
            "            return binascii.a2b_qp(data)",
            "        elif encoding in (\"binary\", \"8bit\", \"7bit\"):",
            "            return data",
            "        else:",
            "            raise RuntimeError(",
            "                \"unknown content transfer encoding: {}\" \"\".format(encoding)",
            "            )",
            "",
            "    def get_charset(self, default: str) -> str:",
            "        \"\"\"Returns charset parameter from Content-Type header or default.\"\"\"",
            "        ctype = self.headers.get(CONTENT_TYPE, \"\")",
            "        mimetype = parse_mimetype(ctype)",
            "        return mimetype.parameters.get(\"charset\", default)",
            "",
            "    @reify",
            "    def name(self) -> Optional[str]:",
            "        \"\"\"Returns name specified in Content-Disposition header.",
            "",
            "        If the header is missing or malformed, returns None.",
            "        \"\"\"",
            "        _, params = parse_content_disposition(self.headers.get(CONTENT_DISPOSITION))",
            "        return content_disposition_filename(params, \"name\")",
            "",
            "    @reify",
            "    def filename(self) -> Optional[str]:",
            "        \"\"\"Returns filename specified in Content-Disposition header.",
            "",
            "        Returns None if the header is missing or malformed.",
            "        \"\"\"",
            "        _, params = parse_content_disposition(self.headers.get(CONTENT_DISPOSITION))",
            "        return content_disposition_filename(params, \"filename\")",
            "",
            "",
            "@payload_type(BodyPartReader, order=Order.try_first)",
            "class BodyPartReaderPayload(Payload):",
            "    def __init__(self, value: BodyPartReader, *args: Any, **kwargs: Any) -> None:",
            "        super().__init__(value, *args, **kwargs)",
            "",
            "        params: Dict[str, str] = {}",
            "        if value.name is not None:",
            "            params[\"name\"] = value.name",
            "        if value.filename is not None:",
            "            params[\"filename\"] = value.filename",
            "",
            "        if params:",
            "            self.set_content_disposition(\"attachment\", True, **params)",
            "",
            "    async def write(self, writer: Any) -> None:",
            "        field = self._value",
            "        chunk = await field.read_chunk(size=2**16)",
            "        while chunk:",
            "            await writer.write(field.decode(chunk))",
            "            chunk = await field.read_chunk(size=2**16)",
            "",
            "",
            "class MultipartReader:",
            "    \"\"\"Multipart body reader.\"\"\"",
            "",
            "    #: Response wrapper, used when multipart readers constructs from response.",
            "    response_wrapper_cls = MultipartResponseWrapper",
            "    #: Multipart reader class, used to handle multipart/* body parts.",
            "    #: None points to type(self)",
            "    multipart_reader_cls = None",
            "    #: Body part reader class for non multipart/* content types.",
            "    part_reader_cls = BodyPartReader",
            "",
            "    def __init__(self, headers: Mapping[str, str], content: StreamReader) -> None:",
            "        self.headers = headers",
            "        self._boundary = (\"--\" + self._get_boundary()).encode()",
            "        self._content = content",
            "        self._last_part: Optional[Union[\"MultipartReader\", BodyPartReader]] = None",
            "        self._at_eof = False",
            "        self._at_bof = True",
            "        self._unread: List[bytes] = []",
            "",
            "    def __aiter__(",
            "        self,",
            "    ) -> AsyncIterator[\"BodyPartReader\"]:",
            "        return self  # type: ignore[return-value]",
            "",
            "    async def __anext__(",
            "        self,",
            "    ) -> Optional[Union[\"MultipartReader\", BodyPartReader]]:",
            "        part = await self.next()",
            "        if part is None:",
            "            raise StopAsyncIteration",
            "        return part",
            "",
            "    @classmethod",
            "    def from_response(",
            "        cls,",
            "        response: \"ClientResponse\",",
            "    ) -> MultipartResponseWrapper:",
            "        \"\"\"Constructs reader instance from HTTP response.",
            "",
            "        :param response: :class:`~aiohttp.client.ClientResponse` instance",
            "        \"\"\"",
            "        obj = cls.response_wrapper_cls(",
            "            response, cls(response.headers, response.content)",
            "        )",
            "        return obj",
            "",
            "    def at_eof(self) -> bool:",
            "        \"\"\"Returns True if the final boundary was reached, false otherwise.\"\"\"",
            "        return self._at_eof",
            "",
            "    async def next(",
            "        self,",
            "    ) -> Optional[Union[\"MultipartReader\", BodyPartReader]]:",
            "        \"\"\"Emits the next multipart body part.\"\"\"",
            "        # So, if we're at BOF, we need to skip till the boundary.",
            "        if self._at_eof:",
            "            return None",
            "        await self._maybe_release_last_part()",
            "        if self._at_bof:",
            "            await self._read_until_first_boundary()",
            "            self._at_bof = False",
            "        else:",
            "            await self._read_boundary()",
            "        if self._at_eof:  # we just read the last boundary, nothing to do there",
            "            return None",
            "        self._last_part = await self.fetch_next_part()",
            "        return self._last_part",
            "",
            "    async def release(self) -> None:",
            "        \"\"\"Reads all the body parts to the void till the final boundary.\"\"\"",
            "        while not self._at_eof:",
            "            item = await self.next()",
            "            if item is None:",
            "                break",
            "            await item.release()",
            "",
            "    async def fetch_next_part(",
            "        self,",
            "    ) -> Union[\"MultipartReader\", BodyPartReader]:",
            "        \"\"\"Returns the next body part reader.\"\"\"",
            "        headers = await self._read_headers()",
            "        return self._get_part_reader(headers)",
            "",
            "    def _get_part_reader(",
            "        self,",
            "        headers: \"CIMultiDictProxy[str]\",",
            "    ) -> Union[\"MultipartReader\", BodyPartReader]:",
            "        \"\"\"Dispatches the response by the `Content-Type` header.",
            "",
            "        Returns a suitable reader instance.",
            "",
            "        :param dict headers: Response headers",
            "        \"\"\"",
            "        ctype = headers.get(CONTENT_TYPE, \"\")",
            "        mimetype = parse_mimetype(ctype)",
            "",
            "        if mimetype.type == \"multipart\":",
            "            if self.multipart_reader_cls is None:",
            "                return type(self)(headers, self._content)",
            "            return self.multipart_reader_cls(headers, self._content)",
            "        else:",
            "            return self.part_reader_cls(self._boundary, headers, self._content)",
            "",
            "    def _get_boundary(self) -> str:",
            "        mimetype = parse_mimetype(self.headers[CONTENT_TYPE])",
            "",
            "        assert mimetype.type == \"multipart\", \"multipart/* content type expected\"",
            "",
            "        if \"boundary\" not in mimetype.parameters:",
            "            raise ValueError(",
            "                \"boundary missed for Content-Type: %s\" % self.headers[CONTENT_TYPE]",
            "            )",
            "",
            "        boundary = mimetype.parameters[\"boundary\"]",
            "        if len(boundary) > 70:",
            "            raise ValueError(\"boundary %r is too long (70 chars max)\" % boundary)",
            "",
            "        return boundary",
            "",
            "    async def _readline(self) -> bytes:",
            "        if self._unread:",
            "            return self._unread.pop()",
            "        return await self._content.readline()",
            "",
            "    async def _read_until_first_boundary(self) -> None:",
            "        while True:",
            "            chunk = await self._readline()",
            "            if chunk == b\"\":",
            "                raise ValueError(",
            "                    \"Could not find starting boundary %r\" % (self._boundary)",
            "                )",
            "            chunk = chunk.rstrip()",
            "            if chunk == self._boundary:",
            "                return",
            "            elif chunk == self._boundary + b\"--\":",
            "                self._at_eof = True",
            "                return",
            "",
            "    async def _read_boundary(self) -> None:",
            "        chunk = (await self._readline()).rstrip()",
            "        if chunk == self._boundary:",
            "            pass",
            "        elif chunk == self._boundary + b\"--\":",
            "            self._at_eof = True",
            "            epilogue = await self._readline()",
            "            next_line = await self._readline()",
            "",
            "            # the epilogue is expected and then either the end of input or the",
            "            # parent multipart boundary, if the parent boundary is found then",
            "            # it should be marked as unread and handed to the parent for",
            "            # processing",
            "            if next_line[:2] == b\"--\":",
            "                self._unread.append(next_line)",
            "            # otherwise the request is likely missing an epilogue and both",
            "            # lines should be passed to the parent for processing",
            "            # (this handles the old behavior gracefully)",
            "            else:",
            "                self._unread.extend([next_line, epilogue])",
            "        else:",
            "            raise ValueError(f\"Invalid boundary {chunk!r}, expected {self._boundary!r}\")",
            "",
            "    async def _read_headers(self) -> \"CIMultiDictProxy[str]\":",
            "        lines = [b\"\"]",
            "        while True:",
            "            chunk = await self._content.readline()",
            "            chunk = chunk.strip()",
            "            lines.append(chunk)",
            "            if not chunk:",
            "                break",
            "        parser = HeadersParser()",
            "        headers, raw_headers = parser.parse_headers(lines)",
            "        return headers",
            "",
            "    async def _maybe_release_last_part(self) -> None:",
            "        \"\"\"Ensures that the last read body part is read completely.\"\"\"",
            "        if self._last_part is not None:",
            "            if not self._last_part.at_eof():",
            "                await self._last_part.release()",
            "            self._unread.extend(self._last_part._unread)",
            "            self._last_part = None",
            "",
            "",
            "_Part = Tuple[Payload, str, str]",
            "",
            "",
            "class MultipartWriter(Payload):",
            "    \"\"\"Multipart body writer.\"\"\"",
            "",
            "    def __init__(self, subtype: str = \"mixed\", boundary: Optional[str] = None) -> None:",
            "        boundary = boundary if boundary is not None else uuid.uuid4().hex",
            "        # The underlying Payload API demands a str (utf-8), not bytes,",
            "        # so we need to ensure we don't lose anything during conversion.",
            "        # As a result, require the boundary to be ASCII only.",
            "        # In both situations.",
            "",
            "        try:",
            "            self._boundary = boundary.encode(\"ascii\")",
            "        except UnicodeEncodeError:",
            "            raise ValueError(\"boundary should contain ASCII only chars\") from None",
            "        ctype = f\"multipart/{subtype}; boundary={self._boundary_value}\"",
            "",
            "        super().__init__(None, content_type=ctype)",
            "",
            "        self._parts: List[_Part] = []",
            "",
            "    def __enter__(self) -> \"MultipartWriter\":",
            "        return self",
            "",
            "    def __exit__(",
            "        self,",
            "        exc_type: Optional[Type[BaseException]],",
            "        exc_val: Optional[BaseException],",
            "        exc_tb: Optional[TracebackType],",
            "    ) -> None:",
            "        pass",
            "",
            "    def __iter__(self) -> Iterator[_Part]:",
            "        return iter(self._parts)",
            "",
            "    def __len__(self) -> int:",
            "        return len(self._parts)",
            "",
            "    def __bool__(self) -> bool:",
            "        return True",
            "",
            "    _valid_tchar_regex = re.compile(rb\"\\A[!#$%&'*+\\-.^_`|~\\w]+\\Z\")",
            "    _invalid_qdtext_char_regex = re.compile(rb\"[\\x00-\\x08\\x0A-\\x1F\\x7F]\")",
            "",
            "    @property",
            "    def _boundary_value(self) -> str:",
            "        \"\"\"Wrap boundary parameter value in quotes, if necessary.",
            "",
            "        Reads self.boundary and returns a unicode string.",
            "        \"\"\"",
            "        # Refer to RFCs 7231, 7230, 5234.",
            "        #",
            "        # parameter      = token \"=\" ( token / quoted-string )",
            "        # token          = 1*tchar",
            "        # quoted-string  = DQUOTE *( qdtext / quoted-pair ) DQUOTE",
            "        # qdtext         = HTAB / SP / %x21 / %x23-5B / %x5D-7E / obs-text",
            "        # obs-text       = %x80-FF",
            "        # quoted-pair    = \"\\\" ( HTAB / SP / VCHAR / obs-text )",
            "        # tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"",
            "        #                  / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"",
            "        #                  / DIGIT / ALPHA",
            "        #                  ; any VCHAR, except delimiters",
            "        # VCHAR           = %x21-7E",
            "        value = self._boundary",
            "        if re.match(self._valid_tchar_regex, value):",
            "            return value.decode(\"ascii\")  # cannot fail",
            "",
            "        if re.search(self._invalid_qdtext_char_regex, value):",
            "            raise ValueError(\"boundary value contains invalid characters\")",
            "",
            "        # escape %x5C and %x22",
            "        quoted_value_content = value.replace(b\"\\\\\", b\"\\\\\\\\\")",
            "        quoted_value_content = quoted_value_content.replace(b'\"', b'\\\\\"')",
            "",
            "        return '\"' + quoted_value_content.decode(\"ascii\") + '\"'",
            "",
            "    @property",
            "    def boundary(self) -> str:",
            "        return self._boundary.decode(\"ascii\")",
            "",
            "    def append(self, obj: Any, headers: Optional[Mapping[str, str]] = None) -> Payload:",
            "        if headers is None:",
            "            headers = CIMultiDict()",
            "",
            "        if isinstance(obj, Payload):",
            "            obj.headers.update(headers)",
            "            return self.append_payload(obj)",
            "        else:",
            "            try:",
            "                payload = get_payload(obj, headers=headers)",
            "            except LookupError:",
            "                raise TypeError(\"Cannot create payload from %r\" % obj)",
            "            else:",
            "                return self.append_payload(payload)",
            "",
            "    def append_payload(self, payload: Payload) -> Payload:",
            "        \"\"\"Adds a new body part to multipart writer.\"\"\"",
            "        # compression",
            "        encoding: Optional[str] = payload.headers.get(",
            "            CONTENT_ENCODING,",
            "            \"\",",
            "        ).lower()",
            "        if encoding and encoding not in (\"deflate\", \"gzip\", \"identity\"):",
            "            raise RuntimeError(f\"unknown content encoding: {encoding}\")",
            "        if encoding == \"identity\":",
            "            encoding = None",
            "",
            "        # te encoding",
            "        te_encoding: Optional[str] = payload.headers.get(",
            "            CONTENT_TRANSFER_ENCODING,",
            "            \"\",",
            "        ).lower()",
            "        if te_encoding not in (\"\", \"base64\", \"quoted-printable\", \"binary\"):",
            "            raise RuntimeError(",
            "                \"unknown content transfer encoding: {}\" \"\".format(te_encoding)",
            "            )",
            "        if te_encoding == \"binary\":",
            "            te_encoding = None",
            "",
            "        # size",
            "        size = payload.size",
            "        if size is not None and not (encoding or te_encoding):",
            "            payload.headers[CONTENT_LENGTH] = str(size)",
            "",
            "        self._parts.append((payload, encoding, te_encoding))  # type: ignore[arg-type]",
            "        return payload",
            "",
            "    def append_json(",
            "        self, obj: Any, headers: Optional[Mapping[str, str]] = None",
            "    ) -> Payload:",
            "        \"\"\"Helper to append JSON part.\"\"\"",
            "        if headers is None:",
            "            headers = CIMultiDict()",
            "",
            "        return self.append_payload(JsonPayload(obj, headers=headers))",
            "",
            "    def append_form(",
            "        self,",
            "        obj: Union[Sequence[Tuple[str, str]], Mapping[str, str]],",
            "        headers: Optional[Mapping[str, str]] = None,",
            "    ) -> Payload:",
            "        \"\"\"Helper to append form urlencoded part.\"\"\"",
            "        assert isinstance(obj, (Sequence, Mapping))",
            "",
            "        if headers is None:",
            "            headers = CIMultiDict()",
            "",
            "        if isinstance(obj, Mapping):",
            "            obj = list(obj.items())",
            "        data = urlencode(obj, doseq=True)",
            "",
            "        return self.append_payload(",
            "            StringPayload(",
            "                data, headers=headers, content_type=\"application/x-www-form-urlencoded\"",
            "            )",
            "        )",
            "",
            "    @property",
            "    def size(self) -> Optional[int]:",
            "        \"\"\"Size of the payload.\"\"\"",
            "        total = 0",
            "        for part, encoding, te_encoding in self._parts:",
            "            if encoding or te_encoding or part.size is None:",
            "                return None",
            "",
            "            total += int(",
            "                2",
            "                + len(self._boundary)",
            "                + 2",
            "                + part.size  # b'--'+self._boundary+b'\\r\\n'",
            "                + len(part._binary_headers)",
            "                + 2  # b'\\r\\n'",
            "            )",
            "",
            "        total += 2 + len(self._boundary) + 4  # b'--'+self._boundary+b'--\\r\\n'",
            "        return total",
            "",
            "    async def write(self, writer: Any, close_boundary: bool = True) -> None:",
            "        \"\"\"Write body.\"\"\"",
            "        for part, encoding, te_encoding in self._parts:",
            "            await writer.write(b\"--\" + self._boundary + b\"\\r\\n\")",
            "            await writer.write(part._binary_headers)",
            "",
            "            if encoding or te_encoding:",
            "                w = MultipartPayloadWriter(writer)",
            "                if encoding:",
            "                    w.enable_compression(encoding)",
            "                if te_encoding:",
            "                    w.enable_encoding(te_encoding)",
            "                await part.write(w)  # type: ignore[arg-type]",
            "                await w.write_eof()",
            "            else:",
            "                await part.write(writer)",
            "",
            "            await writer.write(b\"\\r\\n\")",
            "",
            "        if close_boundary:",
            "            await writer.write(b\"--\" + self._boundary + b\"--\\r\\n\")",
            "",
            "",
            "class MultipartPayloadWriter:",
            "    def __init__(self, writer: Any) -> None:",
            "        self._writer = writer",
            "        self._encoding: Optional[str] = None",
            "        self._compress: Optional[ZLibCompressor] = None",
            "        self._encoding_buffer: Optional[bytearray] = None",
            "",
            "    def enable_encoding(self, encoding: str) -> None:",
            "        if encoding == \"base64\":",
            "            self._encoding = encoding",
            "            self._encoding_buffer = bytearray()",
            "        elif encoding == \"quoted-printable\":",
            "            self._encoding = \"quoted-printable\"",
            "",
            "    def enable_compression(",
            "        self, encoding: str = \"deflate\", strategy: int = zlib.Z_DEFAULT_STRATEGY",
            "    ) -> None:",
            "        self._compress = ZLibCompressor(",
            "            encoding=encoding,",
            "            suppress_deflate_header=True,",
            "            strategy=strategy,",
            "        )",
            "",
            "    async def write_eof(self) -> None:",
            "        if self._compress is not None:",
            "            chunk = self._compress.flush()",
            "            if chunk:",
            "                self._compress = None",
            "                await self.write(chunk)",
            "",
            "        if self._encoding == \"base64\":",
            "            if self._encoding_buffer:",
            "                await self._writer.write(base64.b64encode(self._encoding_buffer))",
            "",
            "    async def write(self, chunk: bytes) -> None:",
            "        if self._compress is not None:",
            "            if chunk:",
            "                chunk = await self._compress.compress(chunk)",
            "                if not chunk:",
            "                    return",
            "",
            "        if self._encoding == \"base64\":",
            "            buf = self._encoding_buffer",
            "            assert buf is not None",
            "            buf.extend(chunk)",
            "",
            "            if buf:",
            "                div, mod = divmod(len(buf), 3)",
            "                enc_chunk, self._encoding_buffer = (buf[: div * 3], buf[div * 3 :])",
            "                if enc_chunk:",
            "                    b64chunk = base64.b64encode(enc_chunk)",
            "                    await self._writer.write(b64chunk)",
            "        elif self._encoding == \"quoted-printable\":",
            "            await self._writer.write(binascii.b2a_qp(chunk))",
            "        else:",
            "            await self._writer.write(chunk)"
        ],
        "afterPatchFile": [
            "import base64",
            "import binascii",
            "import json",
            "import re",
            "import uuid",
            "import warnings",
            "import zlib",
            "from collections import deque",
            "from types import TracebackType",
            "from typing import (",
            "    TYPE_CHECKING,",
            "    Any,",
            "    AsyncIterator,",
            "    Deque,",
            "    Dict,",
            "    Iterator,",
            "    List,",
            "    Mapping,",
            "    Optional,",
            "    Sequence,",
            "    Tuple,",
            "    Type,",
            "    Union,",
            "    cast,",
            ")",
            "from urllib.parse import parse_qsl, unquote, urlencode",
            "",
            "from multidict import CIMultiDict, CIMultiDictProxy",
            "",
            "from .compression_utils import ZLibCompressor, ZLibDecompressor",
            "from .hdrs import (",
            "    CONTENT_DISPOSITION,",
            "    CONTENT_ENCODING,",
            "    CONTENT_LENGTH,",
            "    CONTENT_TRANSFER_ENCODING,",
            "    CONTENT_TYPE,",
            ")",
            "from .helpers import CHAR, TOKEN, parse_mimetype, reify",
            "from .http import HeadersParser",
            "from .payload import (",
            "    JsonPayload,",
            "    LookupError,",
            "    Order,",
            "    Payload,",
            "    StringPayload,",
            "    get_payload,",
            "    payload_type,",
            ")",
            "from .streams import StreamReader",
            "",
            "__all__ = (",
            "    \"MultipartReader\",",
            "    \"MultipartWriter\",",
            "    \"BodyPartReader\",",
            "    \"BadContentDispositionHeader\",",
            "    \"BadContentDispositionParam\",",
            "    \"parse_content_disposition\",",
            "    \"content_disposition_filename\",",
            ")",
            "",
            "",
            "if TYPE_CHECKING:",
            "    from .client_reqrep import ClientResponse",
            "",
            "",
            "class BadContentDispositionHeader(RuntimeWarning):",
            "    pass",
            "",
            "",
            "class BadContentDispositionParam(RuntimeWarning):",
            "    pass",
            "",
            "",
            "def parse_content_disposition(",
            "    header: Optional[str],",
            ") -> Tuple[Optional[str], Dict[str, str]]:",
            "    def is_token(string: str) -> bool:",
            "        return bool(string) and TOKEN >= set(string)",
            "",
            "    def is_quoted(string: str) -> bool:",
            "        return string[0] == string[-1] == '\"'",
            "",
            "    def is_rfc5987(string: str) -> bool:",
            "        return is_token(string) and string.count(\"'\") == 2",
            "",
            "    def is_extended_param(string: str) -> bool:",
            "        return string.endswith(\"*\")",
            "",
            "    def is_continuous_param(string: str) -> bool:",
            "        pos = string.find(\"*\") + 1",
            "        if not pos:",
            "            return False",
            "        substring = string[pos:-1] if string.endswith(\"*\") else string[pos:]",
            "        return substring.isdigit()",
            "",
            "    def unescape(text: str, *, chars: str = \"\".join(map(re.escape, CHAR))) -> str:",
            "        return re.sub(f\"\\\\\\\\([{chars}])\", \"\\\\1\", text)",
            "",
            "    if not header:",
            "        return None, {}",
            "",
            "    disptype, *parts = header.split(\";\")",
            "    if not is_token(disptype):",
            "        warnings.warn(BadContentDispositionHeader(header))",
            "        return None, {}",
            "",
            "    params: Dict[str, str] = {}",
            "    while parts:",
            "        item = parts.pop(0)",
            "",
            "        if \"=\" not in item:",
            "            warnings.warn(BadContentDispositionHeader(header))",
            "            return None, {}",
            "",
            "        key, value = item.split(\"=\", 1)",
            "        key = key.lower().strip()",
            "        value = value.lstrip()",
            "",
            "        if key in params:",
            "            warnings.warn(BadContentDispositionHeader(header))",
            "            return None, {}",
            "",
            "        if not is_token(key):",
            "            warnings.warn(BadContentDispositionParam(item))",
            "            continue",
            "",
            "        elif is_continuous_param(key):",
            "            if is_quoted(value):",
            "                value = unescape(value[1:-1])",
            "            elif not is_token(value):",
            "                warnings.warn(BadContentDispositionParam(item))",
            "                continue",
            "",
            "        elif is_extended_param(key):",
            "            if is_rfc5987(value):",
            "                encoding, _, value = value.split(\"'\", 2)",
            "                encoding = encoding or \"utf-8\"",
            "            else:",
            "                warnings.warn(BadContentDispositionParam(item))",
            "                continue",
            "",
            "            try:",
            "                value = unquote(value, encoding, \"strict\")",
            "            except UnicodeDecodeError:  # pragma: nocover",
            "                warnings.warn(BadContentDispositionParam(item))",
            "                continue",
            "",
            "        else:",
            "            failed = True",
            "            if is_quoted(value):",
            "                failed = False",
            "                value = unescape(value[1:-1].lstrip(\"\\\\/\"))",
            "            elif is_token(value):",
            "                failed = False",
            "            elif parts:",
            "                # maybe just ; in filename, in any case this is just",
            "                # one case fix, for proper fix we need to redesign parser",
            "                _value = f\"{value};{parts[0]}\"",
            "                if is_quoted(_value):",
            "                    parts.pop(0)",
            "                    value = unescape(_value[1:-1].lstrip(\"\\\\/\"))",
            "                    failed = False",
            "",
            "            if failed:",
            "                warnings.warn(BadContentDispositionHeader(header))",
            "                return None, {}",
            "",
            "        params[key] = value",
            "",
            "    return disptype.lower(), params",
            "",
            "",
            "def content_disposition_filename(",
            "    params: Mapping[str, str], name: str = \"filename\"",
            ") -> Optional[str]:",
            "    name_suf = \"%s*\" % name",
            "    if not params:",
            "        return None",
            "    elif name_suf in params:",
            "        return params[name_suf]",
            "    elif name in params:",
            "        return params[name]",
            "    else:",
            "        parts = []",
            "        fnparams = sorted(",
            "            (key, value) for key, value in params.items() if key.startswith(name_suf)",
            "        )",
            "        for num, (key, value) in enumerate(fnparams):",
            "            _, tail = key.split(\"*\", 1)",
            "            if tail.endswith(\"*\"):",
            "                tail = tail[:-1]",
            "            if tail == str(num):",
            "                parts.append(value)",
            "            else:",
            "                break",
            "        if not parts:",
            "            return None",
            "        value = \"\".join(parts)",
            "        if \"'\" in value:",
            "            encoding, _, value = value.split(\"'\", 2)",
            "            encoding = encoding or \"utf-8\"",
            "            return unquote(value, encoding, \"strict\")",
            "        return value",
            "",
            "",
            "class MultipartResponseWrapper:",
            "    \"\"\"Wrapper around the MultipartReader.",
            "",
            "    It takes care about",
            "    underlying connection and close it when it needs in.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        resp: \"ClientResponse\",",
            "        stream: \"MultipartReader\",",
            "    ) -> None:",
            "        self.resp = resp",
            "        self.stream = stream",
            "",
            "    def __aiter__(self) -> \"MultipartResponseWrapper\":",
            "        return self",
            "",
            "    async def __anext__(",
            "        self,",
            "    ) -> Union[\"MultipartReader\", \"BodyPartReader\"]:",
            "        part = await self.next()",
            "        if part is None:",
            "            raise StopAsyncIteration",
            "        return part",
            "",
            "    def at_eof(self) -> bool:",
            "        \"\"\"Returns True when all response data had been read.\"\"\"",
            "        return self.resp.content.at_eof()",
            "",
            "    async def next(",
            "        self,",
            "    ) -> Optional[Union[\"MultipartReader\", \"BodyPartReader\"]]:",
            "        \"\"\"Emits next multipart reader object.\"\"\"",
            "        item = await self.stream.next()",
            "        if self.stream.at_eof():",
            "            await self.release()",
            "        return item",
            "",
            "    async def release(self) -> None:",
            "        \"\"\"Release the connection gracefully.",
            "",
            "        All remaining content is read to the void.",
            "        \"\"\"",
            "        await self.resp.release()",
            "",
            "",
            "class BodyPartReader:",
            "    \"\"\"Multipart reader for single body part.\"\"\"",
            "",
            "    chunk_size = 8192",
            "",
            "    def __init__(",
            "        self,",
            "        boundary: bytes,",
            "        headers: \"CIMultiDictProxy[str]\",",
            "        content: StreamReader,",
            "        *,",
            "        subtype: str = \"mixed\",",
            "        default_charset: Optional[str] = None,",
            "    ) -> None:",
            "        self.headers = headers",
            "        self._boundary = boundary",
            "        self._content = content",
            "        self._default_charset = default_charset",
            "        self._at_eof = False",
            "        self._is_form_data = subtype == \"form-data\"",
            "        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8",
            "        length = None if self._is_form_data else self.headers.get(CONTENT_LENGTH, None)",
            "        self._length = int(length) if length is not None else None",
            "        self._read_bytes = 0",
            "        self._unread: Deque[bytes] = deque()",
            "        self._prev_chunk: Optional[bytes] = None",
            "        self._content_eof = 0",
            "        self._cache: Dict[str, Any] = {}",
            "",
            "    def __aiter__(self) -> AsyncIterator[\"BodyPartReader\"]:",
            "        return self  # type: ignore[return-value]",
            "",
            "    async def __anext__(self) -> bytes:",
            "        part = await self.next()",
            "        if part is None:",
            "            raise StopAsyncIteration",
            "        return part",
            "",
            "    async def next(self) -> Optional[bytes]:",
            "        item = await self.read()",
            "        if not item:",
            "            return None",
            "        return item",
            "",
            "    async def read(self, *, decode: bool = False) -> bytes:",
            "        \"\"\"Reads body part data.",
            "",
            "        decode: Decodes data following by encoding",
            "                method from Content-Encoding header. If it missed",
            "                data remains untouched",
            "        \"\"\"",
            "        if self._at_eof:",
            "            return b\"\"",
            "        data = bytearray()",
            "        while not self._at_eof:",
            "            data.extend(await self.read_chunk(self.chunk_size))",
            "        if decode:",
            "            return self.decode(data)",
            "        return data",
            "",
            "    async def read_chunk(self, size: int = chunk_size) -> bytes:",
            "        \"\"\"Reads body part content chunk of the specified size.",
            "",
            "        size: chunk size",
            "        \"\"\"",
            "        if self._at_eof:",
            "            return b\"\"",
            "        if self._length:",
            "            chunk = await self._read_chunk_from_length(size)",
            "        else:",
            "            chunk = await self._read_chunk_from_stream(size)",
            "",
            "        self._read_bytes += len(chunk)",
            "        if self._read_bytes == self._length:",
            "            self._at_eof = True",
            "        if self._at_eof:",
            "            clrf = await self._content.readline()",
            "            assert (",
            "                b\"\\r\\n\" == clrf",
            "            ), \"reader did not read all the data or it is malformed\"",
            "        return chunk",
            "",
            "    async def _read_chunk_from_length(self, size: int) -> bytes:",
            "        # Reads body part content chunk of the specified size.",
            "        # The body part must has Content-Length header with proper value.",
            "        assert self._length is not None, \"Content-Length required for chunked read\"",
            "        chunk_size = min(size, self._length - self._read_bytes)",
            "        chunk = await self._content.read(chunk_size)",
            "        if self._content.at_eof():",
            "            self._at_eof = True",
            "        return chunk",
            "",
            "    async def _read_chunk_from_stream(self, size: int) -> bytes:",
            "        # Reads content chunk of body part with unknown length.",
            "        # The Content-Length header for body part is not necessary.",
            "        assert (",
            "            size >= len(self._boundary) + 2",
            "        ), \"Chunk size must be greater or equal than boundary length + 2\"",
            "        first_chunk = self._prev_chunk is None",
            "        if first_chunk:",
            "            self._prev_chunk = await self._content.read(size)",
            "",
            "        chunk = await self._content.read(size)",
            "        self._content_eof += int(self._content.at_eof())",
            "        assert self._content_eof < 3, \"Reading after EOF\"",
            "        assert self._prev_chunk is not None",
            "        window = self._prev_chunk + chunk",
            "        sub = b\"\\r\\n\" + self._boundary",
            "        if first_chunk:",
            "            idx = window.find(sub)",
            "        else:",
            "            idx = window.find(sub, max(0, len(self._prev_chunk) - len(sub)))",
            "        if idx >= 0:",
            "            # pushing boundary back to content",
            "            with warnings.catch_warnings():",
            "                warnings.filterwarnings(\"ignore\", category=DeprecationWarning)",
            "                self._content.unread_data(window[idx:])",
            "            if size > idx:",
            "                self._prev_chunk = self._prev_chunk[:idx]",
            "            chunk = window[len(self._prev_chunk) : idx]",
            "            if not chunk:",
            "                self._at_eof = True",
            "        result = self._prev_chunk",
            "        self._prev_chunk = chunk",
            "        return result",
            "",
            "    async def readline(self) -> bytes:",
            "        \"\"\"Reads body part by line by line.\"\"\"",
            "        if self._at_eof:",
            "            return b\"\"",
            "",
            "        if self._unread:",
            "            line = self._unread.popleft()",
            "        else:",
            "            line = await self._content.readline()",
            "",
            "        if line.startswith(self._boundary):",
            "            # the very last boundary may not come with \\r\\n,",
            "            # so set single rules for everyone",
            "            sline = line.rstrip(b\"\\r\\n\")",
            "            boundary = self._boundary",
            "            last_boundary = self._boundary + b\"--\"",
            "            # ensure that we read exactly the boundary, not something alike",
            "            if sline == boundary or sline == last_boundary:",
            "                self._at_eof = True",
            "                self._unread.append(line)",
            "                return b\"\"",
            "        else:",
            "            next_line = await self._content.readline()",
            "            if next_line.startswith(self._boundary):",
            "                line = line[:-2]  # strip CRLF but only once",
            "            self._unread.append(next_line)",
            "",
            "        return line",
            "",
            "    async def release(self) -> None:",
            "        \"\"\"Like read(), but reads all the data to the void.\"\"\"",
            "        if self._at_eof:",
            "            return",
            "        while not self._at_eof:",
            "            await self.read_chunk(self.chunk_size)",
            "",
            "    async def text(self, *, encoding: Optional[str] = None) -> str:",
            "        \"\"\"Like read(), but assumes that body part contains text data.\"\"\"",
            "        data = await self.read(decode=True)",
            "        # see https://www.w3.org/TR/html5/forms.html#multipart/form-data-encoding-algorithm",
            "        # and https://dvcs.w3.org/hg/xhr/raw-file/tip/Overview.html#dom-xmlhttprequest-send",
            "        encoding = encoding or self.get_charset(default=\"utf-8\")",
            "        return data.decode(encoding)",
            "",
            "    async def json(self, *, encoding: Optional[str] = None) -> Optional[Dict[str, Any]]:",
            "        \"\"\"Like read(), but assumes that body parts contains JSON data.\"\"\"",
            "        data = await self.read(decode=True)",
            "        if not data:",
            "            return None",
            "        encoding = encoding or self.get_charset(default=\"utf-8\")",
            "        return cast(Dict[str, Any], json.loads(data.decode(encoding)))",
            "",
            "    async def form(self, *, encoding: Optional[str] = None) -> List[Tuple[str, str]]:",
            "        \"\"\"Like read(), but assumes that body parts contain form urlencoded data.\"\"\"",
            "        data = await self.read(decode=True)",
            "        if not data:",
            "            return []",
            "        if encoding is not None:",
            "            real_encoding = encoding",
            "        else:",
            "            real_encoding = self.get_charset(default=\"utf-8\")",
            "        try:",
            "            decoded_data = data.rstrip().decode(real_encoding)",
            "        except UnicodeDecodeError:",
            "            raise ValueError(\"data cannot be decoded with %s encoding\" % real_encoding)",
            "",
            "        return parse_qsl(",
            "            decoded_data,",
            "            keep_blank_values=True,",
            "            encoding=real_encoding,",
            "        )",
            "",
            "    def at_eof(self) -> bool:",
            "        \"\"\"Returns True if the boundary was reached or False otherwise.\"\"\"",
            "        return self._at_eof",
            "",
            "    def decode(self, data: bytes) -> bytes:",
            "        \"\"\"Decodes data.",
            "",
            "        Decoding is done according the specified Content-Encoding",
            "        or Content-Transfer-Encoding headers value.",
            "        \"\"\"",
            "        if CONTENT_TRANSFER_ENCODING in self.headers:",
            "            data = self._decode_content_transfer(data)",
            "        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8",
            "        if not self._is_form_data and CONTENT_ENCODING in self.headers:",
            "            return self._decode_content(data)",
            "        return data",
            "",
            "    def _decode_content(self, data: bytes) -> bytes:",
            "        encoding = self.headers.get(CONTENT_ENCODING, \"\").lower()",
            "        if encoding == \"identity\":",
            "            return data",
            "        if encoding in {\"deflate\", \"gzip\"}:",
            "            return ZLibDecompressor(",
            "                encoding=encoding,",
            "                suppress_deflate_header=True,",
            "            ).decompress_sync(data)",
            "",
            "        raise RuntimeError(f\"unknown content encoding: {encoding}\")",
            "",
            "    def _decode_content_transfer(self, data: bytes) -> bytes:",
            "        encoding = self.headers.get(CONTENT_TRANSFER_ENCODING, \"\").lower()",
            "",
            "        if encoding == \"base64\":",
            "            return base64.b64decode(data)",
            "        elif encoding == \"quoted-printable\":",
            "            return binascii.a2b_qp(data)",
            "        elif encoding in (\"binary\", \"8bit\", \"7bit\"):",
            "            return data",
            "        else:",
            "            raise RuntimeError(",
            "                \"unknown content transfer encoding: {}\" \"\".format(encoding)",
            "            )",
            "",
            "    def get_charset(self, default: str) -> str:",
            "        \"\"\"Returns charset parameter from Content-Type header or default.\"\"\"",
            "        ctype = self.headers.get(CONTENT_TYPE, \"\")",
            "        mimetype = parse_mimetype(ctype)",
            "        return mimetype.parameters.get(\"charset\", self._default_charset or default)",
            "",
            "    @reify",
            "    def name(self) -> Optional[str]:",
            "        \"\"\"Returns name specified in Content-Disposition header.",
            "",
            "        If the header is missing or malformed, returns None.",
            "        \"\"\"",
            "        _, params = parse_content_disposition(self.headers.get(CONTENT_DISPOSITION))",
            "        return content_disposition_filename(params, \"name\")",
            "",
            "    @reify",
            "    def filename(self) -> Optional[str]:",
            "        \"\"\"Returns filename specified in Content-Disposition header.",
            "",
            "        Returns None if the header is missing or malformed.",
            "        \"\"\"",
            "        _, params = parse_content_disposition(self.headers.get(CONTENT_DISPOSITION))",
            "        return content_disposition_filename(params, \"filename\")",
            "",
            "",
            "@payload_type(BodyPartReader, order=Order.try_first)",
            "class BodyPartReaderPayload(Payload):",
            "    def __init__(self, value: BodyPartReader, *args: Any, **kwargs: Any) -> None:",
            "        super().__init__(value, *args, **kwargs)",
            "",
            "        params: Dict[str, str] = {}",
            "        if value.name is not None:",
            "            params[\"name\"] = value.name",
            "        if value.filename is not None:",
            "            params[\"filename\"] = value.filename",
            "",
            "        if params:",
            "            self.set_content_disposition(\"attachment\", True, **params)",
            "",
            "    async def write(self, writer: Any) -> None:",
            "        field = self._value",
            "        chunk = await field.read_chunk(size=2**16)",
            "        while chunk:",
            "            await writer.write(field.decode(chunk))",
            "            chunk = await field.read_chunk(size=2**16)",
            "",
            "",
            "class MultipartReader:",
            "    \"\"\"Multipart body reader.\"\"\"",
            "",
            "    #: Response wrapper, used when multipart readers constructs from response.",
            "    response_wrapper_cls = MultipartResponseWrapper",
            "    #: Multipart reader class, used to handle multipart/* body parts.",
            "    #: None points to type(self)",
            "    multipart_reader_cls = None",
            "    #: Body part reader class for non multipart/* content types.",
            "    part_reader_cls = BodyPartReader",
            "",
            "    def __init__(self, headers: Mapping[str, str], content: StreamReader) -> None:",
            "        self._mimetype = parse_mimetype(headers[CONTENT_TYPE])",
            "        assert self._mimetype.type == \"multipart\", \"multipart/* content type expected\"",
            "        if \"boundary\" not in self._mimetype.parameters:",
            "            raise ValueError(",
            "                \"boundary missed for Content-Type: %s\" % headers[CONTENT_TYPE]",
            "            )",
            "",
            "        self.headers = headers",
            "        self._boundary = (\"--\" + self._get_boundary()).encode()",
            "        self._content = content",
            "        self._default_charset: Optional[str] = None",
            "        self._last_part: Optional[Union[\"MultipartReader\", BodyPartReader]] = None",
            "        self._at_eof = False",
            "        self._at_bof = True",
            "        self._unread: List[bytes] = []",
            "",
            "    def __aiter__(",
            "        self,",
            "    ) -> AsyncIterator[\"BodyPartReader\"]:",
            "        return self  # type: ignore[return-value]",
            "",
            "    async def __anext__(",
            "        self,",
            "    ) -> Optional[Union[\"MultipartReader\", BodyPartReader]]:",
            "        part = await self.next()",
            "        if part is None:",
            "            raise StopAsyncIteration",
            "        return part",
            "",
            "    @classmethod",
            "    def from_response(",
            "        cls,",
            "        response: \"ClientResponse\",",
            "    ) -> MultipartResponseWrapper:",
            "        \"\"\"Constructs reader instance from HTTP response.",
            "",
            "        :param response: :class:`~aiohttp.client.ClientResponse` instance",
            "        \"\"\"",
            "        obj = cls.response_wrapper_cls(",
            "            response, cls(response.headers, response.content)",
            "        )",
            "        return obj",
            "",
            "    def at_eof(self) -> bool:",
            "        \"\"\"Returns True if the final boundary was reached, false otherwise.\"\"\"",
            "        return self._at_eof",
            "",
            "    async def next(",
            "        self,",
            "    ) -> Optional[Union[\"MultipartReader\", BodyPartReader]]:",
            "        \"\"\"Emits the next multipart body part.\"\"\"",
            "        # So, if we're at BOF, we need to skip till the boundary.",
            "        if self._at_eof:",
            "            return None",
            "        await self._maybe_release_last_part()",
            "        if self._at_bof:",
            "            await self._read_until_first_boundary()",
            "            self._at_bof = False",
            "        else:",
            "            await self._read_boundary()",
            "        if self._at_eof:  # we just read the last boundary, nothing to do there",
            "            return None",
            "",
            "        part = await self.fetch_next_part()",
            "        # https://datatracker.ietf.org/doc/html/rfc7578#section-4.6",
            "        if (",
            "            self._last_part is None",
            "            and self._mimetype.subtype == \"form-data\"",
            "            and isinstance(part, BodyPartReader)",
            "        ):",
            "            _, params = parse_content_disposition(part.headers.get(CONTENT_DISPOSITION))",
            "            if params.get(\"name\") == \"_charset_\":",
            "                # Longest encoding in https://encoding.spec.whatwg.org/encodings.json",
            "                # is 19 characters, so 32 should be more than enough for any valid encoding.",
            "                charset = await part.read_chunk(32)",
            "                if len(charset) > 31:",
            "                    raise RuntimeError(\"Invalid default charset\")",
            "                self._default_charset = charset.strip().decode()",
            "                part = await self.fetch_next_part()",
            "        self._last_part = part",
            "        return self._last_part",
            "",
            "    async def release(self) -> None:",
            "        \"\"\"Reads all the body parts to the void till the final boundary.\"\"\"",
            "        while not self._at_eof:",
            "            item = await self.next()",
            "            if item is None:",
            "                break",
            "            await item.release()",
            "",
            "    async def fetch_next_part(",
            "        self,",
            "    ) -> Union[\"MultipartReader\", BodyPartReader]:",
            "        \"\"\"Returns the next body part reader.\"\"\"",
            "        headers = await self._read_headers()",
            "        return self._get_part_reader(headers)",
            "",
            "    def _get_part_reader(",
            "        self,",
            "        headers: \"CIMultiDictProxy[str]\",",
            "    ) -> Union[\"MultipartReader\", BodyPartReader]:",
            "        \"\"\"Dispatches the response by the `Content-Type` header.",
            "",
            "        Returns a suitable reader instance.",
            "",
            "        :param dict headers: Response headers",
            "        \"\"\"",
            "        ctype = headers.get(CONTENT_TYPE, \"\")",
            "        mimetype = parse_mimetype(ctype)",
            "",
            "        if mimetype.type == \"multipart\":",
            "            if self.multipart_reader_cls is None:",
            "                return type(self)(headers, self._content)",
            "            return self.multipart_reader_cls(headers, self._content)",
            "        else:",
            "            return self.part_reader_cls(",
            "                self._boundary,",
            "                headers,",
            "                self._content,",
            "                subtype=self._mimetype.subtype,",
            "                default_charset=self._default_charset,",
            "            )",
            "",
            "    def _get_boundary(self) -> str:",
            "        boundary = self._mimetype.parameters[\"boundary\"]",
            "        if len(boundary) > 70:",
            "            raise ValueError(\"boundary %r is too long (70 chars max)\" % boundary)",
            "",
            "        return boundary",
            "",
            "    async def _readline(self) -> bytes:",
            "        if self._unread:",
            "            return self._unread.pop()",
            "        return await self._content.readline()",
            "",
            "    async def _read_until_first_boundary(self) -> None:",
            "        while True:",
            "            chunk = await self._readline()",
            "            if chunk == b\"\":",
            "                raise ValueError(",
            "                    \"Could not find starting boundary %r\" % (self._boundary)",
            "                )",
            "            chunk = chunk.rstrip()",
            "            if chunk == self._boundary:",
            "                return",
            "            elif chunk == self._boundary + b\"--\":",
            "                self._at_eof = True",
            "                return",
            "",
            "    async def _read_boundary(self) -> None:",
            "        chunk = (await self._readline()).rstrip()",
            "        if chunk == self._boundary:",
            "            pass",
            "        elif chunk == self._boundary + b\"--\":",
            "            self._at_eof = True",
            "            epilogue = await self._readline()",
            "            next_line = await self._readline()",
            "",
            "            # the epilogue is expected and then either the end of input or the",
            "            # parent multipart boundary, if the parent boundary is found then",
            "            # it should be marked as unread and handed to the parent for",
            "            # processing",
            "            if next_line[:2] == b\"--\":",
            "                self._unread.append(next_line)",
            "            # otherwise the request is likely missing an epilogue and both",
            "            # lines should be passed to the parent for processing",
            "            # (this handles the old behavior gracefully)",
            "            else:",
            "                self._unread.extend([next_line, epilogue])",
            "        else:",
            "            raise ValueError(f\"Invalid boundary {chunk!r}, expected {self._boundary!r}\")",
            "",
            "    async def _read_headers(self) -> \"CIMultiDictProxy[str]\":",
            "        lines = [b\"\"]",
            "        while True:",
            "            chunk = await self._content.readline()",
            "            chunk = chunk.strip()",
            "            lines.append(chunk)",
            "            if not chunk:",
            "                break",
            "        parser = HeadersParser()",
            "        headers, raw_headers = parser.parse_headers(lines)",
            "        return headers",
            "",
            "    async def _maybe_release_last_part(self) -> None:",
            "        \"\"\"Ensures that the last read body part is read completely.\"\"\"",
            "        if self._last_part is not None:",
            "            if not self._last_part.at_eof():",
            "                await self._last_part.release()",
            "            self._unread.extend(self._last_part._unread)",
            "            self._last_part = None",
            "",
            "",
            "_Part = Tuple[Payload, str, str]",
            "",
            "",
            "class MultipartWriter(Payload):",
            "    \"\"\"Multipart body writer.\"\"\"",
            "",
            "    def __init__(self, subtype: str = \"mixed\", boundary: Optional[str] = None) -> None:",
            "        boundary = boundary if boundary is not None else uuid.uuid4().hex",
            "        # The underlying Payload API demands a str (utf-8), not bytes,",
            "        # so we need to ensure we don't lose anything during conversion.",
            "        # As a result, require the boundary to be ASCII only.",
            "        # In both situations.",
            "",
            "        try:",
            "            self._boundary = boundary.encode(\"ascii\")",
            "        except UnicodeEncodeError:",
            "            raise ValueError(\"boundary should contain ASCII only chars\") from None",
            "        ctype = f\"multipart/{subtype}; boundary={self._boundary_value}\"",
            "",
            "        super().__init__(None, content_type=ctype)",
            "",
            "        self._parts: List[_Part] = []",
            "        self._is_form_data = subtype == \"form-data\"",
            "",
            "    def __enter__(self) -> \"MultipartWriter\":",
            "        return self",
            "",
            "    def __exit__(",
            "        self,",
            "        exc_type: Optional[Type[BaseException]],",
            "        exc_val: Optional[BaseException],",
            "        exc_tb: Optional[TracebackType],",
            "    ) -> None:",
            "        pass",
            "",
            "    def __iter__(self) -> Iterator[_Part]:",
            "        return iter(self._parts)",
            "",
            "    def __len__(self) -> int:",
            "        return len(self._parts)",
            "",
            "    def __bool__(self) -> bool:",
            "        return True",
            "",
            "    _valid_tchar_regex = re.compile(rb\"\\A[!#$%&'*+\\-.^_`|~\\w]+\\Z\")",
            "    _invalid_qdtext_char_regex = re.compile(rb\"[\\x00-\\x08\\x0A-\\x1F\\x7F]\")",
            "",
            "    @property",
            "    def _boundary_value(self) -> str:",
            "        \"\"\"Wrap boundary parameter value in quotes, if necessary.",
            "",
            "        Reads self.boundary and returns a unicode string.",
            "        \"\"\"",
            "        # Refer to RFCs 7231, 7230, 5234.",
            "        #",
            "        # parameter      = token \"=\" ( token / quoted-string )",
            "        # token          = 1*tchar",
            "        # quoted-string  = DQUOTE *( qdtext / quoted-pair ) DQUOTE",
            "        # qdtext         = HTAB / SP / %x21 / %x23-5B / %x5D-7E / obs-text",
            "        # obs-text       = %x80-FF",
            "        # quoted-pair    = \"\\\" ( HTAB / SP / VCHAR / obs-text )",
            "        # tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"",
            "        #                  / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"",
            "        #                  / DIGIT / ALPHA",
            "        #                  ; any VCHAR, except delimiters",
            "        # VCHAR           = %x21-7E",
            "        value = self._boundary",
            "        if re.match(self._valid_tchar_regex, value):",
            "            return value.decode(\"ascii\")  # cannot fail",
            "",
            "        if re.search(self._invalid_qdtext_char_regex, value):",
            "            raise ValueError(\"boundary value contains invalid characters\")",
            "",
            "        # escape %x5C and %x22",
            "        quoted_value_content = value.replace(b\"\\\\\", b\"\\\\\\\\\")",
            "        quoted_value_content = quoted_value_content.replace(b'\"', b'\\\\\"')",
            "",
            "        return '\"' + quoted_value_content.decode(\"ascii\") + '\"'",
            "",
            "    @property",
            "    def boundary(self) -> str:",
            "        return self._boundary.decode(\"ascii\")",
            "",
            "    def append(self, obj: Any, headers: Optional[Mapping[str, str]] = None) -> Payload:",
            "        if headers is None:",
            "            headers = CIMultiDict()",
            "",
            "        if isinstance(obj, Payload):",
            "            obj.headers.update(headers)",
            "            return self.append_payload(obj)",
            "        else:",
            "            try:",
            "                payload = get_payload(obj, headers=headers)",
            "            except LookupError:",
            "                raise TypeError(\"Cannot create payload from %r\" % obj)",
            "            else:",
            "                return self.append_payload(payload)",
            "",
            "    def append_payload(self, payload: Payload) -> Payload:",
            "        \"\"\"Adds a new body part to multipart writer.\"\"\"",
            "        encoding: Optional[str] = None",
            "        te_encoding: Optional[str] = None",
            "        if self._is_form_data:",
            "            # https://datatracker.ietf.org/doc/html/rfc7578#section-4.7",
            "            # https://datatracker.ietf.org/doc/html/rfc7578#section-4.8",
            "            assert CONTENT_DISPOSITION in payload.headers",
            "            assert \"name=\" in payload.headers[CONTENT_DISPOSITION]",
            "            assert (",
            "                not {CONTENT_ENCODING, CONTENT_LENGTH, CONTENT_TRANSFER_ENCODING}",
            "                & payload.headers.keys()",
            "            )",
            "        else:",
            "            # compression",
            "            encoding = payload.headers.get(CONTENT_ENCODING, \"\").lower()",
            "            if encoding and encoding not in (\"deflate\", \"gzip\", \"identity\"):",
            "                raise RuntimeError(f\"unknown content encoding: {encoding}\")",
            "            if encoding == \"identity\":",
            "                encoding = None",
            "",
            "            # te encoding",
            "            te_encoding = payload.headers.get(CONTENT_TRANSFER_ENCODING, \"\").lower()",
            "            if te_encoding not in (\"\", \"base64\", \"quoted-printable\", \"binary\"):",
            "                raise RuntimeError(f\"unknown content transfer encoding: {te_encoding}\")",
            "            if te_encoding == \"binary\":",
            "                te_encoding = None",
            "",
            "            # size",
            "            size = payload.size",
            "            if size is not None and not (encoding or te_encoding):",
            "                payload.headers[CONTENT_LENGTH] = str(size)",
            "",
            "        self._parts.append((payload, encoding, te_encoding))  # type: ignore[arg-type]",
            "        return payload",
            "",
            "    def append_json(",
            "        self, obj: Any, headers: Optional[Mapping[str, str]] = None",
            "    ) -> Payload:",
            "        \"\"\"Helper to append JSON part.\"\"\"",
            "        if headers is None:",
            "            headers = CIMultiDict()",
            "",
            "        return self.append_payload(JsonPayload(obj, headers=headers))",
            "",
            "    def append_form(",
            "        self,",
            "        obj: Union[Sequence[Tuple[str, str]], Mapping[str, str]],",
            "        headers: Optional[Mapping[str, str]] = None,",
            "    ) -> Payload:",
            "        \"\"\"Helper to append form urlencoded part.\"\"\"",
            "        assert isinstance(obj, (Sequence, Mapping))",
            "",
            "        if headers is None:",
            "            headers = CIMultiDict()",
            "",
            "        if isinstance(obj, Mapping):",
            "            obj = list(obj.items())",
            "        data = urlencode(obj, doseq=True)",
            "",
            "        return self.append_payload(",
            "            StringPayload(",
            "                data, headers=headers, content_type=\"application/x-www-form-urlencoded\"",
            "            )",
            "        )",
            "",
            "    @property",
            "    def size(self) -> Optional[int]:",
            "        \"\"\"Size of the payload.\"\"\"",
            "        total = 0",
            "        for part, encoding, te_encoding in self._parts:",
            "            if encoding or te_encoding or part.size is None:",
            "                return None",
            "",
            "            total += int(",
            "                2",
            "                + len(self._boundary)",
            "                + 2",
            "                + part.size  # b'--'+self._boundary+b'\\r\\n'",
            "                + len(part._binary_headers)",
            "                + 2  # b'\\r\\n'",
            "            )",
            "",
            "        total += 2 + len(self._boundary) + 4  # b'--'+self._boundary+b'--\\r\\n'",
            "        return total",
            "",
            "    async def write(self, writer: Any, close_boundary: bool = True) -> None:",
            "        \"\"\"Write body.\"\"\"",
            "        for part, encoding, te_encoding in self._parts:",
            "            await writer.write(b\"--\" + self._boundary + b\"\\r\\n\")",
            "            await writer.write(part._binary_headers)",
            "",
            "            if encoding or te_encoding:",
            "                w = MultipartPayloadWriter(writer)",
            "                if encoding:",
            "                    w.enable_compression(encoding)",
            "                if te_encoding:",
            "                    w.enable_encoding(te_encoding)",
            "                await part.write(w)  # type: ignore[arg-type]",
            "                await w.write_eof()",
            "            else:",
            "                await part.write(writer)",
            "",
            "            await writer.write(b\"\\r\\n\")",
            "",
            "        if close_boundary:",
            "            await writer.write(b\"--\" + self._boundary + b\"--\\r\\n\")",
            "",
            "",
            "class MultipartPayloadWriter:",
            "    def __init__(self, writer: Any) -> None:",
            "        self._writer = writer",
            "        self._encoding: Optional[str] = None",
            "        self._compress: Optional[ZLibCompressor] = None",
            "        self._encoding_buffer: Optional[bytearray] = None",
            "",
            "    def enable_encoding(self, encoding: str) -> None:",
            "        if encoding == \"base64\":",
            "            self._encoding = encoding",
            "            self._encoding_buffer = bytearray()",
            "        elif encoding == \"quoted-printable\":",
            "            self._encoding = \"quoted-printable\"",
            "",
            "    def enable_compression(",
            "        self, encoding: str = \"deflate\", strategy: int = zlib.Z_DEFAULT_STRATEGY",
            "    ) -> None:",
            "        self._compress = ZLibCompressor(",
            "            encoding=encoding,",
            "            suppress_deflate_header=True,",
            "            strategy=strategy,",
            "        )",
            "",
            "    async def write_eof(self) -> None:",
            "        if self._compress is not None:",
            "            chunk = self._compress.flush()",
            "            if chunk:",
            "                self._compress = None",
            "                await self.write(chunk)",
            "",
            "        if self._encoding == \"base64\":",
            "            if self._encoding_buffer:",
            "                await self._writer.write(base64.b64encode(self._encoding_buffer))",
            "",
            "    async def write(self, chunk: bytes) -> None:",
            "        if self._compress is not None:",
            "            if chunk:",
            "                chunk = await self._compress.compress(chunk)",
            "                if not chunk:",
            "                    return",
            "",
            "        if self._encoding == \"base64\":",
            "            buf = self._encoding_buffer",
            "            assert buf is not None",
            "            buf.extend(chunk)",
            "",
            "            if buf:",
            "                div, mod = divmod(len(buf), 3)",
            "                enc_chunk, self._encoding_buffer = (buf[: div * 3], buf[div * 3 :])",
            "                if enc_chunk:",
            "                    b64chunk = base64.b64encode(enc_chunk)",
            "                    await self._writer.write(b64chunk)",
            "        elif self._encoding == \"quoted-printable\":",
            "            await self._writer.write(binascii.b2a_qp(chunk))",
            "        else:",
            "            await self._writer.write(chunk)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "259": [
                "BodyPartReader",
                "__init__"
            ],
            "265": [
                "BodyPartReader",
                "__init__"
            ],
            "452": [
                "BodyPartReader",
                "decode"
            ],
            "486": [
                "BodyPartReader",
                "get_charset"
            ],
            "595": [
                "MultipartReader"
            ],
            "631": [
                "MultipartReader",
                "_get_part_reader"
            ],
            "632": [
                "MultipartReader"
            ],
            "633": [
                "MultipartReader",
                "_get_boundary"
            ],
            "634": [
                "MultipartReader",
                "_get_boundary"
            ],
            "635": [
                "MultipartReader",
                "_get_boundary"
            ],
            "636": [
                "MultipartReader",
                "_get_boundary"
            ],
            "637": [
                "MultipartReader",
                "_get_boundary"
            ],
            "638": [
                "MultipartReader",
                "_get_boundary"
            ],
            "639": [
                "MultipartReader",
                "_get_boundary"
            ],
            "640": [
                "MultipartReader",
                "_get_boundary"
            ],
            "643": [
                "MultipartReader",
                "_get_boundary"
            ],
            "811": [
                "MultipartWriter",
                "append_payload"
            ],
            "812": [
                "MultipartWriter",
                "append_payload"
            ],
            "813": [
                "MultipartWriter",
                "append_payload"
            ],
            "814": [
                "MultipartWriter",
                "append_payload"
            ],
            "815": [
                "MultipartWriter",
                "append_payload"
            ],
            "816": [
                "MultipartWriter",
                "append_payload"
            ],
            "817": [
                "MultipartWriter",
                "append_payload"
            ],
            "818": [
                "MultipartWriter",
                "append_payload"
            ],
            "819": [
                "MultipartWriter",
                "append_payload"
            ],
            "820": [
                "MultipartWriter",
                "append_payload"
            ],
            "821": [
                "MultipartWriter",
                "append_payload"
            ],
            "822": [
                "MultipartWriter",
                "append_payload"
            ],
            "823": [
                "MultipartWriter",
                "append_payload"
            ],
            "824": [
                "MultipartWriter",
                "append_payload"
            ],
            "825": [
                "MultipartWriter",
                "append_payload"
            ],
            "826": [
                "MultipartWriter",
                "append_payload"
            ],
            "827": [
                "MultipartWriter",
                "append_payload"
            ],
            "828": [
                "MultipartWriter",
                "append_payload"
            ],
            "830": [
                "MultipartWriter",
                "append_payload"
            ],
            "831": [
                "MultipartWriter",
                "append_payload"
            ],
            "832": [
                "MultipartWriter",
                "append_payload"
            ],
            "833": [
                "MultipartWriter",
                "append_payload"
            ],
            "834": [
                "MultipartWriter",
                "append_payload"
            ],
            "835": [
                "MultipartWriter",
                "append_payload"
            ],
            "836": [
                "MultipartWriter",
                "append_payload"
            ]
        },
        "addLocation": []
    }
}