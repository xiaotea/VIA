{
    "salt/crypt.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 255,
                "afterPatchRowNumber": 255,
                "PatchRowcode": "         md = EVP.MessageDigest(\"sha1\")"
            },
            "1": {
                "beforePatchRowNumber": 256,
                "afterPatchRowNumber": 256,
                "PatchRowcode": "         md.update(salt.utils.stringutils.to_bytes(message))"
            },
            "2": {
                "beforePatchRowNumber": 257,
                "afterPatchRowNumber": 257,
                "PatchRowcode": "         digest = md.final()"
            },
            "3": {
                "beforePatchRowNumber": 258,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return pubkey.verify(digest, signature)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 258,
                "PatchRowcode": "+        try:"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 259,
                "PatchRowcode": "+            return pubkey.verify(digest, signature)"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 260,
                "PatchRowcode": "+        except RSA.RSAError as exc:"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 261,
                "PatchRowcode": "+            if exc.args[0] == \"bad signature\":"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 262,
                "PatchRowcode": "+                return False"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 263,
                "PatchRowcode": "+            raise"
            },
            "10": {
                "beforePatchRowNumber": 259,
                "afterPatchRowNumber": 264,
                "PatchRowcode": "     else:"
            },
            "11": {
                "beforePatchRowNumber": 260,
                "afterPatchRowNumber": 265,
                "PatchRowcode": "         verifier = PKCS1_v1_5.new(pubkey)"
            },
            "12": {
                "beforePatchRowNumber": 261,
                "afterPatchRowNumber": 266,
                "PatchRowcode": "         return verifier.verify("
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "The crypt module manages all of the cryptography functions for minions and",
            "masters, encrypting and decrypting payloads, preparing messages, and",
            "authenticating peers",
            "\"\"\"",
            "",
            "import base64",
            "import binascii",
            "import copy",
            "import getpass",
            "import hashlib",
            "import hmac",
            "import logging",
            "import os",
            "import random",
            "import stat",
            "import sys",
            "import time",
            "import traceback",
            "import weakref",
            "",
            "import salt.defaults.exitcodes",
            "import salt.ext.tornado.gen",
            "import salt.payload",
            "import salt.transport.client",
            "import salt.transport.frame",
            "import salt.utils.crypt",
            "import salt.utils.decorators",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.rsax931",
            "import salt.utils.sdb",
            "import salt.utils.stringutils",
            "import salt.utils.user",
            "import salt.utils.verify",
            "import salt.version",
            "from salt.exceptions import (",
            "    AuthenticationError,",
            "    MasterExit,",
            "    SaltClientError,",
            "    SaltReqTimeoutError,",
            ")",
            "",
            "try:",
            "    from M2Crypto import RSA, EVP, BIO",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "",
            "if not HAS_M2:",
            "    try:",
            "        from Cryptodome.Cipher import AES, PKCS1_OAEP, PKCS1_v1_5 as PKCS1_v1_5_CIPHER",
            "        from Cryptodome.Hash import SHA",
            "        from Cryptodome.PublicKey import RSA",
            "        from Cryptodome.Signature import PKCS1_v1_5",
            "        from Cryptodome import Random",
            "",
            "        HAS_CRYPTO = True",
            "    except ImportError:",
            "        HAS_CRYPTO = False",
            "",
            "if not HAS_M2 and not HAS_CRYPTO:",
            "    try:",
            "        from Crypto.Cipher import (  # nosec",
            "            AES,",
            "            PKCS1_OAEP,",
            "            PKCS1_v1_5 as PKCS1_v1_5_CIPHER,",
            "        )",
            "        from Crypto.Hash import SHA  # nosec",
            "        from Crypto.PublicKey import RSA  # nosec",
            "        from Crypto.Signature import PKCS1_v1_5  # nosec",
            "",
            "        # let this be imported, if possible",
            "        from Crypto import Random  # nosec",
            "",
            "        HAS_CRYPTO = True",
            "    except ImportError:",
            "        HAS_CRYPTO = False",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def dropfile(cachedir, user=None):",
            "    \"\"\"",
            "    Set an AES dropfile to request the master update the publish session key",
            "    \"\"\"",
            "    dfn = os.path.join(cachedir, \".dfn\")",
            "    # set a mask (to avoid a race condition on file creation) and store original.",
            "    with salt.utils.files.set_umask(0o277):",
            "        log.info(\"Rotating AES key\")",
            "        if os.path.isfile(dfn):",
            "            log.info(\"AES key rotation already requested\")",
            "            return",
            "",
            "        if os.path.isfile(dfn) and not os.access(dfn, os.W_OK):",
            "            os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)",
            "        with salt.utils.files.fopen(dfn, \"wb+\") as fp_:",
            "            fp_.write(b\"\")",
            "        os.chmod(dfn, stat.S_IRUSR)",
            "        if user:",
            "            try:",
            "                import pwd",
            "",
            "                uid = pwd.getpwnam(user).pw_uid",
            "                os.chown(dfn, uid, -1)",
            "            except (KeyError, ImportError, OSError):",
            "                pass",
            "",
            "",
            "def gen_keys(keydir, keyname, keysize, user=None, passphrase=None):",
            "    \"\"\"",
            "    Generate a RSA public keypair for use with salt",
            "",
            "    :param str keydir: The directory to write the keypair to",
            "    :param str keyname: The type of salt server for whom this key should be written. (i.e. 'master' or 'minion')",
            "    :param int keysize: The number of bits in the key",
            "    :param str user: The user on the system who should own this keypair",
            "    :param str passphrase: The passphrase which should be used to encrypt the private key",
            "",
            "    :rtype: str",
            "    :return: Path on the filesystem to the RSA private key",
            "    \"\"\"",
            "    base = os.path.join(keydir, keyname)",
            "    priv = \"{}.pem\".format(base)",
            "    pub = \"{}.pub\".format(base)",
            "",
            "    if HAS_M2:",
            "        gen = RSA.gen_key(keysize, 65537, lambda: None)",
            "    else:",
            "        salt.utils.crypt.reinit_crypto()",
            "        gen = RSA.generate(bits=keysize, e=65537)",
            "    if os.path.isfile(priv):",
            "        # Between first checking and the generation another process has made",
            "        # a key! Use the winner's key",
            "        return priv",
            "",
            "    # Do not try writing anything, if directory has no permissions.",
            "    if not os.access(keydir, os.W_OK):",
            "        raise OSError(",
            "            'Write access denied to \"{}\" for user \"{}\".'.format(",
            "                os.path.abspath(keydir), getpass.getuser()",
            "            )",
            "        )",
            "",
            "    with salt.utils.files.set_umask(0o277):",
            "        if HAS_M2:",
            "            # if passphrase is empty or None use no cipher",
            "            if not passphrase:",
            "                gen.save_pem(priv, cipher=None)",
            "            else:",
            "                gen.save_pem(",
            "                    priv,",
            "                    cipher=\"des_ede3_cbc\",",
            "                    callback=lambda x: salt.utils.stringutils.to_bytes(passphrase),",
            "                )",
            "        else:",
            "            with salt.utils.files.fopen(priv, \"wb+\") as f:",
            "                f.write(gen.exportKey(\"PEM\", passphrase))",
            "    if HAS_M2:",
            "        gen.save_pub_key(pub)",
            "    else:",
            "        with salt.utils.files.fopen(pub, \"wb+\") as f:",
            "            f.write(gen.publickey().exportKey(\"PEM\"))",
            "    os.chmod(priv, 0o400)",
            "    if user:",
            "        try:",
            "            import pwd",
            "",
            "            uid = pwd.getpwnam(user).pw_uid",
            "            os.chown(priv, uid, -1)",
            "            os.chown(pub, uid, -1)",
            "        except (KeyError, ImportError, OSError):",
            "            # The specified user was not found, allow the backup systems to",
            "            # report the error",
            "            pass",
            "    return priv",
            "",
            "",
            "@salt.utils.decorators.memoize",
            "def _get_key_with_evict(path, timestamp, passphrase):",
            "    \"\"\"",
            "    Load a private key from disk.  `timestamp` above is intended to be the",
            "    timestamp of the file's last modification. This fn is memoized so if it is",
            "    called with the same path and timestamp (the file's last modified time) the",
            "    second time the result is returned from the memoiziation.  If the file gets",
            "    modified then the params are different and the key is loaded from disk.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt._get_key_with_evict: Loading private key\")",
            "    if HAS_M2:",
            "        key = RSA.load_key(path, lambda x: bytes(passphrase))",
            "    else:",
            "        with salt.utils.files.fopen(path) as f:",
            "            key = RSA.importKey(f.read(), passphrase)",
            "    return key",
            "",
            "",
            "def get_rsa_key(path, passphrase):",
            "    \"\"\"",
            "    Read a private key off the disk.  Poor man's simple cache in effect here,",
            "    we memoize the result of calling _get_rsa_with_evict.  This means the first",
            "    time _get_key_with_evict is called with a path and a timestamp the result",
            "    is cached.  If the file (the private key) does not change then its",
            "    timestamp will not change and the next time the result is returned from the",
            "    cache.  If the key DOES change the next time _get_rsa_with_evict is called",
            "    it is called with different parameters and the fn is run fully to retrieve",
            "    the key from disk.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt.get_rsa_key: Loading private key\")",
            "    return _get_key_with_evict(path, str(os.path.getmtime(path)), passphrase)",
            "",
            "",
            "def get_rsa_pub_key(path):",
            "    \"\"\"",
            "    Read a public key off the disk.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt.get_rsa_pub_key: Loading public key\")",
            "    if HAS_M2:",
            "        with salt.utils.files.fopen(path, \"rb\") as f:",
            "            data = f.read().replace(b\"RSA \", b\"\")",
            "        bio = BIO.MemoryBuffer(data)",
            "        key = RSA.load_pub_key_bio(bio)",
            "    else:",
            "        with salt.utils.files.fopen(path) as f:",
            "            key = RSA.importKey(f.read())",
            "    return key",
            "",
            "",
            "def sign_message(privkey_path, message, passphrase=None):",
            "    \"\"\"",
            "    Use Crypto.Signature.PKCS1_v1_5 to sign a message. Returns the signature.",
            "    \"\"\"",
            "    key = get_rsa_key(privkey_path, passphrase)",
            "    log.debug(\"salt.crypt.sign_message: Signing message.\")",
            "    if HAS_M2:",
            "        md = EVP.MessageDigest(\"sha1\")",
            "        md.update(salt.utils.stringutils.to_bytes(message))",
            "        digest = md.final()",
            "        return key.sign(digest)",
            "    else:",
            "        signer = PKCS1_v1_5.new(key)",
            "        return signer.sign(SHA.new(salt.utils.stringutils.to_bytes(message)))",
            "",
            "",
            "def verify_signature(pubkey_path, message, signature):",
            "    \"\"\"",
            "    Use Crypto.Signature.PKCS1_v1_5 to verify the signature on a message.",
            "    Returns True for valid signature.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt.verify_signature: Loading public key\")",
            "    pubkey = get_rsa_pub_key(pubkey_path)",
            "    log.debug(\"salt.crypt.verify_signature: Verifying signature\")",
            "    if HAS_M2:",
            "        md = EVP.MessageDigest(\"sha1\")",
            "        md.update(salt.utils.stringutils.to_bytes(message))",
            "        digest = md.final()",
            "        return pubkey.verify(digest, signature)",
            "    else:",
            "        verifier = PKCS1_v1_5.new(pubkey)",
            "        return verifier.verify(",
            "            SHA.new(salt.utils.stringutils.to_bytes(message)), signature",
            "        )",
            "",
            "",
            "def gen_signature(priv_path, pub_path, sign_path, passphrase=None):",
            "    \"\"\"",
            "    creates a signature for the given public-key with",
            "    the given private key and writes it to sign_path",
            "    \"\"\"",
            "",
            "    with salt.utils.files.fopen(pub_path) as fp_:",
            "        mpub_64 = fp_.read()",
            "",
            "    mpub_sig = sign_message(priv_path, mpub_64, passphrase)",
            "    mpub_sig_64 = binascii.b2a_base64(mpub_sig)",
            "    if os.path.isfile(sign_path):",
            "        return False",
            "    log.trace(",
            "        \"Calculating signature for %s with %s\",",
            "        os.path.basename(pub_path),",
            "        os.path.basename(priv_path),",
            "    )",
            "",
            "    if os.path.isfile(sign_path):",
            "        log.trace(",
            "            \"Signature file %s already exists, please remove it first and \" \"try again\",",
            "            sign_path,",
            "        )",
            "    else:",
            "        with salt.utils.files.fopen(sign_path, \"wb+\") as sig_f:",
            "            sig_f.write(salt.utils.stringutils.to_bytes(mpub_sig_64))",
            "        log.trace(\"Wrote signature to %s\", sign_path)",
            "    return True",
            "",
            "",
            "def private_encrypt(key, message):",
            "    \"\"\"",
            "    Generate an M2Crypto-compatible signature",
            "",
            "    :param Crypto.PublicKey.RSA._RSAobj key: The RSA key object",
            "    :param str message: The message to sign",
            "    :rtype: str",
            "    :return: The signature, or an empty string if the signature operation failed",
            "    \"\"\"",
            "    if HAS_M2:",
            "        return key.private_encrypt(message, salt.utils.rsax931.RSA_X931_PADDING)",
            "    else:",
            "        signer = salt.utils.rsax931.RSAX931Signer(key.exportKey(\"PEM\"))",
            "        return signer.sign(message)",
            "",
            "",
            "def public_decrypt(pub, message):",
            "    \"\"\"",
            "    Verify an M2Crypto-compatible signature",
            "",
            "    :param Crypto.PublicKey.RSA._RSAobj key: The RSA public key object",
            "    :param str message: The signed message to verify",
            "    :rtype: str",
            "    :return: The message (or digest) recovered from the signature, or an",
            "        empty string if the verification failed",
            "    \"\"\"",
            "    if HAS_M2:",
            "        return pub.public_decrypt(message, salt.utils.rsax931.RSA_X931_PADDING)",
            "    else:",
            "        verifier = salt.utils.rsax931.RSAX931Verifier(pub.exportKey(\"PEM\"))",
            "        return verifier.verify(message)",
            "",
            "",
            "def pwdata_decrypt(rsa_key, pwdata):",
            "    if HAS_M2:",
            "        key = RSA.load_key_string(salt.utils.stringutils.to_bytes(rsa_key, \"ascii\"))",
            "        password = key.private_decrypt(pwdata, RSA.pkcs1_padding)",
            "    else:",
            "        dsize = SHA.digest_size",
            "        sentinel = Random.new().read(15 + dsize)",
            "        key_obj = RSA.importKey(rsa_key)",
            "        key_obj = PKCS1_v1_5_CIPHER.new(key_obj)",
            "        password = key_obj.decrypt(pwdata, sentinel)",
            "    return salt.utils.stringutils.to_unicode(password)",
            "",
            "",
            "class MasterKeys(dict):",
            "    \"\"\"",
            "    The Master Keys class is used to manage the RSA public key pair used for",
            "    authentication by the master.",
            "",
            "    It also generates a signing key-pair if enabled with master_sign_key_name.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts):",
            "        super().__init__()",
            "        self.opts = opts",
            "        self.pub_path = os.path.join(self.opts[\"pki_dir\"], \"master.pub\")",
            "        self.rsa_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "",
            "        key_pass = salt.utils.sdb.sdb_get(self.opts[\"key_pass\"], self.opts)",
            "        self.key = self.__get_keys(passphrase=key_pass)",
            "",
            "        self.pub_signature = None",
            "",
            "        # set names for the signing key-pairs",
            "        if opts[\"master_sign_pubkey\"]:",
            "",
            "            # if only the signature is available, use that",
            "            if opts[\"master_use_pubkey_signature\"]:",
            "                self.sig_path = os.path.join(",
            "                    self.opts[\"pki_dir\"], opts[\"master_pubkey_signature\"]",
            "                )",
            "                if os.path.isfile(self.sig_path):",
            "                    with salt.utils.files.fopen(self.sig_path) as fp_:",
            "                        self.pub_signature = fp_.read()",
            "                    log.info(",
            "                        \"Read %s's signature from %s\",",
            "                        os.path.basename(self.pub_path),",
            "                        self.opts[\"master_pubkey_signature\"],",
            "                    )",
            "                else:",
            "                    log.error(",
            "                        \"Signing the master.pub key with a signature is \"",
            "                        \"enabled but no signature file found at the defined \"",
            "                        \"location %s\",",
            "                        self.sig_path,",
            "                    )",
            "                    log.error(",
            "                        \"The signature-file may be either named differently \"",
            "                        \"or has to be created with 'salt-key --gen-signature'\"",
            "                    )",
            "                    sys.exit(1)",
            "",
            "            # create a new signing key-pair to sign the masters",
            "            # auth-replies when a minion tries to connect",
            "            else:",
            "                key_pass = salt.utils.sdb.sdb_get(",
            "                    self.opts[\"signing_key_pass\"], self.opts",
            "                )",
            "                self.pub_sign_path = os.path.join(",
            "                    self.opts[\"pki_dir\"], opts[\"master_sign_key_name\"] + \".pub\"",
            "                )",
            "                self.rsa_sign_path = os.path.join(",
            "                    self.opts[\"pki_dir\"], opts[\"master_sign_key_name\"] + \".pem\"",
            "                )",
            "                self.sign_key = self.__get_keys(name=opts[\"master_sign_key_name\"])",
            "",
            "    # We need __setstate__ and __getstate__ to avoid pickling errors since",
            "    # some of the member variables correspond to Cython objects which are",
            "    # not picklable.",
            "    # These methods are only used when pickling so will not be used on",
            "    # non-Windows platforms.",
            "    def __setstate__(self, state):",
            "        self.__init__(state[\"opts\"])",
            "",
            "    def __getstate__(self):",
            "        return {\"opts\": self.opts}",
            "",
            "    def __get_keys(self, name=\"master\", passphrase=None):",
            "        \"\"\"",
            "        Returns a key object for a key in the pki-dir",
            "        \"\"\"",
            "        path = os.path.join(self.opts[\"pki_dir\"], name + \".pem\")",
            "        if not os.path.exists(path):",
            "            log.info(\"Generating %s keys: %s\", name, self.opts[\"pki_dir\"])",
            "            gen_keys(",
            "                self.opts[\"pki_dir\"],",
            "                name,",
            "                self.opts[\"keysize\"],",
            "                self.opts.get(\"user\"),",
            "                passphrase,",
            "            )",
            "        if HAS_M2:",
            "            key_error = RSA.RSAError",
            "        else:",
            "            key_error = ValueError",
            "        try:",
            "            key = get_rsa_key(path, passphrase)",
            "        except key_error as e:",
            "            message = \"Unable to read key: {}; passphrase may be incorrect\".format(path)",
            "            log.error(message)",
            "            raise MasterExit(message)",
            "        log.debug(\"Loaded %s key: %s\", name, path)",
            "        return key",
            "",
            "    def get_pub_str(self, name=\"master\"):",
            "        \"\"\"",
            "        Return the string representation of a public key",
            "        in the pki-directory",
            "        \"\"\"",
            "        path = os.path.join(self.opts[\"pki_dir\"], name + \".pub\")",
            "        if not os.path.isfile(path):",
            "            key = self.__get_keys()",
            "            if HAS_M2:",
            "                key.save_pub_key(path)",
            "            else:",
            "                with salt.utils.files.fopen(path, \"wb+\") as wfh:",
            "                    wfh.write(key.publickey().exportKey(\"PEM\"))",
            "        with salt.utils.files.fopen(path) as rfh:",
            "            return rfh.read()",
            "",
            "    def get_mkey_paths(self):",
            "        return self.pub_path, self.rsa_path",
            "",
            "    def get_sign_paths(self):",
            "        return self.pub_sign_path, self.rsa_sign_path",
            "",
            "    def pubkey_signature(self):",
            "        \"\"\"",
            "        returns the base64 encoded signature from the signature file",
            "        or None if the master has its own signing keys",
            "        \"\"\"",
            "        return self.pub_signature",
            "",
            "",
            "class AsyncAuth:",
            "    \"\"\"",
            "    Set up an Async object to maintain authentication with the salt master",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    # mapping of io_loop -> {key -> auth}",
            "    instance_map = weakref.WeakKeyDictionary()",
            "",
            "    # mapping of key -> creds",
            "    creds_map = {}",
            "",
            "    def __new__(cls, opts, io_loop=None):",
            "        \"\"\"",
            "        Only create one instance of AsyncAuth per __key()",
            "        \"\"\"",
            "        # do we have any mapping for this io_loop",
            "        io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()",
            "        if io_loop not in AsyncAuth.instance_map:",
            "            AsyncAuth.instance_map[io_loop] = weakref.WeakValueDictionary()",
            "        loop_instance_map = AsyncAuth.instance_map[io_loop]",
            "",
            "        key = cls.__key(opts)",
            "        auth = loop_instance_map.get(key)",
            "        if auth is None:",
            "            log.debug(\"Initializing new AsyncAuth for %s\", key)",
            "            # we need to make a local variable for this, as we are going to store",
            "            # it in a WeakValueDictionary-- which will remove the item if no one",
            "            # references it-- this forces a reference while we return to the caller",
            "            auth = object.__new__(cls)",
            "            auth.__singleton_init__(opts, io_loop=io_loop)",
            "            loop_instance_map[key] = auth",
            "        else:",
            "            log.debug(\"Re-using AsyncAuth for %s\", key)",
            "        return auth",
            "",
            "    @classmethod",
            "    def __key(cls, opts, io_loop=None):",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            opts[\"master_uri\"],  # master ID",
            "        )",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, io_loop=None):",
            "        pass",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, io_loop=None):",
            "        \"\"\"",
            "        Init an Auth instance",
            "",
            "        :param dict opts: Options for this server",
            "        :return: Auth instance",
            "        :rtype: Auth",
            "        \"\"\"",
            "        self.opts = opts",
            "        self.token = salt.utils.stringutils.to_bytes(Crypticle.generate_key_string())",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.pub_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pub\")",
            "        self.rsa_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pem\")",
            "        if self.opts[\"__role\"] == \"syndic\":",
            "            self.mpub = \"syndic_master.pub\"",
            "        else:",
            "            self.mpub = \"minion_master.pub\"",
            "        if not os.path.isfile(self.pub_path):",
            "            self.get_keys()",
            "",
            "        self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        salt.utils.crypt.reinit_crypto()",
            "        key = self.__key(self.opts)",
            "        # TODO: if we already have creds for this key, lets just re-use",
            "        if key in AsyncAuth.creds_map:",
            "            creds = AsyncAuth.creds_map[key]",
            "            self._creds = creds",
            "            self._crypticle = Crypticle(self.opts, creds[\"aes\"])",
            "            self._authenticate_future = salt.ext.tornado.concurrent.Future()",
            "            self._authenticate_future.set_result(True)",
            "        else:",
            "            self.authenticate()",
            "",
            "    def __deepcopy__(self, memo):",
            "        cls = self.__class__",
            "        result = cls.__new__(cls, copy.deepcopy(self.opts, memo))",
            "        memo[id(self)] = result",
            "        for key in self.__dict__:",
            "            if key in (\"io_loop\",):",
            "                # The io_loop has a thread Lock which will fail to be deep",
            "                # copied. Skip it because it will just be recreated on the",
            "                # new copy.",
            "                continue",
            "            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))",
            "        return result",
            "",
            "    @property",
            "    def creds(self):",
            "        return self._creds",
            "",
            "    @property",
            "    def crypticle(self):",
            "        return self._crypticle",
            "",
            "    @property",
            "    def authenticated(self):",
            "        return (",
            "            hasattr(self, \"_authenticate_future\")",
            "            and self._authenticate_future.done()",
            "            and self._authenticate_future.exception() is None",
            "        )",
            "",
            "    def invalidate(self):",
            "        if self.authenticated:",
            "            del self._authenticate_future",
            "            key = self.__key(self.opts)",
            "            if key in AsyncAuth.creds_map:",
            "                del AsyncAuth.creds_map[key]",
            "",
            "    def authenticate(self, callback=None):",
            "        \"\"\"",
            "        Ask for this client to reconnect to the origin",
            "",
            "        This function will de-dupe all calls here and return a *single* future",
            "        for the sign-in-- whis way callers can all assume there aren't others",
            "        \"\"\"",
            "        # if an auth is in flight-- and not done-- just pass that back as the future to wait on",
            "        if (",
            "            hasattr(self, \"_authenticate_future\")",
            "            and not self._authenticate_future.done()",
            "        ):",
            "            future = self._authenticate_future",
            "        else:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            self._authenticate_future = future",
            "            self.io_loop.add_callback(self._authenticate)",
            "",
            "        if callback is not None:",
            "",
            "            def handle_future(future):",
            "                response = future.result()",
            "                self.io_loop.add_callback(callback, response)",
            "",
            "            future.add_done_callback(handle_future)",
            "",
            "        return future",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _authenticate(self):",
            "        \"\"\"",
            "        Authenticate with the master, this method breaks the functional",
            "        paradigm, it will update the master information from a fresh sign",
            "        in, signing in can occur as often as needed to keep up with the",
            "        revolving master AES key.",
            "",
            "        :rtype: Crypticle",
            "        :returns: A crypticle used for encryption operations",
            "        \"\"\"",
            "        acceptance_wait_time = self.opts[\"acceptance_wait_time\"]",
            "        acceptance_wait_time_max = self.opts[\"acceptance_wait_time_max\"]",
            "        if not acceptance_wait_time_max:",
            "            acceptance_wait_time_max = acceptance_wait_time",
            "        creds = None",
            "",
            "        with salt.transport.client.AsyncReqChannel.factory(",
            "            self.opts, crypt=\"clear\", io_loop=self.io_loop",
            "        ) as channel:",
            "            error = None",
            "            while True:",
            "                try:",
            "                    creds = yield self.sign_in(channel=channel)",
            "                except SaltClientError as exc:",
            "                    error = exc",
            "                    break",
            "                if creds == \"retry\":",
            "                    if self.opts.get(\"detect_mode\") is True:",
            "                        error = SaltClientError(\"Detect mode is on\")",
            "                        break",
            "                    if self.opts.get(\"caller\"):",
            "                        # We have a list of masters, so we should break",
            "                        # and try the next one in the list.",
            "                        if self.opts.get(\"local_masters\", None):",
            "                            error = SaltClientError(",
            "                                \"Minion failed to authenticate\"",
            "                                \" with the master, has the \"",
            "                                \"minion key been accepted?\"",
            "                            )",
            "                            break",
            "                        else:",
            "                            print(",
            "                                \"Minion failed to authenticate with the master, \"",
            "                                \"has the minion key been accepted?\"",
            "                            )",
            "                            sys.exit(2)",
            "                    if acceptance_wait_time:",
            "                        log.info(",
            "                            \"Waiting %s seconds before retry.\", acceptance_wait_time",
            "                        )",
            "                        yield salt.ext.tornado.gen.sleep(acceptance_wait_time)",
            "                    if acceptance_wait_time < acceptance_wait_time_max:",
            "                        acceptance_wait_time += acceptance_wait_time",
            "                        log.debug(",
            "                            \"Authentication wait time is %s\", acceptance_wait_time",
            "                        )",
            "                    continue",
            "                break",
            "            if not isinstance(creds, dict) or \"aes\" not in creds:",
            "                if self.opts.get(\"detect_mode\") is True:",
            "                    error = SaltClientError(\"-|RETRY|-\")",
            "                try:",
            "                    del AsyncAuth.creds_map[self.__key(self.opts)]",
            "                except KeyError:",
            "                    pass",
            "                if not error:",
            "                    error = SaltClientError(",
            "                        \"Attempt to authenticate with the salt master failed\"",
            "                    )",
            "                self._authenticate_future.set_exception(error)",
            "            else:",
            "                key = self.__key(self.opts)",
            "                AsyncAuth.creds_map[key] = creds",
            "                self._creds = creds",
            "                self._crypticle = Crypticle(self.opts, creds[\"aes\"])",
            "                self._authenticate_future.set_result(",
            "                    True",
            "                )  # mark the sign-in as complete",
            "                # Notify the bus about creds change",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    with salt.utils.event.get_event(",
            "                        self.opts.get(\"__role\"), opts=self.opts, listen=False",
            "                    ) as event:",
            "                        event.fire_event(",
            "                            {\"key\": key, \"creds\": creds},",
            "                            salt.utils.event.tagify(prefix=\"auth\", suffix=\"creds\"),",
            "                        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):",
            "        \"\"\"",
            "        Send a sign in request to the master, sets the key information and",
            "        returns a dict containing the master publish interface to bind to",
            "        and the decrypted aes key for transport decryption.",
            "",
            "        :param int timeout: Number of seconds to wait before timing out the sign-in request",
            "        :param bool safe: If True, do not raise an exception on timeout. Retry instead.",
            "        :param int tries: The number of times to try to authenticate before giving up.",
            "",
            "        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set",
            "",
            "        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary",
            "        with the publication port and the shared AES key.",
            "",
            "        \"\"\"",
            "        auth = {}",
            "",
            "        auth_timeout = self.opts.get(\"auth_timeout\", None)",
            "        if auth_timeout is not None:",
            "            timeout = auth_timeout",
            "        auth_safemode = self.opts.get(\"auth_safemode\", None)",
            "        if auth_safemode is not None:",
            "            safe = auth_safemode",
            "        auth_tries = self.opts.get(\"auth_tries\", None)",
            "        if auth_tries is not None:",
            "            tries = auth_tries",
            "",
            "        m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "",
            "        auth[\"master_uri\"] = self.opts[\"master_uri\"]",
            "",
            "        close_channel = False",
            "        if not channel:",
            "            close_channel = True",
            "            channel = salt.transport.client.AsyncReqChannel.factory(",
            "                self.opts, crypt=\"clear\", io_loop=self.io_loop",
            "            )",
            "",
            "        sign_in_payload = self.minion_sign_in_payload()",
            "        try:",
            "            payload = yield channel.send(sign_in_payload, tries=tries, timeout=timeout)",
            "        except SaltReqTimeoutError as e:",
            "            if safe:",
            "                log.warning(\"SaltReqTimeoutError: %s\", e)",
            "                raise salt.ext.tornado.gen.Return(\"retry\")",
            "            if self.opts.get(\"detect_mode\") is True:",
            "                raise salt.ext.tornado.gen.Return(\"retry\")",
            "            else:",
            "                raise SaltClientError(",
            "                    \"Attempt to authenticate with the salt master failed with timeout error\"",
            "                )",
            "        finally:",
            "            if close_channel:",
            "                channel.close()",
            "",
            "        if not isinstance(payload, dict):",
            "            log.error(\"Sign-in attempt failed: %s\", payload)",
            "            raise salt.ext.tornado.gen.Return(False)",
            "        if \"load\" in payload:",
            "            if \"ret\" in payload[\"load\"]:",
            "                if not payload[\"load\"][\"ret\"]:",
            "                    if self.opts[\"rejected_retry\"]:",
            "                        log.error(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key.\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master.\\nThe Salt \"",
            "                            \"Minion will attempt to to re-authenicate.\"",
            "                        )",
            "                        raise salt.ext.tornado.gen.Return(\"retry\")",
            "                    else:",
            "                        log.critical(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key!\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master and restart this \"",
            "                            \"minion.\\nOr restart the Salt Master in open mode to \"",
            "                            \"clean out the keys. The Salt Minion will now exit.\"",
            "                        )",
            "                        # Add a random sleep here for systems that are using a",
            "                        # a service manager to immediately restart the service",
            "                        # to avoid overloading the system",
            "                        time.sleep(random.randint(10, 20))",
            "                        sys.exit(salt.defaults.exitcodes.EX_NOPERM)",
            "                # has the master returned that its maxed out with minions?",
            "                elif payload[\"load\"][\"ret\"] == \"full\":",
            "                    raise salt.ext.tornado.gen.Return(\"full\")",
            "                else:",
            "                    log.error(",
            "                        \"The Salt Master has cached the public key for this \"",
            "                        \"node, this salt minion will wait for %s seconds \"",
            "                        \"before attempting to re-authenticate\",",
            "                        self.opts[\"acceptance_wait_time\"],",
            "                    )",
            "                    raise salt.ext.tornado.gen.Return(\"retry\")",
            "        auth[\"aes\"] = self.verify_master(payload, master_pub=\"token\" in sign_in_payload)",
            "        if not auth[\"aes\"]:",
            "            log.critical(",
            "                \"The Salt Master server's public key did not authenticate!\\n\"",
            "                \"The master may need to be updated if it is a version of Salt \"",
            "                \"lower than %s, or\\n\"",
            "                \"If you are confident that you are connecting to a valid Salt \"",
            "                \"Master, then remove the master public key and restart the \"",
            "                \"Salt Minion.\\nThe master public key can be found \"",
            "                \"at:\\n%s\",",
            "                salt.version.__version__,",
            "                m_pub_fn,",
            "            )",
            "            raise SaltClientError(\"Invalid master key\")",
            "        if self.opts.get(\"syndic_master\", False):  # Is syndic",
            "            syndic_finger = self.opts.get(",
            "                \"syndic_finger\", self.opts.get(\"master_finger\", False)",
            "            )",
            "            if syndic_finger:",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != syndic_finger",
            "                ):",
            "                    self._finger_fail(syndic_finger, m_pub_fn)",
            "        else:",
            "            if self.opts.get(\"master_finger\", False):",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != self.opts[\"master_finger\"]",
            "                ):",
            "                    self._finger_fail(self.opts[\"master_finger\"], m_pub_fn)",
            "        auth[\"publish_port\"] = payload[\"publish_port\"]",
            "        raise salt.ext.tornado.gen.Return(auth)",
            "",
            "    def get_keys(self):",
            "        \"\"\"",
            "        Return keypair object for the minion.",
            "",
            "        :rtype: Crypto.PublicKey.RSA._RSAobj",
            "        :return: The RSA keypair",
            "        \"\"\"",
            "        # Make sure all key parent directories are accessible",
            "        user = self.opts.get(\"user\", \"root\")",
            "        salt.utils.verify.check_path_traversal(self.opts[\"pki_dir\"], user)",
            "",
            "        if not os.path.exists(self.rsa_path):",
            "            log.info(\"Generating keys: %s\", self.opts[\"pki_dir\"])",
            "            gen_keys(",
            "                self.opts[\"pki_dir\"],",
            "                \"minion\",",
            "                self.opts[\"keysize\"],",
            "                self.opts.get(\"user\"),",
            "            )",
            "        key = get_rsa_key(self.rsa_path, None)",
            "        log.debug(\"Loaded minion key: %s\", self.rsa_path)",
            "        return key",
            "",
            "    def gen_token(self, clear_tok):",
            "        \"\"\"",
            "        Encrypt a string with the minion private key to verify identity",
            "        with the master.",
            "",
            "        :param str clear_tok: A plaintext token to encrypt",
            "        :return: Encrypted token",
            "        :rtype: str",
            "        \"\"\"",
            "        return private_encrypt(self.get_keys(), clear_tok)",
            "",
            "    def minion_sign_in_payload(self):",
            "        \"\"\"",
            "        Generates the payload used to authenticate with the master",
            "        server. This payload consists of the passed in id_ and the ssh",
            "        public key to encrypt the AES key sent back from the master.",
            "",
            "        :return: Payload dictionary",
            "        :rtype: dict",
            "        \"\"\"",
            "        payload = {}",
            "        payload[\"cmd\"] = \"_auth\"",
            "        payload[\"id\"] = self.opts[\"id\"]",
            "        if \"autosign_grains\" in self.opts:",
            "            autosign_grains = {}",
            "            for grain in self.opts[\"autosign_grains\"]:",
            "                autosign_grains[grain] = self.opts[\"grains\"].get(grain, None)",
            "            payload[\"autosign_grains\"] = autosign_grains",
            "        try:",
            "            pubkey_path = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "            pub = get_rsa_pub_key(pubkey_path)",
            "            if HAS_M2:",
            "                payload[\"token\"] = pub.public_encrypt(",
            "                    self.token, RSA.pkcs1_oaep_padding",
            "                )",
            "            else:",
            "                cipher = PKCS1_OAEP.new(pub)",
            "                payload[\"token\"] = cipher.encrypt(self.token)",
            "        except Exception:  # pylint: disable=broad-except",
            "            pass",
            "        with salt.utils.files.fopen(self.pub_path) as f:",
            "            payload[\"pub\"] = f.read()",
            "        return payload",
            "",
            "    def decrypt_aes(self, payload, master_pub=True):",
            "        \"\"\"",
            "        This function is used to decrypt the AES seed phrase returned from",
            "        the master server. The seed phrase is decrypted with the SSH RSA",
            "        host key.",
            "",
            "        Pass in the encrypted AES key.",
            "        Returns the decrypted AES seed key, a string",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', etc)",
            "            'sig': The message signature",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The public key of the sender.",
            "",
            "        :rtype: str",
            "        :return: The decrypted token that was provided, with padding.",
            "",
            "        :rtype: str",
            "        :return: The decrypted AES seed key",
            "        \"\"\"",
            "        if self.opts.get(\"auth_trb\", False):",
            "            log.warning(\"Auth Called: %s\", \"\".join(traceback.format_stack()))",
            "        else:",
            "            log.debug(\"Decrypting the current master AES key\")",
            "        key = self.get_keys()",
            "        if HAS_M2:",
            "            key_str = key.private_decrypt(payload[\"aes\"], RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(key)",
            "            key_str = cipher.decrypt(payload[\"aes\"])",
            "        if \"sig\" in payload:",
            "            m_path = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "            if os.path.exists(m_path):",
            "                try:",
            "                    mkey = get_rsa_pub_key(m_path)",
            "                except Exception:  # pylint: disable=broad-except",
            "                    return \"\", \"\"",
            "                digest = hashlib.sha256(key_str).hexdigest()",
            "                digest = salt.utils.stringutils.to_bytes(digest)",
            "                if HAS_M2:",
            "                    m_digest = public_decrypt(mkey, payload[\"sig\"])",
            "                else:",
            "                    m_digest = public_decrypt(mkey.publickey(), payload[\"sig\"])",
            "                if m_digest != digest:",
            "                    return \"\", \"\"",
            "        else:",
            "            return \"\", \"\"",
            "",
            "        key_str = salt.utils.stringutils.to_str(key_str)",
            "",
            "        if \"_|-\" in key_str:",
            "            return key_str.split(\"_|-\")",
            "        else:",
            "            if \"token\" in payload:",
            "                if HAS_M2:",
            "                    token = key.private_decrypt(",
            "                        payload[\"token\"], RSA.pkcs1_oaep_padding",
            "                    )",
            "                else:",
            "                    token = cipher.decrypt(payload[\"token\"])",
            "                return key_str, token",
            "            elif not master_pub:",
            "                return key_str, \"\"",
            "        return \"\", \"\"",
            "",
            "    def verify_pubkey_sig(self, message, sig):",
            "        \"\"\"",
            "        Wraps the verify_signature method so we have",
            "        additional checks.",
            "",
            "        :rtype: bool",
            "        :return: Success or failure of public key verification",
            "        \"\"\"",
            "        if self.opts[\"master_sign_key_name\"]:",
            "            path = os.path.join(",
            "                self.opts[\"pki_dir\"], self.opts[\"master_sign_key_name\"] + \".pub\"",
            "            )",
            "",
            "            if os.path.isfile(path):",
            "                res = verify_signature(path, message, binascii.a2b_base64(sig))",
            "            else:",
            "                log.error(",
            "                    \"Verification public key %s does not exist. You need to \"",
            "                    \"copy it from the master to the minions pki directory\",",
            "                    os.path.basename(path),",
            "                )",
            "                return False",
            "            if res:",
            "                log.debug(",
            "                    \"Successfully verified signature of master public key \"",
            "                    \"with verification public key %s\",",
            "                    self.opts[\"master_sign_key_name\"] + \".pub\",",
            "                )",
            "                return True",
            "            else:",
            "                log.debug(\"Failed to verify signature of public key\")",
            "                return False",
            "        else:",
            "            log.error(",
            "                \"Failed to verify the signature of the message because the \"",
            "                \"verification key-pairs name is not defined. Please make \"",
            "                \"sure that master_sign_key_name is defined.\"",
            "            )",
            "            return False",
            "",
            "    def verify_signing_master(self, payload):",
            "        try:",
            "            if self.verify_pubkey_sig(payload[\"pub_key\"], payload[\"pub_sig\"]):",
            "                log.info(",
            "                    \"Received signed and verified master pubkey from master %s\",",
            "                    self.opts[\"master\"],",
            "                )",
            "                m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "                uid = salt.utils.user.get_uid(self.opts.get(\"user\", None))",
            "                with salt.utils.files.fpopen(m_pub_fn, \"wb+\", uid=uid) as wfh:",
            "                    wfh.write(salt.utils.stringutils.to_bytes(payload[\"pub_key\"]))",
            "                return True",
            "            else:",
            "                log.error(",
            "                    \"Received signed public-key from master %s but signature \"",
            "                    \"verification failed!\",",
            "                    self.opts[\"master\"],",
            "                )",
            "                return False",
            "        except Exception as sign_exc:  # pylint: disable=broad-except",
            "            log.error(",
            "                \"There was an error while verifying the masters public-key \" \"signature\"",
            "            )",
            "            raise Exception(sign_exc)",
            "",
            "    def check_auth_deps(self, payload):",
            "        \"\"\"",
            "        Checks if both master and minion either sign (master) and",
            "        verify (minion). If one side does not, it should fail.",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', 'aes')",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The RSA public key of the sender.",
            "        \"\"\"",
            "        # master and minion sign and verify",
            "        if \"pub_sig\" in payload and self.opts[\"verify_master_pubkey_sign\"]:",
            "            return True",
            "        # master and minion do NOT sign and do NOT verify",
            "        elif \"pub_sig\" not in payload and not self.opts[\"verify_master_pubkey_sign\"]:",
            "            return True",
            "",
            "        # master signs, but minion does NOT verify",
            "        elif \"pub_sig\" in payload and not self.opts[\"verify_master_pubkey_sign\"]:",
            "            log.error(",
            "                \"The masters sent its public-key signature, but signature \"",
            "                \"verification is not enabled on the minion. Either enable \"",
            "                \"signature verification on the minion or disable signing \"",
            "                \"the public key on the master!\"",
            "            )",
            "            return False",
            "        # master does NOT sign but minion wants to verify",
            "        elif \"pub_sig\" not in payload and self.opts[\"verify_master_pubkey_sign\"]:",
            "            log.error(",
            "                \"The master did not send its public-key signature, but \"",
            "                \"signature verification is enabled on the minion. Either \"",
            "                \"disable signature verification on the minion or enable \"",
            "                \"signing the public on the master!\"",
            "            )",
            "            return False",
            "",
            "    def extract_aes(self, payload, master_pub=True):",
            "        \"\"\"",
            "        Return the AES key received from the master after the minion has been",
            "        successfully authenticated.",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', etc)",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The RSA public key of the sender.",
            "",
            "        :rtype: str",
            "        :return: The shared AES key received from the master.",
            "        \"\"\"",
            "        if master_pub:",
            "            try:",
            "                aes, token = self.decrypt_aes(payload, master_pub)",
            "                if token != self.token:",
            "                    log.error(\"The master failed to decrypt the random minion token\")",
            "                    return \"\"",
            "            except Exception:  # pylint: disable=broad-except",
            "                log.error(\"The master failed to decrypt the random minion token\")",
            "                return \"\"",
            "            return aes",
            "        else:",
            "            aes, token = self.decrypt_aes(payload, master_pub)",
            "            return aes",
            "",
            "    def verify_master(self, payload, master_pub=True):",
            "        \"\"\"",
            "        Verify that the master is the same one that was previously accepted.",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', etc)",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The RSA public key of the sender.",
            "        :param bool master_pub: Operate as if minion had no master pubkey when it sent auth request, i.e. don't verify",
            "        the minion signature",
            "",
            "        :rtype: str",
            "        :return: An empty string on verification failure. On success, the decrypted AES message in the payload.",
            "        \"\"\"",
            "        m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "        m_pub_exists = os.path.isfile(m_pub_fn)",
            "        if m_pub_exists and master_pub and not self.opts[\"open_mode\"]:",
            "            with salt.utils.files.fopen(m_pub_fn) as fp_:",
            "                local_master_pub = fp_.read()",
            "",
            "            if payload[\"pub_key\"].replace(\"\\n\", \"\").replace(",
            "                \"\\r\", \"\"",
            "            ) != local_master_pub.replace(\"\\n\", \"\").replace(\"\\r\", \"\"):",
            "                if not self.check_auth_deps(payload):",
            "                    return \"\"",
            "",
            "                if self.opts[\"verify_master_pubkey_sign\"]:",
            "                    if self.verify_signing_master(payload):",
            "                        return self.extract_aes(payload, master_pub=False)",
            "                    else:",
            "                        return \"\"",
            "                else:",
            "                    # This is not the last master we connected to",
            "                    log.error(",
            "                        \"The master key has changed, the salt master could \"",
            "                        \"have been subverted, verify salt master's public \"",
            "                        \"key\"",
            "                    )",
            "                    return \"\"",
            "",
            "            else:",
            "                if not self.check_auth_deps(payload):",
            "                    return \"\"",
            "                # verify the signature of the pubkey even if it has",
            "                # not changed compared with the one we already have",
            "                if self.opts[\"always_verify_signature\"]:",
            "                    if self.verify_signing_master(payload):",
            "                        return self.extract_aes(payload)",
            "                    else:",
            "                        log.error(",
            "                            \"The masters public could not be verified. Is the \"",
            "                            \"verification pubkey %s up to date?\",",
            "                            self.opts[\"master_sign_key_name\"] + \".pub\",",
            "                        )",
            "                        return \"\"",
            "",
            "                else:",
            "                    return self.extract_aes(payload)",
            "        else:",
            "            if not self.check_auth_deps(payload):",
            "                return \"\"",
            "",
            "            # verify the masters pubkey signature if the minion",
            "            # has not received any masters pubkey before",
            "            if self.opts[\"verify_master_pubkey_sign\"]:",
            "                if self.verify_signing_master(payload):",
            "                    return self.extract_aes(payload, master_pub=False)",
            "                else:",
            "                    return \"\"",
            "            else:",
            "                if not m_pub_exists:",
            "                    # the minion has not received any masters pubkey yet, write",
            "                    # the newly received pubkey to minion_master.pub",
            "                    with salt.utils.files.fopen(m_pub_fn, \"wb+\") as fp_:",
            "                        fp_.write(salt.utils.stringutils.to_bytes(payload[\"pub_key\"]))",
            "                return self.extract_aes(payload, master_pub=False)",
            "",
            "    def _finger_fail(self, finger, master_key):",
            "        log.critical(",
            "            \"The specified fingerprint in the master configuration \"",
            "            \"file:\\n%s\\nDoes not match the authenticating master's \"",
            "            \"key:\\n%s\\nVerify that the configured fingerprint \"",
            "            \"matches the fingerprint of the correct master and that \"",
            "            \"this minion is not subject to a man-in-the-middle attack.\",",
            "            finger,",
            "            salt.utils.crypt.pem_finger(master_key, sum_type=self.opts[\"hash_type\"]),",
            "        )",
            "        sys.exit(42)",
            "",
            "",
            "# TODO: remove, we should just return a sync wrapper of AsyncAuth",
            "class SAuth(AsyncAuth):",
            "    \"\"\"",
            "    Set up an object to maintain authentication with the salt master",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    instances = weakref.WeakValueDictionary()",
            "",
            "    def __new__(cls, opts, io_loop=None):",
            "        \"\"\"",
            "        Only create one instance of SAuth per __key()",
            "        \"\"\"",
            "        key = cls.__key(opts)",
            "        auth = SAuth.instances.get(key)",
            "        if auth is None:",
            "            log.debug(\"Initializing new SAuth for %s\", key)",
            "            auth = object.__new__(cls)",
            "            auth.__singleton_init__(opts)",
            "            SAuth.instances[key] = auth",
            "        else:",
            "            log.debug(\"Re-using SAuth for %s\", key)",
            "        return auth",
            "",
            "    @classmethod",
            "    def __key(cls, opts, io_loop=None):",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            opts[\"master_uri\"],  # master ID",
            "        )",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, io_loop=None):",
            "        super().__init__(opts, io_loop=io_loop)",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, io_loop=None):",
            "        \"\"\"",
            "        Init an Auth instance",
            "",
            "        :param dict opts: Options for this server",
            "        :return: Auth instance",
            "        :rtype: Auth",
            "        \"\"\"",
            "        self.opts = opts",
            "        self.token = salt.utils.stringutils.to_bytes(Crypticle.generate_key_string())",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.pub_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pub\")",
            "        self.rsa_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pem\")",
            "        if \"syndic_master\" in self.opts:",
            "            self.mpub = \"syndic_master.pub\"",
            "        elif \"alert_master\" in self.opts:",
            "            self.mpub = \"monitor_master.pub\"",
            "        else:",
            "            self.mpub = \"minion_master.pub\"",
            "        if not os.path.isfile(self.pub_path):",
            "            self.get_keys()",
            "",
            "    @property",
            "    def creds(self):",
            "        if not hasattr(self, \"_creds\"):",
            "            self.authenticate()",
            "        return self._creds",
            "",
            "    @property",
            "    def crypticle(self):",
            "        if not hasattr(self, \"_crypticle\"):",
            "            self.authenticate()",
            "        return self._crypticle",
            "",
            "    def authenticate(self, _=None):  # TODO: remove unused var",
            "        \"\"\"",
            "        Authenticate with the master, this method breaks the functional",
            "        paradigm, it will update the master information from a fresh sign",
            "        in, signing in can occur as often as needed to keep up with the",
            "        revolving master AES key.",
            "",
            "        :rtype: Crypticle",
            "        :returns: A crypticle used for encryption operations",
            "        \"\"\"",
            "        acceptance_wait_time = self.opts[\"acceptance_wait_time\"]",
            "        acceptance_wait_time_max = self.opts[\"acceptance_wait_time_max\"]",
            "        if not acceptance_wait_time_max:",
            "            acceptance_wait_time_max = acceptance_wait_time",
            "        with salt.transport.client.ReqChannel.factory(",
            "            self.opts, crypt=\"clear\"",
            "        ) as channel:",
            "            while True:",
            "                creds = self.sign_in(channel=channel)",
            "                if creds == \"retry\":",
            "                    if self.opts.get(\"caller\"):",
            "                        # We have a list of masters, so we should break",
            "                        # and try the next one in the list.",
            "                        if self.opts.get(\"local_masters\", None):",
            "                            error = SaltClientError(",
            "                                \"Minion failed to authenticate\"",
            "                                \" with the master, has the \"",
            "                                \"minion key been accepted?\"",
            "                            )",
            "                            break",
            "                        else:",
            "                            print(",
            "                                \"Minion failed to authenticate with the master, \"",
            "                                \"has the minion key been accepted?\"",
            "                            )",
            "                            sys.exit(2)",
            "                    if acceptance_wait_time:",
            "                        log.info(",
            "                            \"Waiting %s seconds before retry.\", acceptance_wait_time",
            "                        )",
            "                        time.sleep(acceptance_wait_time)",
            "                    if acceptance_wait_time < acceptance_wait_time_max:",
            "                        acceptance_wait_time += acceptance_wait_time",
            "                        log.debug(",
            "                            \"Authentication wait time is %s\", acceptance_wait_time",
            "                        )",
            "                    continue",
            "                break",
            "            self._creds = creds",
            "            self._crypticle = Crypticle(self.opts, creds[\"aes\"])",
            "",
            "    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):",
            "        \"\"\"",
            "        Send a sign in request to the master, sets the key information and",
            "        returns a dict containing the master publish interface to bind to",
            "        and the decrypted aes key for transport decryption.",
            "",
            "        :param int timeout: Number of seconds to wait before timing out the sign-in request",
            "        :param bool safe: If True, do not raise an exception on timeout. Retry instead.",
            "        :param int tries: The number of times to try to authenticate before giving up.",
            "",
            "        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set",
            "",
            "        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary",
            "        with the publication port and the shared AES key.",
            "",
            "        \"\"\"",
            "        auth = {}",
            "",
            "        auth_timeout = self.opts.get(\"auth_timeout\", None)",
            "        if auth_timeout is not None:",
            "            timeout = auth_timeout",
            "        auth_safemode = self.opts.get(\"auth_safemode\", None)",
            "        if auth_safemode is not None:",
            "            safe = auth_safemode",
            "        auth_tries = self.opts.get(\"auth_tries\", None)",
            "        if auth_tries is not None:",
            "            tries = auth_tries",
            "",
            "        m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "",
            "        auth[\"master_uri\"] = self.opts[\"master_uri\"]",
            "",
            "        close_channel = False",
            "        if not channel:",
            "            close_channel = True",
            "            channel = salt.transport.client.ReqChannel.factory(self.opts, crypt=\"clear\")",
            "",
            "        sign_in_payload = self.minion_sign_in_payload()",
            "        try:",
            "            payload = channel.send(sign_in_payload, tries=tries, timeout=timeout)",
            "        except SaltReqTimeoutError as e:",
            "            if safe:",
            "                log.warning(\"SaltReqTimeoutError: %s\", e)",
            "                return \"retry\"",
            "            raise SaltClientError(",
            "                \"Attempt to authenticate with the salt master failed with timeout error\"",
            "            )",
            "        finally:",
            "            if close_channel:",
            "                channel.close()",
            "",
            "        if \"load\" in payload:",
            "            if \"ret\" in payload[\"load\"]:",
            "                if not payload[\"load\"][\"ret\"]:",
            "                    if self.opts[\"rejected_retry\"]:",
            "                        log.error(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key.\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master.\\nThe Salt \"",
            "                            \"Minion will attempt to to re-authenicate.\"",
            "                        )",
            "                        return \"retry\"",
            "                    else:",
            "                        log.critical(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key!\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master and restart this \"",
            "                            \"minion.\\nOr restart the Salt Master in open mode to \"",
            "                            \"clean out the keys. The Salt Minion will now exit.\"",
            "                        )",
            "                        sys.exit(salt.defaults.exitcodes.EX_NOPERM)",
            "                # has the master returned that its maxed out with minions?",
            "                elif payload[\"load\"][\"ret\"] == \"full\":",
            "                    return \"full\"",
            "                else:",
            "                    log.error(",
            "                        \"The Salt Master has cached the public key for this \"",
            "                        \"node. If this is the first time connecting to this \"",
            "                        \"master then this key may need to be accepted using \"",
            "                        \"'salt-key -a %s' on the salt master. This salt \"",
            "                        \"minion will wait for %s seconds before attempting \"",
            "                        \"to re-authenticate.\",",
            "                        self.opts[\"id\"],",
            "                        self.opts[\"acceptance_wait_time\"],",
            "                    )",
            "                    return \"retry\"",
            "        auth[\"aes\"] = self.verify_master(payload, master_pub=\"token\" in sign_in_payload)",
            "        if not auth[\"aes\"]:",
            "            log.critical(",
            "                \"The Salt Master server's public key did not authenticate!\\n\"",
            "                \"The master may need to be updated if it is a version of Salt \"",
            "                \"lower than %s, or\\n\"",
            "                \"If you are confident that you are connecting to a valid Salt \"",
            "                \"Master, then remove the master public key and restart the \"",
            "                \"Salt Minion.\\nThe master public key can be found \"",
            "                \"at:\\n%s\",",
            "                salt.version.__version__,",
            "                m_pub_fn,",
            "            )",
            "            sys.exit(42)",
            "        if self.opts.get(\"syndic_master\", False):  # Is syndic",
            "            syndic_finger = self.opts.get(",
            "                \"syndic_finger\", self.opts.get(\"master_finger\", False)",
            "            )",
            "            if syndic_finger:",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != syndic_finger",
            "                ):",
            "                    self._finger_fail(syndic_finger, m_pub_fn)",
            "        else:",
            "            if self.opts.get(\"master_finger\", False):",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != self.opts[\"master_finger\"]",
            "                ):",
            "                    self._finger_fail(self.opts[\"master_finger\"], m_pub_fn)",
            "        auth[\"publish_port\"] = payload[\"publish_port\"]",
            "        return auth",
            "",
            "",
            "class Crypticle:",
            "    \"\"\"",
            "    Authenticated encryption class",
            "",
            "    Encryption algorithm: AES-CBC",
            "    Signing algorithm: HMAC-SHA256",
            "    \"\"\"",
            "",
            "    PICKLE_PAD = b\"pickle::\"",
            "    AES_BLOCK_SIZE = 16",
            "    SIG_SIZE = hashlib.sha256().digest_size",
            "",
            "    def __init__(self, opts, key_string, key_size=192):",
            "        self.key_string = key_string",
            "        self.keys = self.extract_keys(self.key_string, key_size)",
            "        self.key_size = key_size",
            "        self.serial = salt.payload.Serial(opts)",
            "",
            "    @classmethod",
            "    def generate_key_string(cls, key_size=192):",
            "        key = os.urandom(key_size // 8 + cls.SIG_SIZE)",
            "        b64key = base64.b64encode(key)",
            "        b64key = b64key.decode(\"utf-8\")",
            "        # Return data must be a base64-encoded string, not a unicode type",
            "        return b64key.replace(\"\\n\", \"\")",
            "",
            "    @classmethod",
            "    def extract_keys(cls, key_string, key_size):",
            "        key = salt.utils.stringutils.to_bytes(base64.b64decode(key_string))",
            "        assert len(key) == key_size / 8 + cls.SIG_SIZE, \"invalid key\"",
            "        return key[: -cls.SIG_SIZE], key[-cls.SIG_SIZE :]",
            "",
            "    def encrypt(self, data):",
            "        \"\"\"",
            "        encrypt data with AES-CBC and sign it with HMAC-SHA256",
            "        \"\"\"",
            "        aes_key, hmac_key = self.keys",
            "        pad = self.AES_BLOCK_SIZE - len(data) % self.AES_BLOCK_SIZE",
            "        data = data + salt.utils.stringutils.to_bytes(pad * chr(pad))",
            "        iv_bytes = os.urandom(self.AES_BLOCK_SIZE)",
            "        if HAS_M2:",
            "            cypher = EVP.Cipher(",
            "                alg=\"aes_192_cbc\", key=aes_key, iv=iv_bytes, op=1, padding=False",
            "            )",
            "            encr = cypher.update(data)",
            "            encr += cypher.final()",
            "        else:",
            "            cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)",
            "            encr = cypher.encrypt(data)",
            "        data = iv_bytes + encr",
            "        sig = hmac.new(hmac_key, data, hashlib.sha256).digest()",
            "        return data + sig",
            "",
            "    def decrypt(self, data):",
            "        \"\"\"",
            "        verify HMAC-SHA256 signature and decrypt data with AES-CBC",
            "        \"\"\"",
            "        aes_key, hmac_key = self.keys",
            "        sig = data[-self.SIG_SIZE :]",
            "        data = data[: -self.SIG_SIZE]",
            "        if not isinstance(data, bytes):",
            "            data = salt.utils.stringutils.to_bytes(data)",
            "        mac_bytes = hmac.new(hmac_key, data, hashlib.sha256).digest()",
            "        if len(mac_bytes) != len(sig):",
            "            log.debug(\"Failed to authenticate message\")",
            "            raise AuthenticationError(\"message authentication failed\")",
            "        result = 0",
            "",
            "        for zipped_x, zipped_y in zip(mac_bytes, sig):",
            "            result |= zipped_x ^ zipped_y",
            "        if result != 0:",
            "            log.debug(\"Failed to authenticate message\")",
            "            raise AuthenticationError(\"message authentication failed\")",
            "        iv_bytes = data[: self.AES_BLOCK_SIZE]",
            "        data = data[self.AES_BLOCK_SIZE :]",
            "        if HAS_M2:",
            "            cypher = EVP.Cipher(",
            "                alg=\"aes_192_cbc\", key=aes_key, iv=iv_bytes, op=0, padding=False",
            "            )",
            "            encr = cypher.update(data)",
            "            data = encr + cypher.final()",
            "        else:",
            "            cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)",
            "            data = cypher.decrypt(data)",
            "        return data[: -data[-1]]",
            "",
            "    def dumps(self, obj):",
            "        \"\"\"",
            "        Serialize and encrypt a python object",
            "        \"\"\"",
            "        return self.encrypt(self.PICKLE_PAD + self.serial.dumps(obj))",
            "",
            "    def loads(self, data, raw=False):",
            "        \"\"\"",
            "        Decrypt and un-serialize a python object",
            "        \"\"\"",
            "        data = self.decrypt(data)",
            "        # simple integrity check to verify that we got meaningful data",
            "        if not data.startswith(self.PICKLE_PAD):",
            "            return {}",
            "        load = self.serial.loads(data[len(self.PICKLE_PAD) :], raw=raw)",
            "        return load"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "The crypt module manages all of the cryptography functions for minions and",
            "masters, encrypting and decrypting payloads, preparing messages, and",
            "authenticating peers",
            "\"\"\"",
            "",
            "import base64",
            "import binascii",
            "import copy",
            "import getpass",
            "import hashlib",
            "import hmac",
            "import logging",
            "import os",
            "import random",
            "import stat",
            "import sys",
            "import time",
            "import traceback",
            "import weakref",
            "",
            "import salt.defaults.exitcodes",
            "import salt.ext.tornado.gen",
            "import salt.payload",
            "import salt.transport.client",
            "import salt.transport.frame",
            "import salt.utils.crypt",
            "import salt.utils.decorators",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.rsax931",
            "import salt.utils.sdb",
            "import salt.utils.stringutils",
            "import salt.utils.user",
            "import salt.utils.verify",
            "import salt.version",
            "from salt.exceptions import (",
            "    AuthenticationError,",
            "    MasterExit,",
            "    SaltClientError,",
            "    SaltReqTimeoutError,",
            ")",
            "",
            "try:",
            "    from M2Crypto import RSA, EVP, BIO",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "",
            "if not HAS_M2:",
            "    try:",
            "        from Cryptodome.Cipher import AES, PKCS1_OAEP, PKCS1_v1_5 as PKCS1_v1_5_CIPHER",
            "        from Cryptodome.Hash import SHA",
            "        from Cryptodome.PublicKey import RSA",
            "        from Cryptodome.Signature import PKCS1_v1_5",
            "        from Cryptodome import Random",
            "",
            "        HAS_CRYPTO = True",
            "    except ImportError:",
            "        HAS_CRYPTO = False",
            "",
            "if not HAS_M2 and not HAS_CRYPTO:",
            "    try:",
            "        from Crypto.Cipher import (  # nosec",
            "            AES,",
            "            PKCS1_OAEP,",
            "            PKCS1_v1_5 as PKCS1_v1_5_CIPHER,",
            "        )",
            "        from Crypto.Hash import SHA  # nosec",
            "        from Crypto.PublicKey import RSA  # nosec",
            "        from Crypto.Signature import PKCS1_v1_5  # nosec",
            "",
            "        # let this be imported, if possible",
            "        from Crypto import Random  # nosec",
            "",
            "        HAS_CRYPTO = True",
            "    except ImportError:",
            "        HAS_CRYPTO = False",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def dropfile(cachedir, user=None):",
            "    \"\"\"",
            "    Set an AES dropfile to request the master update the publish session key",
            "    \"\"\"",
            "    dfn = os.path.join(cachedir, \".dfn\")",
            "    # set a mask (to avoid a race condition on file creation) and store original.",
            "    with salt.utils.files.set_umask(0o277):",
            "        log.info(\"Rotating AES key\")",
            "        if os.path.isfile(dfn):",
            "            log.info(\"AES key rotation already requested\")",
            "            return",
            "",
            "        if os.path.isfile(dfn) and not os.access(dfn, os.W_OK):",
            "            os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)",
            "        with salt.utils.files.fopen(dfn, \"wb+\") as fp_:",
            "            fp_.write(b\"\")",
            "        os.chmod(dfn, stat.S_IRUSR)",
            "        if user:",
            "            try:",
            "                import pwd",
            "",
            "                uid = pwd.getpwnam(user).pw_uid",
            "                os.chown(dfn, uid, -1)",
            "            except (KeyError, ImportError, OSError):",
            "                pass",
            "",
            "",
            "def gen_keys(keydir, keyname, keysize, user=None, passphrase=None):",
            "    \"\"\"",
            "    Generate a RSA public keypair for use with salt",
            "",
            "    :param str keydir: The directory to write the keypair to",
            "    :param str keyname: The type of salt server for whom this key should be written. (i.e. 'master' or 'minion')",
            "    :param int keysize: The number of bits in the key",
            "    :param str user: The user on the system who should own this keypair",
            "    :param str passphrase: The passphrase which should be used to encrypt the private key",
            "",
            "    :rtype: str",
            "    :return: Path on the filesystem to the RSA private key",
            "    \"\"\"",
            "    base = os.path.join(keydir, keyname)",
            "    priv = \"{}.pem\".format(base)",
            "    pub = \"{}.pub\".format(base)",
            "",
            "    if HAS_M2:",
            "        gen = RSA.gen_key(keysize, 65537, lambda: None)",
            "    else:",
            "        salt.utils.crypt.reinit_crypto()",
            "        gen = RSA.generate(bits=keysize, e=65537)",
            "    if os.path.isfile(priv):",
            "        # Between first checking and the generation another process has made",
            "        # a key! Use the winner's key",
            "        return priv",
            "",
            "    # Do not try writing anything, if directory has no permissions.",
            "    if not os.access(keydir, os.W_OK):",
            "        raise OSError(",
            "            'Write access denied to \"{}\" for user \"{}\".'.format(",
            "                os.path.abspath(keydir), getpass.getuser()",
            "            )",
            "        )",
            "",
            "    with salt.utils.files.set_umask(0o277):",
            "        if HAS_M2:",
            "            # if passphrase is empty or None use no cipher",
            "            if not passphrase:",
            "                gen.save_pem(priv, cipher=None)",
            "            else:",
            "                gen.save_pem(",
            "                    priv,",
            "                    cipher=\"des_ede3_cbc\",",
            "                    callback=lambda x: salt.utils.stringutils.to_bytes(passphrase),",
            "                )",
            "        else:",
            "            with salt.utils.files.fopen(priv, \"wb+\") as f:",
            "                f.write(gen.exportKey(\"PEM\", passphrase))",
            "    if HAS_M2:",
            "        gen.save_pub_key(pub)",
            "    else:",
            "        with salt.utils.files.fopen(pub, \"wb+\") as f:",
            "            f.write(gen.publickey().exportKey(\"PEM\"))",
            "    os.chmod(priv, 0o400)",
            "    if user:",
            "        try:",
            "            import pwd",
            "",
            "            uid = pwd.getpwnam(user).pw_uid",
            "            os.chown(priv, uid, -1)",
            "            os.chown(pub, uid, -1)",
            "        except (KeyError, ImportError, OSError):",
            "            # The specified user was not found, allow the backup systems to",
            "            # report the error",
            "            pass",
            "    return priv",
            "",
            "",
            "@salt.utils.decorators.memoize",
            "def _get_key_with_evict(path, timestamp, passphrase):",
            "    \"\"\"",
            "    Load a private key from disk.  `timestamp` above is intended to be the",
            "    timestamp of the file's last modification. This fn is memoized so if it is",
            "    called with the same path and timestamp (the file's last modified time) the",
            "    second time the result is returned from the memoiziation.  If the file gets",
            "    modified then the params are different and the key is loaded from disk.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt._get_key_with_evict: Loading private key\")",
            "    if HAS_M2:",
            "        key = RSA.load_key(path, lambda x: bytes(passphrase))",
            "    else:",
            "        with salt.utils.files.fopen(path) as f:",
            "            key = RSA.importKey(f.read(), passphrase)",
            "    return key",
            "",
            "",
            "def get_rsa_key(path, passphrase):",
            "    \"\"\"",
            "    Read a private key off the disk.  Poor man's simple cache in effect here,",
            "    we memoize the result of calling _get_rsa_with_evict.  This means the first",
            "    time _get_key_with_evict is called with a path and a timestamp the result",
            "    is cached.  If the file (the private key) does not change then its",
            "    timestamp will not change and the next time the result is returned from the",
            "    cache.  If the key DOES change the next time _get_rsa_with_evict is called",
            "    it is called with different parameters and the fn is run fully to retrieve",
            "    the key from disk.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt.get_rsa_key: Loading private key\")",
            "    return _get_key_with_evict(path, str(os.path.getmtime(path)), passphrase)",
            "",
            "",
            "def get_rsa_pub_key(path):",
            "    \"\"\"",
            "    Read a public key off the disk.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt.get_rsa_pub_key: Loading public key\")",
            "    if HAS_M2:",
            "        with salt.utils.files.fopen(path, \"rb\") as f:",
            "            data = f.read().replace(b\"RSA \", b\"\")",
            "        bio = BIO.MemoryBuffer(data)",
            "        key = RSA.load_pub_key_bio(bio)",
            "    else:",
            "        with salt.utils.files.fopen(path) as f:",
            "            key = RSA.importKey(f.read())",
            "    return key",
            "",
            "",
            "def sign_message(privkey_path, message, passphrase=None):",
            "    \"\"\"",
            "    Use Crypto.Signature.PKCS1_v1_5 to sign a message. Returns the signature.",
            "    \"\"\"",
            "    key = get_rsa_key(privkey_path, passphrase)",
            "    log.debug(\"salt.crypt.sign_message: Signing message.\")",
            "    if HAS_M2:",
            "        md = EVP.MessageDigest(\"sha1\")",
            "        md.update(salt.utils.stringutils.to_bytes(message))",
            "        digest = md.final()",
            "        return key.sign(digest)",
            "    else:",
            "        signer = PKCS1_v1_5.new(key)",
            "        return signer.sign(SHA.new(salt.utils.stringutils.to_bytes(message)))",
            "",
            "",
            "def verify_signature(pubkey_path, message, signature):",
            "    \"\"\"",
            "    Use Crypto.Signature.PKCS1_v1_5 to verify the signature on a message.",
            "    Returns True for valid signature.",
            "    \"\"\"",
            "    log.debug(\"salt.crypt.verify_signature: Loading public key\")",
            "    pubkey = get_rsa_pub_key(pubkey_path)",
            "    log.debug(\"salt.crypt.verify_signature: Verifying signature\")",
            "    if HAS_M2:",
            "        md = EVP.MessageDigest(\"sha1\")",
            "        md.update(salt.utils.stringutils.to_bytes(message))",
            "        digest = md.final()",
            "        try:",
            "            return pubkey.verify(digest, signature)",
            "        except RSA.RSAError as exc:",
            "            if exc.args[0] == \"bad signature\":",
            "                return False",
            "            raise",
            "    else:",
            "        verifier = PKCS1_v1_5.new(pubkey)",
            "        return verifier.verify(",
            "            SHA.new(salt.utils.stringutils.to_bytes(message)), signature",
            "        )",
            "",
            "",
            "def gen_signature(priv_path, pub_path, sign_path, passphrase=None):",
            "    \"\"\"",
            "    creates a signature for the given public-key with",
            "    the given private key and writes it to sign_path",
            "    \"\"\"",
            "",
            "    with salt.utils.files.fopen(pub_path) as fp_:",
            "        mpub_64 = fp_.read()",
            "",
            "    mpub_sig = sign_message(priv_path, mpub_64, passphrase)",
            "    mpub_sig_64 = binascii.b2a_base64(mpub_sig)",
            "    if os.path.isfile(sign_path):",
            "        return False",
            "    log.trace(",
            "        \"Calculating signature for %s with %s\",",
            "        os.path.basename(pub_path),",
            "        os.path.basename(priv_path),",
            "    )",
            "",
            "    if os.path.isfile(sign_path):",
            "        log.trace(",
            "            \"Signature file %s already exists, please remove it first and \" \"try again\",",
            "            sign_path,",
            "        )",
            "    else:",
            "        with salt.utils.files.fopen(sign_path, \"wb+\") as sig_f:",
            "            sig_f.write(salt.utils.stringutils.to_bytes(mpub_sig_64))",
            "        log.trace(\"Wrote signature to %s\", sign_path)",
            "    return True",
            "",
            "",
            "def private_encrypt(key, message):",
            "    \"\"\"",
            "    Generate an M2Crypto-compatible signature",
            "",
            "    :param Crypto.PublicKey.RSA._RSAobj key: The RSA key object",
            "    :param str message: The message to sign",
            "    :rtype: str",
            "    :return: The signature, or an empty string if the signature operation failed",
            "    \"\"\"",
            "    if HAS_M2:",
            "        return key.private_encrypt(message, salt.utils.rsax931.RSA_X931_PADDING)",
            "    else:",
            "        signer = salt.utils.rsax931.RSAX931Signer(key.exportKey(\"PEM\"))",
            "        return signer.sign(message)",
            "",
            "",
            "def public_decrypt(pub, message):",
            "    \"\"\"",
            "    Verify an M2Crypto-compatible signature",
            "",
            "    :param Crypto.PublicKey.RSA._RSAobj key: The RSA public key object",
            "    :param str message: The signed message to verify",
            "    :rtype: str",
            "    :return: The message (or digest) recovered from the signature, or an",
            "        empty string if the verification failed",
            "    \"\"\"",
            "    if HAS_M2:",
            "        return pub.public_decrypt(message, salt.utils.rsax931.RSA_X931_PADDING)",
            "    else:",
            "        verifier = salt.utils.rsax931.RSAX931Verifier(pub.exportKey(\"PEM\"))",
            "        return verifier.verify(message)",
            "",
            "",
            "def pwdata_decrypt(rsa_key, pwdata):",
            "    if HAS_M2:",
            "        key = RSA.load_key_string(salt.utils.stringutils.to_bytes(rsa_key, \"ascii\"))",
            "        password = key.private_decrypt(pwdata, RSA.pkcs1_padding)",
            "    else:",
            "        dsize = SHA.digest_size",
            "        sentinel = Random.new().read(15 + dsize)",
            "        key_obj = RSA.importKey(rsa_key)",
            "        key_obj = PKCS1_v1_5_CIPHER.new(key_obj)",
            "        password = key_obj.decrypt(pwdata, sentinel)",
            "    return salt.utils.stringutils.to_unicode(password)",
            "",
            "",
            "class MasterKeys(dict):",
            "    \"\"\"",
            "    The Master Keys class is used to manage the RSA public key pair used for",
            "    authentication by the master.",
            "",
            "    It also generates a signing key-pair if enabled with master_sign_key_name.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts):",
            "        super().__init__()",
            "        self.opts = opts",
            "        self.pub_path = os.path.join(self.opts[\"pki_dir\"], \"master.pub\")",
            "        self.rsa_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "",
            "        key_pass = salt.utils.sdb.sdb_get(self.opts[\"key_pass\"], self.opts)",
            "        self.key = self.__get_keys(passphrase=key_pass)",
            "",
            "        self.pub_signature = None",
            "",
            "        # set names for the signing key-pairs",
            "        if opts[\"master_sign_pubkey\"]:",
            "",
            "            # if only the signature is available, use that",
            "            if opts[\"master_use_pubkey_signature\"]:",
            "                self.sig_path = os.path.join(",
            "                    self.opts[\"pki_dir\"], opts[\"master_pubkey_signature\"]",
            "                )",
            "                if os.path.isfile(self.sig_path):",
            "                    with salt.utils.files.fopen(self.sig_path) as fp_:",
            "                        self.pub_signature = fp_.read()",
            "                    log.info(",
            "                        \"Read %s's signature from %s\",",
            "                        os.path.basename(self.pub_path),",
            "                        self.opts[\"master_pubkey_signature\"],",
            "                    )",
            "                else:",
            "                    log.error(",
            "                        \"Signing the master.pub key with a signature is \"",
            "                        \"enabled but no signature file found at the defined \"",
            "                        \"location %s\",",
            "                        self.sig_path,",
            "                    )",
            "                    log.error(",
            "                        \"The signature-file may be either named differently \"",
            "                        \"or has to be created with 'salt-key --gen-signature'\"",
            "                    )",
            "                    sys.exit(1)",
            "",
            "            # create a new signing key-pair to sign the masters",
            "            # auth-replies when a minion tries to connect",
            "            else:",
            "                key_pass = salt.utils.sdb.sdb_get(",
            "                    self.opts[\"signing_key_pass\"], self.opts",
            "                )",
            "                self.pub_sign_path = os.path.join(",
            "                    self.opts[\"pki_dir\"], opts[\"master_sign_key_name\"] + \".pub\"",
            "                )",
            "                self.rsa_sign_path = os.path.join(",
            "                    self.opts[\"pki_dir\"], opts[\"master_sign_key_name\"] + \".pem\"",
            "                )",
            "                self.sign_key = self.__get_keys(name=opts[\"master_sign_key_name\"])",
            "",
            "    # We need __setstate__ and __getstate__ to avoid pickling errors since",
            "    # some of the member variables correspond to Cython objects which are",
            "    # not picklable.",
            "    # These methods are only used when pickling so will not be used on",
            "    # non-Windows platforms.",
            "    def __setstate__(self, state):",
            "        self.__init__(state[\"opts\"])",
            "",
            "    def __getstate__(self):",
            "        return {\"opts\": self.opts}",
            "",
            "    def __get_keys(self, name=\"master\", passphrase=None):",
            "        \"\"\"",
            "        Returns a key object for a key in the pki-dir",
            "        \"\"\"",
            "        path = os.path.join(self.opts[\"pki_dir\"], name + \".pem\")",
            "        if not os.path.exists(path):",
            "            log.info(\"Generating %s keys: %s\", name, self.opts[\"pki_dir\"])",
            "            gen_keys(",
            "                self.opts[\"pki_dir\"],",
            "                name,",
            "                self.opts[\"keysize\"],",
            "                self.opts.get(\"user\"),",
            "                passphrase,",
            "            )",
            "        if HAS_M2:",
            "            key_error = RSA.RSAError",
            "        else:",
            "            key_error = ValueError",
            "        try:",
            "            key = get_rsa_key(path, passphrase)",
            "        except key_error as e:",
            "            message = \"Unable to read key: {}; passphrase may be incorrect\".format(path)",
            "            log.error(message)",
            "            raise MasterExit(message)",
            "        log.debug(\"Loaded %s key: %s\", name, path)",
            "        return key",
            "",
            "    def get_pub_str(self, name=\"master\"):",
            "        \"\"\"",
            "        Return the string representation of a public key",
            "        in the pki-directory",
            "        \"\"\"",
            "        path = os.path.join(self.opts[\"pki_dir\"], name + \".pub\")",
            "        if not os.path.isfile(path):",
            "            key = self.__get_keys()",
            "            if HAS_M2:",
            "                key.save_pub_key(path)",
            "            else:",
            "                with salt.utils.files.fopen(path, \"wb+\") as wfh:",
            "                    wfh.write(key.publickey().exportKey(\"PEM\"))",
            "        with salt.utils.files.fopen(path) as rfh:",
            "            return rfh.read()",
            "",
            "    def get_mkey_paths(self):",
            "        return self.pub_path, self.rsa_path",
            "",
            "    def get_sign_paths(self):",
            "        return self.pub_sign_path, self.rsa_sign_path",
            "",
            "    def pubkey_signature(self):",
            "        \"\"\"",
            "        returns the base64 encoded signature from the signature file",
            "        or None if the master has its own signing keys",
            "        \"\"\"",
            "        return self.pub_signature",
            "",
            "",
            "class AsyncAuth:",
            "    \"\"\"",
            "    Set up an Async object to maintain authentication with the salt master",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    # mapping of io_loop -> {key -> auth}",
            "    instance_map = weakref.WeakKeyDictionary()",
            "",
            "    # mapping of key -> creds",
            "    creds_map = {}",
            "",
            "    def __new__(cls, opts, io_loop=None):",
            "        \"\"\"",
            "        Only create one instance of AsyncAuth per __key()",
            "        \"\"\"",
            "        # do we have any mapping for this io_loop",
            "        io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()",
            "        if io_loop not in AsyncAuth.instance_map:",
            "            AsyncAuth.instance_map[io_loop] = weakref.WeakValueDictionary()",
            "        loop_instance_map = AsyncAuth.instance_map[io_loop]",
            "",
            "        key = cls.__key(opts)",
            "        auth = loop_instance_map.get(key)",
            "        if auth is None:",
            "            log.debug(\"Initializing new AsyncAuth for %s\", key)",
            "            # we need to make a local variable for this, as we are going to store",
            "            # it in a WeakValueDictionary-- which will remove the item if no one",
            "            # references it-- this forces a reference while we return to the caller",
            "            auth = object.__new__(cls)",
            "            auth.__singleton_init__(opts, io_loop=io_loop)",
            "            loop_instance_map[key] = auth",
            "        else:",
            "            log.debug(\"Re-using AsyncAuth for %s\", key)",
            "        return auth",
            "",
            "    @classmethod",
            "    def __key(cls, opts, io_loop=None):",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            opts[\"master_uri\"],  # master ID",
            "        )",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, io_loop=None):",
            "        pass",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, io_loop=None):",
            "        \"\"\"",
            "        Init an Auth instance",
            "",
            "        :param dict opts: Options for this server",
            "        :return: Auth instance",
            "        :rtype: Auth",
            "        \"\"\"",
            "        self.opts = opts",
            "        self.token = salt.utils.stringutils.to_bytes(Crypticle.generate_key_string())",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.pub_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pub\")",
            "        self.rsa_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pem\")",
            "        if self.opts[\"__role\"] == \"syndic\":",
            "            self.mpub = \"syndic_master.pub\"",
            "        else:",
            "            self.mpub = \"minion_master.pub\"",
            "        if not os.path.isfile(self.pub_path):",
            "            self.get_keys()",
            "",
            "        self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        salt.utils.crypt.reinit_crypto()",
            "        key = self.__key(self.opts)",
            "        # TODO: if we already have creds for this key, lets just re-use",
            "        if key in AsyncAuth.creds_map:",
            "            creds = AsyncAuth.creds_map[key]",
            "            self._creds = creds",
            "            self._crypticle = Crypticle(self.opts, creds[\"aes\"])",
            "            self._authenticate_future = salt.ext.tornado.concurrent.Future()",
            "            self._authenticate_future.set_result(True)",
            "        else:",
            "            self.authenticate()",
            "",
            "    def __deepcopy__(self, memo):",
            "        cls = self.__class__",
            "        result = cls.__new__(cls, copy.deepcopy(self.opts, memo))",
            "        memo[id(self)] = result",
            "        for key in self.__dict__:",
            "            if key in (\"io_loop\",):",
            "                # The io_loop has a thread Lock which will fail to be deep",
            "                # copied. Skip it because it will just be recreated on the",
            "                # new copy.",
            "                continue",
            "            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))",
            "        return result",
            "",
            "    @property",
            "    def creds(self):",
            "        return self._creds",
            "",
            "    @property",
            "    def crypticle(self):",
            "        return self._crypticle",
            "",
            "    @property",
            "    def authenticated(self):",
            "        return (",
            "            hasattr(self, \"_authenticate_future\")",
            "            and self._authenticate_future.done()",
            "            and self._authenticate_future.exception() is None",
            "        )",
            "",
            "    def invalidate(self):",
            "        if self.authenticated:",
            "            del self._authenticate_future",
            "            key = self.__key(self.opts)",
            "            if key in AsyncAuth.creds_map:",
            "                del AsyncAuth.creds_map[key]",
            "",
            "    def authenticate(self, callback=None):",
            "        \"\"\"",
            "        Ask for this client to reconnect to the origin",
            "",
            "        This function will de-dupe all calls here and return a *single* future",
            "        for the sign-in-- whis way callers can all assume there aren't others",
            "        \"\"\"",
            "        # if an auth is in flight-- and not done-- just pass that back as the future to wait on",
            "        if (",
            "            hasattr(self, \"_authenticate_future\")",
            "            and not self._authenticate_future.done()",
            "        ):",
            "            future = self._authenticate_future",
            "        else:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            self._authenticate_future = future",
            "            self.io_loop.add_callback(self._authenticate)",
            "",
            "        if callback is not None:",
            "",
            "            def handle_future(future):",
            "                response = future.result()",
            "                self.io_loop.add_callback(callback, response)",
            "",
            "            future.add_done_callback(handle_future)",
            "",
            "        return future",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _authenticate(self):",
            "        \"\"\"",
            "        Authenticate with the master, this method breaks the functional",
            "        paradigm, it will update the master information from a fresh sign",
            "        in, signing in can occur as often as needed to keep up with the",
            "        revolving master AES key.",
            "",
            "        :rtype: Crypticle",
            "        :returns: A crypticle used for encryption operations",
            "        \"\"\"",
            "        acceptance_wait_time = self.opts[\"acceptance_wait_time\"]",
            "        acceptance_wait_time_max = self.opts[\"acceptance_wait_time_max\"]",
            "        if not acceptance_wait_time_max:",
            "            acceptance_wait_time_max = acceptance_wait_time",
            "        creds = None",
            "",
            "        with salt.transport.client.AsyncReqChannel.factory(",
            "            self.opts, crypt=\"clear\", io_loop=self.io_loop",
            "        ) as channel:",
            "            error = None",
            "            while True:",
            "                try:",
            "                    creds = yield self.sign_in(channel=channel)",
            "                except SaltClientError as exc:",
            "                    error = exc",
            "                    break",
            "                if creds == \"retry\":",
            "                    if self.opts.get(\"detect_mode\") is True:",
            "                        error = SaltClientError(\"Detect mode is on\")",
            "                        break",
            "                    if self.opts.get(\"caller\"):",
            "                        # We have a list of masters, so we should break",
            "                        # and try the next one in the list.",
            "                        if self.opts.get(\"local_masters\", None):",
            "                            error = SaltClientError(",
            "                                \"Minion failed to authenticate\"",
            "                                \" with the master, has the \"",
            "                                \"minion key been accepted?\"",
            "                            )",
            "                            break",
            "                        else:",
            "                            print(",
            "                                \"Minion failed to authenticate with the master, \"",
            "                                \"has the minion key been accepted?\"",
            "                            )",
            "                            sys.exit(2)",
            "                    if acceptance_wait_time:",
            "                        log.info(",
            "                            \"Waiting %s seconds before retry.\", acceptance_wait_time",
            "                        )",
            "                        yield salt.ext.tornado.gen.sleep(acceptance_wait_time)",
            "                    if acceptance_wait_time < acceptance_wait_time_max:",
            "                        acceptance_wait_time += acceptance_wait_time",
            "                        log.debug(",
            "                            \"Authentication wait time is %s\", acceptance_wait_time",
            "                        )",
            "                    continue",
            "                break",
            "            if not isinstance(creds, dict) or \"aes\" not in creds:",
            "                if self.opts.get(\"detect_mode\") is True:",
            "                    error = SaltClientError(\"-|RETRY|-\")",
            "                try:",
            "                    del AsyncAuth.creds_map[self.__key(self.opts)]",
            "                except KeyError:",
            "                    pass",
            "                if not error:",
            "                    error = SaltClientError(",
            "                        \"Attempt to authenticate with the salt master failed\"",
            "                    )",
            "                self._authenticate_future.set_exception(error)",
            "            else:",
            "                key = self.__key(self.opts)",
            "                AsyncAuth.creds_map[key] = creds",
            "                self._creds = creds",
            "                self._crypticle = Crypticle(self.opts, creds[\"aes\"])",
            "                self._authenticate_future.set_result(",
            "                    True",
            "                )  # mark the sign-in as complete",
            "                # Notify the bus about creds change",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    with salt.utils.event.get_event(",
            "                        self.opts.get(\"__role\"), opts=self.opts, listen=False",
            "                    ) as event:",
            "                        event.fire_event(",
            "                            {\"key\": key, \"creds\": creds},",
            "                            salt.utils.event.tagify(prefix=\"auth\", suffix=\"creds\"),",
            "                        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):",
            "        \"\"\"",
            "        Send a sign in request to the master, sets the key information and",
            "        returns a dict containing the master publish interface to bind to",
            "        and the decrypted aes key for transport decryption.",
            "",
            "        :param int timeout: Number of seconds to wait before timing out the sign-in request",
            "        :param bool safe: If True, do not raise an exception on timeout. Retry instead.",
            "        :param int tries: The number of times to try to authenticate before giving up.",
            "",
            "        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set",
            "",
            "        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary",
            "        with the publication port and the shared AES key.",
            "",
            "        \"\"\"",
            "        auth = {}",
            "",
            "        auth_timeout = self.opts.get(\"auth_timeout\", None)",
            "        if auth_timeout is not None:",
            "            timeout = auth_timeout",
            "        auth_safemode = self.opts.get(\"auth_safemode\", None)",
            "        if auth_safemode is not None:",
            "            safe = auth_safemode",
            "        auth_tries = self.opts.get(\"auth_tries\", None)",
            "        if auth_tries is not None:",
            "            tries = auth_tries",
            "",
            "        m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "",
            "        auth[\"master_uri\"] = self.opts[\"master_uri\"]",
            "",
            "        close_channel = False",
            "        if not channel:",
            "            close_channel = True",
            "            channel = salt.transport.client.AsyncReqChannel.factory(",
            "                self.opts, crypt=\"clear\", io_loop=self.io_loop",
            "            )",
            "",
            "        sign_in_payload = self.minion_sign_in_payload()",
            "        try:",
            "            payload = yield channel.send(sign_in_payload, tries=tries, timeout=timeout)",
            "        except SaltReqTimeoutError as e:",
            "            if safe:",
            "                log.warning(\"SaltReqTimeoutError: %s\", e)",
            "                raise salt.ext.tornado.gen.Return(\"retry\")",
            "            if self.opts.get(\"detect_mode\") is True:",
            "                raise salt.ext.tornado.gen.Return(\"retry\")",
            "            else:",
            "                raise SaltClientError(",
            "                    \"Attempt to authenticate with the salt master failed with timeout error\"",
            "                )",
            "        finally:",
            "            if close_channel:",
            "                channel.close()",
            "",
            "        if not isinstance(payload, dict):",
            "            log.error(\"Sign-in attempt failed: %s\", payload)",
            "            raise salt.ext.tornado.gen.Return(False)",
            "        if \"load\" in payload:",
            "            if \"ret\" in payload[\"load\"]:",
            "                if not payload[\"load\"][\"ret\"]:",
            "                    if self.opts[\"rejected_retry\"]:",
            "                        log.error(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key.\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master.\\nThe Salt \"",
            "                            \"Minion will attempt to to re-authenicate.\"",
            "                        )",
            "                        raise salt.ext.tornado.gen.Return(\"retry\")",
            "                    else:",
            "                        log.critical(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key!\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master and restart this \"",
            "                            \"minion.\\nOr restart the Salt Master in open mode to \"",
            "                            \"clean out the keys. The Salt Minion will now exit.\"",
            "                        )",
            "                        # Add a random sleep here for systems that are using a",
            "                        # a service manager to immediately restart the service",
            "                        # to avoid overloading the system",
            "                        time.sleep(random.randint(10, 20))",
            "                        sys.exit(salt.defaults.exitcodes.EX_NOPERM)",
            "                # has the master returned that its maxed out with minions?",
            "                elif payload[\"load\"][\"ret\"] == \"full\":",
            "                    raise salt.ext.tornado.gen.Return(\"full\")",
            "                else:",
            "                    log.error(",
            "                        \"The Salt Master has cached the public key for this \"",
            "                        \"node, this salt minion will wait for %s seconds \"",
            "                        \"before attempting to re-authenticate\",",
            "                        self.opts[\"acceptance_wait_time\"],",
            "                    )",
            "                    raise salt.ext.tornado.gen.Return(\"retry\")",
            "        auth[\"aes\"] = self.verify_master(payload, master_pub=\"token\" in sign_in_payload)",
            "        if not auth[\"aes\"]:",
            "            log.critical(",
            "                \"The Salt Master server's public key did not authenticate!\\n\"",
            "                \"The master may need to be updated if it is a version of Salt \"",
            "                \"lower than %s, or\\n\"",
            "                \"If you are confident that you are connecting to a valid Salt \"",
            "                \"Master, then remove the master public key and restart the \"",
            "                \"Salt Minion.\\nThe master public key can be found \"",
            "                \"at:\\n%s\",",
            "                salt.version.__version__,",
            "                m_pub_fn,",
            "            )",
            "            raise SaltClientError(\"Invalid master key\")",
            "        if self.opts.get(\"syndic_master\", False):  # Is syndic",
            "            syndic_finger = self.opts.get(",
            "                \"syndic_finger\", self.opts.get(\"master_finger\", False)",
            "            )",
            "            if syndic_finger:",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != syndic_finger",
            "                ):",
            "                    self._finger_fail(syndic_finger, m_pub_fn)",
            "        else:",
            "            if self.opts.get(\"master_finger\", False):",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != self.opts[\"master_finger\"]",
            "                ):",
            "                    self._finger_fail(self.opts[\"master_finger\"], m_pub_fn)",
            "        auth[\"publish_port\"] = payload[\"publish_port\"]",
            "        raise salt.ext.tornado.gen.Return(auth)",
            "",
            "    def get_keys(self):",
            "        \"\"\"",
            "        Return keypair object for the minion.",
            "",
            "        :rtype: Crypto.PublicKey.RSA._RSAobj",
            "        :return: The RSA keypair",
            "        \"\"\"",
            "        # Make sure all key parent directories are accessible",
            "        user = self.opts.get(\"user\", \"root\")",
            "        salt.utils.verify.check_path_traversal(self.opts[\"pki_dir\"], user)",
            "",
            "        if not os.path.exists(self.rsa_path):",
            "            log.info(\"Generating keys: %s\", self.opts[\"pki_dir\"])",
            "            gen_keys(",
            "                self.opts[\"pki_dir\"],",
            "                \"minion\",",
            "                self.opts[\"keysize\"],",
            "                self.opts.get(\"user\"),",
            "            )",
            "        key = get_rsa_key(self.rsa_path, None)",
            "        log.debug(\"Loaded minion key: %s\", self.rsa_path)",
            "        return key",
            "",
            "    def gen_token(self, clear_tok):",
            "        \"\"\"",
            "        Encrypt a string with the minion private key to verify identity",
            "        with the master.",
            "",
            "        :param str clear_tok: A plaintext token to encrypt",
            "        :return: Encrypted token",
            "        :rtype: str",
            "        \"\"\"",
            "        return private_encrypt(self.get_keys(), clear_tok)",
            "",
            "    def minion_sign_in_payload(self):",
            "        \"\"\"",
            "        Generates the payload used to authenticate with the master",
            "        server. This payload consists of the passed in id_ and the ssh",
            "        public key to encrypt the AES key sent back from the master.",
            "",
            "        :return: Payload dictionary",
            "        :rtype: dict",
            "        \"\"\"",
            "        payload = {}",
            "        payload[\"cmd\"] = \"_auth\"",
            "        payload[\"id\"] = self.opts[\"id\"]",
            "        if \"autosign_grains\" in self.opts:",
            "            autosign_grains = {}",
            "            for grain in self.opts[\"autosign_grains\"]:",
            "                autosign_grains[grain] = self.opts[\"grains\"].get(grain, None)",
            "            payload[\"autosign_grains\"] = autosign_grains",
            "        try:",
            "            pubkey_path = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "            pub = get_rsa_pub_key(pubkey_path)",
            "            if HAS_M2:",
            "                payload[\"token\"] = pub.public_encrypt(",
            "                    self.token, RSA.pkcs1_oaep_padding",
            "                )",
            "            else:",
            "                cipher = PKCS1_OAEP.new(pub)",
            "                payload[\"token\"] = cipher.encrypt(self.token)",
            "        except Exception:  # pylint: disable=broad-except",
            "            pass",
            "        with salt.utils.files.fopen(self.pub_path) as f:",
            "            payload[\"pub\"] = f.read()",
            "        return payload",
            "",
            "    def decrypt_aes(self, payload, master_pub=True):",
            "        \"\"\"",
            "        This function is used to decrypt the AES seed phrase returned from",
            "        the master server. The seed phrase is decrypted with the SSH RSA",
            "        host key.",
            "",
            "        Pass in the encrypted AES key.",
            "        Returns the decrypted AES seed key, a string",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', etc)",
            "            'sig': The message signature",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The public key of the sender.",
            "",
            "        :rtype: str",
            "        :return: The decrypted token that was provided, with padding.",
            "",
            "        :rtype: str",
            "        :return: The decrypted AES seed key",
            "        \"\"\"",
            "        if self.opts.get(\"auth_trb\", False):",
            "            log.warning(\"Auth Called: %s\", \"\".join(traceback.format_stack()))",
            "        else:",
            "            log.debug(\"Decrypting the current master AES key\")",
            "        key = self.get_keys()",
            "        if HAS_M2:",
            "            key_str = key.private_decrypt(payload[\"aes\"], RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(key)",
            "            key_str = cipher.decrypt(payload[\"aes\"])",
            "        if \"sig\" in payload:",
            "            m_path = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "            if os.path.exists(m_path):",
            "                try:",
            "                    mkey = get_rsa_pub_key(m_path)",
            "                except Exception:  # pylint: disable=broad-except",
            "                    return \"\", \"\"",
            "                digest = hashlib.sha256(key_str).hexdigest()",
            "                digest = salt.utils.stringutils.to_bytes(digest)",
            "                if HAS_M2:",
            "                    m_digest = public_decrypt(mkey, payload[\"sig\"])",
            "                else:",
            "                    m_digest = public_decrypt(mkey.publickey(), payload[\"sig\"])",
            "                if m_digest != digest:",
            "                    return \"\", \"\"",
            "        else:",
            "            return \"\", \"\"",
            "",
            "        key_str = salt.utils.stringutils.to_str(key_str)",
            "",
            "        if \"_|-\" in key_str:",
            "            return key_str.split(\"_|-\")",
            "        else:",
            "            if \"token\" in payload:",
            "                if HAS_M2:",
            "                    token = key.private_decrypt(",
            "                        payload[\"token\"], RSA.pkcs1_oaep_padding",
            "                    )",
            "                else:",
            "                    token = cipher.decrypt(payload[\"token\"])",
            "                return key_str, token",
            "            elif not master_pub:",
            "                return key_str, \"\"",
            "        return \"\", \"\"",
            "",
            "    def verify_pubkey_sig(self, message, sig):",
            "        \"\"\"",
            "        Wraps the verify_signature method so we have",
            "        additional checks.",
            "",
            "        :rtype: bool",
            "        :return: Success or failure of public key verification",
            "        \"\"\"",
            "        if self.opts[\"master_sign_key_name\"]:",
            "            path = os.path.join(",
            "                self.opts[\"pki_dir\"], self.opts[\"master_sign_key_name\"] + \".pub\"",
            "            )",
            "",
            "            if os.path.isfile(path):",
            "                res = verify_signature(path, message, binascii.a2b_base64(sig))",
            "            else:",
            "                log.error(",
            "                    \"Verification public key %s does not exist. You need to \"",
            "                    \"copy it from the master to the minions pki directory\",",
            "                    os.path.basename(path),",
            "                )",
            "                return False",
            "            if res:",
            "                log.debug(",
            "                    \"Successfully verified signature of master public key \"",
            "                    \"with verification public key %s\",",
            "                    self.opts[\"master_sign_key_name\"] + \".pub\",",
            "                )",
            "                return True",
            "            else:",
            "                log.debug(\"Failed to verify signature of public key\")",
            "                return False",
            "        else:",
            "            log.error(",
            "                \"Failed to verify the signature of the message because the \"",
            "                \"verification key-pairs name is not defined. Please make \"",
            "                \"sure that master_sign_key_name is defined.\"",
            "            )",
            "            return False",
            "",
            "    def verify_signing_master(self, payload):",
            "        try:",
            "            if self.verify_pubkey_sig(payload[\"pub_key\"], payload[\"pub_sig\"]):",
            "                log.info(",
            "                    \"Received signed and verified master pubkey from master %s\",",
            "                    self.opts[\"master\"],",
            "                )",
            "                m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "                uid = salt.utils.user.get_uid(self.opts.get(\"user\", None))",
            "                with salt.utils.files.fpopen(m_pub_fn, \"wb+\", uid=uid) as wfh:",
            "                    wfh.write(salt.utils.stringutils.to_bytes(payload[\"pub_key\"]))",
            "                return True",
            "            else:",
            "                log.error(",
            "                    \"Received signed public-key from master %s but signature \"",
            "                    \"verification failed!\",",
            "                    self.opts[\"master\"],",
            "                )",
            "                return False",
            "        except Exception as sign_exc:  # pylint: disable=broad-except",
            "            log.error(",
            "                \"There was an error while verifying the masters public-key \" \"signature\"",
            "            )",
            "            raise Exception(sign_exc)",
            "",
            "    def check_auth_deps(self, payload):",
            "        \"\"\"",
            "        Checks if both master and minion either sign (master) and",
            "        verify (minion). If one side does not, it should fail.",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', 'aes')",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The RSA public key of the sender.",
            "        \"\"\"",
            "        # master and minion sign and verify",
            "        if \"pub_sig\" in payload and self.opts[\"verify_master_pubkey_sign\"]:",
            "            return True",
            "        # master and minion do NOT sign and do NOT verify",
            "        elif \"pub_sig\" not in payload and not self.opts[\"verify_master_pubkey_sign\"]:",
            "            return True",
            "",
            "        # master signs, but minion does NOT verify",
            "        elif \"pub_sig\" in payload and not self.opts[\"verify_master_pubkey_sign\"]:",
            "            log.error(",
            "                \"The masters sent its public-key signature, but signature \"",
            "                \"verification is not enabled on the minion. Either enable \"",
            "                \"signature verification on the minion or disable signing \"",
            "                \"the public key on the master!\"",
            "            )",
            "            return False",
            "        # master does NOT sign but minion wants to verify",
            "        elif \"pub_sig\" not in payload and self.opts[\"verify_master_pubkey_sign\"]:",
            "            log.error(",
            "                \"The master did not send its public-key signature, but \"",
            "                \"signature verification is enabled on the minion. Either \"",
            "                \"disable signature verification on the minion or enable \"",
            "                \"signing the public on the master!\"",
            "            )",
            "            return False",
            "",
            "    def extract_aes(self, payload, master_pub=True):",
            "        \"\"\"",
            "        Return the AES key received from the master after the minion has been",
            "        successfully authenticated.",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', etc)",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The RSA public key of the sender.",
            "",
            "        :rtype: str",
            "        :return: The shared AES key received from the master.",
            "        \"\"\"",
            "        if master_pub:",
            "            try:",
            "                aes, token = self.decrypt_aes(payload, master_pub)",
            "                if token != self.token:",
            "                    log.error(\"The master failed to decrypt the random minion token\")",
            "                    return \"\"",
            "            except Exception:  # pylint: disable=broad-except",
            "                log.error(\"The master failed to decrypt the random minion token\")",
            "                return \"\"",
            "            return aes",
            "        else:",
            "            aes, token = self.decrypt_aes(payload, master_pub)",
            "            return aes",
            "",
            "    def verify_master(self, payload, master_pub=True):",
            "        \"\"\"",
            "        Verify that the master is the same one that was previously accepted.",
            "",
            "        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:",
            "            'aes': The shared AES key",
            "            'enc': The format of the message. ('clear', 'pub', etc)",
            "            'publish_port': The TCP port which published the message",
            "            'token': The encrypted token used to verify the message.",
            "            'pub_key': The RSA public key of the sender.",
            "        :param bool master_pub: Operate as if minion had no master pubkey when it sent auth request, i.e. don't verify",
            "        the minion signature",
            "",
            "        :rtype: str",
            "        :return: An empty string on verification failure. On success, the decrypted AES message in the payload.",
            "        \"\"\"",
            "        m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "        m_pub_exists = os.path.isfile(m_pub_fn)",
            "        if m_pub_exists and master_pub and not self.opts[\"open_mode\"]:",
            "            with salt.utils.files.fopen(m_pub_fn) as fp_:",
            "                local_master_pub = fp_.read()",
            "",
            "            if payload[\"pub_key\"].replace(\"\\n\", \"\").replace(",
            "                \"\\r\", \"\"",
            "            ) != local_master_pub.replace(\"\\n\", \"\").replace(\"\\r\", \"\"):",
            "                if not self.check_auth_deps(payload):",
            "                    return \"\"",
            "",
            "                if self.opts[\"verify_master_pubkey_sign\"]:",
            "                    if self.verify_signing_master(payload):",
            "                        return self.extract_aes(payload, master_pub=False)",
            "                    else:",
            "                        return \"\"",
            "                else:",
            "                    # This is not the last master we connected to",
            "                    log.error(",
            "                        \"The master key has changed, the salt master could \"",
            "                        \"have been subverted, verify salt master's public \"",
            "                        \"key\"",
            "                    )",
            "                    return \"\"",
            "",
            "            else:",
            "                if not self.check_auth_deps(payload):",
            "                    return \"\"",
            "                # verify the signature of the pubkey even if it has",
            "                # not changed compared with the one we already have",
            "                if self.opts[\"always_verify_signature\"]:",
            "                    if self.verify_signing_master(payload):",
            "                        return self.extract_aes(payload)",
            "                    else:",
            "                        log.error(",
            "                            \"The masters public could not be verified. Is the \"",
            "                            \"verification pubkey %s up to date?\",",
            "                            self.opts[\"master_sign_key_name\"] + \".pub\",",
            "                        )",
            "                        return \"\"",
            "",
            "                else:",
            "                    return self.extract_aes(payload)",
            "        else:",
            "            if not self.check_auth_deps(payload):",
            "                return \"\"",
            "",
            "            # verify the masters pubkey signature if the minion",
            "            # has not received any masters pubkey before",
            "            if self.opts[\"verify_master_pubkey_sign\"]:",
            "                if self.verify_signing_master(payload):",
            "                    return self.extract_aes(payload, master_pub=False)",
            "                else:",
            "                    return \"\"",
            "            else:",
            "                if not m_pub_exists:",
            "                    # the minion has not received any masters pubkey yet, write",
            "                    # the newly received pubkey to minion_master.pub",
            "                    with salt.utils.files.fopen(m_pub_fn, \"wb+\") as fp_:",
            "                        fp_.write(salt.utils.stringutils.to_bytes(payload[\"pub_key\"]))",
            "                return self.extract_aes(payload, master_pub=False)",
            "",
            "    def _finger_fail(self, finger, master_key):",
            "        log.critical(",
            "            \"The specified fingerprint in the master configuration \"",
            "            \"file:\\n%s\\nDoes not match the authenticating master's \"",
            "            \"key:\\n%s\\nVerify that the configured fingerprint \"",
            "            \"matches the fingerprint of the correct master and that \"",
            "            \"this minion is not subject to a man-in-the-middle attack.\",",
            "            finger,",
            "            salt.utils.crypt.pem_finger(master_key, sum_type=self.opts[\"hash_type\"]),",
            "        )",
            "        sys.exit(42)",
            "",
            "",
            "# TODO: remove, we should just return a sync wrapper of AsyncAuth",
            "class SAuth(AsyncAuth):",
            "    \"\"\"",
            "    Set up an object to maintain authentication with the salt master",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    instances = weakref.WeakValueDictionary()",
            "",
            "    def __new__(cls, opts, io_loop=None):",
            "        \"\"\"",
            "        Only create one instance of SAuth per __key()",
            "        \"\"\"",
            "        key = cls.__key(opts)",
            "        auth = SAuth.instances.get(key)",
            "        if auth is None:",
            "            log.debug(\"Initializing new SAuth for %s\", key)",
            "            auth = object.__new__(cls)",
            "            auth.__singleton_init__(opts)",
            "            SAuth.instances[key] = auth",
            "        else:",
            "            log.debug(\"Re-using SAuth for %s\", key)",
            "        return auth",
            "",
            "    @classmethod",
            "    def __key(cls, opts, io_loop=None):",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            opts[\"master_uri\"],  # master ID",
            "        )",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, io_loop=None):",
            "        super().__init__(opts, io_loop=io_loop)",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, io_loop=None):",
            "        \"\"\"",
            "        Init an Auth instance",
            "",
            "        :param dict opts: Options for this server",
            "        :return: Auth instance",
            "        :rtype: Auth",
            "        \"\"\"",
            "        self.opts = opts",
            "        self.token = salt.utils.stringutils.to_bytes(Crypticle.generate_key_string())",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.pub_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pub\")",
            "        self.rsa_path = os.path.join(self.opts[\"pki_dir\"], \"minion.pem\")",
            "        if \"syndic_master\" in self.opts:",
            "            self.mpub = \"syndic_master.pub\"",
            "        elif \"alert_master\" in self.opts:",
            "            self.mpub = \"monitor_master.pub\"",
            "        else:",
            "            self.mpub = \"minion_master.pub\"",
            "        if not os.path.isfile(self.pub_path):",
            "            self.get_keys()",
            "",
            "    @property",
            "    def creds(self):",
            "        if not hasattr(self, \"_creds\"):",
            "            self.authenticate()",
            "        return self._creds",
            "",
            "    @property",
            "    def crypticle(self):",
            "        if not hasattr(self, \"_crypticle\"):",
            "            self.authenticate()",
            "        return self._crypticle",
            "",
            "    def authenticate(self, _=None):  # TODO: remove unused var",
            "        \"\"\"",
            "        Authenticate with the master, this method breaks the functional",
            "        paradigm, it will update the master information from a fresh sign",
            "        in, signing in can occur as often as needed to keep up with the",
            "        revolving master AES key.",
            "",
            "        :rtype: Crypticle",
            "        :returns: A crypticle used for encryption operations",
            "        \"\"\"",
            "        acceptance_wait_time = self.opts[\"acceptance_wait_time\"]",
            "        acceptance_wait_time_max = self.opts[\"acceptance_wait_time_max\"]",
            "        if not acceptance_wait_time_max:",
            "            acceptance_wait_time_max = acceptance_wait_time",
            "        with salt.transport.client.ReqChannel.factory(",
            "            self.opts, crypt=\"clear\"",
            "        ) as channel:",
            "            while True:",
            "                creds = self.sign_in(channel=channel)",
            "                if creds == \"retry\":",
            "                    if self.opts.get(\"caller\"):",
            "                        # We have a list of masters, so we should break",
            "                        # and try the next one in the list.",
            "                        if self.opts.get(\"local_masters\", None):",
            "                            error = SaltClientError(",
            "                                \"Minion failed to authenticate\"",
            "                                \" with the master, has the \"",
            "                                \"minion key been accepted?\"",
            "                            )",
            "                            break",
            "                        else:",
            "                            print(",
            "                                \"Minion failed to authenticate with the master, \"",
            "                                \"has the minion key been accepted?\"",
            "                            )",
            "                            sys.exit(2)",
            "                    if acceptance_wait_time:",
            "                        log.info(",
            "                            \"Waiting %s seconds before retry.\", acceptance_wait_time",
            "                        )",
            "                        time.sleep(acceptance_wait_time)",
            "                    if acceptance_wait_time < acceptance_wait_time_max:",
            "                        acceptance_wait_time += acceptance_wait_time",
            "                        log.debug(",
            "                            \"Authentication wait time is %s\", acceptance_wait_time",
            "                        )",
            "                    continue",
            "                break",
            "            self._creds = creds",
            "            self._crypticle = Crypticle(self.opts, creds[\"aes\"])",
            "",
            "    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):",
            "        \"\"\"",
            "        Send a sign in request to the master, sets the key information and",
            "        returns a dict containing the master publish interface to bind to",
            "        and the decrypted aes key for transport decryption.",
            "",
            "        :param int timeout: Number of seconds to wait before timing out the sign-in request",
            "        :param bool safe: If True, do not raise an exception on timeout. Retry instead.",
            "        :param int tries: The number of times to try to authenticate before giving up.",
            "",
            "        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set",
            "",
            "        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary",
            "        with the publication port and the shared AES key.",
            "",
            "        \"\"\"",
            "        auth = {}",
            "",
            "        auth_timeout = self.opts.get(\"auth_timeout\", None)",
            "        if auth_timeout is not None:",
            "            timeout = auth_timeout",
            "        auth_safemode = self.opts.get(\"auth_safemode\", None)",
            "        if auth_safemode is not None:",
            "            safe = auth_safemode",
            "        auth_tries = self.opts.get(\"auth_tries\", None)",
            "        if auth_tries is not None:",
            "            tries = auth_tries",
            "",
            "        m_pub_fn = os.path.join(self.opts[\"pki_dir\"], self.mpub)",
            "",
            "        auth[\"master_uri\"] = self.opts[\"master_uri\"]",
            "",
            "        close_channel = False",
            "        if not channel:",
            "            close_channel = True",
            "            channel = salt.transport.client.ReqChannel.factory(self.opts, crypt=\"clear\")",
            "",
            "        sign_in_payload = self.minion_sign_in_payload()",
            "        try:",
            "            payload = channel.send(sign_in_payload, tries=tries, timeout=timeout)",
            "        except SaltReqTimeoutError as e:",
            "            if safe:",
            "                log.warning(\"SaltReqTimeoutError: %s\", e)",
            "                return \"retry\"",
            "            raise SaltClientError(",
            "                \"Attempt to authenticate with the salt master failed with timeout error\"",
            "            )",
            "        finally:",
            "            if close_channel:",
            "                channel.close()",
            "",
            "        if \"load\" in payload:",
            "            if \"ret\" in payload[\"load\"]:",
            "                if not payload[\"load\"][\"ret\"]:",
            "                    if self.opts[\"rejected_retry\"]:",
            "                        log.error(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key.\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master.\\nThe Salt \"",
            "                            \"Minion will attempt to to re-authenicate.\"",
            "                        )",
            "                        return \"retry\"",
            "                    else:",
            "                        log.critical(",
            "                            \"The Salt Master has rejected this minion's public \"",
            "                            \"key!\\nTo repair this issue, delete the public key \"",
            "                            \"for this minion on the Salt Master and restart this \"",
            "                            \"minion.\\nOr restart the Salt Master in open mode to \"",
            "                            \"clean out the keys. The Salt Minion will now exit.\"",
            "                        )",
            "                        sys.exit(salt.defaults.exitcodes.EX_NOPERM)",
            "                # has the master returned that its maxed out with minions?",
            "                elif payload[\"load\"][\"ret\"] == \"full\":",
            "                    return \"full\"",
            "                else:",
            "                    log.error(",
            "                        \"The Salt Master has cached the public key for this \"",
            "                        \"node. If this is the first time connecting to this \"",
            "                        \"master then this key may need to be accepted using \"",
            "                        \"'salt-key -a %s' on the salt master. This salt \"",
            "                        \"minion will wait for %s seconds before attempting \"",
            "                        \"to re-authenticate.\",",
            "                        self.opts[\"id\"],",
            "                        self.opts[\"acceptance_wait_time\"],",
            "                    )",
            "                    return \"retry\"",
            "        auth[\"aes\"] = self.verify_master(payload, master_pub=\"token\" in sign_in_payload)",
            "        if not auth[\"aes\"]:",
            "            log.critical(",
            "                \"The Salt Master server's public key did not authenticate!\\n\"",
            "                \"The master may need to be updated if it is a version of Salt \"",
            "                \"lower than %s, or\\n\"",
            "                \"If you are confident that you are connecting to a valid Salt \"",
            "                \"Master, then remove the master public key and restart the \"",
            "                \"Salt Minion.\\nThe master public key can be found \"",
            "                \"at:\\n%s\",",
            "                salt.version.__version__,",
            "                m_pub_fn,",
            "            )",
            "            sys.exit(42)",
            "        if self.opts.get(\"syndic_master\", False):  # Is syndic",
            "            syndic_finger = self.opts.get(",
            "                \"syndic_finger\", self.opts.get(\"master_finger\", False)",
            "            )",
            "            if syndic_finger:",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != syndic_finger",
            "                ):",
            "                    self._finger_fail(syndic_finger, m_pub_fn)",
            "        else:",
            "            if self.opts.get(\"master_finger\", False):",
            "                if (",
            "                    salt.utils.crypt.pem_finger(",
            "                        m_pub_fn, sum_type=self.opts[\"hash_type\"]",
            "                    )",
            "                    != self.opts[\"master_finger\"]",
            "                ):",
            "                    self._finger_fail(self.opts[\"master_finger\"], m_pub_fn)",
            "        auth[\"publish_port\"] = payload[\"publish_port\"]",
            "        return auth",
            "",
            "",
            "class Crypticle:",
            "    \"\"\"",
            "    Authenticated encryption class",
            "",
            "    Encryption algorithm: AES-CBC",
            "    Signing algorithm: HMAC-SHA256",
            "    \"\"\"",
            "",
            "    PICKLE_PAD = b\"pickle::\"",
            "    AES_BLOCK_SIZE = 16",
            "    SIG_SIZE = hashlib.sha256().digest_size",
            "",
            "    def __init__(self, opts, key_string, key_size=192):",
            "        self.key_string = key_string",
            "        self.keys = self.extract_keys(self.key_string, key_size)",
            "        self.key_size = key_size",
            "        self.serial = salt.payload.Serial(opts)",
            "",
            "    @classmethod",
            "    def generate_key_string(cls, key_size=192):",
            "        key = os.urandom(key_size // 8 + cls.SIG_SIZE)",
            "        b64key = base64.b64encode(key)",
            "        b64key = b64key.decode(\"utf-8\")",
            "        # Return data must be a base64-encoded string, not a unicode type",
            "        return b64key.replace(\"\\n\", \"\")",
            "",
            "    @classmethod",
            "    def extract_keys(cls, key_string, key_size):",
            "        key = salt.utils.stringutils.to_bytes(base64.b64decode(key_string))",
            "        assert len(key) == key_size / 8 + cls.SIG_SIZE, \"invalid key\"",
            "        return key[: -cls.SIG_SIZE], key[-cls.SIG_SIZE :]",
            "",
            "    def encrypt(self, data):",
            "        \"\"\"",
            "        encrypt data with AES-CBC and sign it with HMAC-SHA256",
            "        \"\"\"",
            "        aes_key, hmac_key = self.keys",
            "        pad = self.AES_BLOCK_SIZE - len(data) % self.AES_BLOCK_SIZE",
            "        data = data + salt.utils.stringutils.to_bytes(pad * chr(pad))",
            "        iv_bytes = os.urandom(self.AES_BLOCK_SIZE)",
            "        if HAS_M2:",
            "            cypher = EVP.Cipher(",
            "                alg=\"aes_192_cbc\", key=aes_key, iv=iv_bytes, op=1, padding=False",
            "            )",
            "            encr = cypher.update(data)",
            "            encr += cypher.final()",
            "        else:",
            "            cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)",
            "            encr = cypher.encrypt(data)",
            "        data = iv_bytes + encr",
            "        sig = hmac.new(hmac_key, data, hashlib.sha256).digest()",
            "        return data + sig",
            "",
            "    def decrypt(self, data):",
            "        \"\"\"",
            "        verify HMAC-SHA256 signature and decrypt data with AES-CBC",
            "        \"\"\"",
            "        aes_key, hmac_key = self.keys",
            "        sig = data[-self.SIG_SIZE :]",
            "        data = data[: -self.SIG_SIZE]",
            "        if not isinstance(data, bytes):",
            "            data = salt.utils.stringutils.to_bytes(data)",
            "        mac_bytes = hmac.new(hmac_key, data, hashlib.sha256).digest()",
            "        if len(mac_bytes) != len(sig):",
            "            log.debug(\"Failed to authenticate message\")",
            "            raise AuthenticationError(\"message authentication failed\")",
            "        result = 0",
            "",
            "        for zipped_x, zipped_y in zip(mac_bytes, sig):",
            "            result |= zipped_x ^ zipped_y",
            "        if result != 0:",
            "            log.debug(\"Failed to authenticate message\")",
            "            raise AuthenticationError(\"message authentication failed\")",
            "        iv_bytes = data[: self.AES_BLOCK_SIZE]",
            "        data = data[self.AES_BLOCK_SIZE :]",
            "        if HAS_M2:",
            "            cypher = EVP.Cipher(",
            "                alg=\"aes_192_cbc\", key=aes_key, iv=iv_bytes, op=0, padding=False",
            "            )",
            "            encr = cypher.update(data)",
            "            data = encr + cypher.final()",
            "        else:",
            "            cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)",
            "            data = cypher.decrypt(data)",
            "        return data[: -data[-1]]",
            "",
            "    def dumps(self, obj):",
            "        \"\"\"",
            "        Serialize and encrypt a python object",
            "        \"\"\"",
            "        return self.encrypt(self.PICKLE_PAD + self.serial.dumps(obj))",
            "",
            "    def loads(self, data, raw=False):",
            "        \"\"\"",
            "        Decrypt and un-serialize a python object",
            "        \"\"\"",
            "        data = self.decrypt(data)",
            "        # simple integrity check to verify that we got meaningful data",
            "        if not data.startswith(self.PICKLE_PAD):",
            "            return {}",
            "        load = self.serial.loads(data[len(self.PICKLE_PAD) :], raw=raw)",
            "        return load"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "258": [
                "verify_signature"
            ]
        },
        "addLocation": []
    },
    "salt/pillar/__init__.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " import os"
            },
            "1": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " import sys"
            },
            "2": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import traceback"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 14,
                "PatchRowcode": "+import uuid"
            },
            "4": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " import salt.ext.tornado.gen"
            },
            "6": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import salt.fileclient"
            },
            "7": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 243,
                "PatchRowcode": "             ret_pillar = yield self.channel.crypted_transfer_decode_dictentry("
            },
            "8": {
                "beforePatchRowNumber": 243,
                "afterPatchRowNumber": 244,
                "PatchRowcode": "                 load, dictkey=\"pillar\","
            },
            "9": {
                "beforePatchRowNumber": 244,
                "afterPatchRowNumber": 245,
                "PatchRowcode": "             )"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+        except salt.crypt.AuthenticationError as exc:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 247,
                "PatchRowcode": "+            log.error(exc.message)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+            raise SaltClientError(\"Exception getting pillar.\")"
            },
            "13": {
                "beforePatchRowNumber": 245,
                "afterPatchRowNumber": 249,
                "PatchRowcode": "         except Exception:  # pylint: disable=broad-except"
            },
            "14": {
                "beforePatchRowNumber": 246,
                "afterPatchRowNumber": 250,
                "PatchRowcode": "             log.exception(\"Exception getting pillar:\")"
            },
            "15": {
                "beforePatchRowNumber": 247,
                "afterPatchRowNumber": 251,
                "PatchRowcode": "             raise SaltClientError(\"Exception getting pillar.\")"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Render the pillar data",
            "\"\"\"",
            "",
            "",
            "import collections",
            "import copy",
            "import fnmatch",
            "import inspect",
            "import logging",
            "import os",
            "import sys",
            "import traceback",
            "",
            "import salt.ext.tornado.gen",
            "import salt.fileclient",
            "import salt.loader",
            "import salt.minion",
            "import salt.transport.client",
            "import salt.utils.args",
            "import salt.utils.cache",
            "import salt.utils.crypt",
            "import salt.utils.data",
            "import salt.utils.dictupdate",
            "import salt.utils.url",
            "from salt.exceptions import SaltClientError",
            "from salt.ext import six",
            "from salt.template import compile_template",
            "",
            "# Even though dictupdate is imported, invoking salt.utils.dictupdate.merge here",
            "# causes an UnboundLocalError. This should be investigated and fixed, but until",
            "# then, leave the import directly below this comment intact.",
            "from salt.utils.dictupdate import merge",
            "from salt.utils.odict import OrderedDict",
            "from salt.version import __version__",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def get_pillar(",
            "    opts,",
            "    grains,",
            "    minion_id,",
            "    saltenv=None,",
            "    ext=None,",
            "    funcs=None,",
            "    pillar_override=None,",
            "    pillarenv=None,",
            "    extra_minion_data=None,",
            "):",
            "    \"\"\"",
            "    Return the correct pillar driver based on the file_client option",
            "    \"\"\"",
            "    # When file_client is 'local' this makes the minion masterless",
            "    # but sometimes we want the minion to read its files from the local",
            "    # filesystem instead of asking for them from the master, but still",
            "    # get commands from the master.",
            "    # To enable this functionality set file_client=local and",
            "    # use_master_when_local=True in the minion config.  Then here we override",
            "    # the file client to be 'remote' for getting pillar.  If we don't do this",
            "    # then the minion never sends the event that the master uses to update",
            "    # its minion_data_cache.  If the master doesn't update the minion_data_cache",
            "    # then the SSE salt-master plugin won't see any grains for those minions.",
            "    file_client = opts[\"file_client\"]",
            "    if opts.get(\"master_type\") == \"disable\" and file_client == \"remote\":",
            "        file_client = \"local\"",
            "    elif file_client == \"local\" and opts.get(\"use_master_when_local\"):",
            "        file_client = \"remote\"",
            "",
            "    ptype = {\"remote\": RemotePillar, \"local\": Pillar}.get(file_client, Pillar)",
            "    # If local pillar and we're caching, run through the cache system first",
            "    log.debug(\"Determining pillar cache\")",
            "    if opts[\"pillar_cache\"]:",
            "        log.debug(\"get_pillar using pillar cache with ext: %s\", ext)",
            "        return PillarCache(",
            "            opts,",
            "            grains,",
            "            minion_id,",
            "            saltenv,",
            "            ext=ext,",
            "            functions=funcs,",
            "            pillar_override=pillar_override,",
            "            pillarenv=pillarenv,",
            "        )",
            "    return ptype(",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext,",
            "        functions=funcs,",
            "        pillar_override=pillar_override,",
            "        pillarenv=pillarenv,",
            "        extra_minion_data=extra_minion_data,",
            "    )",
            "",
            "",
            "# TODO: migrate everyone to this one!",
            "def get_async_pillar(",
            "    opts,",
            "    grains,",
            "    minion_id,",
            "    saltenv=None,",
            "    ext=None,",
            "    funcs=None,",
            "    pillar_override=None,",
            "    pillarenv=None,",
            "    extra_minion_data=None,",
            "):",
            "    \"\"\"",
            "    Return the correct pillar driver based on the file_client option",
            "    \"\"\"",
            "    file_client = opts[\"file_client\"]",
            "    if opts.get(\"master_type\") == \"disable\" and file_client == \"remote\":",
            "        file_client = \"local\"",
            "    elif file_client == \"local\" and opts.get(\"use_master_when_local\"):",
            "        file_client = \"remote\"",
            "    ptype = {\"remote\": AsyncRemotePillar, \"local\": AsyncPillar}.get(",
            "        file_client, AsyncPillar",
            "    )",
            "    return ptype(",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext,",
            "        functions=funcs,",
            "        pillar_override=pillar_override,",
            "        pillarenv=pillarenv,",
            "        extra_minion_data=extra_minion_data,",
            "    )",
            "",
            "",
            "class RemotePillarMixin:",
            "    \"\"\"",
            "    Common remote pillar functionality",
            "    \"\"\"",
            "",
            "    def get_ext_pillar_extra_minion_data(self, opts):",
            "        \"\"\"",
            "        Returns the extra data from the minion's opts dict (the config file).",
            "",
            "        This data will be passed to external pillar functions.",
            "        \"\"\"",
            "",
            "        def get_subconfig(opts_key):",
            "            \"\"\"",
            "            Returns a dict containing the opts key subtree, while maintaining",
            "            the opts structure",
            "            \"\"\"",
            "            ret_dict = aux_dict = {}",
            "            config_val = opts",
            "            subkeys = opts_key.split(\":\")",
            "            # Build an empty dict with the opts path",
            "            for subkey in subkeys[:-1]:",
            "                aux_dict[subkey] = {}",
            "                aux_dict = aux_dict[subkey]",
            "                if not config_val.get(subkey):",
            "                    # The subkey is not in the config",
            "                    return {}",
            "                config_val = config_val[subkey]",
            "            if subkeys[-1] not in config_val:",
            "                return {}",
            "            aux_dict[subkeys[-1]] = config_val[subkeys[-1]]",
            "            return ret_dict",
            "",
            "        extra_data = {}",
            "        if \"pass_to_ext_pillars\" in opts:",
            "            if not isinstance(opts[\"pass_to_ext_pillars\"], list):",
            "                log.exception(\"'pass_to_ext_pillars' config is malformed.\")",
            "                raise SaltClientError(\"'pass_to_ext_pillars' config is \" \"malformed.\")",
            "            for key in opts[\"pass_to_ext_pillars\"]:",
            "                salt.utils.dictupdate.update(",
            "                    extra_data,",
            "                    get_subconfig(key),",
            "                    recursive_update=True,",
            "                    merge_lists=True,",
            "                )",
            "        log.trace(\"ext_pillar_extra_data = %s\", extra_data)",
            "        return extra_data",
            "",
            "",
            "class AsyncRemotePillar(RemotePillarMixin):",
            "    \"\"\"",
            "    Get the pillar from the master",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        self.opts = opts",
            "        self.opts[\"saltenv\"] = saltenv",
            "        self.ext = ext",
            "        self.grains = grains",
            "        self.minion_id = minion_id",
            "        self.channel = salt.transport.client.AsyncReqChannel.factory(opts)",
            "        if pillarenv is not None:",
            "            self.opts[\"pillarenv\"] = pillarenv",
            "        self.pillar_override = pillar_override or {}",
            "        if not isinstance(self.pillar_override, dict):",
            "            self.pillar_override = {}",
            "            log.error(\"Pillar data must be a dictionary\")",
            "        self.extra_minion_data = extra_minion_data or {}",
            "        if not isinstance(self.extra_minion_data, dict):",
            "            self.extra_minion_data = {}",
            "            log.error(\"Extra minion data must be a dictionary\")",
            "        salt.utils.dictupdate.update(",
            "            self.extra_minion_data,",
            "            self.get_ext_pillar_extra_minion_data(opts),",
            "            recursive_update=True,",
            "            merge_lists=True,",
            "        )",
            "        self._closing = False",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def compile_pillar(self):",
            "        \"\"\"",
            "        Return a future which will contain the pillar data from the master",
            "        \"\"\"",
            "        load = {",
            "            \"id\": self.minion_id,",
            "            \"grains\": self.grains,",
            "            \"saltenv\": self.opts[\"saltenv\"],",
            "            \"pillarenv\": self.opts[\"pillarenv\"],",
            "            \"pillar_override\": self.pillar_override,",
            "            \"extra_minion_data\": self.extra_minion_data,",
            "            \"ver\": \"2\",",
            "            \"cmd\": \"_pillar\",",
            "        }",
            "        if self.ext:",
            "            load[\"ext\"] = self.ext",
            "        try:",
            "            ret_pillar = yield self.channel.crypted_transfer_decode_dictentry(",
            "                load, dictkey=\"pillar\",",
            "            )",
            "        except Exception:  # pylint: disable=broad-except",
            "            log.exception(\"Exception getting pillar:\")",
            "            raise SaltClientError(\"Exception getting pillar.\")",
            "",
            "        if not isinstance(ret_pillar, dict):",
            "            msg = (",
            "                \"Got a bad pillar from master, type {}, expecting dict: \" \"{}\"",
            "            ).format(type(ret_pillar).__name__, ret_pillar)",
            "            log.error(msg)",
            "            # raise an exception! Pillar isn't empty, we can't sync it!",
            "            raise SaltClientError(msg)",
            "        raise salt.ext.tornado.gen.Return(ret_pillar)",
            "",
            "    def destroy(self):",
            "        if self._closing:",
            "            return",
            "",
            "        self._closing = True",
            "        self.channel.close()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.destroy()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "class RemotePillar(RemotePillarMixin):",
            "    \"\"\"",
            "    Get the pillar from the master",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        self.opts = opts",
            "        self.opts[\"saltenv\"] = saltenv",
            "        self.ext = ext",
            "        self.grains = grains",
            "        self.minion_id = minion_id",
            "        self.channel = salt.transport.client.ReqChannel.factory(opts)",
            "        if pillarenv is not None:",
            "            self.opts[\"pillarenv\"] = pillarenv",
            "        self.pillar_override = pillar_override or {}",
            "        if not isinstance(self.pillar_override, dict):",
            "            self.pillar_override = {}",
            "            log.error(\"Pillar data must be a dictionary\")",
            "        self.extra_minion_data = extra_minion_data or {}",
            "        if not isinstance(self.extra_minion_data, dict):",
            "            self.extra_minion_data = {}",
            "            log.error(\"Extra minion data must be a dictionary\")",
            "        salt.utils.dictupdate.update(",
            "            self.extra_minion_data,",
            "            self.get_ext_pillar_extra_minion_data(opts),",
            "            recursive_update=True,",
            "            merge_lists=True,",
            "        )",
            "        self._closing = False",
            "",
            "    def compile_pillar(self):",
            "        \"\"\"",
            "        Return the pillar data from the master",
            "        \"\"\"",
            "        load = {",
            "            \"id\": self.minion_id,",
            "            \"grains\": self.grains,",
            "            \"saltenv\": self.opts[\"saltenv\"],",
            "            \"pillarenv\": self.opts[\"pillarenv\"],",
            "            \"pillar_override\": self.pillar_override,",
            "            \"extra_minion_data\": self.extra_minion_data,",
            "            \"ver\": \"2\",",
            "            \"cmd\": \"_pillar\",",
            "        }",
            "        if self.ext:",
            "            load[\"ext\"] = self.ext",
            "        ret_pillar = self.channel.crypted_transfer_decode_dictentry(",
            "            load, dictkey=\"pillar\",",
            "        )",
            "",
            "        if not isinstance(ret_pillar, dict):",
            "            log.error(",
            "                \"Got a bad pillar from master, type %s, expecting dict: %s\",",
            "                type(ret_pillar).__name__,",
            "                ret_pillar,",
            "            )",
            "            return {}",
            "        return ret_pillar",
            "",
            "    def destroy(self):",
            "        if hasattr(self, \"_closing\") and self._closing:",
            "            return",
            "",
            "        self._closing = True",
            "        self.channel.close()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.destroy()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "class PillarCache:",
            "    \"\"\"",
            "    Return a cached pillar if it exists, otherwise cache it.",
            "",
            "    Pillar caches are structed in two diminensions: minion_id with a dict of",
            "    saltenvs. Each saltenv contains a pillar dict",
            "",
            "    Example data structure:",
            "",
            "    ```",
            "    {'minion_1':",
            "        {'base': {'pilar_key_1' 'pillar_val_1'}",
            "    }",
            "    \"\"\"",
            "",
            "    # TODO ABC?",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        # Yes, we need all of these because we need to route to the Pillar object",
            "        # if we have no cache. This is another refactor target.",
            "",
            "        # Go ahead and assign these because they may be needed later",
            "        self.opts = opts",
            "        self.grains = grains",
            "        self.minion_id = minion_id",
            "        self.ext = ext",
            "        self.functions = functions",
            "        self.pillar_override = pillar_override",
            "        self.pillarenv = pillarenv",
            "",
            "        if saltenv is None:",
            "            self.saltenv = \"base\"",
            "        else:",
            "            self.saltenv = saltenv",
            "",
            "        # Determine caching backend",
            "        self.cache = salt.utils.cache.CacheFactory.factory(",
            "            self.opts[\"pillar_cache_backend\"],",
            "            self.opts[\"pillar_cache_ttl\"],",
            "            minion_cache_path=self._minion_cache_path(minion_id),",
            "        )",
            "",
            "    def _minion_cache_path(self, minion_id):",
            "        \"\"\"",
            "        Return the path to the cache file for the minion.",
            "",
            "        Used only for disk-based backends",
            "        \"\"\"",
            "        return os.path.join(self.opts[\"cachedir\"], \"pillar_cache\", minion_id)",
            "",
            "    def fetch_pillar(self):",
            "        \"\"\"",
            "        In the event of a cache miss, we need to incur the overhead of caching",
            "        a new pillar.",
            "        \"\"\"",
            "        log.debug(\"Pillar cache getting external pillar with ext: %s\", self.ext)",
            "        fresh_pillar = Pillar(",
            "            self.opts,",
            "            self.grains,",
            "            self.minion_id,",
            "            self.saltenv,",
            "            ext=self.ext,",
            "            functions=self.functions,",
            "            pillar_override=self.pillar_override,",
            "            pillarenv=self.pillarenv,",
            "        )",
            "        return fresh_pillar.compile_pillar()",
            "",
            "    def clear_pillar(self):",
            "        \"\"\"",
            "        Clear the cache",
            "        \"\"\"",
            "        self.cache.clear()",
            "",
            "        return True",
            "",
            "    def compile_pillar(self, *args, **kwargs):  # Will likely just be pillar_dirs",
            "        log.debug(",
            "            \"Scanning pillar cache for information about minion %s and pillarenv %s\",",
            "            self.minion_id,",
            "            self.pillarenv,",
            "        )",
            "        if self.opts[\"pillar_cache_backend\"] == \"memory\":",
            "            cache_dict = self.cache",
            "        else:",
            "            cache_dict = self.cache._dict",
            "",
            "        log.debug(\"Scanning cache: %s\", cache_dict)",
            "        # Check the cache!",
            "        if self.minion_id in self.cache:  # Keyed by minion_id",
            "            # TODO Compare grains, etc?",
            "            if self.pillarenv in self.cache[self.minion_id]:",
            "                # We have a cache hit! Send it back.",
            "                log.debug(",
            "                    \"Pillar cache hit for minion %s and pillarenv %s\",",
            "                    self.minion_id,",
            "                    self.pillarenv,",
            "                )",
            "                return self.cache[self.minion_id][self.pillarenv]",
            "            else:",
            "                # We found the minion but not the env. Store it.",
            "                fresh_pillar = self.fetch_pillar()",
            "",
            "                minion_cache = self.cache[self.minion_id]",
            "                minion_cache[self.pillarenv] = fresh_pillar",
            "                self.cache[self.minion_id] = minion_cache",
            "",
            "                log.debug(",
            "                    \"Pillar cache miss for pillarenv %s for minion %s\",",
            "                    self.pillarenv,",
            "                    self.minion_id,",
            "                )",
            "                return fresh_pillar",
            "        else:",
            "            # We haven't seen this minion yet in the cache. Store it.",
            "            fresh_pillar = self.fetch_pillar()",
            "            self.cache[self.minion_id] = {self.pillarenv: fresh_pillar}",
            "            log.debug(\"Pillar cache miss for minion %s\", self.minion_id)",
            "            log.debug(\"Current pillar cache: %s\", cache_dict)  # FIXME hack!",
            "            return fresh_pillar",
            "",
            "",
            "class Pillar:",
            "    \"\"\"",
            "    Read over the pillar top files and render the pillar data",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        self.minion_id = minion_id",
            "        self.ext = ext",
            "        if pillarenv is None:",
            "            if opts.get(\"pillarenv_from_saltenv\", False):",
            "                opts[\"pillarenv\"] = saltenv",
            "        # use the local file client",
            "        self.opts = self.__gen_opts(opts, grains, saltenv=saltenv, pillarenv=pillarenv)",
            "        self.saltenv = saltenv",
            "        self.client = salt.fileclient.get_file_client(self.opts, True)",
            "        self.avail = self.__gather_avail()",
            "",
            "        if opts.get(\"file_client\", \"\") == \"local\" and not opts.get(",
            "            \"use_master_when_local\", False",
            "        ):",
            "            opts[\"grains\"] = grains",
            "",
            "        # if we didn't pass in functions, lets load them",
            "        if functions is None:",
            "            utils = salt.loader.utils(opts)",
            "            if opts.get(\"file_client\", \"\") == \"local\":",
            "                self.functions = salt.loader.minion_mods(opts, utils=utils)",
            "            else:",
            "                self.functions = salt.loader.minion_mods(self.opts, utils=utils)",
            "        else:",
            "            self.functions = functions",
            "",
            "        self.opts[\"minion_id\"] = minion_id",
            "        self.matchers = salt.loader.matchers(self.opts)",
            "        self.rend = salt.loader.render(self.opts, self.functions)",
            "        ext_pillar_opts = copy.deepcopy(self.opts)",
            "        # Keep the incoming opts ID intact, ie, the master id",
            "        if \"id\" in opts:",
            "            ext_pillar_opts[\"id\"] = opts[\"id\"]",
            "        self.merge_strategy = \"smart\"",
            "        if opts.get(\"pillar_source_merging_strategy\"):",
            "            self.merge_strategy = opts[\"pillar_source_merging_strategy\"]",
            "",
            "        self.ext_pillars = salt.loader.pillars(ext_pillar_opts, self.functions)",
            "        self.ignored_pillars = {}",
            "        self.pillar_override = pillar_override or {}",
            "        if not isinstance(self.pillar_override, dict):",
            "            self.pillar_override = {}",
            "            log.error(\"Pillar data must be a dictionary\")",
            "        self.extra_minion_data = extra_minion_data or {}",
            "        if not isinstance(self.extra_minion_data, dict):",
            "            self.extra_minion_data = {}",
            "            log.error(\"Extra minion data must be a dictionary\")",
            "        self._closing = False",
            "",
            "    def __valid_on_demand_ext_pillar(self, opts):",
            "        \"\"\"",
            "        Check to see if the on demand external pillar is allowed",
            "        \"\"\"",
            "        if not isinstance(self.ext, dict):",
            "            log.error(\"On-demand pillar %s is not formatted as a dictionary\", self.ext)",
            "            return False",
            "",
            "        on_demand = opts.get(\"on_demand_ext_pillar\", [])",
            "        try:",
            "            invalid_on_demand = {x for x in self.ext if x not in on_demand}",
            "        except TypeError:",
            "            # Prevent traceback when on_demand_ext_pillar option is malformed",
            "            log.error(",
            "                \"The 'on_demand_ext_pillar' configuration option is \"",
            "                \"malformed, it should be a list of ext_pillar module names\"",
            "            )",
            "            return False",
            "",
            "        if invalid_on_demand:",
            "            log.error(",
            "                \"The following ext_pillar modules are not allowed for \"",
            "                \"on-demand pillar data: %s. Valid on-demand ext_pillar \"",
            "                \"modules are: %s. The valid modules can be adjusted by \"",
            "                \"setting the 'on_demand_ext_pillar' config option.\",",
            "                \", \".join(sorted(invalid_on_demand)),",
            "                \", \".join(on_demand),",
            "            )",
            "            return False",
            "        return True",
            "",
            "    def __gather_avail(self):",
            "        \"\"\"",
            "        Gather the lists of available sls data from the master",
            "        \"\"\"",
            "        avail = {}",
            "        for saltenv in self._get_envs():",
            "            avail[saltenv] = self.client.list_states(saltenv)",
            "        return avail",
            "",
            "    def __gen_opts(self, opts_in, grains, saltenv=None, ext=None, pillarenv=None):",
            "        \"\"\"",
            "        The options need to be altered to conform to the file client",
            "        \"\"\"",
            "        opts = copy.deepcopy(opts_in)",
            "        opts[\"file_client\"] = \"local\"",
            "        if not grains:",
            "            opts[\"grains\"] = {}",
            "        else:",
            "            opts[\"grains\"] = grains",
            "        # Allow minion/CLI saltenv/pillarenv to take precedence over master",
            "        opts[\"saltenv\"] = saltenv if saltenv is not None else opts.get(\"saltenv\")",
            "        opts[\"pillarenv\"] = (",
            "            pillarenv if pillarenv is not None else opts.get(\"pillarenv\")",
            "        )",
            "        opts[\"id\"] = self.minion_id",
            "        if opts[\"state_top\"].startswith(\"salt://\"):",
            "            opts[\"state_top\"] = opts[\"state_top\"]",
            "        elif opts[\"state_top\"].startswith(\"/\"):",
            "            opts[\"state_top\"] = salt.utils.url.create(opts[\"state_top\"][1:])",
            "        else:",
            "            opts[\"state_top\"] = salt.utils.url.create(opts[\"state_top\"])",
            "        if self.ext and self.__valid_on_demand_ext_pillar(opts):",
            "            if \"ext_pillar\" in opts:",
            "                opts[\"ext_pillar\"].append(self.ext)",
            "            else:",
            "                opts[\"ext_pillar\"] = [self.ext]",
            "        if \"__env__\" in opts[\"pillar_roots\"]:",
            "            env = opts.get(\"pillarenv\") or opts.get(\"saltenv\") or \"base\"",
            "            if env not in opts[\"pillar_roots\"]:",
            "                log.debug(",
            "                    \"pillar environment '%s' maps to __env__ pillar_roots directory\",",
            "                    env,",
            "                )",
            "                opts[\"pillar_roots\"][env] = opts[\"pillar_roots\"].pop(\"__env__\")",
            "            else:",
            "                log.debug(",
            "                    \"pillar_roots __env__ ignored (environment '%s' found in pillar_roots)\",",
            "                    env,",
            "                )",
            "                opts[\"pillar_roots\"].pop(\"__env__\")",
            "        return opts",
            "",
            "    def _get_envs(self):",
            "        \"\"\"",
            "        Pull the file server environments out of the master options",
            "        \"\"\"",
            "        envs = {\"base\"}",
            "        if \"pillar_roots\" in self.opts:",
            "            envs.update(list(self.opts[\"pillar_roots\"]))",
            "        return envs",
            "",
            "    def get_tops(self):",
            "        \"\"\"",
            "        Gather the top files",
            "        \"\"\"",
            "        tops = collections.defaultdict(list)",
            "        include = collections.defaultdict(list)",
            "        done = collections.defaultdict(list)",
            "        errors = []",
            "        # Gather initial top files",
            "        try:",
            "            saltenvs = set()",
            "            if self.opts[\"pillarenv\"]:",
            "                # If the specified pillarenv is not present in the available",
            "                # pillar environments, do not cache the pillar top file.",
            "                if self.opts[\"pillarenv\"] not in self.opts[\"pillar_roots\"]:",
            "                    log.debug(",
            "                        \"pillarenv '%s' not found in the configured pillar \"",
            "                        \"environments (%s)\",",
            "                        self.opts[\"pillarenv\"],",
            "                        \", \".join(self.opts[\"pillar_roots\"]),",
            "                    )",
            "                else:",
            "                    saltenvs.add(self.opts[\"pillarenv\"])",
            "            else:",
            "                saltenvs = self._get_envs()",
            "                if self.opts.get(\"pillar_source_merging_strategy\", None) == \"none\":",
            "                    saltenvs &= {self.saltenv or \"base\"}",
            "",
            "            for saltenv in saltenvs:",
            "                top = self.client.cache_file(self.opts[\"state_top\"], saltenv)",
            "                if top:",
            "                    tops[saltenv].append(",
            "                        compile_template(",
            "                            top,",
            "                            self.rend,",
            "                            self.opts[\"renderer\"],",
            "                            self.opts[\"renderer_blacklist\"],",
            "                            self.opts[\"renderer_whitelist\"],",
            "                            saltenv=saltenv,",
            "                            _pillar_rend=True,",
            "                        )",
            "                    )",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            errors.append(",
            "                \"Rendering Primary Top file failed, render error:\\n{}\".format(exc)",
            "            )",
            "            log.exception(\"Pillar rendering failed for minion %s\", self.minion_id)",
            "",
            "        # Search initial top files for includes",
            "        for saltenv, ctops in tops.items():",
            "            for ctop in ctops:",
            "                if \"include\" not in ctop:",
            "                    continue",
            "                for sls in ctop[\"include\"]:",
            "                    include[saltenv].append(sls)",
            "                ctop.pop(\"include\")",
            "        # Go through the includes and pull out the extra tops and add them",
            "        while include:",
            "            pops = []",
            "            for saltenv, states in include.items():",
            "                pops.append(saltenv)",
            "                if not states:",
            "                    continue",
            "                for sls in states:",
            "                    if sls in done[saltenv]:",
            "                        continue",
            "                    try:",
            "                        tops[saltenv].append(",
            "                            compile_template(",
            "                                self.client.get_state(sls, saltenv).get(\"dest\", False),",
            "                                self.rend,",
            "                                self.opts[\"renderer\"],",
            "                                self.opts[\"renderer_blacklist\"],",
            "                                self.opts[\"renderer_whitelist\"],",
            "                                saltenv=saltenv,",
            "                                _pillar_rend=True,",
            "                            )",
            "                        )",
            "                    except Exception as exc:  # pylint: disable=broad-except",
            "                        errors.append(",
            "                            (",
            "                                \"Rendering Top file {} failed, render error\" \":\\n{}\"",
            "                            ).format(sls, exc)",
            "                        )",
            "                    done[saltenv].append(sls)",
            "            for saltenv in pops:",
            "                if saltenv in include:",
            "                    include.pop(saltenv)",
            "",
            "        return tops, errors",
            "",
            "    def merge_tops(self, tops):",
            "        \"\"\"",
            "        Cleanly merge the top files",
            "        \"\"\"",
            "        top = collections.defaultdict(OrderedDict)",
            "        orders = collections.defaultdict(OrderedDict)",
            "        for ctops in tops.values():",
            "            for ctop in ctops:",
            "                for saltenv, targets in ctop.items():",
            "                    if saltenv == \"include\":",
            "                        continue",
            "                    for tgt in targets:",
            "                        matches = []",
            "                        states = OrderedDict()",
            "                        orders[saltenv][tgt] = 0",
            "                        ignore_missing = False",
            "                        for comp in ctop[saltenv][tgt]:",
            "                            if isinstance(comp, dict):",
            "                                if \"match\" in comp:",
            "                                    matches.append(comp)",
            "                                if \"order\" in comp:",
            "                                    order = comp[\"order\"]",
            "                                    if not isinstance(order, int):",
            "                                        try:",
            "                                            order = int(order)",
            "                                        except ValueError:",
            "                                            order = 0",
            "                                    orders[saltenv][tgt] = order",
            "                                if comp.get(\"ignore_missing\", False):",
            "                                    ignore_missing = True",
            "                            if isinstance(comp, str):",
            "                                states[comp] = True",
            "                        if ignore_missing:",
            "                            if saltenv not in self.ignored_pillars:",
            "                                self.ignored_pillars[saltenv] = []",
            "                            self.ignored_pillars[saltenv].extend(states.keys())",
            "                        top[saltenv][tgt] = matches",
            "                        top[saltenv][tgt].extend(states)",
            "        return self.sort_top_targets(top, orders)",
            "",
            "    def sort_top_targets(self, top, orders):",
            "        \"\"\"",
            "        Returns the sorted high data from the merged top files",
            "        \"\"\"",
            "        sorted_top = collections.defaultdict(OrderedDict)",
            "        # pylint: disable=cell-var-from-loop",
            "        for saltenv, targets in top.items():",
            "            sorted_targets = sorted(targets, key=lambda target: orders[saltenv][target])",
            "            for target in sorted_targets:",
            "                sorted_top[saltenv][target] = targets[target]",
            "        # pylint: enable=cell-var-from-loop",
            "        return sorted_top",
            "",
            "    def get_top(self):",
            "        \"\"\"",
            "        Returns the high data derived from the top file",
            "        \"\"\"",
            "        tops, errors = self.get_tops()",
            "        try:",
            "            merged_tops = self.merge_tops(tops)",
            "        except TypeError as err:",
            "            merged_tops = OrderedDict()",
            "            errors.append(\"Error encountered while rendering pillar top file.\")",
            "        return merged_tops, errors",
            "",
            "    def top_matches(self, top, reload=False):",
            "        \"\"\"",
            "        Search through the top high data for matches and return the states",
            "        that this minion needs to execute.",
            "",
            "        Returns:",
            "        {'saltenv': ['state1', 'state2', ...]}",
            "",
            "        reload",
            "            Reload the matcher loader",
            "        \"\"\"",
            "        matches = {}",
            "        if reload:",
            "            self.matchers = salt.loader.matchers(self.opts)",
            "        for saltenv, body in top.items():",
            "            if self.opts[\"pillarenv\"]:",
            "                if saltenv != self.opts[\"pillarenv\"]:",
            "                    continue",
            "            for match, data in body.items():",
            "                if self.matchers[\"confirm_top.confirm_top\"](",
            "                    match, data, self.opts.get(\"nodegroups\", {}),",
            "                ):",
            "                    if saltenv not in matches:",
            "                        matches[saltenv] = env_matches = []",
            "                    else:",
            "                        env_matches = matches[saltenv]",
            "                    for item in data:",
            "                        if isinstance(item, str) and item not in env_matches:",
            "                            env_matches.append(item)",
            "        return matches",
            "",
            "    def render_pstate(self, sls, saltenv, mods, defaults=None):",
            "        \"\"\"",
            "        Collect a single pillar sls file and render it",
            "        \"\"\"",
            "        if defaults is None:",
            "            defaults = {}",
            "        err = \"\"",
            "        errors = []",
            "        state_data = self.client.get_state(sls, saltenv)",
            "        fn_ = state_data.get(\"dest\", False)",
            "        if not fn_:",
            "            if sls in self.ignored_pillars.get(saltenv, []):",
            "                log.debug(",
            "                    \"Skipping ignored and missing SLS '%s' in \" \"environment '%s'\",",
            "                    sls,",
            "                    saltenv,",
            "                )",
            "                return None, mods, errors",
            "            elif self.opts[\"pillar_roots\"].get(saltenv):",
            "                msg = (",
            "                    \"Specified SLS '{}' in environment '{}' is not\"",
            "                    \" available on the salt master\"",
            "                ).format(sls, saltenv)",
            "                log.error(msg)",
            "                errors.append(msg)",
            "            else:",
            "                msg = (",
            "                    \"Specified SLS '{}' in environment '{}' was not \"",
            "                    \"found. \".format(sls, saltenv)",
            "                )",
            "                if self.opts.get(\"__git_pillar\", False) is True:",
            "                    msg += (",
            "                        \"This is likely caused by a git_pillar top file \"",
            "                        \"containing an environment other than the one for the \"",
            "                        \"branch in which it resides. Each git_pillar \"",
            "                        \"branch/tag must have its own top file.\"",
            "                    )",
            "                else:",
            "                    msg += (",
            "                        \"This could be because SLS '{0}' is in an \"",
            "                        \"environment other than '{1}', but '{1}' is \"",
            "                        \"included in that environment's Pillar top file. It \"",
            "                        \"could also be due to environment '{1}' not being \"",
            "                        \"defined in 'pillar_roots'.\".format(sls, saltenv)",
            "                    )",
            "                log.debug(msg)",
            "                # return state, mods, errors",
            "                return None, mods, errors",
            "        state = None",
            "        try:",
            "            state = compile_template(",
            "                fn_,",
            "                self.rend,",
            "                self.opts[\"renderer\"],",
            "                self.opts[\"renderer_blacklist\"],",
            "                self.opts[\"renderer_whitelist\"],",
            "                saltenv,",
            "                sls,",
            "                _pillar_rend=True,",
            "                **defaults",
            "            )",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            msg = \"Rendering SLS '{}' failed, render error:\\n{}\".format(sls, exc)",
            "            log.critical(msg, exc_info=True)",
            "            if self.opts.get(\"pillar_safe_render_error\", True):",
            "                errors.append(",
            "                    \"Rendering SLS '{}' failed. Please see master log for \"",
            "                    \"details.\".format(sls)",
            "                )",
            "            else:",
            "                errors.append(msg)",
            "        mods[sls] = state",
            "        nstate = None",
            "        if state:",
            "            if not isinstance(state, dict):",
            "                msg = \"SLS '{}' does not render to a dictionary\".format(sls)",
            "                log.error(msg)",
            "                errors.append(msg)",
            "            else:",
            "                if \"include\" in state:",
            "                    if not isinstance(state[\"include\"], list):",
            "                        msg = (",
            "                            \"Include Declaration in SLS '{}' is not \"",
            "                            \"formed as a list\".format(sls)",
            "                        )",
            "                        log.error(msg)",
            "                        errors.append(msg)",
            "                    else:",
            "                        # render included state(s)",
            "                        include_states = []",
            "                        for sub_sls in state.pop(\"include\"):",
            "                            if isinstance(sub_sls, dict):",
            "                                sub_sls, v = next(iter(sub_sls.items()))",
            "                                defaults = v.get(\"defaults\", {})",
            "                                key = v.get(\"key\", None)",
            "                            else:",
            "                                key = None",
            "                            try:",
            "                                matched_pstates = fnmatch.filter(",
            "                                    self.avail[saltenv],",
            "                                    sub_sls.lstrip(\".\").replace(\"/\", \".\"),",
            "                                )",
            "                                if sub_sls.startswith(\".\"):",
            "                                    if state_data.get(\"source\", \"\").endswith(",
            "                                        \"/init.sls\"",
            "                                    ):",
            "                                        include_parts = sls.split(\".\")",
            "                                    else:",
            "                                        include_parts = sls.split(\".\")[:-1]",
            "                                    sub_sls = \".\".join(include_parts + [sub_sls[1:]])",
            "                                matches = fnmatch.filter(self.avail[saltenv], sub_sls,)",
            "                                matched_pstates.extend(matches)",
            "                            except KeyError:",
            "                                errors.extend(",
            "                                    [",
            "                                        \"No matching pillar environment for environment \"",
            "                                        \"'{}' found\".format(saltenv)",
            "                                    ]",
            "                                )",
            "                                matched_pstates = [sub_sls]",
            "                            # If matched_pstates is empty, set to sub_sls",
            "                            if len(matched_pstates) < 1:",
            "                                matched_pstates = [sub_sls]",
            "                            for m_sub_sls in matched_pstates:",
            "                                if m_sub_sls not in mods:",
            "                                    nstate, mods, err = self.render_pstate(",
            "                                        m_sub_sls, saltenv, mods, defaults",
            "                                    )",
            "                                else:",
            "                                    nstate = mods[m_sub_sls]",
            "                                if nstate:",
            "                                    if key:",
            "                                        # If key is x:y, convert it to {x: {y: nstate}}",
            "                                        for key_fragment in reversed(key.split(\":\")):",
            "                                            nstate = {key_fragment: nstate}",
            "                                    if not self.opts.get(",
            "                                        \"pillar_includes_override_sls\", False",
            "                                    ):",
            "                                        include_states.append(nstate)",
            "                                    else:",
            "                                        state = merge(",
            "                                            state,",
            "                                            nstate,",
            "                                            self.merge_strategy,",
            "                                            self.opts.get(\"renderer\", \"yaml\"),",
            "                                            self.opts.get(\"pillar_merge_lists\", False),",
            "                                        )",
            "                                if err:",
            "                                    errors += err",
            "                        if not self.opts.get(\"pillar_includes_override_sls\", False):",
            "                            # merge included state(s) with the current state",
            "                            # merged last to ensure that its values are",
            "                            # authoritative.",
            "                            include_states.append(state)",
            "                            state = None",
            "                            for s in include_states:",
            "                                if state is None:",
            "                                    state = s",
            "                                else:",
            "                                    state = merge(",
            "                                        state,",
            "                                        s,",
            "                                        self.merge_strategy,",
            "                                        self.opts.get(\"renderer\", \"yaml\"),",
            "                                        self.opts.get(\"pillar_merge_lists\", False),",
            "                                    )",
            "        return state, mods, errors",
            "",
            "    def render_pillar(self, matches, errors=None):",
            "        \"\"\"",
            "        Extract the sls pillar files from the matches and render them into the",
            "        pillar",
            "        \"\"\"",
            "        pillar = copy.copy(self.pillar_override)",
            "        if errors is None:",
            "            errors = []",
            "        for saltenv, pstates in matches.items():",
            "            pstatefiles = []",
            "            mods = {}",
            "            for sls_match in pstates:",
            "                matched_pstates = []",
            "                try:",
            "                    matched_pstates = fnmatch.filter(self.avail[saltenv], sls_match)",
            "                except KeyError:",
            "                    errors.extend(",
            "                        [",
            "                            \"No matching pillar environment for environment \"",
            "                            \"'{}' found\".format(saltenv)",
            "                        ]",
            "                    )",
            "                if matched_pstates:",
            "                    pstatefiles.extend(matched_pstates)",
            "                else:",
            "                    pstatefiles.append(sls_match)",
            "",
            "            for sls in pstatefiles:",
            "                pstate, mods, err = self.render_pstate(sls, saltenv, mods)",
            "",
            "                if err:",
            "                    errors += err",
            "",
            "                if pstate is not None:",
            "                    if not isinstance(pstate, dict):",
            "                        log.error(",
            "                            \"The rendered pillar sls file, '%s' state did \"",
            "                            \"not return the expected data format. This is \"",
            "                            \"a sign of a malformed pillar sls file. Returned \"",
            "                            \"errors: %s\",",
            "                            sls,",
            "                            \", \".join([\"'{}'\".format(e) for e in errors]),",
            "                        )",
            "                        continue",
            "                    pillar = merge(",
            "                        pillar,",
            "                        pstate,",
            "                        self.merge_strategy,",
            "                        self.opts.get(\"renderer\", \"yaml\"),",
            "                        self.opts.get(\"pillar_merge_lists\", False),",
            "                    )",
            "",
            "        return pillar, errors",
            "",
            "    def _external_pillar_data(self, pillar, val, key):",
            "        \"\"\"",
            "        Builds actual pillar data structure and updates the ``pillar`` variable",
            "        \"\"\"",
            "        ext = None",
            "        args = salt.utils.args.get_function_argspec(self.ext_pillars[key]).args",
            "",
            "        if isinstance(val, dict):",
            "            if (\"extra_minion_data\" in args) and self.extra_minion_data:",
            "                ext = self.ext_pillars[key](",
            "                    self.minion_id,",
            "                    pillar,",
            "                    extra_minion_data=self.extra_minion_data,",
            "                    **val",
            "                )",
            "            else:",
            "                ext = self.ext_pillars[key](self.minion_id, pillar, **val)",
            "        elif isinstance(val, list):",
            "            if (\"extra_minion_data\" in args) and self.extra_minion_data:",
            "                ext = self.ext_pillars[key](",
            "                    self.minion_id,",
            "                    pillar,",
            "                    *val,",
            "                    extra_minion_data=self.extra_minion_data",
            "                )",
            "            else:",
            "                ext = self.ext_pillars[key](self.minion_id, pillar, *val)",
            "        else:",
            "            if (\"extra_minion_data\" in args) and self.extra_minion_data:",
            "                ext = self.ext_pillars[key](",
            "                    self.minion_id,",
            "                    pillar,",
            "                    val,",
            "                    extra_minion_data=self.extra_minion_data,",
            "                )",
            "            else:",
            "                ext = self.ext_pillars[key](self.minion_id, pillar, val)",
            "        return ext",
            "",
            "    def ext_pillar(self, pillar, errors=None):",
            "        \"\"\"",
            "        Render the external pillar data",
            "        \"\"\"",
            "        if errors is None:",
            "            errors = []",
            "        try:",
            "            # Make sure that on-demand git_pillar is fetched before we try to",
            "            # compile the pillar data. git_pillar will fetch a remote when",
            "            # the git ext_pillar() func is run, but only for masterless.",
            "            if self.ext and \"git\" in self.ext and self.opts.get(\"__role\") != \"minion\":",
            "                # Avoid circular import",
            "                import salt.utils.gitfs",
            "                import salt.pillar.git_pillar",
            "",
            "                git_pillar = salt.utils.gitfs.GitPillar(",
            "                    self.opts,",
            "                    self.ext[\"git\"],",
            "                    per_remote_overrides=salt.pillar.git_pillar.PER_REMOTE_OVERRIDES,",
            "                    per_remote_only=salt.pillar.git_pillar.PER_REMOTE_ONLY,",
            "                    global_only=salt.pillar.git_pillar.GLOBAL_ONLY,",
            "                )",
            "                git_pillar.fetch_remotes()",
            "        except TypeError:",
            "            # Handle malformed ext_pillar",
            "            pass",
            "        if \"ext_pillar\" not in self.opts:",
            "            return pillar, errors",
            "        if not isinstance(self.opts[\"ext_pillar\"], list):",
            "            errors.append('The \"ext_pillar\" option is malformed')",
            "            log.critical(errors[-1])",
            "            return pillar, errors",
            "        ext = None",
            "        # Bring in CLI pillar data",
            "        if self.pillar_override:",
            "            pillar = merge(",
            "                pillar,",
            "                self.pillar_override,",
            "                self.merge_strategy,",
            "                self.opts.get(\"renderer\", \"yaml\"),",
            "                self.opts.get(\"pillar_merge_lists\", False),",
            "            )",
            "",
            "        for run in self.opts[\"ext_pillar\"]:",
            "            if not isinstance(run, dict):",
            "                errors.append('The \"ext_pillar\" option is malformed')",
            "                log.critical(errors[-1])",
            "                return {}, errors",
            "            if next(iter(run.keys())) in self.opts.get(\"exclude_ext_pillar\", []):",
            "                continue",
            "            for key, val in run.items():",
            "                if key not in self.ext_pillars:",
            "                    log.critical(",
            "                        \"Specified ext_pillar interface %s is unavailable\", key",
            "                    )",
            "                    continue",
            "                try:",
            "                    ext = self._external_pillar_data(pillar, val, key)",
            "                except Exception as exc:  # pylint: disable=broad-except",
            "                    errors.append(",
            "                        \"Failed to load ext_pillar {}: {}\".format(key, exc.__str__(),)",
            "                    )",
            "                    log.error(",
            "                        \"Exception caught loading ext_pillar '%s':\\n%s\",",
            "                        key,",
            "                        \"\".join(traceback.format_tb(sys.exc_info()[2])),",
            "                    )",
            "            if ext:",
            "                pillar = merge(",
            "                    pillar,",
            "                    ext,",
            "                    self.merge_strategy,",
            "                    self.opts.get(\"renderer\", \"yaml\"),",
            "                    self.opts.get(\"pillar_merge_lists\", False),",
            "                )",
            "                ext = None",
            "        return pillar, errors",
            "",
            "    def compile_pillar(self, ext=True):",
            "        \"\"\"",
            "        Render the pillar data and return",
            "        \"\"\"",
            "        top, top_errors = self.get_top()",
            "        if ext:",
            "            if self.opts.get(\"ext_pillar_first\", False):",
            "                self.opts[\"pillar\"], errors = self.ext_pillar(self.pillar_override)",
            "                self.rend = salt.loader.render(self.opts, self.functions)",
            "                matches = self.top_matches(top, reload=True)",
            "                pillar, errors = self.render_pillar(matches, errors=errors)",
            "                pillar = merge(",
            "                    self.opts[\"pillar\"],",
            "                    pillar,",
            "                    self.merge_strategy,",
            "                    self.opts.get(\"renderer\", \"yaml\"),",
            "                    self.opts.get(\"pillar_merge_lists\", False),",
            "                )",
            "            else:",
            "                matches = self.top_matches(top)",
            "                pillar, errors = self.render_pillar(matches)",
            "                pillar, errors = self.ext_pillar(pillar, errors=errors)",
            "        else:",
            "            matches = self.top_matches(top)",
            "            pillar, errors = self.render_pillar(matches)",
            "        errors.extend(top_errors)",
            "        if self.opts.get(\"pillar_opts\", False):",
            "            mopts = dict(self.opts)",
            "            if \"grains\" in mopts:",
            "                mopts.pop(\"grains\")",
            "            mopts[\"saltversion\"] = __version__",
            "            pillar[\"master\"] = mopts",
            "        if \"pillar\" in self.opts and self.opts.get(\"ssh_merge_pillar\", False):",
            "            pillar = merge(",
            "                self.opts[\"pillar\"],",
            "                pillar,",
            "                self.merge_strategy,",
            "                self.opts.get(\"renderer\", \"yaml\"),",
            "                self.opts.get(\"pillar_merge_lists\", False),",
            "            )",
            "        if errors:",
            "            for error in errors:",
            "                log.critical(\"Pillar render error: %s\", error)",
            "            pillar[\"_errors\"] = errors",
            "",
            "        if self.pillar_override:",
            "            pillar = merge(",
            "                pillar,",
            "                self.pillar_override,",
            "                self.merge_strategy,",
            "                self.opts.get(\"renderer\", \"yaml\"),",
            "                self.opts.get(\"pillar_merge_lists\", False),",
            "            )",
            "",
            "        decrypt_errors = self.decrypt_pillar(pillar)",
            "        if decrypt_errors:",
            "            pillar.setdefault(\"_errors\", []).extend(decrypt_errors)",
            "        return pillar",
            "",
            "    def decrypt_pillar(self, pillar):",
            "        \"\"\"",
            "        Decrypt the specified pillar dictionary items, if configured to do so",
            "        \"\"\"",
            "        errors = []",
            "        if self.opts.get(\"decrypt_pillar\"):",
            "            decrypt_pillar = self.opts[\"decrypt_pillar\"]",
            "            if not isinstance(decrypt_pillar, dict):",
            "                decrypt_pillar = salt.utils.data.repack_dictlist(",
            "                    self.opts[\"decrypt_pillar\"]",
            "                )",
            "            if not decrypt_pillar:",
            "                errors.append(\"decrypt_pillar config option is malformed\")",
            "            for key, rend in decrypt_pillar.items():",
            "                ptr = salt.utils.data.traverse_dict(",
            "                    pillar,",
            "                    key,",
            "                    default=None,",
            "                    delimiter=self.opts[\"decrypt_pillar_delimiter\"],",
            "                )",
            "                if ptr is None:",
            "                    log.debug(\"Pillar key %s not present\", key)",
            "                    continue",
            "                try:",
            "                    hash(ptr)",
            "                    immutable = True",
            "                except TypeError:",
            "                    immutable = False",
            "                try:",
            "                    ret = salt.utils.crypt.decrypt(",
            "                        ptr,",
            "                        rend or self.opts[\"decrypt_pillar_default\"],",
            "                        renderers=self.rend,",
            "                        opts=self.opts,",
            "                        valid_rend=self.opts[\"decrypt_pillar_renderers\"],",
            "                    )",
            "                    if immutable:",
            "                        # Since the key pointed to an immutable type, we need",
            "                        # to replace it in the pillar dict. First we will find",
            "                        # the parent, and then we will replace the child key",
            "                        # with the return data from the renderer.",
            "                        parent, _, child = key.rpartition(",
            "                            self.opts[\"decrypt_pillar_delimiter\"]",
            "                        )",
            "                        if not parent:",
            "                            # key is a top-level key, so the pointer to the",
            "                            # parent is the pillar dict itself.",
            "                            ptr = pillar",
            "                        else:",
            "                            ptr = salt.utils.data.traverse_dict(",
            "                                pillar,",
            "                                parent,",
            "                                default=None,",
            "                                delimiter=self.opts[\"decrypt_pillar_delimiter\"],",
            "                            )",
            "                        if ptr is not None:",
            "                            ptr[child] = ret",
            "                except Exception as exc:  # pylint: disable=broad-except",
            "                    msg = \"Failed to decrypt pillar key '{}': {}\".format(key, exc)",
            "                    errors.append(msg)",
            "                    log.error(msg, exc_info=True)",
            "        return errors",
            "",
            "    def destroy(self):",
            "        \"\"\"",
            "        This method exist in order to be API compatible with RemotePillar",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.destroy()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "# TODO: actually migrate from Pillar to AsyncPillar to allow for futures in",
            "# ext_pillar etc.",
            "class AsyncPillar(Pillar):",
            "    @salt.ext.tornado.gen.coroutine",
            "    def compile_pillar(self, ext=True):",
            "        ret = super().compile_pillar(ext=ext)",
            "        raise salt.ext.tornado.gen.Return(ret)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Render the pillar data",
            "\"\"\"",
            "",
            "",
            "import collections",
            "import copy",
            "import fnmatch",
            "import inspect",
            "import logging",
            "import os",
            "import sys",
            "import traceback",
            "import uuid",
            "",
            "import salt.ext.tornado.gen",
            "import salt.fileclient",
            "import salt.loader",
            "import salt.minion",
            "import salt.transport.client",
            "import salt.utils.args",
            "import salt.utils.cache",
            "import salt.utils.crypt",
            "import salt.utils.data",
            "import salt.utils.dictupdate",
            "import salt.utils.url",
            "from salt.exceptions import SaltClientError",
            "from salt.ext import six",
            "from salt.template import compile_template",
            "",
            "# Even though dictupdate is imported, invoking salt.utils.dictupdate.merge here",
            "# causes an UnboundLocalError. This should be investigated and fixed, but until",
            "# then, leave the import directly below this comment intact.",
            "from salt.utils.dictupdate import merge",
            "from salt.utils.odict import OrderedDict",
            "from salt.version import __version__",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def get_pillar(",
            "    opts,",
            "    grains,",
            "    minion_id,",
            "    saltenv=None,",
            "    ext=None,",
            "    funcs=None,",
            "    pillar_override=None,",
            "    pillarenv=None,",
            "    extra_minion_data=None,",
            "):",
            "    \"\"\"",
            "    Return the correct pillar driver based on the file_client option",
            "    \"\"\"",
            "    # When file_client is 'local' this makes the minion masterless",
            "    # but sometimes we want the minion to read its files from the local",
            "    # filesystem instead of asking for them from the master, but still",
            "    # get commands from the master.",
            "    # To enable this functionality set file_client=local and",
            "    # use_master_when_local=True in the minion config.  Then here we override",
            "    # the file client to be 'remote' for getting pillar.  If we don't do this",
            "    # then the minion never sends the event that the master uses to update",
            "    # its minion_data_cache.  If the master doesn't update the minion_data_cache",
            "    # then the SSE salt-master plugin won't see any grains for those minions.",
            "    file_client = opts[\"file_client\"]",
            "    if opts.get(\"master_type\") == \"disable\" and file_client == \"remote\":",
            "        file_client = \"local\"",
            "    elif file_client == \"local\" and opts.get(\"use_master_when_local\"):",
            "        file_client = \"remote\"",
            "",
            "    ptype = {\"remote\": RemotePillar, \"local\": Pillar}.get(file_client, Pillar)",
            "    # If local pillar and we're caching, run through the cache system first",
            "    log.debug(\"Determining pillar cache\")",
            "    if opts[\"pillar_cache\"]:",
            "        log.debug(\"get_pillar using pillar cache with ext: %s\", ext)",
            "        return PillarCache(",
            "            opts,",
            "            grains,",
            "            minion_id,",
            "            saltenv,",
            "            ext=ext,",
            "            functions=funcs,",
            "            pillar_override=pillar_override,",
            "            pillarenv=pillarenv,",
            "        )",
            "    return ptype(",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext,",
            "        functions=funcs,",
            "        pillar_override=pillar_override,",
            "        pillarenv=pillarenv,",
            "        extra_minion_data=extra_minion_data,",
            "    )",
            "",
            "",
            "# TODO: migrate everyone to this one!",
            "def get_async_pillar(",
            "    opts,",
            "    grains,",
            "    minion_id,",
            "    saltenv=None,",
            "    ext=None,",
            "    funcs=None,",
            "    pillar_override=None,",
            "    pillarenv=None,",
            "    extra_minion_data=None,",
            "):",
            "    \"\"\"",
            "    Return the correct pillar driver based on the file_client option",
            "    \"\"\"",
            "    file_client = opts[\"file_client\"]",
            "    if opts.get(\"master_type\") == \"disable\" and file_client == \"remote\":",
            "        file_client = \"local\"",
            "    elif file_client == \"local\" and opts.get(\"use_master_when_local\"):",
            "        file_client = \"remote\"",
            "    ptype = {\"remote\": AsyncRemotePillar, \"local\": AsyncPillar}.get(",
            "        file_client, AsyncPillar",
            "    )",
            "    return ptype(",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext,",
            "        functions=funcs,",
            "        pillar_override=pillar_override,",
            "        pillarenv=pillarenv,",
            "        extra_minion_data=extra_minion_data,",
            "    )",
            "",
            "",
            "class RemotePillarMixin:",
            "    \"\"\"",
            "    Common remote pillar functionality",
            "    \"\"\"",
            "",
            "    def get_ext_pillar_extra_minion_data(self, opts):",
            "        \"\"\"",
            "        Returns the extra data from the minion's opts dict (the config file).",
            "",
            "        This data will be passed to external pillar functions.",
            "        \"\"\"",
            "",
            "        def get_subconfig(opts_key):",
            "            \"\"\"",
            "            Returns a dict containing the opts key subtree, while maintaining",
            "            the opts structure",
            "            \"\"\"",
            "            ret_dict = aux_dict = {}",
            "            config_val = opts",
            "            subkeys = opts_key.split(\":\")",
            "            # Build an empty dict with the opts path",
            "            for subkey in subkeys[:-1]:",
            "                aux_dict[subkey] = {}",
            "                aux_dict = aux_dict[subkey]",
            "                if not config_val.get(subkey):",
            "                    # The subkey is not in the config",
            "                    return {}",
            "                config_val = config_val[subkey]",
            "            if subkeys[-1] not in config_val:",
            "                return {}",
            "            aux_dict[subkeys[-1]] = config_val[subkeys[-1]]",
            "            return ret_dict",
            "",
            "        extra_data = {}",
            "        if \"pass_to_ext_pillars\" in opts:",
            "            if not isinstance(opts[\"pass_to_ext_pillars\"], list):",
            "                log.exception(\"'pass_to_ext_pillars' config is malformed.\")",
            "                raise SaltClientError(\"'pass_to_ext_pillars' config is \" \"malformed.\")",
            "            for key in opts[\"pass_to_ext_pillars\"]:",
            "                salt.utils.dictupdate.update(",
            "                    extra_data,",
            "                    get_subconfig(key),",
            "                    recursive_update=True,",
            "                    merge_lists=True,",
            "                )",
            "        log.trace(\"ext_pillar_extra_data = %s\", extra_data)",
            "        return extra_data",
            "",
            "",
            "class AsyncRemotePillar(RemotePillarMixin):",
            "    \"\"\"",
            "    Get the pillar from the master",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        self.opts = opts",
            "        self.opts[\"saltenv\"] = saltenv",
            "        self.ext = ext",
            "        self.grains = grains",
            "        self.minion_id = minion_id",
            "        self.channel = salt.transport.client.AsyncReqChannel.factory(opts)",
            "        if pillarenv is not None:",
            "            self.opts[\"pillarenv\"] = pillarenv",
            "        self.pillar_override = pillar_override or {}",
            "        if not isinstance(self.pillar_override, dict):",
            "            self.pillar_override = {}",
            "            log.error(\"Pillar data must be a dictionary\")",
            "        self.extra_minion_data = extra_minion_data or {}",
            "        if not isinstance(self.extra_minion_data, dict):",
            "            self.extra_minion_data = {}",
            "            log.error(\"Extra minion data must be a dictionary\")",
            "        salt.utils.dictupdate.update(",
            "            self.extra_minion_data,",
            "            self.get_ext_pillar_extra_minion_data(opts),",
            "            recursive_update=True,",
            "            merge_lists=True,",
            "        )",
            "        self._closing = False",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def compile_pillar(self):",
            "        \"\"\"",
            "        Return a future which will contain the pillar data from the master",
            "        \"\"\"",
            "        load = {",
            "            \"id\": self.minion_id,",
            "            \"grains\": self.grains,",
            "            \"saltenv\": self.opts[\"saltenv\"],",
            "            \"pillarenv\": self.opts[\"pillarenv\"],",
            "            \"pillar_override\": self.pillar_override,",
            "            \"extra_minion_data\": self.extra_minion_data,",
            "            \"ver\": \"2\",",
            "            \"cmd\": \"_pillar\",",
            "        }",
            "        if self.ext:",
            "            load[\"ext\"] = self.ext",
            "        try:",
            "            ret_pillar = yield self.channel.crypted_transfer_decode_dictentry(",
            "                load, dictkey=\"pillar\",",
            "            )",
            "        except salt.crypt.AuthenticationError as exc:",
            "            log.error(exc.message)",
            "            raise SaltClientError(\"Exception getting pillar.\")",
            "        except Exception:  # pylint: disable=broad-except",
            "            log.exception(\"Exception getting pillar:\")",
            "            raise SaltClientError(\"Exception getting pillar.\")",
            "",
            "        if not isinstance(ret_pillar, dict):",
            "            msg = (",
            "                \"Got a bad pillar from master, type {}, expecting dict: \" \"{}\"",
            "            ).format(type(ret_pillar).__name__, ret_pillar)",
            "            log.error(msg)",
            "            # raise an exception! Pillar isn't empty, we can't sync it!",
            "            raise SaltClientError(msg)",
            "        raise salt.ext.tornado.gen.Return(ret_pillar)",
            "",
            "    def destroy(self):",
            "        if self._closing:",
            "            return",
            "",
            "        self._closing = True",
            "        self.channel.close()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.destroy()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "class RemotePillar(RemotePillarMixin):",
            "    \"\"\"",
            "    Get the pillar from the master",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        self.opts = opts",
            "        self.opts[\"saltenv\"] = saltenv",
            "        self.ext = ext",
            "        self.grains = grains",
            "        self.minion_id = minion_id",
            "        self.channel = salt.transport.client.ReqChannel.factory(opts)",
            "        if pillarenv is not None:",
            "            self.opts[\"pillarenv\"] = pillarenv",
            "        self.pillar_override = pillar_override or {}",
            "        if not isinstance(self.pillar_override, dict):",
            "            self.pillar_override = {}",
            "            log.error(\"Pillar data must be a dictionary\")",
            "        self.extra_minion_data = extra_minion_data or {}",
            "        if not isinstance(self.extra_minion_data, dict):",
            "            self.extra_minion_data = {}",
            "            log.error(\"Extra minion data must be a dictionary\")",
            "        salt.utils.dictupdate.update(",
            "            self.extra_minion_data,",
            "            self.get_ext_pillar_extra_minion_data(opts),",
            "            recursive_update=True,",
            "            merge_lists=True,",
            "        )",
            "        self._closing = False",
            "",
            "    def compile_pillar(self):",
            "        \"\"\"",
            "        Return the pillar data from the master",
            "        \"\"\"",
            "        load = {",
            "            \"id\": self.minion_id,",
            "            \"grains\": self.grains,",
            "            \"saltenv\": self.opts[\"saltenv\"],",
            "            \"pillarenv\": self.opts[\"pillarenv\"],",
            "            \"pillar_override\": self.pillar_override,",
            "            \"extra_minion_data\": self.extra_minion_data,",
            "            \"ver\": \"2\",",
            "            \"cmd\": \"_pillar\",",
            "        }",
            "        if self.ext:",
            "            load[\"ext\"] = self.ext",
            "        ret_pillar = self.channel.crypted_transfer_decode_dictentry(",
            "            load, dictkey=\"pillar\",",
            "        )",
            "",
            "        if not isinstance(ret_pillar, dict):",
            "            log.error(",
            "                \"Got a bad pillar from master, type %s, expecting dict: %s\",",
            "                type(ret_pillar).__name__,",
            "                ret_pillar,",
            "            )",
            "            return {}",
            "        return ret_pillar",
            "",
            "    def destroy(self):",
            "        if hasattr(self, \"_closing\") and self._closing:",
            "            return",
            "",
            "        self._closing = True",
            "        self.channel.close()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.destroy()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "class PillarCache:",
            "    \"\"\"",
            "    Return a cached pillar if it exists, otherwise cache it.",
            "",
            "    Pillar caches are structed in two diminensions: minion_id with a dict of",
            "    saltenvs. Each saltenv contains a pillar dict",
            "",
            "    Example data structure:",
            "",
            "    ```",
            "    {'minion_1':",
            "        {'base': {'pilar_key_1' 'pillar_val_1'}",
            "    }",
            "    \"\"\"",
            "",
            "    # TODO ABC?",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        # Yes, we need all of these because we need to route to the Pillar object",
            "        # if we have no cache. This is another refactor target.",
            "",
            "        # Go ahead and assign these because they may be needed later",
            "        self.opts = opts",
            "        self.grains = grains",
            "        self.minion_id = minion_id",
            "        self.ext = ext",
            "        self.functions = functions",
            "        self.pillar_override = pillar_override",
            "        self.pillarenv = pillarenv",
            "",
            "        if saltenv is None:",
            "            self.saltenv = \"base\"",
            "        else:",
            "            self.saltenv = saltenv",
            "",
            "        # Determine caching backend",
            "        self.cache = salt.utils.cache.CacheFactory.factory(",
            "            self.opts[\"pillar_cache_backend\"],",
            "            self.opts[\"pillar_cache_ttl\"],",
            "            minion_cache_path=self._minion_cache_path(minion_id),",
            "        )",
            "",
            "    def _minion_cache_path(self, minion_id):",
            "        \"\"\"",
            "        Return the path to the cache file for the minion.",
            "",
            "        Used only for disk-based backends",
            "        \"\"\"",
            "        return os.path.join(self.opts[\"cachedir\"], \"pillar_cache\", minion_id)",
            "",
            "    def fetch_pillar(self):",
            "        \"\"\"",
            "        In the event of a cache miss, we need to incur the overhead of caching",
            "        a new pillar.",
            "        \"\"\"",
            "        log.debug(\"Pillar cache getting external pillar with ext: %s\", self.ext)",
            "        fresh_pillar = Pillar(",
            "            self.opts,",
            "            self.grains,",
            "            self.minion_id,",
            "            self.saltenv,",
            "            ext=self.ext,",
            "            functions=self.functions,",
            "            pillar_override=self.pillar_override,",
            "            pillarenv=self.pillarenv,",
            "        )",
            "        return fresh_pillar.compile_pillar()",
            "",
            "    def clear_pillar(self):",
            "        \"\"\"",
            "        Clear the cache",
            "        \"\"\"",
            "        self.cache.clear()",
            "",
            "        return True",
            "",
            "    def compile_pillar(self, *args, **kwargs):  # Will likely just be pillar_dirs",
            "        log.debug(",
            "            \"Scanning pillar cache for information about minion %s and pillarenv %s\",",
            "            self.minion_id,",
            "            self.pillarenv,",
            "        )",
            "        if self.opts[\"pillar_cache_backend\"] == \"memory\":",
            "            cache_dict = self.cache",
            "        else:",
            "            cache_dict = self.cache._dict",
            "",
            "        log.debug(\"Scanning cache: %s\", cache_dict)",
            "        # Check the cache!",
            "        if self.minion_id in self.cache:  # Keyed by minion_id",
            "            # TODO Compare grains, etc?",
            "            if self.pillarenv in self.cache[self.minion_id]:",
            "                # We have a cache hit! Send it back.",
            "                log.debug(",
            "                    \"Pillar cache hit for minion %s and pillarenv %s\",",
            "                    self.minion_id,",
            "                    self.pillarenv,",
            "                )",
            "                return self.cache[self.minion_id][self.pillarenv]",
            "            else:",
            "                # We found the minion but not the env. Store it.",
            "                fresh_pillar = self.fetch_pillar()",
            "",
            "                minion_cache = self.cache[self.minion_id]",
            "                minion_cache[self.pillarenv] = fresh_pillar",
            "                self.cache[self.minion_id] = minion_cache",
            "",
            "                log.debug(",
            "                    \"Pillar cache miss for pillarenv %s for minion %s\",",
            "                    self.pillarenv,",
            "                    self.minion_id,",
            "                )",
            "                return fresh_pillar",
            "        else:",
            "            # We haven't seen this minion yet in the cache. Store it.",
            "            fresh_pillar = self.fetch_pillar()",
            "            self.cache[self.minion_id] = {self.pillarenv: fresh_pillar}",
            "            log.debug(\"Pillar cache miss for minion %s\", self.minion_id)",
            "            log.debug(\"Current pillar cache: %s\", cache_dict)  # FIXME hack!",
            "            return fresh_pillar",
            "",
            "",
            "class Pillar:",
            "    \"\"\"",
            "    Read over the pillar top files and render the pillar data",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        grains,",
            "        minion_id,",
            "        saltenv,",
            "        ext=None,",
            "        functions=None,",
            "        pillar_override=None,",
            "        pillarenv=None,",
            "        extra_minion_data=None,",
            "    ):",
            "        self.minion_id = minion_id",
            "        self.ext = ext",
            "        if pillarenv is None:",
            "            if opts.get(\"pillarenv_from_saltenv\", False):",
            "                opts[\"pillarenv\"] = saltenv",
            "        # use the local file client",
            "        self.opts = self.__gen_opts(opts, grains, saltenv=saltenv, pillarenv=pillarenv)",
            "        self.saltenv = saltenv",
            "        self.client = salt.fileclient.get_file_client(self.opts, True)",
            "        self.avail = self.__gather_avail()",
            "",
            "        if opts.get(\"file_client\", \"\") == \"local\" and not opts.get(",
            "            \"use_master_when_local\", False",
            "        ):",
            "            opts[\"grains\"] = grains",
            "",
            "        # if we didn't pass in functions, lets load them",
            "        if functions is None:",
            "            utils = salt.loader.utils(opts)",
            "            if opts.get(\"file_client\", \"\") == \"local\":",
            "                self.functions = salt.loader.minion_mods(opts, utils=utils)",
            "            else:",
            "                self.functions = salt.loader.minion_mods(self.opts, utils=utils)",
            "        else:",
            "            self.functions = functions",
            "",
            "        self.opts[\"minion_id\"] = minion_id",
            "        self.matchers = salt.loader.matchers(self.opts)",
            "        self.rend = salt.loader.render(self.opts, self.functions)",
            "        ext_pillar_opts = copy.deepcopy(self.opts)",
            "        # Keep the incoming opts ID intact, ie, the master id",
            "        if \"id\" in opts:",
            "            ext_pillar_opts[\"id\"] = opts[\"id\"]",
            "        self.merge_strategy = \"smart\"",
            "        if opts.get(\"pillar_source_merging_strategy\"):",
            "            self.merge_strategy = opts[\"pillar_source_merging_strategy\"]",
            "",
            "        self.ext_pillars = salt.loader.pillars(ext_pillar_opts, self.functions)",
            "        self.ignored_pillars = {}",
            "        self.pillar_override = pillar_override or {}",
            "        if not isinstance(self.pillar_override, dict):",
            "            self.pillar_override = {}",
            "            log.error(\"Pillar data must be a dictionary\")",
            "        self.extra_minion_data = extra_minion_data or {}",
            "        if not isinstance(self.extra_minion_data, dict):",
            "            self.extra_minion_data = {}",
            "            log.error(\"Extra minion data must be a dictionary\")",
            "        self._closing = False",
            "",
            "    def __valid_on_demand_ext_pillar(self, opts):",
            "        \"\"\"",
            "        Check to see if the on demand external pillar is allowed",
            "        \"\"\"",
            "        if not isinstance(self.ext, dict):",
            "            log.error(\"On-demand pillar %s is not formatted as a dictionary\", self.ext)",
            "            return False",
            "",
            "        on_demand = opts.get(\"on_demand_ext_pillar\", [])",
            "        try:",
            "            invalid_on_demand = {x for x in self.ext if x not in on_demand}",
            "        except TypeError:",
            "            # Prevent traceback when on_demand_ext_pillar option is malformed",
            "            log.error(",
            "                \"The 'on_demand_ext_pillar' configuration option is \"",
            "                \"malformed, it should be a list of ext_pillar module names\"",
            "            )",
            "            return False",
            "",
            "        if invalid_on_demand:",
            "            log.error(",
            "                \"The following ext_pillar modules are not allowed for \"",
            "                \"on-demand pillar data: %s. Valid on-demand ext_pillar \"",
            "                \"modules are: %s. The valid modules can be adjusted by \"",
            "                \"setting the 'on_demand_ext_pillar' config option.\",",
            "                \", \".join(sorted(invalid_on_demand)),",
            "                \", \".join(on_demand),",
            "            )",
            "            return False",
            "        return True",
            "",
            "    def __gather_avail(self):",
            "        \"\"\"",
            "        Gather the lists of available sls data from the master",
            "        \"\"\"",
            "        avail = {}",
            "        for saltenv in self._get_envs():",
            "            avail[saltenv] = self.client.list_states(saltenv)",
            "        return avail",
            "",
            "    def __gen_opts(self, opts_in, grains, saltenv=None, ext=None, pillarenv=None):",
            "        \"\"\"",
            "        The options need to be altered to conform to the file client",
            "        \"\"\"",
            "        opts = copy.deepcopy(opts_in)",
            "        opts[\"file_client\"] = \"local\"",
            "        if not grains:",
            "            opts[\"grains\"] = {}",
            "        else:",
            "            opts[\"grains\"] = grains",
            "        # Allow minion/CLI saltenv/pillarenv to take precedence over master",
            "        opts[\"saltenv\"] = saltenv if saltenv is not None else opts.get(\"saltenv\")",
            "        opts[\"pillarenv\"] = (",
            "            pillarenv if pillarenv is not None else opts.get(\"pillarenv\")",
            "        )",
            "        opts[\"id\"] = self.minion_id",
            "        if opts[\"state_top\"].startswith(\"salt://\"):",
            "            opts[\"state_top\"] = opts[\"state_top\"]",
            "        elif opts[\"state_top\"].startswith(\"/\"):",
            "            opts[\"state_top\"] = salt.utils.url.create(opts[\"state_top\"][1:])",
            "        else:",
            "            opts[\"state_top\"] = salt.utils.url.create(opts[\"state_top\"])",
            "        if self.ext and self.__valid_on_demand_ext_pillar(opts):",
            "            if \"ext_pillar\" in opts:",
            "                opts[\"ext_pillar\"].append(self.ext)",
            "            else:",
            "                opts[\"ext_pillar\"] = [self.ext]",
            "        if \"__env__\" in opts[\"pillar_roots\"]:",
            "            env = opts.get(\"pillarenv\") or opts.get(\"saltenv\") or \"base\"",
            "            if env not in opts[\"pillar_roots\"]:",
            "                log.debug(",
            "                    \"pillar environment '%s' maps to __env__ pillar_roots directory\",",
            "                    env,",
            "                )",
            "                opts[\"pillar_roots\"][env] = opts[\"pillar_roots\"].pop(\"__env__\")",
            "            else:",
            "                log.debug(",
            "                    \"pillar_roots __env__ ignored (environment '%s' found in pillar_roots)\",",
            "                    env,",
            "                )",
            "                opts[\"pillar_roots\"].pop(\"__env__\")",
            "        return opts",
            "",
            "    def _get_envs(self):",
            "        \"\"\"",
            "        Pull the file server environments out of the master options",
            "        \"\"\"",
            "        envs = {\"base\"}",
            "        if \"pillar_roots\" in self.opts:",
            "            envs.update(list(self.opts[\"pillar_roots\"]))",
            "        return envs",
            "",
            "    def get_tops(self):",
            "        \"\"\"",
            "        Gather the top files",
            "        \"\"\"",
            "        tops = collections.defaultdict(list)",
            "        include = collections.defaultdict(list)",
            "        done = collections.defaultdict(list)",
            "        errors = []",
            "        # Gather initial top files",
            "        try:",
            "            saltenvs = set()",
            "            if self.opts[\"pillarenv\"]:",
            "                # If the specified pillarenv is not present in the available",
            "                # pillar environments, do not cache the pillar top file.",
            "                if self.opts[\"pillarenv\"] not in self.opts[\"pillar_roots\"]:",
            "                    log.debug(",
            "                        \"pillarenv '%s' not found in the configured pillar \"",
            "                        \"environments (%s)\",",
            "                        self.opts[\"pillarenv\"],",
            "                        \", \".join(self.opts[\"pillar_roots\"]),",
            "                    )",
            "                else:",
            "                    saltenvs.add(self.opts[\"pillarenv\"])",
            "            else:",
            "                saltenvs = self._get_envs()",
            "                if self.opts.get(\"pillar_source_merging_strategy\", None) == \"none\":",
            "                    saltenvs &= {self.saltenv or \"base\"}",
            "",
            "            for saltenv in saltenvs:",
            "                top = self.client.cache_file(self.opts[\"state_top\"], saltenv)",
            "                if top:",
            "                    tops[saltenv].append(",
            "                        compile_template(",
            "                            top,",
            "                            self.rend,",
            "                            self.opts[\"renderer\"],",
            "                            self.opts[\"renderer_blacklist\"],",
            "                            self.opts[\"renderer_whitelist\"],",
            "                            saltenv=saltenv,",
            "                            _pillar_rend=True,",
            "                        )",
            "                    )",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            errors.append(",
            "                \"Rendering Primary Top file failed, render error:\\n{}\".format(exc)",
            "            )",
            "            log.exception(\"Pillar rendering failed for minion %s\", self.minion_id)",
            "",
            "        # Search initial top files for includes",
            "        for saltenv, ctops in tops.items():",
            "            for ctop in ctops:",
            "                if \"include\" not in ctop:",
            "                    continue",
            "                for sls in ctop[\"include\"]:",
            "                    include[saltenv].append(sls)",
            "                ctop.pop(\"include\")",
            "        # Go through the includes and pull out the extra tops and add them",
            "        while include:",
            "            pops = []",
            "            for saltenv, states in include.items():",
            "                pops.append(saltenv)",
            "                if not states:",
            "                    continue",
            "                for sls in states:",
            "                    if sls in done[saltenv]:",
            "                        continue",
            "                    try:",
            "                        tops[saltenv].append(",
            "                            compile_template(",
            "                                self.client.get_state(sls, saltenv).get(\"dest\", False),",
            "                                self.rend,",
            "                                self.opts[\"renderer\"],",
            "                                self.opts[\"renderer_blacklist\"],",
            "                                self.opts[\"renderer_whitelist\"],",
            "                                saltenv=saltenv,",
            "                                _pillar_rend=True,",
            "                            )",
            "                        )",
            "                    except Exception as exc:  # pylint: disable=broad-except",
            "                        errors.append(",
            "                            (",
            "                                \"Rendering Top file {} failed, render error\" \":\\n{}\"",
            "                            ).format(sls, exc)",
            "                        )",
            "                    done[saltenv].append(sls)",
            "            for saltenv in pops:",
            "                if saltenv in include:",
            "                    include.pop(saltenv)",
            "",
            "        return tops, errors",
            "",
            "    def merge_tops(self, tops):",
            "        \"\"\"",
            "        Cleanly merge the top files",
            "        \"\"\"",
            "        top = collections.defaultdict(OrderedDict)",
            "        orders = collections.defaultdict(OrderedDict)",
            "        for ctops in tops.values():",
            "            for ctop in ctops:",
            "                for saltenv, targets in ctop.items():",
            "                    if saltenv == \"include\":",
            "                        continue",
            "                    for tgt in targets:",
            "                        matches = []",
            "                        states = OrderedDict()",
            "                        orders[saltenv][tgt] = 0",
            "                        ignore_missing = False",
            "                        for comp in ctop[saltenv][tgt]:",
            "                            if isinstance(comp, dict):",
            "                                if \"match\" in comp:",
            "                                    matches.append(comp)",
            "                                if \"order\" in comp:",
            "                                    order = comp[\"order\"]",
            "                                    if not isinstance(order, int):",
            "                                        try:",
            "                                            order = int(order)",
            "                                        except ValueError:",
            "                                            order = 0",
            "                                    orders[saltenv][tgt] = order",
            "                                if comp.get(\"ignore_missing\", False):",
            "                                    ignore_missing = True",
            "                            if isinstance(comp, str):",
            "                                states[comp] = True",
            "                        if ignore_missing:",
            "                            if saltenv not in self.ignored_pillars:",
            "                                self.ignored_pillars[saltenv] = []",
            "                            self.ignored_pillars[saltenv].extend(states.keys())",
            "                        top[saltenv][tgt] = matches",
            "                        top[saltenv][tgt].extend(states)",
            "        return self.sort_top_targets(top, orders)",
            "",
            "    def sort_top_targets(self, top, orders):",
            "        \"\"\"",
            "        Returns the sorted high data from the merged top files",
            "        \"\"\"",
            "        sorted_top = collections.defaultdict(OrderedDict)",
            "        # pylint: disable=cell-var-from-loop",
            "        for saltenv, targets in top.items():",
            "            sorted_targets = sorted(targets, key=lambda target: orders[saltenv][target])",
            "            for target in sorted_targets:",
            "                sorted_top[saltenv][target] = targets[target]",
            "        # pylint: enable=cell-var-from-loop",
            "        return sorted_top",
            "",
            "    def get_top(self):",
            "        \"\"\"",
            "        Returns the high data derived from the top file",
            "        \"\"\"",
            "        tops, errors = self.get_tops()",
            "        try:",
            "            merged_tops = self.merge_tops(tops)",
            "        except TypeError as err:",
            "            merged_tops = OrderedDict()",
            "            errors.append(\"Error encountered while rendering pillar top file.\")",
            "        return merged_tops, errors",
            "",
            "    def top_matches(self, top, reload=False):",
            "        \"\"\"",
            "        Search through the top high data for matches and return the states",
            "        that this minion needs to execute.",
            "",
            "        Returns:",
            "        {'saltenv': ['state1', 'state2', ...]}",
            "",
            "        reload",
            "            Reload the matcher loader",
            "        \"\"\"",
            "        matches = {}",
            "        if reload:",
            "            self.matchers = salt.loader.matchers(self.opts)",
            "        for saltenv, body in top.items():",
            "            if self.opts[\"pillarenv\"]:",
            "                if saltenv != self.opts[\"pillarenv\"]:",
            "                    continue",
            "            for match, data in body.items():",
            "                if self.matchers[\"confirm_top.confirm_top\"](",
            "                    match, data, self.opts.get(\"nodegroups\", {}),",
            "                ):",
            "                    if saltenv not in matches:",
            "                        matches[saltenv] = env_matches = []",
            "                    else:",
            "                        env_matches = matches[saltenv]",
            "                    for item in data:",
            "                        if isinstance(item, str) and item not in env_matches:",
            "                            env_matches.append(item)",
            "        return matches",
            "",
            "    def render_pstate(self, sls, saltenv, mods, defaults=None):",
            "        \"\"\"",
            "        Collect a single pillar sls file and render it",
            "        \"\"\"",
            "        if defaults is None:",
            "            defaults = {}",
            "        err = \"\"",
            "        errors = []",
            "        state_data = self.client.get_state(sls, saltenv)",
            "        fn_ = state_data.get(\"dest\", False)",
            "        if not fn_:",
            "            if sls in self.ignored_pillars.get(saltenv, []):",
            "                log.debug(",
            "                    \"Skipping ignored and missing SLS '%s' in \" \"environment '%s'\",",
            "                    sls,",
            "                    saltenv,",
            "                )",
            "                return None, mods, errors",
            "            elif self.opts[\"pillar_roots\"].get(saltenv):",
            "                msg = (",
            "                    \"Specified SLS '{}' in environment '{}' is not\"",
            "                    \" available on the salt master\"",
            "                ).format(sls, saltenv)",
            "                log.error(msg)",
            "                errors.append(msg)",
            "            else:",
            "                msg = (",
            "                    \"Specified SLS '{}' in environment '{}' was not \"",
            "                    \"found. \".format(sls, saltenv)",
            "                )",
            "                if self.opts.get(\"__git_pillar\", False) is True:",
            "                    msg += (",
            "                        \"This is likely caused by a git_pillar top file \"",
            "                        \"containing an environment other than the one for the \"",
            "                        \"branch in which it resides. Each git_pillar \"",
            "                        \"branch/tag must have its own top file.\"",
            "                    )",
            "                else:",
            "                    msg += (",
            "                        \"This could be because SLS '{0}' is in an \"",
            "                        \"environment other than '{1}', but '{1}' is \"",
            "                        \"included in that environment's Pillar top file. It \"",
            "                        \"could also be due to environment '{1}' not being \"",
            "                        \"defined in 'pillar_roots'.\".format(sls, saltenv)",
            "                    )",
            "                log.debug(msg)",
            "                # return state, mods, errors",
            "                return None, mods, errors",
            "        state = None",
            "        try:",
            "            state = compile_template(",
            "                fn_,",
            "                self.rend,",
            "                self.opts[\"renderer\"],",
            "                self.opts[\"renderer_blacklist\"],",
            "                self.opts[\"renderer_whitelist\"],",
            "                saltenv,",
            "                sls,",
            "                _pillar_rend=True,",
            "                **defaults",
            "            )",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            msg = \"Rendering SLS '{}' failed, render error:\\n{}\".format(sls, exc)",
            "            log.critical(msg, exc_info=True)",
            "            if self.opts.get(\"pillar_safe_render_error\", True):",
            "                errors.append(",
            "                    \"Rendering SLS '{}' failed. Please see master log for \"",
            "                    \"details.\".format(sls)",
            "                )",
            "            else:",
            "                errors.append(msg)",
            "        mods[sls] = state",
            "        nstate = None",
            "        if state:",
            "            if not isinstance(state, dict):",
            "                msg = \"SLS '{}' does not render to a dictionary\".format(sls)",
            "                log.error(msg)",
            "                errors.append(msg)",
            "            else:",
            "                if \"include\" in state:",
            "                    if not isinstance(state[\"include\"], list):",
            "                        msg = (",
            "                            \"Include Declaration in SLS '{}' is not \"",
            "                            \"formed as a list\".format(sls)",
            "                        )",
            "                        log.error(msg)",
            "                        errors.append(msg)",
            "                    else:",
            "                        # render included state(s)",
            "                        include_states = []",
            "                        for sub_sls in state.pop(\"include\"):",
            "                            if isinstance(sub_sls, dict):",
            "                                sub_sls, v = next(iter(sub_sls.items()))",
            "                                defaults = v.get(\"defaults\", {})",
            "                                key = v.get(\"key\", None)",
            "                            else:",
            "                                key = None",
            "                            try:",
            "                                matched_pstates = fnmatch.filter(",
            "                                    self.avail[saltenv],",
            "                                    sub_sls.lstrip(\".\").replace(\"/\", \".\"),",
            "                                )",
            "                                if sub_sls.startswith(\".\"):",
            "                                    if state_data.get(\"source\", \"\").endswith(",
            "                                        \"/init.sls\"",
            "                                    ):",
            "                                        include_parts = sls.split(\".\")",
            "                                    else:",
            "                                        include_parts = sls.split(\".\")[:-1]",
            "                                    sub_sls = \".\".join(include_parts + [sub_sls[1:]])",
            "                                matches = fnmatch.filter(self.avail[saltenv], sub_sls,)",
            "                                matched_pstates.extend(matches)",
            "                            except KeyError:",
            "                                errors.extend(",
            "                                    [",
            "                                        \"No matching pillar environment for environment \"",
            "                                        \"'{}' found\".format(saltenv)",
            "                                    ]",
            "                                )",
            "                                matched_pstates = [sub_sls]",
            "                            # If matched_pstates is empty, set to sub_sls",
            "                            if len(matched_pstates) < 1:",
            "                                matched_pstates = [sub_sls]",
            "                            for m_sub_sls in matched_pstates:",
            "                                if m_sub_sls not in mods:",
            "                                    nstate, mods, err = self.render_pstate(",
            "                                        m_sub_sls, saltenv, mods, defaults",
            "                                    )",
            "                                else:",
            "                                    nstate = mods[m_sub_sls]",
            "                                if nstate:",
            "                                    if key:",
            "                                        # If key is x:y, convert it to {x: {y: nstate}}",
            "                                        for key_fragment in reversed(key.split(\":\")):",
            "                                            nstate = {key_fragment: nstate}",
            "                                    if not self.opts.get(",
            "                                        \"pillar_includes_override_sls\", False",
            "                                    ):",
            "                                        include_states.append(nstate)",
            "                                    else:",
            "                                        state = merge(",
            "                                            state,",
            "                                            nstate,",
            "                                            self.merge_strategy,",
            "                                            self.opts.get(\"renderer\", \"yaml\"),",
            "                                            self.opts.get(\"pillar_merge_lists\", False),",
            "                                        )",
            "                                if err:",
            "                                    errors += err",
            "                        if not self.opts.get(\"pillar_includes_override_sls\", False):",
            "                            # merge included state(s) with the current state",
            "                            # merged last to ensure that its values are",
            "                            # authoritative.",
            "                            include_states.append(state)",
            "                            state = None",
            "                            for s in include_states:",
            "                                if state is None:",
            "                                    state = s",
            "                                else:",
            "                                    state = merge(",
            "                                        state,",
            "                                        s,",
            "                                        self.merge_strategy,",
            "                                        self.opts.get(\"renderer\", \"yaml\"),",
            "                                        self.opts.get(\"pillar_merge_lists\", False),",
            "                                    )",
            "        return state, mods, errors",
            "",
            "    def render_pillar(self, matches, errors=None):",
            "        \"\"\"",
            "        Extract the sls pillar files from the matches and render them into the",
            "        pillar",
            "        \"\"\"",
            "        pillar = copy.copy(self.pillar_override)",
            "        if errors is None:",
            "            errors = []",
            "        for saltenv, pstates in matches.items():",
            "            pstatefiles = []",
            "            mods = {}",
            "            for sls_match in pstates:",
            "                matched_pstates = []",
            "                try:",
            "                    matched_pstates = fnmatch.filter(self.avail[saltenv], sls_match)",
            "                except KeyError:",
            "                    errors.extend(",
            "                        [",
            "                            \"No matching pillar environment for environment \"",
            "                            \"'{}' found\".format(saltenv)",
            "                        ]",
            "                    )",
            "                if matched_pstates:",
            "                    pstatefiles.extend(matched_pstates)",
            "                else:",
            "                    pstatefiles.append(sls_match)",
            "",
            "            for sls in pstatefiles:",
            "                pstate, mods, err = self.render_pstate(sls, saltenv, mods)",
            "",
            "                if err:",
            "                    errors += err",
            "",
            "                if pstate is not None:",
            "                    if not isinstance(pstate, dict):",
            "                        log.error(",
            "                            \"The rendered pillar sls file, '%s' state did \"",
            "                            \"not return the expected data format. This is \"",
            "                            \"a sign of a malformed pillar sls file. Returned \"",
            "                            \"errors: %s\",",
            "                            sls,",
            "                            \", \".join([\"'{}'\".format(e) for e in errors]),",
            "                        )",
            "                        continue",
            "                    pillar = merge(",
            "                        pillar,",
            "                        pstate,",
            "                        self.merge_strategy,",
            "                        self.opts.get(\"renderer\", \"yaml\"),",
            "                        self.opts.get(\"pillar_merge_lists\", False),",
            "                    )",
            "",
            "        return pillar, errors",
            "",
            "    def _external_pillar_data(self, pillar, val, key):",
            "        \"\"\"",
            "        Builds actual pillar data structure and updates the ``pillar`` variable",
            "        \"\"\"",
            "        ext = None",
            "        args = salt.utils.args.get_function_argspec(self.ext_pillars[key]).args",
            "",
            "        if isinstance(val, dict):",
            "            if (\"extra_minion_data\" in args) and self.extra_minion_data:",
            "                ext = self.ext_pillars[key](",
            "                    self.minion_id,",
            "                    pillar,",
            "                    extra_minion_data=self.extra_minion_data,",
            "                    **val",
            "                )",
            "            else:",
            "                ext = self.ext_pillars[key](self.minion_id, pillar, **val)",
            "        elif isinstance(val, list):",
            "            if (\"extra_minion_data\" in args) and self.extra_minion_data:",
            "                ext = self.ext_pillars[key](",
            "                    self.minion_id,",
            "                    pillar,",
            "                    *val,",
            "                    extra_minion_data=self.extra_minion_data",
            "                )",
            "            else:",
            "                ext = self.ext_pillars[key](self.minion_id, pillar, *val)",
            "        else:",
            "            if (\"extra_minion_data\" in args) and self.extra_minion_data:",
            "                ext = self.ext_pillars[key](",
            "                    self.minion_id,",
            "                    pillar,",
            "                    val,",
            "                    extra_minion_data=self.extra_minion_data,",
            "                )",
            "            else:",
            "                ext = self.ext_pillars[key](self.minion_id, pillar, val)",
            "        return ext",
            "",
            "    def ext_pillar(self, pillar, errors=None):",
            "        \"\"\"",
            "        Render the external pillar data",
            "        \"\"\"",
            "        if errors is None:",
            "            errors = []",
            "        try:",
            "            # Make sure that on-demand git_pillar is fetched before we try to",
            "            # compile the pillar data. git_pillar will fetch a remote when",
            "            # the git ext_pillar() func is run, but only for masterless.",
            "            if self.ext and \"git\" in self.ext and self.opts.get(\"__role\") != \"minion\":",
            "                # Avoid circular import",
            "                import salt.utils.gitfs",
            "                import salt.pillar.git_pillar",
            "",
            "                git_pillar = salt.utils.gitfs.GitPillar(",
            "                    self.opts,",
            "                    self.ext[\"git\"],",
            "                    per_remote_overrides=salt.pillar.git_pillar.PER_REMOTE_OVERRIDES,",
            "                    per_remote_only=salt.pillar.git_pillar.PER_REMOTE_ONLY,",
            "                    global_only=salt.pillar.git_pillar.GLOBAL_ONLY,",
            "                )",
            "                git_pillar.fetch_remotes()",
            "        except TypeError:",
            "            # Handle malformed ext_pillar",
            "            pass",
            "        if \"ext_pillar\" not in self.opts:",
            "            return pillar, errors",
            "        if not isinstance(self.opts[\"ext_pillar\"], list):",
            "            errors.append('The \"ext_pillar\" option is malformed')",
            "            log.critical(errors[-1])",
            "            return pillar, errors",
            "        ext = None",
            "        # Bring in CLI pillar data",
            "        if self.pillar_override:",
            "            pillar = merge(",
            "                pillar,",
            "                self.pillar_override,",
            "                self.merge_strategy,",
            "                self.opts.get(\"renderer\", \"yaml\"),",
            "                self.opts.get(\"pillar_merge_lists\", False),",
            "            )",
            "",
            "        for run in self.opts[\"ext_pillar\"]:",
            "            if not isinstance(run, dict):",
            "                errors.append('The \"ext_pillar\" option is malformed')",
            "                log.critical(errors[-1])",
            "                return {}, errors",
            "            if next(iter(run.keys())) in self.opts.get(\"exclude_ext_pillar\", []):",
            "                continue",
            "            for key, val in run.items():",
            "                if key not in self.ext_pillars:",
            "                    log.critical(",
            "                        \"Specified ext_pillar interface %s is unavailable\", key",
            "                    )",
            "                    continue",
            "                try:",
            "                    ext = self._external_pillar_data(pillar, val, key)",
            "                except Exception as exc:  # pylint: disable=broad-except",
            "                    errors.append(",
            "                        \"Failed to load ext_pillar {}: {}\".format(key, exc.__str__(),)",
            "                    )",
            "                    log.error(",
            "                        \"Exception caught loading ext_pillar '%s':\\n%s\",",
            "                        key,",
            "                        \"\".join(traceback.format_tb(sys.exc_info()[2])),",
            "                    )",
            "            if ext:",
            "                pillar = merge(",
            "                    pillar,",
            "                    ext,",
            "                    self.merge_strategy,",
            "                    self.opts.get(\"renderer\", \"yaml\"),",
            "                    self.opts.get(\"pillar_merge_lists\", False),",
            "                )",
            "                ext = None",
            "        return pillar, errors",
            "",
            "    def compile_pillar(self, ext=True):",
            "        \"\"\"",
            "        Render the pillar data and return",
            "        \"\"\"",
            "        top, top_errors = self.get_top()",
            "        if ext:",
            "            if self.opts.get(\"ext_pillar_first\", False):",
            "                self.opts[\"pillar\"], errors = self.ext_pillar(self.pillar_override)",
            "                self.rend = salt.loader.render(self.opts, self.functions)",
            "                matches = self.top_matches(top, reload=True)",
            "                pillar, errors = self.render_pillar(matches, errors=errors)",
            "                pillar = merge(",
            "                    self.opts[\"pillar\"],",
            "                    pillar,",
            "                    self.merge_strategy,",
            "                    self.opts.get(\"renderer\", \"yaml\"),",
            "                    self.opts.get(\"pillar_merge_lists\", False),",
            "                )",
            "            else:",
            "                matches = self.top_matches(top)",
            "                pillar, errors = self.render_pillar(matches)",
            "                pillar, errors = self.ext_pillar(pillar, errors=errors)",
            "        else:",
            "            matches = self.top_matches(top)",
            "            pillar, errors = self.render_pillar(matches)",
            "        errors.extend(top_errors)",
            "        if self.opts.get(\"pillar_opts\", False):",
            "            mopts = dict(self.opts)",
            "            if \"grains\" in mopts:",
            "                mopts.pop(\"grains\")",
            "            mopts[\"saltversion\"] = __version__",
            "            pillar[\"master\"] = mopts",
            "        if \"pillar\" in self.opts and self.opts.get(\"ssh_merge_pillar\", False):",
            "            pillar = merge(",
            "                self.opts[\"pillar\"],",
            "                pillar,",
            "                self.merge_strategy,",
            "                self.opts.get(\"renderer\", \"yaml\"),",
            "                self.opts.get(\"pillar_merge_lists\", False),",
            "            )",
            "        if errors:",
            "            for error in errors:",
            "                log.critical(\"Pillar render error: %s\", error)",
            "            pillar[\"_errors\"] = errors",
            "",
            "        if self.pillar_override:",
            "            pillar = merge(",
            "                pillar,",
            "                self.pillar_override,",
            "                self.merge_strategy,",
            "                self.opts.get(\"renderer\", \"yaml\"),",
            "                self.opts.get(\"pillar_merge_lists\", False),",
            "            )",
            "",
            "        decrypt_errors = self.decrypt_pillar(pillar)",
            "        if decrypt_errors:",
            "            pillar.setdefault(\"_errors\", []).extend(decrypt_errors)",
            "        return pillar",
            "",
            "    def decrypt_pillar(self, pillar):",
            "        \"\"\"",
            "        Decrypt the specified pillar dictionary items, if configured to do so",
            "        \"\"\"",
            "        errors = []",
            "        if self.opts.get(\"decrypt_pillar\"):",
            "            decrypt_pillar = self.opts[\"decrypt_pillar\"]",
            "            if not isinstance(decrypt_pillar, dict):",
            "                decrypt_pillar = salt.utils.data.repack_dictlist(",
            "                    self.opts[\"decrypt_pillar\"]",
            "                )",
            "            if not decrypt_pillar:",
            "                errors.append(\"decrypt_pillar config option is malformed\")",
            "            for key, rend in decrypt_pillar.items():",
            "                ptr = salt.utils.data.traverse_dict(",
            "                    pillar,",
            "                    key,",
            "                    default=None,",
            "                    delimiter=self.opts[\"decrypt_pillar_delimiter\"],",
            "                )",
            "                if ptr is None:",
            "                    log.debug(\"Pillar key %s not present\", key)",
            "                    continue",
            "                try:",
            "                    hash(ptr)",
            "                    immutable = True",
            "                except TypeError:",
            "                    immutable = False",
            "                try:",
            "                    ret = salt.utils.crypt.decrypt(",
            "                        ptr,",
            "                        rend or self.opts[\"decrypt_pillar_default\"],",
            "                        renderers=self.rend,",
            "                        opts=self.opts,",
            "                        valid_rend=self.opts[\"decrypt_pillar_renderers\"],",
            "                    )",
            "                    if immutable:",
            "                        # Since the key pointed to an immutable type, we need",
            "                        # to replace it in the pillar dict. First we will find",
            "                        # the parent, and then we will replace the child key",
            "                        # with the return data from the renderer.",
            "                        parent, _, child = key.rpartition(",
            "                            self.opts[\"decrypt_pillar_delimiter\"]",
            "                        )",
            "                        if not parent:",
            "                            # key is a top-level key, so the pointer to the",
            "                            # parent is the pillar dict itself.",
            "                            ptr = pillar",
            "                        else:",
            "                            ptr = salt.utils.data.traverse_dict(",
            "                                pillar,",
            "                                parent,",
            "                                default=None,",
            "                                delimiter=self.opts[\"decrypt_pillar_delimiter\"],",
            "                            )",
            "                        if ptr is not None:",
            "                            ptr[child] = ret",
            "                except Exception as exc:  # pylint: disable=broad-except",
            "                    msg = \"Failed to decrypt pillar key '{}': {}\".format(key, exc)",
            "                    errors.append(msg)",
            "                    log.error(msg, exc_info=True)",
            "        return errors",
            "",
            "    def destroy(self):",
            "        \"\"\"",
            "        This method exist in order to be API compatible with RemotePillar",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.destroy()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "# TODO: actually migrate from Pillar to AsyncPillar to allow for futures in",
            "# ext_pillar etc.",
            "class AsyncPillar(Pillar):",
            "    @salt.ext.tornado.gen.coroutine",
            "    def compile_pillar(self, ext=True):",
            "        ret = super().compile_pillar(ext=ext)",
            "        raise salt.ext.tornado.gen.Return(ret)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "helpdesk.models.FollowUp",
            "salt.pillar.AsyncRemotePillar.compile_pillar.load"
        ]
    },
    "salt/transport/mixins/auth.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 113,
                "afterPatchRowNumber": 113,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 114,
                "afterPatchRowNumber": 114,
                "PatchRowcode": "         self.master_key = salt.crypt.MasterKeys(self.opts)"
            },
            "2": {
                "beforePatchRowNumber": 115,
                "afterPatchRowNumber": 115,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 116,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    def _encrypt_private(self, ret, dictkey, target):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 116,
                "PatchRowcode": "+    def _encrypt_private(self, ret, dictkey, target, nonce=None, sign_messages=True):"
            },
            "5": {
                "beforePatchRowNumber": 117,
                "afterPatchRowNumber": 117,
                "PatchRowcode": "         \"\"\""
            },
            "6": {
                "beforePatchRowNumber": 118,
                "afterPatchRowNumber": 118,
                "PatchRowcode": "         The server equivalent of ReqChannel.crypted_transfer_decode_dictentry"
            },
            "7": {
                "beforePatchRowNumber": 119,
                "afterPatchRowNumber": 119,
                "PatchRowcode": "         \"\"\""
            },
            "8": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 128,
                "PatchRowcode": "         except OSError:"
            },
            "9": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 129,
                "PatchRowcode": "             log.error(\"AES key not found\")"
            },
            "10": {
                "beforePatchRowNumber": 130,
                "afterPatchRowNumber": 130,
                "PatchRowcode": "             return {\"error\": \"AES key not found\"}"
            },
            "11": {
                "beforePatchRowNumber": 131,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "12": {
                "beforePatchRowNumber": 132,
                "afterPatchRowNumber": 131,
                "PatchRowcode": "         pret = {}"
            },
            "13": {
                "beforePatchRowNumber": 133,
                "afterPatchRowNumber": 132,
                "PatchRowcode": "         key = salt.utils.stringutils.to_bytes(key)"
            },
            "14": {
                "beforePatchRowNumber": 134,
                "afterPatchRowNumber": 133,
                "PatchRowcode": "         if HAS_M2:"
            },
            "15": {
                "beforePatchRowNumber": 135,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "             pret[\"key\"] = pub.public_encrypt(key, RSA.pkcs1_oaep_padding)"
            },
            "16": {
                "beforePatchRowNumber": 136,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "         else:"
            },
            "17": {
                "beforePatchRowNumber": 137,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "             cipher = PKCS1_OAEP.new(pub)"
            },
            "18": {
                "beforePatchRowNumber": 138,
                "afterPatchRowNumber": 137,
                "PatchRowcode": "             pret[\"key\"] = cipher.encrypt(key)"
            },
            "19": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        pret[dictkey] = pcrypt.dumps(ret if ret is not False else {})"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 138,
                "PatchRowcode": "+        if ret is False:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 139,
                "PatchRowcode": "+            ret = {}"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 140,
                "PatchRowcode": "+        if sign_messages:"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 141,
                "PatchRowcode": "+            if nonce is None:"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 142,
                "PatchRowcode": "+                return {\"error\": \"Nonce not included in request\"}"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+            tosign = self.serial.dumps("
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+                {\"key\": pret[\"key\"], \"pillar\": ret, \"nonce\": nonce}"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+            )"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+            master_pem_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 147,
                "PatchRowcode": "+            signed_msg = {"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 148,
                "PatchRowcode": "+                \"data\": tosign,"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+                \"sig\": salt.crypt.sign_message(master_pem_path, tosign),"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 150,
                "PatchRowcode": "+            }"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 151,
                "PatchRowcode": "+            pret[dictkey] = pcrypt.dumps(signed_msg)"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 152,
                "PatchRowcode": "+        else:"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+            pret[dictkey] = pcrypt.dumps(ret)"
            },
            "36": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 154,
                "PatchRowcode": "         return pret"
            },
            "37": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 155,
                "PatchRowcode": " "
            },
            "38": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "     def _update_aes(self):"
            }
        },
        "frontPatchFile": [
            "import binascii",
            "import ctypes",
            "import hashlib",
            "import logging",
            "import multiprocessing",
            "import os",
            "import shutil",
            "",
            "import salt.crypt",
            "import salt.ext.tornado.gen",
            "import salt.master",
            "import salt.payload",
            "import salt.transport.frame",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.minions",
            "import salt.utils.stringutils",
            "import salt.utils.verify",
            "from salt.utils.cache import CacheCli",
            "",
            "try:",
            "    from M2Crypto import RSA",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "    try:",
            "        from Cryptodome.Cipher import PKCS1_OAEP",
            "    except ImportError:",
            "        from Crypto.Cipher import PKCS1_OAEP  # nosec",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "# TODO: rename",
            "class AESPubClientMixin:",
            "    def _verify_master_signature(self, payload):",
            "        if self.opts.get(\"sign_pub_messages\"):",
            "            if not payload.get(\"sig\", False):",
            "                raise salt.crypt.AuthenticationError(",
            "                    \"Message signing is enabled but the payload has no signature.\"",
            "                )",
            "",
            "            # Verify that the signature is valid",
            "            master_pubkey_path = os.path.join(self.opts[\"pki_dir\"], \"minion_master.pub\")",
            "            if not salt.crypt.verify_signature(",
            "                master_pubkey_path, payload[\"load\"], payload.get(\"sig\")",
            "            ):",
            "                raise salt.crypt.AuthenticationError(",
            "                    \"Message signature failed to validate.\"",
            "                )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _decode_payload(self, payload):",
            "        # we need to decrypt it",
            "        log.trace(\"Decoding payload: %s\", payload)",
            "        if payload[\"enc\"] == \"aes\":",
            "            self._verify_master_signature(payload)",
            "            try:",
            "                payload[\"load\"] = self.auth.crypticle.loads(payload[\"load\"])",
            "            except salt.crypt.AuthenticationError:",
            "                yield self.auth.authenticate()",
            "                payload[\"load\"] = self.auth.crypticle.loads(payload[\"load\"])",
            "",
            "        raise salt.ext.tornado.gen.Return(payload)",
            "",
            "",
            "# TODO: rename?",
            "class AESReqServerMixin:",
            "    \"\"\"",
            "    Mixin to house all of the master-side auth crypto",
            "    \"\"\"",
            "",
            "    def pre_fork(self, _):",
            "        \"\"\"",
            "        Pre-fork we need to create the zmq router device",
            "        \"\"\"",
            "        if \"aes\" not in salt.master.SMaster.secrets:",
            "            # TODO: This is still needed only for the unit tests",
            "            # 'tcp_test.py' and 'zeromq_test.py'. Fix that. In normal",
            "            # cases, 'aes' is already set in the secrets.",
            "            salt.master.SMaster.secrets[\"aes\"] = {",
            "                \"secret\": multiprocessing.Array(",
            "                    ctypes.c_char,",
            "                    salt.utils.stringutils.to_bytes(",
            "                        salt.crypt.Crypticle.generate_key_string()",
            "                    ),",
            "                ),",
            "                \"reload\": salt.crypt.Crypticle.generate_key_string,",
            "            }",
            "",
            "    def post_fork(self, _, __):",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.crypticle = salt.crypt.Crypticle(",
            "            self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "        )",
            "",
            "        # other things needed for _auth",
            "        # Create the event manager",
            "        self.event = salt.utils.event.get_master_event(",
            "            self.opts, self.opts[\"sock_dir\"], listen=False",
            "        )",
            "        self.auto_key = salt.daemons.masterapi.AutoKey(self.opts)",
            "",
            "        # only create a con_cache-client if the con_cache is active",
            "        if self.opts[\"con_cache\"]:",
            "            self.cache_cli = CacheCli(self.opts)",
            "        else:",
            "            self.cache_cli = False",
            "            # Make an minion checker object",
            "            self.ckminions = salt.utils.minions.CkMinions(self.opts)",
            "",
            "        self.master_key = salt.crypt.MasterKeys(self.opts)",
            "",
            "    def _encrypt_private(self, ret, dictkey, target):",
            "        \"\"\"",
            "        The server equivalent of ReqChannel.crypted_transfer_decode_dictentry",
            "        \"\"\"",
            "        # encrypt with a specific AES key",
            "        pubfn = os.path.join(self.opts[\"pki_dir\"], \"minions\", target)",
            "        key = salt.crypt.Crypticle.generate_key_string()",
            "        pcrypt = salt.crypt.Crypticle(self.opts, key)",
            "        try:",
            "            pub = salt.crypt.get_rsa_pub_key(pubfn)",
            "        except (ValueError, IndexError, TypeError):",
            "            return self.crypticle.dumps({})",
            "        except OSError:",
            "            log.error(\"AES key not found\")",
            "            return {\"error\": \"AES key not found\"}",
            "",
            "        pret = {}",
            "        key = salt.utils.stringutils.to_bytes(key)",
            "        if HAS_M2:",
            "            pret[\"key\"] = pub.public_encrypt(key, RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(pub)",
            "            pret[\"key\"] = cipher.encrypt(key)",
            "        pret[dictkey] = pcrypt.dumps(ret if ret is not False else {})",
            "        return pret",
            "",
            "    def _update_aes(self):",
            "        \"\"\"",
            "        Check to see if a fresh AES key is available and update the components",
            "        of the worker",
            "        \"\"\"",
            "        if (",
            "            salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "            != self.crypticle.key_string",
            "        ):",
            "            self.crypticle = salt.crypt.Crypticle(",
            "                self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "            )",
            "            return True",
            "        return False",
            "",
            "    def _decode_payload(self, payload):",
            "        # we need to decrypt it",
            "        if payload[\"enc\"] == \"aes\":",
            "            try:",
            "                payload[\"load\"] = self.crypticle.loads(payload[\"load\"])",
            "            except salt.crypt.AuthenticationError:",
            "                if not self._update_aes():",
            "                    raise",
            "                payload[\"load\"] = self.crypticle.loads(payload[\"load\"])",
            "        return payload",
            "",
            "    def _auth(self, load):",
            "        \"\"\"",
            "        Authenticate the client, use the sent public key to encrypt the AES key",
            "        which was generated at start up.",
            "",
            "        This method fires an event over the master event manager. The event is",
            "        tagged \"auth\" and returns a dict with information about the auth",
            "        event",
            "",
            "        # Verify that the key we are receiving matches the stored key",
            "        # Store the key if it is not there",
            "        # Make an RSA key with the pub key",
            "        # Encrypt the AES key as an encrypted salt.payload",
            "        # Package the return and return it",
            "        \"\"\"",
            "",
            "        if not salt.utils.verify.valid_id(self.opts, load[\"id\"]):",
            "            log.info(\"Authentication request from invalid id %s\", load[\"id\"])",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "        log.info(\"Authentication request from %s\", load[\"id\"])",
            "",
            "        # 0 is default which should be 'unlimited'",
            "        if self.opts[\"max_minions\"] > 0:",
            "            # use the ConCache if enabled, else use the minion utils",
            "            if self.cache_cli:",
            "                minions = self.cache_cli.get_cached()",
            "            else:",
            "                minions = self.ckminions.connected_ids()",
            "                if len(minions) > 1000:",
            "                    log.info(",
            "                        \"With large numbers of minions it is advised \"",
            "                        \"to enable the ConCache with 'con_cache: True' \"",
            "                        \"in the masters configuration file.\"",
            "                    )",
            "",
            "            if not len(minions) <= self.opts[\"max_minions\"]:",
            "                # we reject new minions, minions that are already",
            "                # connected must be allowed for the mine, highstate, etc.",
            "                if load[\"id\"] not in minions:",
            "                    msg = (",
            "                        \"Too many minions connected (max_minions={}). \"",
            "                        \"Rejecting connection from id \"",
            "                        \"{}\".format(self.opts[\"max_minions\"], load[\"id\"])",
            "                    )",
            "                    log.info(msg)",
            "                    eload = {",
            "                        \"result\": False,",
            "                        \"act\": \"full\",",
            "                        \"id\": load[\"id\"],",
            "                        \"pub\": load[\"pub\"],",
            "                    }",
            "",
            "                    if self.opts.get(\"auth_events\") is True:",
            "                        self.event.fire_event(",
            "                            eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                        )",
            "                    return {\"enc\": \"clear\", \"load\": {\"ret\": \"full\"}}",
            "",
            "        # Check if key is configured to be auto-rejected/signed",
            "        auto_reject = self.auto_key.check_autoreject(load[\"id\"])",
            "        auto_sign = self.auto_key.check_autosign(",
            "            load[\"id\"], load.get(\"autosign_grains\", None)",
            "        )",
            "",
            "        pubfn = os.path.join(self.opts[\"pki_dir\"], \"minions\", load[\"id\"])",
            "        pubfn_pend = os.path.join(self.opts[\"pki_dir\"], \"minions_pre\", load[\"id\"])",
            "        pubfn_rejected = os.path.join(",
            "            self.opts[\"pki_dir\"], \"minions_rejected\", load[\"id\"]",
            "        )",
            "        pubfn_denied = os.path.join(self.opts[\"pki_dir\"], \"minions_denied\", load[\"id\"])",
            "        if self.opts[\"open_mode\"]:",
            "            # open mode is turned on, nuts to checks and overwrite whatever",
            "            # is there",
            "            pass",
            "        elif os.path.isfile(pubfn_rejected):",
            "            # The key has been rejected, don't place it in pending",
            "            log.info(",
            "                \"Public key rejected for %s. Key is present in \" \"rejection key dir.\",",
            "                load[\"id\"],",
            "            )",
            "            eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "            if self.opts.get(\"auth_events\") is True:",
            "                self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        elif os.path.isfile(pubfn):",
            "            # The key has been accepted, check it",
            "            with salt.utils.files.fopen(pubfn, \"r\") as pubfn_handle:",
            "                if pubfn_handle.read().strip() != load[\"pub\"].strip():",
            "                    log.error(",
            "                        \"Authentication attempt from %s failed, the public \"",
            "                        \"keys did not match. This may be an attempt to compromise \"",
            "                        \"the Salt cluster.\",",
            "                        load[\"id\"],",
            "                    )",
            "                    # put denied minion key into minions_denied",
            "                    with salt.utils.files.fopen(pubfn_denied, \"w+\") as fp_:",
            "                        fp_.write(load[\"pub\"])",
            "                    eload = {",
            "                        \"result\": False,",
            "                        \"id\": load[\"id\"],",
            "                        \"act\": \"denied\",",
            "                        \"pub\": load[\"pub\"],",
            "                    }",
            "                    if self.opts.get(\"auth_events\") is True:",
            "                        self.event.fire_event(",
            "                            eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                        )",
            "                    return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        elif not os.path.isfile(pubfn_pend):",
            "            # The key has not been accepted, this is a new minion",
            "            if os.path.isdir(pubfn_pend):",
            "                # The key path is a directory, error out",
            "                log.info(\"New public key %s is a directory\", load[\"id\"])",
            "                eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "                return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "            if auto_reject:",
            "                key_path = pubfn_rejected",
            "                log.info(",
            "                    \"New public key for %s rejected via autoreject_file\", load[\"id\"]",
            "                )",
            "                key_act = \"reject\"",
            "                key_result = False",
            "            elif not auto_sign:",
            "                key_path = pubfn_pend",
            "                log.info(\"New public key for %s placed in pending\", load[\"id\"])",
            "                key_act = \"pend\"",
            "                key_result = True",
            "            else:",
            "                # The key is being automatically accepted, don't do anything",
            "                # here and let the auto accept logic below handle it.",
            "                key_path = None",
            "",
            "            if key_path is not None:",
            "                # Write the key to the appropriate location",
            "                with salt.utils.files.fopen(key_path, \"w+\") as fp_:",
            "                    fp_.write(load[\"pub\"])",
            "                ret = {\"enc\": \"clear\", \"load\": {\"ret\": key_result}}",
            "                eload = {",
            "                    \"result\": key_result,",
            "                    \"act\": key_act,",
            "                    \"id\": load[\"id\"],",
            "                    \"pub\": load[\"pub\"],",
            "                }",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "                return ret",
            "",
            "        elif os.path.isfile(pubfn_pend):",
            "            # This key is in the pending dir and is awaiting acceptance",
            "            if auto_reject:",
            "                # We don't care if the keys match, this minion is being",
            "                # auto-rejected. Move the key file from the pending dir to the",
            "                # rejected dir.",
            "                try:",
            "                    shutil.move(pubfn_pend, pubfn_rejected)",
            "                except OSError:",
            "                    pass",
            "                log.info(",
            "                    \"Pending public key for %s rejected via \" \"autoreject_file\",",
            "                    load[\"id\"],",
            "                )",
            "                ret = {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "                eload = {",
            "                    \"result\": False,",
            "                    \"act\": \"reject\",",
            "                    \"id\": load[\"id\"],",
            "                    \"pub\": load[\"pub\"],",
            "                }",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "                return ret",
            "",
            "            elif not auto_sign:",
            "                # This key is in the pending dir and is not being auto-signed.",
            "                # Check if the keys are the same and error out if this is the",
            "                # case. Otherwise log the fact that the minion is still",
            "                # pending.",
            "                with salt.utils.files.fopen(pubfn_pend, \"r\") as pubfn_handle:",
            "                    if pubfn_handle.read() != load[\"pub\"]:",
            "                        log.error(",
            "                            \"Authentication attempt from %s failed, the public \"",
            "                            \"key in pending did not match. This may be an \"",
            "                            \"attempt to compromise the Salt cluster.\",",
            "                            load[\"id\"],",
            "                        )",
            "                        # put denied minion key into minions_denied",
            "                        with salt.utils.files.fopen(pubfn_denied, \"w+\") as fp_:",
            "                            fp_.write(load[\"pub\"])",
            "                        eload = {",
            "                            \"result\": False,",
            "                            \"id\": load[\"id\"],",
            "                            \"act\": \"denied\",",
            "                            \"pub\": load[\"pub\"],",
            "                        }",
            "                        if self.opts.get(\"auth_events\") is True:",
            "                            self.event.fire_event(",
            "                                eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                            )",
            "                        return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "                    else:",
            "                        log.info(",
            "                            \"Authentication failed from host %s, the key is in \"",
            "                            \"pending and needs to be accepted with salt-key \"",
            "                            \"-a %s\",",
            "                            load[\"id\"],",
            "                            load[\"id\"],",
            "                        )",
            "                        eload = {",
            "                            \"result\": True,",
            "                            \"act\": \"pend\",",
            "                            \"id\": load[\"id\"],",
            "                            \"pub\": load[\"pub\"],",
            "                        }",
            "                        if self.opts.get(\"auth_events\") is True:",
            "                            self.event.fire_event(",
            "                                eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                            )",
            "                        return {\"enc\": \"clear\", \"load\": {\"ret\": True}}",
            "            else:",
            "                # This key is in pending and has been configured to be",
            "                # auto-signed. Check to see if it is the same key, and if",
            "                # so, pass on doing anything here, and let it get automatically",
            "                # accepted below.",
            "                with salt.utils.files.fopen(pubfn_pend, \"r\") as pubfn_handle:",
            "                    if pubfn_handle.read() != load[\"pub\"]:",
            "                        log.error(",
            "                            \"Authentication attempt from %s failed, the public \"",
            "                            \"keys in pending did not match. This may be an \"",
            "                            \"attempt to compromise the Salt cluster.\",",
            "                            load[\"id\"],",
            "                        )",
            "                        # put denied minion key into minions_denied",
            "                        with salt.utils.files.fopen(pubfn_denied, \"w+\") as fp_:",
            "                            fp_.write(load[\"pub\"])",
            "                        eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "                        if self.opts.get(\"auth_events\") is True:",
            "                            self.event.fire_event(",
            "                                eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                            )",
            "                        return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "                    else:",
            "                        os.remove(pubfn_pend)",
            "",
            "        else:",
            "            # Something happened that I have not accounted for, FAIL!",
            "            log.warning(\"Unaccounted for authentication failure\")",
            "            eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "            if self.opts.get(\"auth_events\") is True:",
            "                self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        log.info(\"Authentication accepted from %s\", load[\"id\"])",
            "        # only write to disk if you are adding the file, and in open mode,",
            "        # which implies we accept any key from a minion.",
            "        if not os.path.isfile(pubfn) and not self.opts[\"open_mode\"]:",
            "            with salt.utils.files.fopen(pubfn, \"w+\") as fp_:",
            "                fp_.write(load[\"pub\"])",
            "        elif self.opts[\"open_mode\"]:",
            "            disk_key = \"\"",
            "            if os.path.isfile(pubfn):",
            "                with salt.utils.files.fopen(pubfn, \"r\") as fp_:",
            "                    disk_key = fp_.read()",
            "            if load[\"pub\"] and load[\"pub\"] != disk_key:",
            "                log.debug(\"Host key change detected in open mode.\")",
            "                with salt.utils.files.fopen(pubfn, \"w+\") as fp_:",
            "                    fp_.write(load[\"pub\"])",
            "            elif not load[\"pub\"]:",
            "                log.error(\"Public key is empty: {}\".format(load[\"id\"]))",
            "                return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        pub = None",
            "",
            "        # the con_cache is enabled, send the minion id to the cache",
            "        if self.cache_cli:",
            "            self.cache_cli.put_cache([load[\"id\"]])",
            "",
            "        # The key payload may sometimes be corrupt when using auto-accept",
            "        # and an empty request comes in",
            "        try:",
            "            pub = salt.crypt.get_rsa_pub_key(pubfn)",
            "        except (ValueError, IndexError, TypeError) as err:",
            "            log.error('Corrupt public key \"%s\": %s', pubfn, err)",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        if not HAS_M2:",
            "            cipher = PKCS1_OAEP.new(pub)",
            "        ret = {",
            "            \"enc\": \"pub\",",
            "            \"pub_key\": self.master_key.get_pub_str(),",
            "            \"publish_port\": self.opts[\"publish_port\"],",
            "        }",
            "",
            "        # sign the master's pubkey (if enabled) before it is",
            "        # sent to the minion that was just authenticated",
            "        if self.opts[\"master_sign_pubkey\"]:",
            "            # append the pre-computed signature to the auth-reply",
            "            if self.master_key.pubkey_signature():",
            "                log.debug(\"Adding pubkey signature to auth-reply\")",
            "                log.debug(self.master_key.pubkey_signature())",
            "                ret.update({\"pub_sig\": self.master_key.pubkey_signature()})",
            "            else:",
            "                # the master has its own signing-keypair, compute the master.pub's",
            "                # signature and append that to the auth-reply",
            "",
            "                # get the key_pass for the signing key",
            "                key_pass = salt.utils.sdb.sdb_get(",
            "                    self.opts[\"signing_key_pass\"], self.opts",
            "                )",
            "",
            "                log.debug(\"Signing master public key before sending\")",
            "                pub_sign = salt.crypt.sign_message(",
            "                    self.master_key.get_sign_paths()[1], ret[\"pub_key\"], key_pass",
            "                )",
            "                ret.update({\"pub_sig\": binascii.b2a_base64(pub_sign)})",
            "",
            "        if not HAS_M2:",
            "            mcipher = PKCS1_OAEP.new(self.master_key.key)",
            "        if self.opts[\"auth_mode\"] >= 2:",
            "            if \"token\" in load:",
            "                try:",
            "                    if HAS_M2:",
            "                        mtoken = self.master_key.key.private_decrypt(",
            "                            load[\"token\"], RSA.pkcs1_oaep_padding",
            "                        )",
            "                    else:",
            "                        mtoken = mcipher.decrypt(load[\"token\"])",
            "                    aes = \"{}_|-{}\".format(",
            "                        salt.master.SMaster.secrets[\"aes\"][\"secret\"].value, mtoken",
            "                    )",
            "                except Exception:  # pylint: disable=broad-except",
            "                    # Token failed to decrypt, send back the salty bacon to",
            "                    # support older minions",
            "                    pass",
            "            else:",
            "                aes = salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "",
            "            if HAS_M2:",
            "                ret[\"aes\"] = pub.public_encrypt(aes, RSA.pkcs1_oaep_padding)",
            "            else:",
            "                ret[\"aes\"] = cipher.encrypt(aes)",
            "        else:",
            "            if \"token\" in load:",
            "                try:",
            "                    if HAS_M2:",
            "                        mtoken = self.master_key.key.private_decrypt(",
            "                            load[\"token\"], RSA.pkcs1_oaep_padding",
            "                        )",
            "                        ret[\"token\"] = pub.public_encrypt(",
            "                            mtoken, RSA.pkcs1_oaep_padding",
            "                        )",
            "                    else:",
            "                        mtoken = mcipher.decrypt(load[\"token\"])",
            "                        ret[\"token\"] = cipher.encrypt(mtoken)",
            "                except Exception:  # pylint: disable=broad-except",
            "                    # Token failed to decrypt, send back the salty bacon to",
            "                    # support older minions",
            "                    pass",
            "",
            "            aes = salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "            if HAS_M2:",
            "                ret[\"aes\"] = pub.public_encrypt(aes, RSA.pkcs1_oaep_padding)",
            "            else:",
            "                ret[\"aes\"] = cipher.encrypt(aes)",
            "        # Be aggressive about the signature",
            "        digest = salt.utils.stringutils.to_bytes(hashlib.sha256(aes).hexdigest())",
            "        ret[\"sig\"] = salt.crypt.private_encrypt(self.master_key.key, digest)",
            "        eload = {\"result\": True, \"act\": \"accept\", \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "        if self.opts.get(\"auth_events\") is True:",
            "            self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "        return ret"
        ],
        "afterPatchFile": [
            "import binascii",
            "import ctypes",
            "import hashlib",
            "import logging",
            "import multiprocessing",
            "import os",
            "import shutil",
            "",
            "import salt.crypt",
            "import salt.ext.tornado.gen",
            "import salt.master",
            "import salt.payload",
            "import salt.transport.frame",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.minions",
            "import salt.utils.stringutils",
            "import salt.utils.verify",
            "from salt.utils.cache import CacheCli",
            "",
            "try:",
            "    from M2Crypto import RSA",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "    try:",
            "        from Cryptodome.Cipher import PKCS1_OAEP",
            "    except ImportError:",
            "        from Crypto.Cipher import PKCS1_OAEP  # nosec",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "# TODO: rename",
            "class AESPubClientMixin:",
            "    def _verify_master_signature(self, payload):",
            "        if self.opts.get(\"sign_pub_messages\"):",
            "            if not payload.get(\"sig\", False):",
            "                raise salt.crypt.AuthenticationError(",
            "                    \"Message signing is enabled but the payload has no signature.\"",
            "                )",
            "",
            "            # Verify that the signature is valid",
            "            master_pubkey_path = os.path.join(self.opts[\"pki_dir\"], \"minion_master.pub\")",
            "            if not salt.crypt.verify_signature(",
            "                master_pubkey_path, payload[\"load\"], payload.get(\"sig\")",
            "            ):",
            "                raise salt.crypt.AuthenticationError(",
            "                    \"Message signature failed to validate.\"",
            "                )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _decode_payload(self, payload):",
            "        # we need to decrypt it",
            "        log.trace(\"Decoding payload: %s\", payload)",
            "        if payload[\"enc\"] == \"aes\":",
            "            self._verify_master_signature(payload)",
            "            try:",
            "                payload[\"load\"] = self.auth.crypticle.loads(payload[\"load\"])",
            "            except salt.crypt.AuthenticationError:",
            "                yield self.auth.authenticate()",
            "                payload[\"load\"] = self.auth.crypticle.loads(payload[\"load\"])",
            "",
            "        raise salt.ext.tornado.gen.Return(payload)",
            "",
            "",
            "# TODO: rename?",
            "class AESReqServerMixin:",
            "    \"\"\"",
            "    Mixin to house all of the master-side auth crypto",
            "    \"\"\"",
            "",
            "    def pre_fork(self, _):",
            "        \"\"\"",
            "        Pre-fork we need to create the zmq router device",
            "        \"\"\"",
            "        if \"aes\" not in salt.master.SMaster.secrets:",
            "            # TODO: This is still needed only for the unit tests",
            "            # 'tcp_test.py' and 'zeromq_test.py'. Fix that. In normal",
            "            # cases, 'aes' is already set in the secrets.",
            "            salt.master.SMaster.secrets[\"aes\"] = {",
            "                \"secret\": multiprocessing.Array(",
            "                    ctypes.c_char,",
            "                    salt.utils.stringutils.to_bytes(",
            "                        salt.crypt.Crypticle.generate_key_string()",
            "                    ),",
            "                ),",
            "                \"reload\": salt.crypt.Crypticle.generate_key_string,",
            "            }",
            "",
            "    def post_fork(self, _, __):",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.crypticle = salt.crypt.Crypticle(",
            "            self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "        )",
            "",
            "        # other things needed for _auth",
            "        # Create the event manager",
            "        self.event = salt.utils.event.get_master_event(",
            "            self.opts, self.opts[\"sock_dir\"], listen=False",
            "        )",
            "        self.auto_key = salt.daemons.masterapi.AutoKey(self.opts)",
            "",
            "        # only create a con_cache-client if the con_cache is active",
            "        if self.opts[\"con_cache\"]:",
            "            self.cache_cli = CacheCli(self.opts)",
            "        else:",
            "            self.cache_cli = False",
            "            # Make an minion checker object",
            "            self.ckminions = salt.utils.minions.CkMinions(self.opts)",
            "",
            "        self.master_key = salt.crypt.MasterKeys(self.opts)",
            "",
            "    def _encrypt_private(self, ret, dictkey, target, nonce=None, sign_messages=True):",
            "        \"\"\"",
            "        The server equivalent of ReqChannel.crypted_transfer_decode_dictentry",
            "        \"\"\"",
            "        # encrypt with a specific AES key",
            "        pubfn = os.path.join(self.opts[\"pki_dir\"], \"minions\", target)",
            "        key = salt.crypt.Crypticle.generate_key_string()",
            "        pcrypt = salt.crypt.Crypticle(self.opts, key)",
            "        try:",
            "            pub = salt.crypt.get_rsa_pub_key(pubfn)",
            "        except (ValueError, IndexError, TypeError):",
            "            return self.crypticle.dumps({})",
            "        except OSError:",
            "            log.error(\"AES key not found\")",
            "            return {\"error\": \"AES key not found\"}",
            "        pret = {}",
            "        key = salt.utils.stringutils.to_bytes(key)",
            "        if HAS_M2:",
            "            pret[\"key\"] = pub.public_encrypt(key, RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(pub)",
            "            pret[\"key\"] = cipher.encrypt(key)",
            "        if ret is False:",
            "            ret = {}",
            "        if sign_messages:",
            "            if nonce is None:",
            "                return {\"error\": \"Nonce not included in request\"}",
            "            tosign = self.serial.dumps(",
            "                {\"key\": pret[\"key\"], \"pillar\": ret, \"nonce\": nonce}",
            "            )",
            "            master_pem_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "            signed_msg = {",
            "                \"data\": tosign,",
            "                \"sig\": salt.crypt.sign_message(master_pem_path, tosign),",
            "            }",
            "            pret[dictkey] = pcrypt.dumps(signed_msg)",
            "        else:",
            "            pret[dictkey] = pcrypt.dumps(ret)",
            "        return pret",
            "",
            "    def _update_aes(self):",
            "        \"\"\"",
            "        Check to see if a fresh AES key is available and update the components",
            "        of the worker",
            "        \"\"\"",
            "        if (",
            "            salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "            != self.crypticle.key_string",
            "        ):",
            "            self.crypticle = salt.crypt.Crypticle(",
            "                self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "            )",
            "            return True",
            "        return False",
            "",
            "    def _decode_payload(self, payload):",
            "        # we need to decrypt it",
            "        if payload[\"enc\"] == \"aes\":",
            "            try:",
            "                payload[\"load\"] = self.crypticle.loads(payload[\"load\"])",
            "            except salt.crypt.AuthenticationError:",
            "                if not self._update_aes():",
            "                    raise",
            "                payload[\"load\"] = self.crypticle.loads(payload[\"load\"])",
            "        return payload",
            "",
            "    def _auth(self, load):",
            "        \"\"\"",
            "        Authenticate the client, use the sent public key to encrypt the AES key",
            "        which was generated at start up.",
            "",
            "        This method fires an event over the master event manager. The event is",
            "        tagged \"auth\" and returns a dict with information about the auth",
            "        event",
            "",
            "        # Verify that the key we are receiving matches the stored key",
            "        # Store the key if it is not there",
            "        # Make an RSA key with the pub key",
            "        # Encrypt the AES key as an encrypted salt.payload",
            "        # Package the return and return it",
            "        \"\"\"",
            "",
            "        if not salt.utils.verify.valid_id(self.opts, load[\"id\"]):",
            "            log.info(\"Authentication request from invalid id %s\", load[\"id\"])",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "        log.info(\"Authentication request from %s\", load[\"id\"])",
            "",
            "        # 0 is default which should be 'unlimited'",
            "        if self.opts[\"max_minions\"] > 0:",
            "            # use the ConCache if enabled, else use the minion utils",
            "            if self.cache_cli:",
            "                minions = self.cache_cli.get_cached()",
            "            else:",
            "                minions = self.ckminions.connected_ids()",
            "                if len(minions) > 1000:",
            "                    log.info(",
            "                        \"With large numbers of minions it is advised \"",
            "                        \"to enable the ConCache with 'con_cache: True' \"",
            "                        \"in the masters configuration file.\"",
            "                    )",
            "",
            "            if not len(minions) <= self.opts[\"max_minions\"]:",
            "                # we reject new minions, minions that are already",
            "                # connected must be allowed for the mine, highstate, etc.",
            "                if load[\"id\"] not in minions:",
            "                    msg = (",
            "                        \"Too many minions connected (max_minions={}). \"",
            "                        \"Rejecting connection from id \"",
            "                        \"{}\".format(self.opts[\"max_minions\"], load[\"id\"])",
            "                    )",
            "                    log.info(msg)",
            "                    eload = {",
            "                        \"result\": False,",
            "                        \"act\": \"full\",",
            "                        \"id\": load[\"id\"],",
            "                        \"pub\": load[\"pub\"],",
            "                    }",
            "",
            "                    if self.opts.get(\"auth_events\") is True:",
            "                        self.event.fire_event(",
            "                            eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                        )",
            "                    return {\"enc\": \"clear\", \"load\": {\"ret\": \"full\"}}",
            "",
            "        # Check if key is configured to be auto-rejected/signed",
            "        auto_reject = self.auto_key.check_autoreject(load[\"id\"])",
            "        auto_sign = self.auto_key.check_autosign(",
            "            load[\"id\"], load.get(\"autosign_grains\", None)",
            "        )",
            "",
            "        pubfn = os.path.join(self.opts[\"pki_dir\"], \"minions\", load[\"id\"])",
            "        pubfn_pend = os.path.join(self.opts[\"pki_dir\"], \"minions_pre\", load[\"id\"])",
            "        pubfn_rejected = os.path.join(",
            "            self.opts[\"pki_dir\"], \"minions_rejected\", load[\"id\"]",
            "        )",
            "        pubfn_denied = os.path.join(self.opts[\"pki_dir\"], \"minions_denied\", load[\"id\"])",
            "        if self.opts[\"open_mode\"]:",
            "            # open mode is turned on, nuts to checks and overwrite whatever",
            "            # is there",
            "            pass",
            "        elif os.path.isfile(pubfn_rejected):",
            "            # The key has been rejected, don't place it in pending",
            "            log.info(",
            "                \"Public key rejected for %s. Key is present in \" \"rejection key dir.\",",
            "                load[\"id\"],",
            "            )",
            "            eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "            if self.opts.get(\"auth_events\") is True:",
            "                self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        elif os.path.isfile(pubfn):",
            "            # The key has been accepted, check it",
            "            with salt.utils.files.fopen(pubfn, \"r\") as pubfn_handle:",
            "                if pubfn_handle.read().strip() != load[\"pub\"].strip():",
            "                    log.error(",
            "                        \"Authentication attempt from %s failed, the public \"",
            "                        \"keys did not match. This may be an attempt to compromise \"",
            "                        \"the Salt cluster.\",",
            "                        load[\"id\"],",
            "                    )",
            "                    # put denied minion key into minions_denied",
            "                    with salt.utils.files.fopen(pubfn_denied, \"w+\") as fp_:",
            "                        fp_.write(load[\"pub\"])",
            "                    eload = {",
            "                        \"result\": False,",
            "                        \"id\": load[\"id\"],",
            "                        \"act\": \"denied\",",
            "                        \"pub\": load[\"pub\"],",
            "                    }",
            "                    if self.opts.get(\"auth_events\") is True:",
            "                        self.event.fire_event(",
            "                            eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                        )",
            "                    return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        elif not os.path.isfile(pubfn_pend):",
            "            # The key has not been accepted, this is a new minion",
            "            if os.path.isdir(pubfn_pend):",
            "                # The key path is a directory, error out",
            "                log.info(\"New public key %s is a directory\", load[\"id\"])",
            "                eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "                return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "            if auto_reject:",
            "                key_path = pubfn_rejected",
            "                log.info(",
            "                    \"New public key for %s rejected via autoreject_file\", load[\"id\"]",
            "                )",
            "                key_act = \"reject\"",
            "                key_result = False",
            "            elif not auto_sign:",
            "                key_path = pubfn_pend",
            "                log.info(\"New public key for %s placed in pending\", load[\"id\"])",
            "                key_act = \"pend\"",
            "                key_result = True",
            "            else:",
            "                # The key is being automatically accepted, don't do anything",
            "                # here and let the auto accept logic below handle it.",
            "                key_path = None",
            "",
            "            if key_path is not None:",
            "                # Write the key to the appropriate location",
            "                with salt.utils.files.fopen(key_path, \"w+\") as fp_:",
            "                    fp_.write(load[\"pub\"])",
            "                ret = {\"enc\": \"clear\", \"load\": {\"ret\": key_result}}",
            "                eload = {",
            "                    \"result\": key_result,",
            "                    \"act\": key_act,",
            "                    \"id\": load[\"id\"],",
            "                    \"pub\": load[\"pub\"],",
            "                }",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "                return ret",
            "",
            "        elif os.path.isfile(pubfn_pend):",
            "            # This key is in the pending dir and is awaiting acceptance",
            "            if auto_reject:",
            "                # We don't care if the keys match, this minion is being",
            "                # auto-rejected. Move the key file from the pending dir to the",
            "                # rejected dir.",
            "                try:",
            "                    shutil.move(pubfn_pend, pubfn_rejected)",
            "                except OSError:",
            "                    pass",
            "                log.info(",
            "                    \"Pending public key for %s rejected via \" \"autoreject_file\",",
            "                    load[\"id\"],",
            "                )",
            "                ret = {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "                eload = {",
            "                    \"result\": False,",
            "                    \"act\": \"reject\",",
            "                    \"id\": load[\"id\"],",
            "                    \"pub\": load[\"pub\"],",
            "                }",
            "                if self.opts.get(\"auth_events\") is True:",
            "                    self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "                return ret",
            "",
            "            elif not auto_sign:",
            "                # This key is in the pending dir and is not being auto-signed.",
            "                # Check if the keys are the same and error out if this is the",
            "                # case. Otherwise log the fact that the minion is still",
            "                # pending.",
            "                with salt.utils.files.fopen(pubfn_pend, \"r\") as pubfn_handle:",
            "                    if pubfn_handle.read() != load[\"pub\"]:",
            "                        log.error(",
            "                            \"Authentication attempt from %s failed, the public \"",
            "                            \"key in pending did not match. This may be an \"",
            "                            \"attempt to compromise the Salt cluster.\",",
            "                            load[\"id\"],",
            "                        )",
            "                        # put denied minion key into minions_denied",
            "                        with salt.utils.files.fopen(pubfn_denied, \"w+\") as fp_:",
            "                            fp_.write(load[\"pub\"])",
            "                        eload = {",
            "                            \"result\": False,",
            "                            \"id\": load[\"id\"],",
            "                            \"act\": \"denied\",",
            "                            \"pub\": load[\"pub\"],",
            "                        }",
            "                        if self.opts.get(\"auth_events\") is True:",
            "                            self.event.fire_event(",
            "                                eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                            )",
            "                        return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "                    else:",
            "                        log.info(",
            "                            \"Authentication failed from host %s, the key is in \"",
            "                            \"pending and needs to be accepted with salt-key \"",
            "                            \"-a %s\",",
            "                            load[\"id\"],",
            "                            load[\"id\"],",
            "                        )",
            "                        eload = {",
            "                            \"result\": True,",
            "                            \"act\": \"pend\",",
            "                            \"id\": load[\"id\"],",
            "                            \"pub\": load[\"pub\"],",
            "                        }",
            "                        if self.opts.get(\"auth_events\") is True:",
            "                            self.event.fire_event(",
            "                                eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                            )",
            "                        return {\"enc\": \"clear\", \"load\": {\"ret\": True}}",
            "            else:",
            "                # This key is in pending and has been configured to be",
            "                # auto-signed. Check to see if it is the same key, and if",
            "                # so, pass on doing anything here, and let it get automatically",
            "                # accepted below.",
            "                with salt.utils.files.fopen(pubfn_pend, \"r\") as pubfn_handle:",
            "                    if pubfn_handle.read() != load[\"pub\"]:",
            "                        log.error(",
            "                            \"Authentication attempt from %s failed, the public \"",
            "                            \"keys in pending did not match. This may be an \"",
            "                            \"attempt to compromise the Salt cluster.\",",
            "                            load[\"id\"],",
            "                        )",
            "                        # put denied minion key into minions_denied",
            "                        with salt.utils.files.fopen(pubfn_denied, \"w+\") as fp_:",
            "                            fp_.write(load[\"pub\"])",
            "                        eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "                        if self.opts.get(\"auth_events\") is True:",
            "                            self.event.fire_event(",
            "                                eload, salt.utils.event.tagify(prefix=\"auth\")",
            "                            )",
            "                        return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "                    else:",
            "                        os.remove(pubfn_pend)",
            "",
            "        else:",
            "            # Something happened that I have not accounted for, FAIL!",
            "            log.warning(\"Unaccounted for authentication failure\")",
            "            eload = {\"result\": False, \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "            if self.opts.get(\"auth_events\") is True:",
            "                self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        log.info(\"Authentication accepted from %s\", load[\"id\"])",
            "        # only write to disk if you are adding the file, and in open mode,",
            "        # which implies we accept any key from a minion.",
            "        if not os.path.isfile(pubfn) and not self.opts[\"open_mode\"]:",
            "            with salt.utils.files.fopen(pubfn, \"w+\") as fp_:",
            "                fp_.write(load[\"pub\"])",
            "        elif self.opts[\"open_mode\"]:",
            "            disk_key = \"\"",
            "            if os.path.isfile(pubfn):",
            "                with salt.utils.files.fopen(pubfn, \"r\") as fp_:",
            "                    disk_key = fp_.read()",
            "            if load[\"pub\"] and load[\"pub\"] != disk_key:",
            "                log.debug(\"Host key change detected in open mode.\")",
            "                with salt.utils.files.fopen(pubfn, \"w+\") as fp_:",
            "                    fp_.write(load[\"pub\"])",
            "            elif not load[\"pub\"]:",
            "                log.error(\"Public key is empty: {}\".format(load[\"id\"]))",
            "                return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        pub = None",
            "",
            "        # the con_cache is enabled, send the minion id to the cache",
            "        if self.cache_cli:",
            "            self.cache_cli.put_cache([load[\"id\"]])",
            "",
            "        # The key payload may sometimes be corrupt when using auto-accept",
            "        # and an empty request comes in",
            "        try:",
            "            pub = salt.crypt.get_rsa_pub_key(pubfn)",
            "        except (ValueError, IndexError, TypeError) as err:",
            "            log.error('Corrupt public key \"%s\": %s', pubfn, err)",
            "            return {\"enc\": \"clear\", \"load\": {\"ret\": False}}",
            "",
            "        if not HAS_M2:",
            "            cipher = PKCS1_OAEP.new(pub)",
            "        ret = {",
            "            \"enc\": \"pub\",",
            "            \"pub_key\": self.master_key.get_pub_str(),",
            "            \"publish_port\": self.opts[\"publish_port\"],",
            "        }",
            "",
            "        # sign the master's pubkey (if enabled) before it is",
            "        # sent to the minion that was just authenticated",
            "        if self.opts[\"master_sign_pubkey\"]:",
            "            # append the pre-computed signature to the auth-reply",
            "            if self.master_key.pubkey_signature():",
            "                log.debug(\"Adding pubkey signature to auth-reply\")",
            "                log.debug(self.master_key.pubkey_signature())",
            "                ret.update({\"pub_sig\": self.master_key.pubkey_signature()})",
            "            else:",
            "                # the master has its own signing-keypair, compute the master.pub's",
            "                # signature and append that to the auth-reply",
            "",
            "                # get the key_pass for the signing key",
            "                key_pass = salt.utils.sdb.sdb_get(",
            "                    self.opts[\"signing_key_pass\"], self.opts",
            "                )",
            "",
            "                log.debug(\"Signing master public key before sending\")",
            "                pub_sign = salt.crypt.sign_message(",
            "                    self.master_key.get_sign_paths()[1], ret[\"pub_key\"], key_pass",
            "                )",
            "                ret.update({\"pub_sig\": binascii.b2a_base64(pub_sign)})",
            "",
            "        if not HAS_M2:",
            "            mcipher = PKCS1_OAEP.new(self.master_key.key)",
            "        if self.opts[\"auth_mode\"] >= 2:",
            "            if \"token\" in load:",
            "                try:",
            "                    if HAS_M2:",
            "                        mtoken = self.master_key.key.private_decrypt(",
            "                            load[\"token\"], RSA.pkcs1_oaep_padding",
            "                        )",
            "                    else:",
            "                        mtoken = mcipher.decrypt(load[\"token\"])",
            "                    aes = \"{}_|-{}\".format(",
            "                        salt.master.SMaster.secrets[\"aes\"][\"secret\"].value, mtoken",
            "                    )",
            "                except Exception:  # pylint: disable=broad-except",
            "                    # Token failed to decrypt, send back the salty bacon to",
            "                    # support older minions",
            "                    pass",
            "            else:",
            "                aes = salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "",
            "            if HAS_M2:",
            "                ret[\"aes\"] = pub.public_encrypt(aes, RSA.pkcs1_oaep_padding)",
            "            else:",
            "                ret[\"aes\"] = cipher.encrypt(aes)",
            "        else:",
            "            if \"token\" in load:",
            "                try:",
            "                    if HAS_M2:",
            "                        mtoken = self.master_key.key.private_decrypt(",
            "                            load[\"token\"], RSA.pkcs1_oaep_padding",
            "                        )",
            "                        ret[\"token\"] = pub.public_encrypt(",
            "                            mtoken, RSA.pkcs1_oaep_padding",
            "                        )",
            "                    else:",
            "                        mtoken = mcipher.decrypt(load[\"token\"])",
            "                        ret[\"token\"] = cipher.encrypt(mtoken)",
            "                except Exception:  # pylint: disable=broad-except",
            "                    # Token failed to decrypt, send back the salty bacon to",
            "                    # support older minions",
            "                    pass",
            "",
            "            aes = salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "            if HAS_M2:",
            "                ret[\"aes\"] = pub.public_encrypt(aes, RSA.pkcs1_oaep_padding)",
            "            else:",
            "                ret[\"aes\"] = cipher.encrypt(aes)",
            "        # Be aggressive about the signature",
            "        digest = salt.utils.stringutils.to_bytes(hashlib.sha256(aes).hexdigest())",
            "        ret[\"sig\"] = salt.crypt.private_encrypt(self.master_key.key, digest)",
            "        eload = {\"result\": True, \"act\": \"accept\", \"id\": load[\"id\"], \"pub\": load[\"pub\"]}",
            "        if self.opts.get(\"auth_events\") is True:",
            "            self.event.fire_event(eload, salt.utils.event.tagify(prefix=\"auth\"))",
            "        return ret"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "116": [
                "AESReqServerMixin",
                "_encrypt_private"
            ],
            "131": [
                "AESReqServerMixin",
                "_encrypt_private"
            ],
            "139": [
                "AESReqServerMixin",
                "_encrypt_private"
            ]
        },
        "addLocation": []
    },
    "salt/transport/tcp.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import time"
            },
            "1": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " import traceback"
            },
            "2": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " import urllib.parse as urlparse"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 16,
                "PatchRowcode": "+import uuid"
            },
            "4": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " import weakref"
            },
            "5": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " "
            },
            "6": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " import salt.crypt"
            },
            "7": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 368,
                "PatchRowcode": "         return {"
            },
            "8": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": 369,
                "PatchRowcode": "             \"enc\": self.crypt,"
            },
            "9": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": 370,
                "PatchRowcode": "             \"load\": load,"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+            \"version\": 2,"
            },
            "11": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 372,
                "PatchRowcode": "         }"
            },
            "12": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 373,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "     @salt.ext.tornado.gen.coroutine"
            },
            "14": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "     def crypted_transfer_decode_dictentry("
            },
            "15": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "         self, load, dictkey=None, tries=3, timeout=60"
            },
            "16": {
                "beforePatchRowNumber": 375,
                "afterPatchRowNumber": 377,
                "PatchRowcode": "     ):"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 378,
                "PatchRowcode": "+        nonce = uuid.uuid4().hex"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 379,
                "PatchRowcode": "+        load[\"nonce\"] = nonce"
            },
            "19": {
                "beforePatchRowNumber": 376,
                "afterPatchRowNumber": 380,
                "PatchRowcode": "         if not self.auth.authenticated:"
            },
            "20": {
                "beforePatchRowNumber": 377,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "             yield self.auth.authenticate()"
            },
            "21": {
                "beforePatchRowNumber": 378,
                "afterPatchRowNumber": 382,
                "PatchRowcode": "         ret = yield self.message_client.send("
            },
            "22": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 390,
                "PatchRowcode": "         else:"
            },
            "23": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": 391,
                "PatchRowcode": "             cipher = PKCS1_OAEP.new(key)"
            },
            "24": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 392,
                "PatchRowcode": "             aes = cipher.decrypt(ret[\"key\"])"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 393,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 394,
                "PatchRowcode": "+        # Decrypt using the public key."
            },
            "27": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 395,
                "PatchRowcode": "         pcrypt = salt.crypt.Crypticle(self.opts, aes)"
            },
            "28": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        data = pcrypt.loads(ret[dictkey])"
            },
            "29": {
                "beforePatchRowNumber": 391,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        data = salt.transport.frame.decode_embedded_strs(data)"
            },
            "30": {
                "beforePatchRowNumber": 392,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        raise salt.ext.tornado.gen.Return(data)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+        signed_msg = pcrypt.loads(ret[dictkey])"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+        # Validate the master's signature."
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+        master_pubkey_path = os.path.join(self.opts[\"pki_dir\"], \"minion_master.pub\")"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 400,
                "PatchRowcode": "+        if not salt.crypt.verify_signature("
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 401,
                "PatchRowcode": "+            master_pubkey_path, signed_msg[\"data\"], signed_msg[\"sig\"]"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 402,
                "PatchRowcode": "+        ):"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 403,
                "PatchRowcode": "+            raise salt.crypt.AuthenticationError("
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 404,
                "PatchRowcode": "+                \"Pillar payload signature failed to validate.\""
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 405,
                "PatchRowcode": "+            )"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 406,
                "PatchRowcode": "+"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 407,
                "PatchRowcode": "+        # Make sure the signed key matches the key we used to decrypt the data."
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 408,
                "PatchRowcode": "+        data = salt.payload.Serial({}).loads(signed_msg[\"data\"])"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 409,
                "PatchRowcode": "+        if data[\"key\"] != ret[\"key\"]:"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 410,
                "PatchRowcode": "+            raise salt.crypt.AuthenticationError(\"Key verification failed.\")"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 411,
                "PatchRowcode": "+"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 412,
                "PatchRowcode": "+        # Validate the nonce."
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 413,
                "PatchRowcode": "+        if data[\"nonce\"] != nonce:"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 414,
                "PatchRowcode": "+            raise salt.crypt.AuthenticationError(\"Pillar nonce verification failed.\")"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 415,
                "PatchRowcode": "+        raise salt.ext.tornado.gen.Return(data[\"pillar\"])"
            },
            "51": {
                "beforePatchRowNumber": 393,
                "afterPatchRowNumber": 416,
                "PatchRowcode": " "
            },
            "52": {
                "beforePatchRowNumber": 394,
                "afterPatchRowNumber": 417,
                "PatchRowcode": "     @salt.ext.tornado.gen.coroutine"
            },
            "53": {
                "beforePatchRowNumber": 395,
                "afterPatchRowNumber": 418,
                "PatchRowcode": "     def _crypted_transfer(self, load, tries=3, timeout=60):"
            },
            "54": {
                "beforePatchRowNumber": 796,
                "afterPatchRowNumber": 819,
                "PatchRowcode": "                 )"
            },
            "55": {
                "beforePatchRowNumber": 797,
                "afterPatchRowNumber": 820,
                "PatchRowcode": "                 raise salt.ext.tornado.gen.Return()"
            },
            "56": {
                "beforePatchRowNumber": 798,
                "afterPatchRowNumber": 821,
                "PatchRowcode": " "
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 822,
                "PatchRowcode": "+            version = 0"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 823,
                "PatchRowcode": "+            if \"version\" in payload:"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 824,
                "PatchRowcode": "+                version = payload[\"version\"]"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 825,
                "PatchRowcode": "+"
            },
            "61": {
                "beforePatchRowNumber": 799,
                "afterPatchRowNumber": 826,
                "PatchRowcode": "             # intercept the \"_auth\" commands, since the main daemon shouldn't know"
            },
            "62": {
                "beforePatchRowNumber": 800,
                "afterPatchRowNumber": 827,
                "PatchRowcode": "             # anything about our key auth"
            },
            "63": {
                "beforePatchRowNumber": 801,
                "afterPatchRowNumber": 828,
                "PatchRowcode": "             if ("
            },
            "64": {
                "beforePatchRowNumber": 831,
                "afterPatchRowNumber": 858,
                "PatchRowcode": "                     )"
            },
            "65": {
                "beforePatchRowNumber": 832,
                "afterPatchRowNumber": 859,
                "PatchRowcode": "                 )"
            },
            "66": {
                "beforePatchRowNumber": 833,
                "afterPatchRowNumber": 860,
                "PatchRowcode": "             elif req_fun == \"send_private\":"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 861,
                "PatchRowcode": "+                sign_messages = False"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 862,
                "PatchRowcode": "+                nonce = None"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 863,
                "PatchRowcode": "+                if version > 1:"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 864,
                "PatchRowcode": "+                    sign_messages = True"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 865,
                "PatchRowcode": "+                    nonce = payload[\"load\"].get(\"nonce\")"
            },
            "72": {
                "beforePatchRowNumber": 834,
                "afterPatchRowNumber": 866,
                "PatchRowcode": "                 stream.write("
            },
            "73": {
                "beforePatchRowNumber": 835,
                "afterPatchRowNumber": 867,
                "PatchRowcode": "                     salt.transport.frame.frame_msg("
            },
            "74": {
                "beforePatchRowNumber": 836,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        self._encrypt_private(ret, req_opts[\"key\"], req_opts[\"tgt\"],),"
            },
            "75": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 868,
                "PatchRowcode": "+                        self._encrypt_private("
            },
            "76": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 869,
                "PatchRowcode": "+                            ret, req_opts[\"key\"], req_opts[\"tgt\"], nonce, sign_messages,"
            },
            "77": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 870,
                "PatchRowcode": "+                        ),"
            },
            "78": {
                "beforePatchRowNumber": 837,
                "afterPatchRowNumber": 871,
                "PatchRowcode": "                         header=header,"
            },
            "79": {
                "beforePatchRowNumber": 838,
                "afterPatchRowNumber": 872,
                "PatchRowcode": "                     )"
            },
            "80": {
                "beforePatchRowNumber": 839,
                "afterPatchRowNumber": 873,
                "PatchRowcode": "                 )"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "TCP transport classes",
            "",
            "Wire protocol: \"len(payload) msgpack({'head': SOMEHEADER, 'body': SOMEBODY})\"",
            "",
            "\"\"\"",
            "import errno",
            "import logging",
            "import os",
            "import queue",
            "import socket",
            "import threading",
            "import time",
            "import traceback",
            "import urllib.parse as urlparse",
            "import weakref",
            "",
            "import salt.crypt",
            "import salt.exceptions",
            "import salt.ext.tornado",
            "import salt.ext.tornado.concurrent",
            "import salt.ext.tornado.gen",
            "import salt.ext.tornado.iostream",
            "import salt.ext.tornado.netutil",
            "import salt.ext.tornado.tcpclient",
            "import salt.ext.tornado.tcpserver",
            "import salt.payload",
            "import salt.transport.client",
            "import salt.transport.frame",
            "import salt.transport.ipc",
            "import salt.transport.mixins.auth",
            "import salt.transport.server",
            "import salt.utils.asynchronous",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.msgpack",
            "import salt.utils.platform",
            "import salt.utils.process",
            "import salt.utils.verify",
            "import salt.utils.versions",
            "from salt.exceptions import SaltClientError, SaltReqTimeoutError",
            "from salt.transport import iter_transport_opts",
            "",
            "try:",
            "    from M2Crypto import RSA",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "    try:",
            "        from Cryptodome.Cipher import PKCS1_OAEP",
            "    except ImportError:",
            "        from Crypto.Cipher import PKCS1_OAEP  # nosec",
            "",
            "if salt.utils.platform.is_windows():",
            "    USE_LOAD_BALANCER = True",
            "else:",
            "    USE_LOAD_BALANCER = False",
            "",
            "if USE_LOAD_BALANCER:",
            "    import threading",
            "    import multiprocessing",
            "    import salt.ext.tornado.util",
            "    from salt.utils.process import SignalHandlingProcess",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def _set_tcp_keepalive(sock, opts):",
            "    \"\"\"",
            "    Ensure that TCP keepalives are set for the socket.",
            "    \"\"\"",
            "    if hasattr(socket, \"SO_KEEPALIVE\"):",
            "        if opts.get(\"tcp_keepalive\", False):",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)",
            "            if hasattr(socket, \"SOL_TCP\"):",
            "                if hasattr(socket, \"TCP_KEEPIDLE\"):",
            "                    tcp_keepalive_idle = opts.get(\"tcp_keepalive_idle\", -1)",
            "                    if tcp_keepalive_idle > 0:",
            "                        sock.setsockopt(",
            "                            socket.SOL_TCP, socket.TCP_KEEPIDLE, int(tcp_keepalive_idle)",
            "                        )",
            "                if hasattr(socket, \"TCP_KEEPCNT\"):",
            "                    tcp_keepalive_cnt = opts.get(\"tcp_keepalive_cnt\", -1)",
            "                    if tcp_keepalive_cnt > 0:",
            "                        sock.setsockopt(",
            "                            socket.SOL_TCP, socket.TCP_KEEPCNT, int(tcp_keepalive_cnt)",
            "                        )",
            "                if hasattr(socket, \"TCP_KEEPINTVL\"):",
            "                    tcp_keepalive_intvl = opts.get(\"tcp_keepalive_intvl\", -1)",
            "                    if tcp_keepalive_intvl > 0:",
            "                        sock.setsockopt(",
            "                            socket.SOL_TCP,",
            "                            socket.TCP_KEEPINTVL,",
            "                            int(tcp_keepalive_intvl),",
            "                        )",
            "            if hasattr(socket, \"SIO_KEEPALIVE_VALS\"):",
            "                # Windows doesn't support TCP_KEEPIDLE, TCP_KEEPCNT, nor",
            "                # TCP_KEEPINTVL. Instead, it has its own proprietary",
            "                # SIO_KEEPALIVE_VALS.",
            "                tcp_keepalive_idle = opts.get(\"tcp_keepalive_idle\", -1)",
            "                tcp_keepalive_intvl = opts.get(\"tcp_keepalive_intvl\", -1)",
            "                # Windows doesn't support changing something equivalent to",
            "                # TCP_KEEPCNT.",
            "                if tcp_keepalive_idle > 0 or tcp_keepalive_intvl > 0:",
            "                    # Windows defaults may be found by using the link below.",
            "                    # Search for 'KeepAliveTime' and 'KeepAliveInterval'.",
            "                    # https://technet.microsoft.com/en-us/library/bb726981.aspx#EDAA",
            "                    # If one value is set and the other isn't, we still need",
            "                    # to send both values to SIO_KEEPALIVE_VALS and they both",
            "                    # need to be valid. So in that case, use the Windows",
            "                    # default.",
            "                    if tcp_keepalive_idle <= 0:",
            "                        tcp_keepalive_idle = 7200",
            "                    if tcp_keepalive_intvl <= 0:",
            "                        tcp_keepalive_intvl = 1",
            "                    # The values expected are in milliseconds, so multiply by",
            "                    # 1000.",
            "                    sock.ioctl(",
            "                        socket.SIO_KEEPALIVE_VALS,",
            "                        (",
            "                            1,",
            "                            int(tcp_keepalive_idle * 1000),",
            "                            int(tcp_keepalive_intvl * 1000),",
            "                        ),",
            "                    )",
            "        else:",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 0)",
            "",
            "",
            "if USE_LOAD_BALANCER:",
            "",
            "    class LoadBalancerServer(SignalHandlingProcess):",
            "        \"\"\"",
            "        Raw TCP server which runs in its own process and will listen",
            "        for incoming connections. Each incoming connection will be",
            "        sent via multiprocessing queue to the workers.",
            "        Since the queue is shared amongst workers, only one worker will",
            "        handle a given connection.",
            "        \"\"\"",
            "",
            "        # TODO: opts!",
            "        # Based on default used in salt.ext.tornado.netutil.bind_sockets()",
            "        backlog = 128",
            "",
            "        def __init__(self, opts, socket_queue, **kwargs):",
            "            super().__init__(**kwargs)",
            "            self.opts = opts",
            "            self.socket_queue = socket_queue",
            "            self._socket = None",
            "",
            "        # __setstate__ and __getstate__ are only used on Windows.",
            "        # We do this so that __init__ will be invoked on Windows in the child",
            "        # process so that a register_after_fork() equivalent will work on",
            "        # Windows.",
            "        def __setstate__(self, state):",
            "            self.__init__(",
            "                state[\"opts\"],",
            "                state[\"socket_queue\"],",
            "                log_queue=state[\"log_queue\"],",
            "                log_queue_level=state[\"log_queue_level\"],",
            "            )",
            "",
            "        def __getstate__(self):",
            "            return {",
            "                \"opts\": self.opts,",
            "                \"socket_queue\": self.socket_queue,",
            "                \"log_queue\": self.log_queue,",
            "                \"log_queue_level\": self.log_queue_level,",
            "            }",
            "",
            "        def close(self):",
            "            if self._socket is not None:",
            "                self._socket.shutdown(socket.SHUT_RDWR)",
            "                self._socket.close()",
            "                self._socket = None",
            "",
            "        # pylint: disable=W1701",
            "        def __del__(self):",
            "            self.close()",
            "",
            "        # pylint: enable=W1701",
            "",
            "        def run(self):",
            "            \"\"\"",
            "            Start the load balancer",
            "            \"\"\"",
            "            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "            _set_tcp_keepalive(self._socket, self.opts)",
            "            self._socket.setblocking(1)",
            "            self._socket.bind((self.opts[\"interface\"], int(self.opts[\"ret_port\"])))",
            "            self._socket.listen(self.backlog)",
            "",
            "            while True:",
            "                try:",
            "                    # Wait for a connection to occur since the socket is",
            "                    # blocking.",
            "                    connection, address = self._socket.accept()",
            "                    # Wait for a free slot to be available to put",
            "                    # the connection into.",
            "                    # Sockets are picklable on Windows in Python 3.",
            "                    self.socket_queue.put((connection, address), True, None)",
            "                except OSError as e:",
            "                    # ECONNABORTED indicates that there was a connection",
            "                    # but it was closed while still in the accept queue.",
            "                    # (observed on FreeBSD).",
            "                    if (",
            "                        salt.ext.tornado.util.errno_from_exception(e)",
            "                        == errno.ECONNABORTED",
            "                    ):",
            "                        continue",
            "                    raise",
            "",
            "",
            "# TODO: move serial down into message library",
            "class AsyncTCPReqChannel(salt.transport.client.ReqChannel):",
            "    \"\"\"",
            "    Encapsulate sending routines to tcp.",
            "",
            "    Note: this class returns a singleton",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    # mapping of io_loop -> {key -> channel}",
            "    instance_map = weakref.WeakKeyDictionary()",
            "    async_methods = [",
            "        \"crypted_transfer_decode_dictentry\",",
            "        \"_crypted_transfer\",",
            "        \"_uncrypted_transfer\",",
            "        \"send\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __new__(cls, opts, **kwargs):",
            "        \"\"\"",
            "        Only create one instance of channel per __key()",
            "        \"\"\"",
            "        # do we have any mapping for this io_loop",
            "        io_loop = kwargs.get(\"io_loop\") or salt.ext.tornado.ioloop.IOLoop.current()",
            "        if io_loop not in cls.instance_map:",
            "            cls.instance_map[io_loop] = weakref.WeakValueDictionary()",
            "        loop_instance_map = cls.instance_map[io_loop]",
            "",
            "        key = cls.__key(opts, **kwargs)",
            "        obj = loop_instance_map.get(key)",
            "        if obj is None:",
            "            log.debug(\"Initializing new AsyncTCPReqChannel for %s\", key)",
            "            # we need to make a local variable for this, as we are going to store",
            "            # it in a WeakValueDictionary-- which will remove the item if no one",
            "            # references it-- this forces a reference while we return to the caller",
            "            obj = object.__new__(cls)",
            "            obj.__singleton_init__(opts, **kwargs)",
            "            obj._instance_key = key",
            "            loop_instance_map[key] = obj",
            "            obj._refcount = 1",
            "            obj._refcount_lock = threading.RLock()",
            "        else:",
            "            with obj._refcount_lock:",
            "                obj._refcount += 1",
            "            log.debug(\"Re-using AsyncTCPReqChannel for %s\", key)",
            "        return obj",
            "",
            "    @classmethod",
            "    def __key(cls, opts, **kwargs):",
            "        if \"master_uri\" in kwargs:",
            "            opts[\"master_uri\"] = kwargs[\"master_uri\"]",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            opts[\"master_uri\"],",
            "            kwargs.get(\"crypt\", \"aes\"),  # TODO: use the same channel for crypt",
            "        )",
            "",
            "    @classmethod",
            "    def force_close_all_instances(cls):",
            "        \"\"\"",
            "        Will force close all instances",
            "        :return: None",
            "        \"\"\"",
            "        for weak_dict in list(cls.instance_map.values()):",
            "            for instance in list(weak_dict.values()):",
            "                instance.close()",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, **kwargs):",
            "        pass",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, **kwargs):",
            "        self.opts = dict(opts)",
            "",
            "        self.serial = salt.payload.Serial(self.opts)",
            "",
            "        # crypt defaults to 'aes'",
            "        self.crypt = kwargs.get(\"crypt\", \"aes\")",
            "",
            "        self.io_loop = kwargs.get(\"io_loop\") or salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        if self.crypt != \"clear\":",
            "            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)",
            "",
            "        resolver = kwargs.get(\"resolver\")",
            "",
            "        parse = urlparse.urlparse(self.opts[\"master_uri\"])",
            "        master_host, master_port = parse.netloc.rsplit(\":\", 1)",
            "        self.master_addr = (master_host, int(master_port))",
            "        self._closing = False",
            "        self.message_client = SaltMessageClientPool(",
            "            self.opts,",
            "            args=(self.opts, master_host, int(master_port),),",
            "            kwargs={",
            "                \"io_loop\": self.io_loop,",
            "                \"resolver\": resolver,",
            "                \"source_ip\": self.opts.get(\"source_ip\"),",
            "                \"source_port\": self.opts.get(\"source_ret_port\"),",
            "            },",
            "        )",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "",
            "        if self._refcount > 1:",
            "            # Decrease refcount",
            "            with self._refcount_lock:",
            "                self._refcount -= 1",
            "            log.debug(",
            "                \"This is not the last %s instance. Not closing yet.\",",
            "                self.__class__.__name__,",
            "            )",
            "            return",
            "",
            "        log.debug(\"Closing %s instance\", self.__class__.__name__)",
            "        self._closing = True",
            "        self.message_client.close()",
            "",
            "        # Remove the entry from the instance map so that a closed entry may not",
            "        # be reused.",
            "        # This forces this operation even if the reference count of the entry",
            "        # has not yet gone to zero.",
            "        if self.io_loop in self.__class__.instance_map:",
            "            loop_instance_map = self.__class__.instance_map[self.io_loop]",
            "            if self._instance_key in loop_instance_map:",
            "                del loop_instance_map[self._instance_key]",
            "            if not loop_instance_map:",
            "                del self.__class__.instance_map[self.io_loop]",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        with self._refcount_lock:",
            "            # Make sure we actually close no matter if something",
            "            # went wrong with our ref counting",
            "            self._refcount = 1",
            "        try:",
            "            self.close()",
            "        except OSError as exc:",
            "            if exc.errno != errno.EBADF:",
            "                # If its not a bad file descriptor error, raise",
            "                raise",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _package_load(self, load):",
            "        return {",
            "            \"enc\": self.crypt,",
            "            \"load\": load,",
            "        }",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def crypted_transfer_decode_dictentry(",
            "        self, load, dictkey=None, tries=3, timeout=60",
            "    ):",
            "        if not self.auth.authenticated:",
            "            yield self.auth.authenticate()",
            "        ret = yield self.message_client.send(",
            "            self._package_load(self.auth.crypticle.dumps(load)),",
            "            timeout=timeout,",
            "            tries=tries,",
            "        )",
            "        key = self.auth.get_keys()",
            "        if HAS_M2:",
            "            aes = key.private_decrypt(ret[\"key\"], RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(key)",
            "            aes = cipher.decrypt(ret[\"key\"])",
            "        pcrypt = salt.crypt.Crypticle(self.opts, aes)",
            "        data = pcrypt.loads(ret[dictkey])",
            "        data = salt.transport.frame.decode_embedded_strs(data)",
            "        raise salt.ext.tornado.gen.Return(data)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _crypted_transfer(self, load, tries=3, timeout=60):",
            "        \"\"\"",
            "        In case of authentication errors, try to renegotiate authentication",
            "        and retry the method.",
            "        Indeed, we can fail too early in case of a master restart during a",
            "        minion state execution call",
            "        \"\"\"",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def _do_transfer():",
            "            data = yield self.message_client.send(",
            "                self._package_load(self.auth.crypticle.dumps(load)),",
            "                timeout=timeout,",
            "                tries=tries,",
            "            )",
            "            # we may not have always data",
            "            # as for example for saltcall ret submission, this is a blind",
            "            # communication, we do not subscribe to return events, we just",
            "            # upload the results to the master",
            "            if data:",
            "                data = self.auth.crypticle.loads(data)",
            "                data = salt.transport.frame.decode_embedded_strs(data)",
            "            raise salt.ext.tornado.gen.Return(data)",
            "",
            "        if not self.auth.authenticated:",
            "            yield self.auth.authenticate()",
            "        try:",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "        except salt.crypt.AuthenticationError:",
            "            yield self.auth.authenticate()",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _uncrypted_transfer(self, load, tries=3, timeout=60):",
            "        ret = yield self.message_client.send(",
            "            self._package_load(load), timeout=timeout, tries=tries,",
            "        )",
            "",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def send(self, load, tries=3, timeout=60, raw=False):",
            "        \"\"\"",
            "        Send a request, return a future which will complete when we send the message",
            "        \"\"\"",
            "        try:",
            "            if self.crypt == \"clear\":",
            "                ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)",
            "            else:",
            "                ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout)",
            "        except salt.ext.tornado.iostream.StreamClosedError:",
            "            # Convert to 'SaltClientError' so that clients can handle this",
            "            # exception more appropriately.",
            "            raise SaltClientError(\"Connection to master lost\")",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "",
            "class AsyncTCPPubChannel(",
            "    salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel",
            "):",
            "    async_methods = [",
            "        \"send_id\",",
            "        \"connect_callback\",",
            "        \"connect\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __init__(self, opts, **kwargs):",
            "        self.opts = opts",
            "",
            "        self.serial = salt.payload.Serial(self.opts)",
            "",
            "        self.crypt = kwargs.get(\"crypt\", \"aes\")",
            "        self.io_loop = kwargs.get(\"io_loop\") or salt.ext.tornado.ioloop.IOLoop.current()",
            "        self.connected = False",
            "        self._closing = False",
            "        self._reconnected = False",
            "        self.message_client = None",
            "        self.event = salt.utils.event.get_event(\"minion\", opts=self.opts, listen=False)",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if self.message_client is not None:",
            "            self.message_client.close()",
            "            self.message_client = None",
            "        if self.event is not None:",
            "            self.event.destroy()",
            "            self.event = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _package_load(self, load):",
            "        return {",
            "            \"enc\": self.crypt,",
            "            \"load\": load,",
            "        }",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def send_id(self, tok, force_auth):",
            "        \"\"\"",
            "        Send the minion id to the master so that the master may better",
            "        track the connection state of the minion.",
            "        In case of authentication errors, try to renegotiate authentication",
            "        and retry the method.",
            "        \"\"\"",
            "        load = {\"id\": self.opts[\"id\"], \"tok\": tok}",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def _do_transfer():",
            "            msg = self._package_load(self.auth.crypticle.dumps(load))",
            "            package = salt.transport.frame.frame_msg(msg, header=None)",
            "            yield self.message_client.write_to_stream(package)",
            "            raise salt.ext.tornado.gen.Return(True)",
            "",
            "        if force_auth or not self.auth.authenticated:",
            "            count = 0",
            "            while (",
            "                count <= self.opts[\"tcp_authentication_retries\"]",
            "                or self.opts[\"tcp_authentication_retries\"] < 0",
            "            ):",
            "                try:",
            "                    yield self.auth.authenticate()",
            "                    break",
            "                except SaltClientError as exc:",
            "                    log.debug(exc)",
            "                    count += 1",
            "        try:",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "        except salt.crypt.AuthenticationError:",
            "            yield self.auth.authenticate()",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect_callback(self, result):",
            "        if self._closing:",
            "            return",
            "        # Force re-auth on reconnect since the master",
            "        # may have been restarted",
            "        yield self.send_id(self.tok, self._reconnected)",
            "        self.connected = True",
            "        self.event.fire_event({\"master\": self.opts[\"master\"]}, \"__master_connected\")",
            "        if self._reconnected:",
            "            # On reconnects, fire a master event to notify that the minion is",
            "            # available.",
            "            if self.opts.get(\"__role\") == \"syndic\":",
            "                data = \"Syndic {} started at {}\".format(self.opts[\"id\"], time.asctime())",
            "                tag = salt.utils.event.tagify([self.opts[\"id\"], \"start\"], \"syndic\")",
            "            else:",
            "                data = \"Minion {} started at {}\".format(self.opts[\"id\"], time.asctime())",
            "                tag = salt.utils.event.tagify([self.opts[\"id\"], \"start\"], \"minion\")",
            "            load = {",
            "                \"id\": self.opts[\"id\"],",
            "                \"cmd\": \"_minion_event\",",
            "                \"pretag\": None,",
            "                \"tok\": self.tok,",
            "                \"data\": data,",
            "                \"tag\": tag,",
            "            }",
            "            req_channel = salt.utils.asynchronous.SyncWrapper(",
            "                AsyncTCPReqChannel, (self.opts,), loop_kwarg=\"io_loop\",",
            "            )",
            "            try:",
            "                req_channel.send(load, timeout=60)",
            "            except salt.exceptions.SaltReqTimeoutError:",
            "                log.info(",
            "                    \"fire_master failed: master could not be contacted. Request timed out.\"",
            "                )",
            "            except Exception:  # pylint: disable=broad-except",
            "                log.info(\"fire_master failed: %s\", traceback.format_exc())",
            "            finally:",
            "                # SyncWrapper will call either close() or destroy(), whichever is available",
            "                del req_channel",
            "        else:",
            "            self._reconnected = True",
            "",
            "    def disconnect_callback(self):",
            "        if self._closing:",
            "            return",
            "        self.connected = False",
            "        self.event.fire_event({\"master\": self.opts[\"master\"]}, \"__master_disconnected\")",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect(self):",
            "        try:",
            "            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)",
            "            self.tok = self.auth.gen_token(b\"salt\")",
            "            if not self.auth.authenticated:",
            "                yield self.auth.authenticate()",
            "            if self.auth.authenticated:",
            "                # if this is changed from the default, we assume it was intentional",
            "                if int(self.opts.get(\"publish_port\", 4505)) != 4505:",
            "                    self.publish_port = self.opts.get(\"publish_port\")",
            "                # else take the relayed publish_port master reports",
            "                else:",
            "                    self.publish_port = self.auth.creds[\"publish_port\"]",
            "",
            "                self.message_client = SaltMessageClientPool(",
            "                    self.opts,",
            "                    args=(self.opts, self.opts[\"master_ip\"], int(self.publish_port)),",
            "                    kwargs={",
            "                        \"io_loop\": self.io_loop,",
            "                        \"connect_callback\": self.connect_callback,",
            "                        \"disconnect_callback\": self.disconnect_callback,",
            "                        \"source_ip\": self.opts.get(\"source_ip\"),",
            "                        \"source_port\": self.opts.get(\"source_publish_port\"),",
            "                    },",
            "                )",
            "                yield self.message_client.connect()  # wait for the client to be connected",
            "                self.connected = True",
            "        # TODO: better exception handling...",
            "        except KeyboardInterrupt:  # pylint: disable=try-except-raise",
            "            raise",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            if \"-|RETRY|-\" not in str(exc):",
            "                raise SaltClientError(",
            "                    \"Unable to sign_in to master: {}\".format(exc)",
            "                )  # TODO: better error message",
            "",
            "    def on_recv(self, callback):",
            "        \"\"\"",
            "        Register an on_recv callback",
            "        \"\"\"",
            "        if callback is None:",
            "            return self.message_client.on_recv(callback)",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def wrap_callback(body):",
            "            if not isinstance(body, dict):",
            "                # TODO: For some reason we need to decode here for things",
            "                #       to work. Fix this.",
            "                body = salt.utils.msgpack.loads(body)",
            "                body = salt.transport.frame.decode_embedded_strs(body)",
            "            ret = yield self._decode_payload(body)",
            "            callback(ret)",
            "",
            "        return self.message_client.on_recv(wrap_callback)",
            "",
            "",
            "class TCPReqServerChannel(",
            "    salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel",
            "):",
            "    # TODO: opts!",
            "    backlog = 5",
            "",
            "    def __init__(self, opts):",
            "        salt.transport.server.ReqServerChannel.__init__(self, opts)",
            "        self._socket = None",
            "        self.req_server = None",
            "",
            "    @property",
            "    def socket(self):",
            "        return self._socket",
            "",
            "    def close(self):",
            "        if self._socket is not None:",
            "            try:",
            "                self._socket.shutdown(socket.SHUT_RDWR)",
            "            except OSError as exc:",
            "                if exc.errno == errno.ENOTCONN:",
            "                    # We may try to shutdown a socket which is already disconnected.",
            "                    # Ignore this condition and continue.",
            "                    pass",
            "                else:",
            "                    raise",
            "            if self.req_server is None:",
            "                # We only close the socket if we don't have a req_server instance.",
            "                # If we did, because the req_server is also handling this socket, when we call",
            "                # req_server.stop(), tornado will give us an AssertionError because it's trying to",
            "                # match the socket.fileno() (after close it's -1) to the fd it holds on it's _sockets cache",
            "                # so it can remove the socket from the IOLoop handlers",
            "                self._socket.close()",
            "            self._socket = None",
            "        if self.req_server is not None:",
            "            try:",
            "                self.req_server.close()",
            "            except OSError as exc:",
            "                if exc.errno != 9:",
            "                    raise",
            "                log.exception(",
            "                    \"TCPReqServerChannel close generated an exception: %s\", str(exc)",
            "                )",
            "            self.req_server = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    def pre_fork(self, process_manager):",
            "        \"\"\"",
            "        Pre-fork we need to create the zmq router device",
            "        \"\"\"",
            "        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)",
            "        if USE_LOAD_BALANCER:",
            "            self.socket_queue = multiprocessing.Queue()",
            "            process_manager.add_process(",
            "                LoadBalancerServer, args=(self.opts, self.socket_queue)",
            "            )",
            "        elif not salt.utils.platform.is_windows():",
            "            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "            _set_tcp_keepalive(self._socket, self.opts)",
            "            self._socket.setblocking(0)",
            "            self._socket.bind((self.opts[\"interface\"], int(self.opts[\"ret_port\"])))",
            "",
            "    def post_fork(self, payload_handler, io_loop):",
            "        \"\"\"",
            "        After forking we need to create all of the local sockets to listen to the",
            "        router",
            "",
            "        payload_handler: function to call with your payloads",
            "        \"\"\"",
            "        if self.opts[\"pub_server_niceness\"] and not salt.utils.platform.is_windows():",
            "            log.info(",
            "                \"setting Publish daemon niceness to %i\",",
            "                self.opts[\"pub_server_niceness\"],",
            "            )",
            "            os.nice(self.opts[\"pub_server_niceness\"])",
            "",
            "        self.payload_handler = payload_handler",
            "        self.io_loop = io_loop",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        with salt.utils.asynchronous.current_ioloop(self.io_loop):",
            "            if USE_LOAD_BALANCER:",
            "                self.req_server = LoadBalancerWorker(",
            "                    self.socket_queue,",
            "                    self.handle_message,",
            "                    ssl_options=self.opts.get(\"ssl\"),",
            "                )",
            "            else:",
            "                if salt.utils.platform.is_windows():",
            "                    self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "                    self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "                    _set_tcp_keepalive(self._socket, self.opts)",
            "                    self._socket.setblocking(0)",
            "                    self._socket.bind(",
            "                        (self.opts[\"interface\"], int(self.opts[\"ret_port\"]))",
            "                    )",
            "                self.req_server = SaltMessageServer(",
            "                    self.handle_message,",
            "                    ssl_options=self.opts.get(\"ssl\"),",
            "                    io_loop=self.io_loop,",
            "                )",
            "                self.req_server.add_socket(self._socket)",
            "                self._socket.listen(self.backlog)",
            "        salt.transport.mixins.auth.AESReqServerMixin.post_fork(",
            "            self, payload_handler, io_loop",
            "        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def handle_message(self, stream, header, payload):",
            "        \"\"\"",
            "        Handle incoming messages from underlying tcp streams",
            "        \"\"\"",
            "        try:",
            "            try:",
            "                payload = self._decode_payload(payload)",
            "            except Exception:  # pylint: disable=broad-except",
            "                stream.write(salt.transport.frame.frame_msg(\"bad load\", header=header))",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            # TODO helper functions to normalize payload?",
            "            if not isinstance(payload, dict) or not isinstance(",
            "                payload.get(\"load\"), dict",
            "            ):",
            "                yield stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        \"payload and load must be a dict\", header=header",
            "                    )",
            "                )",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            try:",
            "                id_ = payload[\"load\"].get(\"id\", \"\")",
            "                if \"\\0\" in id_:",
            "                    log.error(\"Payload contains an id with a null byte: %s\", payload)",
            "                    stream.send(self.serial.dumps(\"bad load: id contains a null byte\"))",
            "                    raise salt.ext.tornado.gen.Return()",
            "            except TypeError:",
            "                log.error(\"Payload contains non-string id: %s\", payload)",
            "                stream.send(",
            "                    self.serial.dumps(\"bad load: id {} is not a string\".format(id_))",
            "                )",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            # intercept the \"_auth\" commands, since the main daemon shouldn't know",
            "            # anything about our key auth",
            "            if (",
            "                payload[\"enc\"] == \"clear\"",
            "                and payload.get(\"load\", {}).get(\"cmd\") == \"_auth\"",
            "            ):",
            "                yield stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        self._auth(payload[\"load\"]), header=header",
            "                    )",
            "                )",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            # TODO: test",
            "            try:",
            "                ret, req_opts = yield self.payload_handler(payload)",
            "            except Exception as e:  # pylint: disable=broad-except",
            "                # always attempt to return an error to the minion",
            "                stream.write(\"Some exception handling minion payload\")",
            "                log.error(",
            "                    \"Some exception handling a payload from minion\", exc_info=True",
            "                )",
            "                stream.close()",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            req_fun = req_opts.get(\"fun\", \"send\")",
            "            if req_fun == \"send_clear\":",
            "                stream.write(salt.transport.frame.frame_msg(ret, header=header))",
            "            elif req_fun == \"send\":",
            "                stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        self.crypticle.dumps(ret), header=header",
            "                    )",
            "                )",
            "            elif req_fun == \"send_private\":",
            "                stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        self._encrypt_private(ret, req_opts[\"key\"], req_opts[\"tgt\"],),",
            "                        header=header,",
            "                    )",
            "                )",
            "            else:",
            "                log.error(\"Unknown req_fun %s\", req_fun)",
            "                # always attempt to return an error to the minion",
            "                stream.write(\"Server-side exception handling payload\")",
            "                stream.close()",
            "        except salt.ext.tornado.gen.Return:",
            "            raise",
            "        except salt.ext.tornado.iostream.StreamClosedError:",
            "            # Stream was closed. This could happen if the remote side",
            "            # closed the connection on its end (eg in a timeout or shutdown",
            "            # situation).",
            "            log.error(\"Connection was unexpectedly closed\", exc_info=True)",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            # Absorb any other exceptions",
            "            log.error(\"Unexpected exception occurred: %s\", exc, exc_info=True)",
            "",
            "        raise salt.ext.tornado.gen.Return()",
            "",
            "",
            "class SaltMessageServer(salt.ext.tornado.tcpserver.TCPServer):",
            "    \"\"\"",
            "    Raw TCP server which will receive all of the TCP streams and re-assemble",
            "    messages that are sent through to us",
            "    \"\"\"",
            "",
            "    def __init__(self, message_handler, *args, **kwargs):",
            "        io_loop = (",
            "            kwargs.pop(\"io_loop\", None) or salt.ext.tornado.ioloop.IOLoop.current()",
            "        )",
            "        self._closing = False",
            "        super().__init__(*args, **kwargs)",
            "        self.io_loop = io_loop",
            "        self.clients = []",
            "        self.message_handler = message_handler",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def handle_stream(self, stream, address):",
            "        \"\"\"",
            "        Handle incoming streams and add messages to the incoming queue",
            "        \"\"\"",
            "        log.trace(\"Req client %s connected\", address)",
            "        self.clients.append((stream, address))",
            "        unpacker = salt.utils.msgpack.Unpacker()",
            "        try:",
            "            while True:",
            "                wire_bytes = yield stream.read_bytes(4096, partial=True)",
            "                unpacker.feed(wire_bytes)",
            "                for framed_msg in unpacker:",
            "                    framed_msg = salt.transport.frame.decode_embedded_strs(framed_msg)",
            "                    header = framed_msg[\"head\"]",
            "                    self.io_loop.spawn_callback(",
            "                        self.message_handler, stream, header, framed_msg[\"body\"]",
            "                    )",
            "        except salt.ext.tornado.iostream.StreamClosedError:",
            "            log.trace(\"req client disconnected %s\", address)",
            "            self.remove_client((stream, address))",
            "        except Exception as e:  # pylint: disable=broad-except",
            "            log.trace(\"other master-side exception: %s\", e)",
            "            self.remove_client((stream, address))",
            "            stream.close()",
            "",
            "    def remove_client(self, client):",
            "        try:",
            "            self.clients.remove(client)",
            "        except ValueError:",
            "            log.trace(\"Message server client was not in list to remove\")",
            "",
            "    def shutdown(self):",
            "        \"\"\"",
            "        Shutdown the whole server",
            "        \"\"\"",
            "        salt.utils.versions.warn_until(",
            "            \"Phosphorus\",",
            "            \"Please stop calling {0}.{1}.shutdown() and instead call {0}.{1}.close()\".format(",
            "                __name__, self.__class__.__name__",
            "            ),",
            "        )",
            "        self.close()",
            "",
            "    def close(self):",
            "        \"\"\"",
            "        Close the server",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        for item in self.clients:",
            "            client, address = item",
            "            client.close()",
            "            self.remove_client(item)",
            "        try:",
            "            self.stop()",
            "        except OSError as exc:",
            "            if exc.errno != 9:",
            "                raise",
            "",
            "",
            "if USE_LOAD_BALANCER:",
            "",
            "    class LoadBalancerWorker(SaltMessageServer):",
            "        \"\"\"",
            "        This will receive TCP connections from 'LoadBalancerServer' via",
            "        a multiprocessing queue.",
            "        Since the queue is shared amongst workers, only one worker will handle",
            "        a given connection.",
            "        \"\"\"",
            "",
            "        def __init__(self, socket_queue, message_handler, *args, **kwargs):",
            "            super().__init__(message_handler, *args, **kwargs)",
            "            self.socket_queue = socket_queue",
            "            self._stop = threading.Event()",
            "            self.thread = threading.Thread(target=self.socket_queue_thread)",
            "            self.thread.start()",
            "",
            "        def stop(self):",
            "            salt.utils.versions.warn_until(",
            "                \"Phosphorus\",",
            "                \"Please stop calling {0}.{1}.stop() and instead call {0}.{1}.close()\".format(",
            "                    __name__, self.__class__.__name__",
            "                ),",
            "            )",
            "            self.close()",
            "",
            "        def close(self):",
            "            self._stop.set()",
            "            self.thread.join()",
            "            super().close()",
            "",
            "        def socket_queue_thread(self):",
            "            try:",
            "                while True:",
            "                    try:",
            "                        client_socket, address = self.socket_queue.get(True, 1)",
            "                    except queue.Empty:",
            "                        if self._stop.is_set():",
            "                            break",
            "                        continue",
            "                    # 'self.io_loop' initialized in super class",
            "                    # 'salt.ext.tornado.tcpserver.TCPServer'.",
            "                    # 'self._handle_connection' defined in same super class.",
            "                    self.io_loop.spawn_callback(",
            "                        self._handle_connection, client_socket, address",
            "                    )",
            "            except (KeyboardInterrupt, SystemExit):",
            "                pass",
            "",
            "",
            "class TCPClientKeepAlive(salt.ext.tornado.tcpclient.TCPClient):",
            "    \"\"\"",
            "    Override _create_stream() in TCPClient to enable keep alive support.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, resolver=None):",
            "        self.opts = opts",
            "        super().__init__(resolver=resolver)",
            "",
            "    def _create_stream(",
            "        self, max_buffer_size, af, addr, **kwargs",
            "    ):  # pylint: disable=unused-argument,arguments-differ",
            "        \"\"\"",
            "        Override _create_stream() in TCPClient.",
            "",
            "        Tornado 4.5 added the kwargs 'source_ip' and 'source_port'.",
            "        Due to this, use **kwargs to swallow these and any future",
            "        kwargs to maintain compatibility.",
            "        \"\"\"",
            "        # Always connect in plaintext; we'll convert to ssl if necessary",
            "        # after one connection has completed.",
            "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "        _set_tcp_keepalive(sock, self.opts)",
            "        stream = salt.ext.tornado.iostream.IOStream(",
            "            sock, max_buffer_size=max_buffer_size",
            "        )",
            "        if salt.ext.tornado.version_info < (5,):",
            "            return stream.connect(addr)",
            "        return stream, stream.connect(addr)",
            "",
            "",
            "class SaltMessageClientPool(salt.transport.MessageClientPool):",
            "    \"\"\"",
            "    Wrapper class of SaltMessageClient to avoid blocking waiting while writing data to socket.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, args=None, kwargs=None):",
            "        super().__init__(SaltMessageClient, opts, args=args, kwargs=kwargs)",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def close(self):",
            "        for message_client in self.message_clients:",
            "            message_client.close()",
            "        self.message_clients = []",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect(self):",
            "        futures = []",
            "        for message_client in self.message_clients:",
            "            futures.append(message_client.connect())",
            "        yield futures",
            "        raise salt.ext.tornado.gen.Return(None)",
            "",
            "    def on_recv(self, *args, **kwargs):",
            "        for message_client in self.message_clients:",
            "            message_client.on_recv(*args, **kwargs)",
            "",
            "    def send(self, *args, **kwargs):",
            "        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))",
            "        return message_clients[0].send(*args, **kwargs)",
            "",
            "    def write_to_stream(self, *args, **kwargs):",
            "        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))",
            "        return message_clients[0]._stream.write(*args, **kwargs)",
            "",
            "",
            "# TODO consolidate with IPCClient",
            "# TODO: limit in-flight messages.",
            "# TODO: singleton? Something to not re-create the tcp connection so much",
            "class SaltMessageClient:",
            "    \"\"\"",
            "    Low-level message sending client",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        host,",
            "        port,",
            "        io_loop=None,",
            "        resolver=None,",
            "        connect_callback=None,",
            "        disconnect_callback=None,",
            "        source_ip=None,",
            "        source_port=None,",
            "    ):",
            "        self.opts = opts",
            "        self.host = host",
            "        self.port = port",
            "        self.source_ip = source_ip",
            "        self.source_port = source_port",
            "        self.connect_callback = connect_callback",
            "        self.disconnect_callback = disconnect_callback",
            "",
            "        self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        with salt.utils.asynchronous.current_ioloop(self.io_loop):",
            "            self._tcp_client = TCPClientKeepAlive(opts, resolver=resolver)",
            "",
            "        self._mid = 1",
            "        self._max_messages = int((1 << 31) - 2)  # number of IDs before we wrap",
            "",
            "        # TODO: max queue size",
            "        self.send_queue = []  # queue of messages to be sent",
            "        self.send_future_map = {}  # mapping of request_id -> Future",
            "        self.send_timeout_map = {}  # request_id -> timeout_callback",
            "",
            "        self._read_until_future = None",
            "        self._on_recv = None",
            "        self._closing = False",
            "        self._connecting_future = self.connect()",
            "        self._stream_return_future = salt.ext.tornado.concurrent.Future()",
            "        self.io_loop.spawn_callback(self._stream_return)",
            "",
            "        self.backoff = opts.get(\"tcp_reconnect_backoff\", 1)",
            "",
            "    def _stop_io_loop(self):",
            "        if self.io_loop is not None:",
            "            self.io_loop.stop()",
            "",
            "    # TODO: timeout inflight sessions",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if hasattr(self, \"_stream\") and not self._stream.closed():",
            "            # If _stream_return() hasn't completed, it means the IO",
            "            # Loop is stopped (such as when using",
            "            # 'salt.utils.asynchronous.SyncWrapper'). Ensure that",
            "            # _stream_return() completes by restarting the IO Loop.",
            "            # This will prevent potential errors on shutdown.",
            "            try:",
            "                orig_loop = salt.ext.tornado.ioloop.IOLoop.current()",
            "                self.io_loop.make_current()",
            "                self._stream.close()",
            "                if self._read_until_future is not None:",
            "                    # This will prevent this message from showing up:",
            "                    # '[ERROR   ] Future exception was never retrieved:",
            "                    # StreamClosedError'",
            "                    # This happens because the logic is always waiting to read",
            "                    # the next message and the associated read future is marked",
            "                    # 'StreamClosedError' when the stream is closed.",
            "                    if self._read_until_future.done():",
            "                        self._read_until_future.exception()",
            "                    if (",
            "                        self.io_loop",
            "                        != salt.ext.tornado.ioloop.IOLoop.current(instance=False)",
            "                        or not self._stream_return_future.done()",
            "                    ):",
            "                        self.io_loop.add_future(",
            "                            self._stream_return_future,",
            "                            lambda future: self._stop_io_loop(),",
            "                        )",
            "                        self.io_loop.start()",
            "            except Exception as e:  # pylint: disable=broad-except",
            "                log.info(\"Exception caught in SaltMessageClient.close: %s\", str(e))",
            "            finally:",
            "                orig_loop.make_current()",
            "        self._tcp_client.close()",
            "        self.io_loop = None",
            "        self._read_until_future = None",
            "        # Clear callback references to allow the object that they belong to",
            "        # to be deleted.",
            "        self.connect_callback = None",
            "        self.disconnect_callback = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def connect(self):",
            "        \"\"\"",
            "        Ask for this client to reconnect to the origin",
            "        \"\"\"",
            "        if hasattr(self, \"_connecting_future\") and not self._connecting_future.done():",
            "            future = self._connecting_future",
            "        else:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            self._connecting_future = future",
            "            self.io_loop.add_callback(self._connect)",
            "",
            "            # Add the callback only when a new future is created",
            "            if self.connect_callback is not None:",
            "",
            "                def handle_future(future):",
            "                    response = future.result()",
            "                    self.io_loop.add_callback(self.connect_callback, response)",
            "",
            "                future.add_done_callback(handle_future)",
            "",
            "        return future",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _connect(self):",
            "        \"\"\"",
            "        Try to connect for the rest of time!",
            "        \"\"\"",
            "        while True:",
            "            if self._closing:",
            "                break",
            "            try:",
            "                kwargs = {}",
            "                if self.source_ip or self.source_port:",
            "                    if salt.ext.tornado.version_info >= (4, 5):",
            "                        ### source_ip and source_port are supported only in Tornado >= 4.5",
            "                        # See http://www.tornadoweb.org/en/stable/releases/v4.5.0.html",
            "                        # Otherwise will just ignore these args",
            "                        kwargs = {",
            "                            \"source_ip\": self.source_ip,",
            "                            \"source_port\": self.source_port,",
            "                        }",
            "                    else:",
            "                        log.warning(",
            "                            \"If you need a certain source IP/port, consider upgrading Tornado >= 4.5\"",
            "                        )",
            "                with salt.utils.asynchronous.current_ioloop(self.io_loop):",
            "                    self._stream = yield self._tcp_client.connect(",
            "                        self.host, self.port, ssl_options=self.opts.get(\"ssl\"), **kwargs",
            "                    )",
            "                self._connecting_future.set_result(True)",
            "                break",
            "            except Exception as exc:  # pylint: disable=broad-except",
            "                log.warning(",
            "                    \"TCP Message Client encountered an exception while connecting to %s:%s: %r, will reconnect in %d seconds\",",
            "                    self.host,",
            "                    self.port,",
            "                    exc,",
            "                    self.backoff,",
            "                )",
            "                yield salt.ext.tornado.gen.sleep(self.backoff)",
            "                # self._connecting_future.set_exception(exc)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _stream_return(self):",
            "        try:",
            "            while not self._closing and (",
            "                not self._connecting_future.done()",
            "                or self._connecting_future.result() is not True",
            "            ):",
            "                yield self._connecting_future",
            "            unpacker = salt.utils.msgpack.Unpacker()",
            "            while not self._closing:",
            "                try:",
            "                    self._read_until_future = self._stream.read_bytes(",
            "                        4096, partial=True",
            "                    )",
            "                    wire_bytes = yield self._read_until_future",
            "                    unpacker.feed(wire_bytes)",
            "                    for framed_msg in unpacker:",
            "                        framed_msg = salt.transport.frame.decode_embedded_strs(",
            "                            framed_msg",
            "                        )",
            "                        header = framed_msg[\"head\"]",
            "                        body = framed_msg[\"body\"]",
            "                        message_id = header.get(\"mid\")",
            "",
            "                        if message_id in self.send_future_map:",
            "                            self.send_future_map.pop(message_id).set_result(body)",
            "                            self.remove_message_timeout(message_id)",
            "                        else:",
            "                            if self._on_recv is not None:",
            "                                self.io_loop.spawn_callback(self._on_recv, header, body)",
            "                            else:",
            "                                log.error(",
            "                                    \"Got response for message_id %s that we are not tracking\",",
            "                                    message_id,",
            "                                )",
            "                except salt.ext.tornado.iostream.StreamClosedError as e:",
            "                    log.debug(",
            "                        \"tcp stream to %s:%s closed, unable to recv\",",
            "                        self.host,",
            "                        self.port,",
            "                    )",
            "                    for future in self.send_future_map.values():",
            "                        future.set_exception(e)",
            "                    self.send_future_map = {}",
            "                    if self._closing:",
            "                        return",
            "                    if self.disconnect_callback:",
            "                        self.disconnect_callback()",
            "                    # if the last connect finished, then we need to make a new one",
            "                    if self._connecting_future.done():",
            "                        self._connecting_future = self.connect()",
            "                    yield self._connecting_future",
            "                except TypeError:",
            "                    # This is an invalid transport",
            "                    if \"detect_mode\" in self.opts:",
            "                        log.info(",
            "                            \"There was an error trying to use TCP transport; \"",
            "                            \"attempting to fallback to another transport\"",
            "                        )",
            "                    else:",
            "                        raise SaltClientError",
            "                except Exception as e:  # pylint: disable=broad-except",
            "                    log.error(\"Exception parsing response\", exc_info=True)",
            "                    for future in self.send_future_map.values():",
            "                        future.set_exception(e)",
            "                    self.send_future_map = {}",
            "                    if self._closing:",
            "                        return",
            "                    if self.disconnect_callback:",
            "                        self.disconnect_callback()",
            "                    # if the last connect finished, then we need to make a new one",
            "                    if self._connecting_future.done():",
            "                        self._connecting_future = self.connect()",
            "                    yield self._connecting_future",
            "        finally:",
            "            self._stream_return_future.set_result(True)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _stream_send(self):",
            "        while (",
            "            not self._connecting_future.done()",
            "            or self._connecting_future.result() is not True",
            "        ):",
            "            yield self._connecting_future",
            "        while len(self.send_queue) > 0:",
            "            message_id, item = self.send_queue[0]",
            "            try:",
            "                yield self._stream.write(item)",
            "                del self.send_queue[0]",
            "            # if the connection is dead, lets fail this send, and make sure we",
            "            # attempt to reconnect",
            "            except salt.ext.tornado.iostream.StreamClosedError as e:",
            "                if message_id in self.send_future_map:",
            "                    self.send_future_map.pop(message_id).set_exception(e)",
            "                self.remove_message_timeout(message_id)",
            "                del self.send_queue[0]",
            "                if self._closing:",
            "                    return",
            "                if self.disconnect_callback:",
            "                    self.disconnect_callback()",
            "                # if the last connect finished, then we need to make a new one",
            "                if self._connecting_future.done():",
            "                    self._connecting_future = self.connect()",
            "                yield self._connecting_future",
            "",
            "    def _message_id(self):",
            "        wrap = False",
            "        while self._mid in self.send_future_map:",
            "            if self._mid >= self._max_messages:",
            "                if wrap:",
            "                    # this shouldn't ever happen, but just in case",
            "                    raise Exception(\"Unable to find available messageid\")",
            "                self._mid = 1",
            "                wrap = True",
            "            else:",
            "                self._mid += 1",
            "",
            "        return self._mid",
            "",
            "    # TODO: return a message object which takes care of multiplexing?",
            "    def on_recv(self, callback):",
            "        \"\"\"",
            "        Register a callback for received messages (that we didn't initiate)",
            "        \"\"\"",
            "        if callback is None:",
            "            self._on_recv = callback",
            "        else:",
            "",
            "            def wrap_recv(header, body):",
            "                callback(body)",
            "",
            "            self._on_recv = wrap_recv",
            "",
            "    def remove_message_timeout(self, message_id):",
            "        if message_id not in self.send_timeout_map:",
            "            return",
            "        timeout = self.send_timeout_map.pop(message_id)",
            "        self.io_loop.remove_timeout(timeout)",
            "",
            "    def timeout_message(self, message_id, msg):",
            "        if message_id in self.send_timeout_map:",
            "            del self.send_timeout_map[message_id]",
            "        if message_id in self.send_future_map:",
            "            future = self.send_future_map.pop(message_id)",
            "            # In a race condition the message might have been sent by the time",
            "            # we're timing it out. Make sure the future is not None",
            "            if future is not None:",
            "                if future.attempts < future.tries:",
            "                    future.attempts += 1",
            "",
            "                    log.debug(",
            "                        \"SaltReqTimeoutError, retrying. (%s/%s)\",",
            "                        future.attempts,",
            "                        future.tries,",
            "                    )",
            "                    self.send(",
            "                        msg, timeout=future.timeout, tries=future.tries, future=future,",
            "                    )",
            "",
            "                else:",
            "                    future.set_exception(SaltReqTimeoutError(\"Message timed out\"))",
            "",
            "    def send(self, msg, timeout=None, callback=None, raw=False, future=None, tries=3):",
            "        \"\"\"",
            "        Send given message, and return a future",
            "        \"\"\"",
            "        message_id = self._message_id()",
            "        header = {\"mid\": message_id}",
            "",
            "        if future is None:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            future.tries = tries",
            "            future.attempts = 0",
            "            future.timeout = timeout",
            "",
            "        if callback is not None:",
            "",
            "            def handle_future(future):",
            "                response = future.result()",
            "                self.io_loop.add_callback(callback, response)",
            "",
            "            future.add_done_callback(handle_future)",
            "        # Add this future to the mapping",
            "        self.send_future_map[message_id] = future",
            "",
            "        if self.opts.get(\"detect_mode\") is True:",
            "            timeout = 1",
            "",
            "        if timeout is not None:",
            "            send_timeout = self.io_loop.call_later(",
            "                timeout, self.timeout_message, message_id, msg",
            "            )",
            "            self.send_timeout_map[message_id] = send_timeout",
            "",
            "        # if we don't have a send queue, we need to spawn the callback to do the sending",
            "        if len(self.send_queue) == 0:",
            "            self.io_loop.spawn_callback(self._stream_send)",
            "        self.send_queue.append(",
            "            (message_id, salt.transport.frame.frame_msg(msg, header=header))",
            "        )",
            "        return future",
            "",
            "",
            "class Subscriber:",
            "    \"\"\"",
            "    Client object for use with the TCP publisher server",
            "    \"\"\"",
            "",
            "    def __init__(self, stream, address):",
            "        self.stream = stream",
            "        self.address = address",
            "        self._closing = False",
            "        self._read_until_future = None",
            "        self.id_ = None",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if not self.stream.closed():",
            "            self.stream.close()",
            "            if self._read_until_future is not None and self._read_until_future.done():",
            "                # This will prevent this message from showing up:",
            "                # '[ERROR   ] Future exception was never retrieved:",
            "                # StreamClosedError'",
            "                # This happens because the logic is always waiting to read",
            "                # the next message and the associated read future is marked",
            "                # 'StreamClosedError' when the stream is closed.",
            "                self._read_until_future.exception()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "class PubServer(salt.ext.tornado.tcpserver.TCPServer):",
            "    \"\"\"",
            "    TCP publisher",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, io_loop=None):",
            "        super().__init__(ssl_options=opts.get(\"ssl\"))",
            "        self.io_loop = io_loop",
            "        self.opts = opts",
            "        self._closing = False",
            "        self.clients = set()",
            "        self.aes_funcs = salt.master.AESFuncs(self.opts)",
            "        self.present = {}",
            "        self.event = None",
            "        self.presence_events = False",
            "        if self.opts.get(\"presence_events\", False):",
            "            tcp_only = True",
            "            for transport, _ in iter_transport_opts(self.opts):",
            "                if transport != \"tcp\":",
            "                    tcp_only = False",
            "            if tcp_only:",
            "                # Only when the transport is TCP only, the presence events will",
            "                # be handled here. Otherwise, it will be handled in the",
            "                # 'Maintenance' process.",
            "                self.presence_events = True",
            "",
            "        if self.presence_events:",
            "            self.event = salt.utils.event.get_event(",
            "                \"master\", opts=self.opts, listen=False",
            "            )",
            "        else:",
            "            self.event = None",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if self.event is not None:",
            "            self.event.destroy()",
            "            self.event = None",
            "        if self.aes_funcs is not None:",
            "            self.aes_funcs.destroy()",
            "            self.aes_funcs = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _add_client_present(self, client):",
            "        id_ = client.id_",
            "        if id_ in self.present:",
            "            clients = self.present[id_]",
            "            clients.add(client)",
            "        else:",
            "            self.present[id_] = {client}",
            "            if self.presence_events:",
            "                data = {\"new\": [id_], \"lost\": []}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"change\", \"presence\")",
            "                )",
            "                data = {\"present\": list(self.present.keys())}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"present\", \"presence\")",
            "                )",
            "",
            "    def _remove_client_present(self, client):",
            "        id_ = client.id_",
            "        if id_ is None or id_ not in self.present:",
            "            # This is possible if _remove_client_present() is invoked",
            "            # before the minion's id is validated.",
            "            return",
            "",
            "        clients = self.present[id_]",
            "        if client not in clients:",
            "            # Since _remove_client_present() is potentially called from",
            "            # _stream_read() and/or publish_payload(), it is possible for",
            "            # it to be called twice, in which case we will get here.",
            "            # This is not an abnormal case, so no logging is required.",
            "            return",
            "",
            "        clients.remove(client)",
            "        if len(clients) == 0:",
            "            del self.present[id_]",
            "            if self.presence_events:",
            "                data = {\"new\": [], \"lost\": [id_]}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"change\", \"presence\")",
            "                )",
            "                data = {\"present\": list(self.present.keys())}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"present\", \"presence\")",
            "                )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _stream_read(self, client):",
            "        unpacker = salt.utils.msgpack.Unpacker()",
            "        while not self._closing:",
            "            try:",
            "                client._read_until_future = client.stream.read_bytes(4096, partial=True)",
            "                wire_bytes = yield client._read_until_future",
            "                unpacker.feed(wire_bytes)",
            "                for framed_msg in unpacker:",
            "                    framed_msg = salt.transport.frame.decode_embedded_strs(framed_msg)",
            "                    body = framed_msg[\"body\"]",
            "                    if body[\"enc\"] != \"aes\":",
            "                        # We only accept 'aes' encoded messages for 'id'",
            "                        continue",
            "                    crypticle = salt.crypt.Crypticle(",
            "                        self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "                    )",
            "                    load = crypticle.loads(body[\"load\"])",
            "                    load = salt.transport.frame.decode_embedded_strs(load)",
            "                    if not self.aes_funcs.verify_minion(load[\"id\"], load[\"tok\"]):",
            "                        continue",
            "                    client.id_ = load[\"id\"]",
            "                    self._add_client_present(client)",
            "            except salt.ext.tornado.iostream.StreamClosedError as e:",
            "                log.debug(\"tcp stream to %s closed, unable to recv\", client.address)",
            "                client.close()",
            "                self._remove_client_present(client)",
            "                self.clients.discard(client)",
            "                break",
            "            except Exception as e:  # pylint: disable=broad-except",
            "                log.error(",
            "                    \"Exception parsing response from %s\", client.address, exc_info=True",
            "                )",
            "                continue",
            "",
            "    def handle_stream(self, stream, address):",
            "        log.trace(\"Subscriber at %s connected\", address)",
            "        client = Subscriber(stream, address)",
            "        self.clients.add(client)",
            "        self.io_loop.spawn_callback(self._stream_read, client)",
            "",
            "    # TODO: ACK the publish through IPC",
            "    @salt.ext.tornado.gen.coroutine",
            "    def publish_payload(self, package, _):",
            "        log.debug(\"TCP PubServer sending payload: %s\", package)",
            "        payload = salt.transport.frame.frame_msg(package[\"payload\"])",
            "",
            "        to_remove = []",
            "        if \"topic_lst\" in package:",
            "            topic_lst = package[\"topic_lst\"]",
            "            for topic in topic_lst:",
            "                if topic in self.present:",
            "                    # This will rarely be a list of more than 1 item. It will",
            "                    # be more than 1 item if the minion disconnects from the",
            "                    # master in an unclean manner (eg cable yank), then",
            "                    # restarts and the master is yet to detect the disconnect",
            "                    # via TCP keep-alive.",
            "                    for client in self.present[topic]:",
            "                        try:",
            "                            # Write the packed str",
            "                            f = client.stream.write(payload)",
            "                            self.io_loop.add_future(f, lambda f: True)",
            "                        except salt.ext.tornado.iostream.StreamClosedError:",
            "                            to_remove.append(client)",
            "                else:",
            "                    log.debug(\"Publish target %s not connected\", topic)",
            "        else:",
            "            for client in self.clients:",
            "                try:",
            "                    # Write the packed str",
            "                    f = client.stream.write(payload)",
            "                    self.io_loop.add_future(f, lambda f: True)",
            "                except salt.ext.tornado.iostream.StreamClosedError:",
            "                    to_remove.append(client)",
            "        for client in to_remove:",
            "            log.debug(",
            "                \"Subscriber at %s has disconnected from publisher\", client.address",
            "            )",
            "            client.close()",
            "            self._remove_client_present(client)",
            "            self.clients.discard(client)",
            "        log.trace(\"TCP PubServer finished publishing payload\")",
            "",
            "",
            "class TCPPubServerChannel(salt.transport.server.PubServerChannel):",
            "    # TODO: opts!",
            "    # Based on default used in salt.ext.tornado.netutil.bind_sockets()",
            "    backlog = 128",
            "",
            "    def __init__(self, opts):",
            "        self.opts = opts",
            "        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?",
            "        self.ckminions = salt.utils.minions.CkMinions(opts)",
            "        self.io_loop = None",
            "",
            "    def __setstate__(self, state):",
            "        salt.master.SMaster.secrets = state[\"secrets\"]",
            "        self.__init__(state[\"opts\"])",
            "",
            "    def __getstate__(self):",
            "        return {\"opts\": self.opts, \"secrets\": salt.master.SMaster.secrets}",
            "",
            "    def _publish_daemon(self, **kwargs):",
            "        \"\"\"",
            "        Bind to the interface specified in the configuration file",
            "        \"\"\"",
            "        salt.utils.process.appendproctitle(self.__class__.__name__)",
            "",
            "        log_queue = kwargs.get(\"log_queue\")",
            "        if log_queue is not None:",
            "            salt.log.setup.set_multiprocessing_logging_queue(log_queue)",
            "        log_queue_level = kwargs.get(\"log_queue_level\")",
            "        if log_queue_level is not None:",
            "            salt.log.setup.set_multiprocessing_logging_level(log_queue_level)",
            "        salt.log.setup.setup_multiprocessing_logging(log_queue)",
            "",
            "        # Check if io_loop was set outside",
            "        if self.io_loop is None:",
            "            self.io_loop = salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        # Spin up the publisher",
            "        pub_server = PubServer(self.opts, io_loop=self.io_loop)",
            "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "        _set_tcp_keepalive(sock, self.opts)",
            "        sock.setblocking(0)",
            "        sock.bind((self.opts[\"interface\"], int(self.opts[\"publish_port\"])))",
            "        sock.listen(self.backlog)",
            "        # pub_server will take ownership of the socket",
            "        pub_server.add_socket(sock)",
            "",
            "        # Set up Salt IPC server",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = int(self.opts.get(\"tcp_master_publish_pull\", 4514))",
            "        else:",
            "            pull_uri = os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "",
            "        pull_sock = salt.transport.ipc.IPCMessageServer(",
            "            pull_uri, io_loop=self.io_loop, payload_handler=pub_server.publish_payload,",
            "        )",
            "",
            "        # Securely create socket",
            "        log.info(\"Starting the Salt Puller on %s\", pull_uri)",
            "        with salt.utils.files.set_umask(0o177):",
            "            pull_sock.start()",
            "",
            "        # run forever",
            "        try:",
            "            self.io_loop.start()",
            "        except (KeyboardInterrupt, SystemExit):",
            "            salt.log.setup.shutdown_multiprocessing_logging()",
            "        finally:",
            "            pull_sock.close()",
            "",
            "    def pre_fork(self, process_manager, kwargs=None):",
            "        \"\"\"",
            "        Do anything necessary pre-fork. Since this is on the master side this will",
            "        primarily be used to create IPC channels and create our daemon process to",
            "        do the actual publishing",
            "        \"\"\"",
            "        process_manager.add_process(self._publish_daemon, kwargs=kwargs)",
            "",
            "    def publish(self, load):",
            "        \"\"\"",
            "        Publish \"load\" to minions",
            "        \"\"\"",
            "        payload = {\"enc\": \"aes\"}",
            "",
            "        crypticle = salt.crypt.Crypticle(",
            "            self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "        )",
            "        payload[\"load\"] = crypticle.dumps(load)",
            "        if self.opts[\"sign_pub_messages\"]:",
            "            master_pem_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "            log.debug(\"Signing data packet\")",
            "            payload[\"sig\"] = salt.crypt.sign_message(master_pem_path, payload[\"load\"])",
            "        # Use the Salt IPC server",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = int(self.opts.get(\"tcp_master_publish_pull\", 4514))",
            "        else:",
            "            pull_uri = os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "        # TODO: switch to the actual asynchronous interface",
            "        # pub_sock = salt.transport.ipc.IPCMessageClient(self.opts, io_loop=self.io_loop)",
            "        pub_sock = salt.utils.asynchronous.SyncWrapper(",
            "            salt.transport.ipc.IPCMessageClient, (pull_uri,), loop_kwarg=\"io_loop\",",
            "        )",
            "        pub_sock.connect()",
            "",
            "        int_payload = {\"payload\": self.serial.dumps(payload)}",
            "",
            "        # add some targeting stuff for lists only (for now)",
            "        if load[\"tgt_type\"] == \"list\" and not self.opts.get(\"order_masters\", False):",
            "            if isinstance(load[\"tgt\"], str):",
            "                # Fetch a list of minions that match",
            "                _res = self.ckminions.check_minions(",
            "                    load[\"tgt\"], tgt_type=load[\"tgt_type\"]",
            "                )",
            "                match_ids = _res[\"minions\"]",
            "",
            "                log.debug(\"Publish Side Match: %s\", match_ids)",
            "                # Send list of miions thru so zmq can target them",
            "                int_payload[\"topic_lst\"] = match_ids",
            "            else:",
            "                int_payload[\"topic_lst\"] = load[\"tgt\"]",
            "        # Send it over IPC!",
            "        pub_sock.send(int_payload)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "TCP transport classes",
            "",
            "Wire protocol: \"len(payload) msgpack({'head': SOMEHEADER, 'body': SOMEBODY})\"",
            "",
            "\"\"\"",
            "import errno",
            "import logging",
            "import os",
            "import queue",
            "import socket",
            "import threading",
            "import time",
            "import traceback",
            "import urllib.parse as urlparse",
            "import uuid",
            "import weakref",
            "",
            "import salt.crypt",
            "import salt.exceptions",
            "import salt.ext.tornado",
            "import salt.ext.tornado.concurrent",
            "import salt.ext.tornado.gen",
            "import salt.ext.tornado.iostream",
            "import salt.ext.tornado.netutil",
            "import salt.ext.tornado.tcpclient",
            "import salt.ext.tornado.tcpserver",
            "import salt.payload",
            "import salt.transport.client",
            "import salt.transport.frame",
            "import salt.transport.ipc",
            "import salt.transport.mixins.auth",
            "import salt.transport.server",
            "import salt.utils.asynchronous",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.msgpack",
            "import salt.utils.platform",
            "import salt.utils.process",
            "import salt.utils.verify",
            "import salt.utils.versions",
            "from salt.exceptions import SaltClientError, SaltReqTimeoutError",
            "from salt.transport import iter_transport_opts",
            "",
            "try:",
            "    from M2Crypto import RSA",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "    try:",
            "        from Cryptodome.Cipher import PKCS1_OAEP",
            "    except ImportError:",
            "        from Crypto.Cipher import PKCS1_OAEP  # nosec",
            "",
            "if salt.utils.platform.is_windows():",
            "    USE_LOAD_BALANCER = True",
            "else:",
            "    USE_LOAD_BALANCER = False",
            "",
            "if USE_LOAD_BALANCER:",
            "    import threading",
            "    import multiprocessing",
            "    import salt.ext.tornado.util",
            "    from salt.utils.process import SignalHandlingProcess",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def _set_tcp_keepalive(sock, opts):",
            "    \"\"\"",
            "    Ensure that TCP keepalives are set for the socket.",
            "    \"\"\"",
            "    if hasattr(socket, \"SO_KEEPALIVE\"):",
            "        if opts.get(\"tcp_keepalive\", False):",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)",
            "            if hasattr(socket, \"SOL_TCP\"):",
            "                if hasattr(socket, \"TCP_KEEPIDLE\"):",
            "                    tcp_keepalive_idle = opts.get(\"tcp_keepalive_idle\", -1)",
            "                    if tcp_keepalive_idle > 0:",
            "                        sock.setsockopt(",
            "                            socket.SOL_TCP, socket.TCP_KEEPIDLE, int(tcp_keepalive_idle)",
            "                        )",
            "                if hasattr(socket, \"TCP_KEEPCNT\"):",
            "                    tcp_keepalive_cnt = opts.get(\"tcp_keepalive_cnt\", -1)",
            "                    if tcp_keepalive_cnt > 0:",
            "                        sock.setsockopt(",
            "                            socket.SOL_TCP, socket.TCP_KEEPCNT, int(tcp_keepalive_cnt)",
            "                        )",
            "                if hasattr(socket, \"TCP_KEEPINTVL\"):",
            "                    tcp_keepalive_intvl = opts.get(\"tcp_keepalive_intvl\", -1)",
            "                    if tcp_keepalive_intvl > 0:",
            "                        sock.setsockopt(",
            "                            socket.SOL_TCP,",
            "                            socket.TCP_KEEPINTVL,",
            "                            int(tcp_keepalive_intvl),",
            "                        )",
            "            if hasattr(socket, \"SIO_KEEPALIVE_VALS\"):",
            "                # Windows doesn't support TCP_KEEPIDLE, TCP_KEEPCNT, nor",
            "                # TCP_KEEPINTVL. Instead, it has its own proprietary",
            "                # SIO_KEEPALIVE_VALS.",
            "                tcp_keepalive_idle = opts.get(\"tcp_keepalive_idle\", -1)",
            "                tcp_keepalive_intvl = opts.get(\"tcp_keepalive_intvl\", -1)",
            "                # Windows doesn't support changing something equivalent to",
            "                # TCP_KEEPCNT.",
            "                if tcp_keepalive_idle > 0 or tcp_keepalive_intvl > 0:",
            "                    # Windows defaults may be found by using the link below.",
            "                    # Search for 'KeepAliveTime' and 'KeepAliveInterval'.",
            "                    # https://technet.microsoft.com/en-us/library/bb726981.aspx#EDAA",
            "                    # If one value is set and the other isn't, we still need",
            "                    # to send both values to SIO_KEEPALIVE_VALS and they both",
            "                    # need to be valid. So in that case, use the Windows",
            "                    # default.",
            "                    if tcp_keepalive_idle <= 0:",
            "                        tcp_keepalive_idle = 7200",
            "                    if tcp_keepalive_intvl <= 0:",
            "                        tcp_keepalive_intvl = 1",
            "                    # The values expected are in milliseconds, so multiply by",
            "                    # 1000.",
            "                    sock.ioctl(",
            "                        socket.SIO_KEEPALIVE_VALS,",
            "                        (",
            "                            1,",
            "                            int(tcp_keepalive_idle * 1000),",
            "                            int(tcp_keepalive_intvl * 1000),",
            "                        ),",
            "                    )",
            "        else:",
            "            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 0)",
            "",
            "",
            "if USE_LOAD_BALANCER:",
            "",
            "    class LoadBalancerServer(SignalHandlingProcess):",
            "        \"\"\"",
            "        Raw TCP server which runs in its own process and will listen",
            "        for incoming connections. Each incoming connection will be",
            "        sent via multiprocessing queue to the workers.",
            "        Since the queue is shared amongst workers, only one worker will",
            "        handle a given connection.",
            "        \"\"\"",
            "",
            "        # TODO: opts!",
            "        # Based on default used in salt.ext.tornado.netutil.bind_sockets()",
            "        backlog = 128",
            "",
            "        def __init__(self, opts, socket_queue, **kwargs):",
            "            super().__init__(**kwargs)",
            "            self.opts = opts",
            "            self.socket_queue = socket_queue",
            "            self._socket = None",
            "",
            "        # __setstate__ and __getstate__ are only used on Windows.",
            "        # We do this so that __init__ will be invoked on Windows in the child",
            "        # process so that a register_after_fork() equivalent will work on",
            "        # Windows.",
            "        def __setstate__(self, state):",
            "            self.__init__(",
            "                state[\"opts\"],",
            "                state[\"socket_queue\"],",
            "                log_queue=state[\"log_queue\"],",
            "                log_queue_level=state[\"log_queue_level\"],",
            "            )",
            "",
            "        def __getstate__(self):",
            "            return {",
            "                \"opts\": self.opts,",
            "                \"socket_queue\": self.socket_queue,",
            "                \"log_queue\": self.log_queue,",
            "                \"log_queue_level\": self.log_queue_level,",
            "            }",
            "",
            "        def close(self):",
            "            if self._socket is not None:",
            "                self._socket.shutdown(socket.SHUT_RDWR)",
            "                self._socket.close()",
            "                self._socket = None",
            "",
            "        # pylint: disable=W1701",
            "        def __del__(self):",
            "            self.close()",
            "",
            "        # pylint: enable=W1701",
            "",
            "        def run(self):",
            "            \"\"\"",
            "            Start the load balancer",
            "            \"\"\"",
            "            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "            _set_tcp_keepalive(self._socket, self.opts)",
            "            self._socket.setblocking(1)",
            "            self._socket.bind((self.opts[\"interface\"], int(self.opts[\"ret_port\"])))",
            "            self._socket.listen(self.backlog)",
            "",
            "            while True:",
            "                try:",
            "                    # Wait for a connection to occur since the socket is",
            "                    # blocking.",
            "                    connection, address = self._socket.accept()",
            "                    # Wait for a free slot to be available to put",
            "                    # the connection into.",
            "                    # Sockets are picklable on Windows in Python 3.",
            "                    self.socket_queue.put((connection, address), True, None)",
            "                except OSError as e:",
            "                    # ECONNABORTED indicates that there was a connection",
            "                    # but it was closed while still in the accept queue.",
            "                    # (observed on FreeBSD).",
            "                    if (",
            "                        salt.ext.tornado.util.errno_from_exception(e)",
            "                        == errno.ECONNABORTED",
            "                    ):",
            "                        continue",
            "                    raise",
            "",
            "",
            "# TODO: move serial down into message library",
            "class AsyncTCPReqChannel(salt.transport.client.ReqChannel):",
            "    \"\"\"",
            "    Encapsulate sending routines to tcp.",
            "",
            "    Note: this class returns a singleton",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    # mapping of io_loop -> {key -> channel}",
            "    instance_map = weakref.WeakKeyDictionary()",
            "    async_methods = [",
            "        \"crypted_transfer_decode_dictentry\",",
            "        \"_crypted_transfer\",",
            "        \"_uncrypted_transfer\",",
            "        \"send\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __new__(cls, opts, **kwargs):",
            "        \"\"\"",
            "        Only create one instance of channel per __key()",
            "        \"\"\"",
            "        # do we have any mapping for this io_loop",
            "        io_loop = kwargs.get(\"io_loop\") or salt.ext.tornado.ioloop.IOLoop.current()",
            "        if io_loop not in cls.instance_map:",
            "            cls.instance_map[io_loop] = weakref.WeakValueDictionary()",
            "        loop_instance_map = cls.instance_map[io_loop]",
            "",
            "        key = cls.__key(opts, **kwargs)",
            "        obj = loop_instance_map.get(key)",
            "        if obj is None:",
            "            log.debug(\"Initializing new AsyncTCPReqChannel for %s\", key)",
            "            # we need to make a local variable for this, as we are going to store",
            "            # it in a WeakValueDictionary-- which will remove the item if no one",
            "            # references it-- this forces a reference while we return to the caller",
            "            obj = object.__new__(cls)",
            "            obj.__singleton_init__(opts, **kwargs)",
            "            obj._instance_key = key",
            "            loop_instance_map[key] = obj",
            "            obj._refcount = 1",
            "            obj._refcount_lock = threading.RLock()",
            "        else:",
            "            with obj._refcount_lock:",
            "                obj._refcount += 1",
            "            log.debug(\"Re-using AsyncTCPReqChannel for %s\", key)",
            "        return obj",
            "",
            "    @classmethod",
            "    def __key(cls, opts, **kwargs):",
            "        if \"master_uri\" in kwargs:",
            "            opts[\"master_uri\"] = kwargs[\"master_uri\"]",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            opts[\"master_uri\"],",
            "            kwargs.get(\"crypt\", \"aes\"),  # TODO: use the same channel for crypt",
            "        )",
            "",
            "    @classmethod",
            "    def force_close_all_instances(cls):",
            "        \"\"\"",
            "        Will force close all instances",
            "        :return: None",
            "        \"\"\"",
            "        for weak_dict in list(cls.instance_map.values()):",
            "            for instance in list(weak_dict.values()):",
            "                instance.close()",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, **kwargs):",
            "        pass",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, **kwargs):",
            "        self.opts = dict(opts)",
            "",
            "        self.serial = salt.payload.Serial(self.opts)",
            "",
            "        # crypt defaults to 'aes'",
            "        self.crypt = kwargs.get(\"crypt\", \"aes\")",
            "",
            "        self.io_loop = kwargs.get(\"io_loop\") or salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        if self.crypt != \"clear\":",
            "            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)",
            "",
            "        resolver = kwargs.get(\"resolver\")",
            "",
            "        parse = urlparse.urlparse(self.opts[\"master_uri\"])",
            "        master_host, master_port = parse.netloc.rsplit(\":\", 1)",
            "        self.master_addr = (master_host, int(master_port))",
            "        self._closing = False",
            "        self.message_client = SaltMessageClientPool(",
            "            self.opts,",
            "            args=(self.opts, master_host, int(master_port),),",
            "            kwargs={",
            "                \"io_loop\": self.io_loop,",
            "                \"resolver\": resolver,",
            "                \"source_ip\": self.opts.get(\"source_ip\"),",
            "                \"source_port\": self.opts.get(\"source_ret_port\"),",
            "            },",
            "        )",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "",
            "        if self._refcount > 1:",
            "            # Decrease refcount",
            "            with self._refcount_lock:",
            "                self._refcount -= 1",
            "            log.debug(",
            "                \"This is not the last %s instance. Not closing yet.\",",
            "                self.__class__.__name__,",
            "            )",
            "            return",
            "",
            "        log.debug(\"Closing %s instance\", self.__class__.__name__)",
            "        self._closing = True",
            "        self.message_client.close()",
            "",
            "        # Remove the entry from the instance map so that a closed entry may not",
            "        # be reused.",
            "        # This forces this operation even if the reference count of the entry",
            "        # has not yet gone to zero.",
            "        if self.io_loop in self.__class__.instance_map:",
            "            loop_instance_map = self.__class__.instance_map[self.io_loop]",
            "            if self._instance_key in loop_instance_map:",
            "                del loop_instance_map[self._instance_key]",
            "            if not loop_instance_map:",
            "                del self.__class__.instance_map[self.io_loop]",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        with self._refcount_lock:",
            "            # Make sure we actually close no matter if something",
            "            # went wrong with our ref counting",
            "            self._refcount = 1",
            "        try:",
            "            self.close()",
            "        except OSError as exc:",
            "            if exc.errno != errno.EBADF:",
            "                # If its not a bad file descriptor error, raise",
            "                raise",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _package_load(self, load):",
            "        return {",
            "            \"enc\": self.crypt,",
            "            \"load\": load,",
            "            \"version\": 2,",
            "        }",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def crypted_transfer_decode_dictentry(",
            "        self, load, dictkey=None, tries=3, timeout=60",
            "    ):",
            "        nonce = uuid.uuid4().hex",
            "        load[\"nonce\"] = nonce",
            "        if not self.auth.authenticated:",
            "            yield self.auth.authenticate()",
            "        ret = yield self.message_client.send(",
            "            self._package_load(self.auth.crypticle.dumps(load)),",
            "            timeout=timeout,",
            "            tries=tries,",
            "        )",
            "        key = self.auth.get_keys()",
            "        if HAS_M2:",
            "            aes = key.private_decrypt(ret[\"key\"], RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(key)",
            "            aes = cipher.decrypt(ret[\"key\"])",
            "",
            "        # Decrypt using the public key.",
            "        pcrypt = salt.crypt.Crypticle(self.opts, aes)",
            "        signed_msg = pcrypt.loads(ret[dictkey])",
            "",
            "        # Validate the master's signature.",
            "        master_pubkey_path = os.path.join(self.opts[\"pki_dir\"], \"minion_master.pub\")",
            "        if not salt.crypt.verify_signature(",
            "            master_pubkey_path, signed_msg[\"data\"], signed_msg[\"sig\"]",
            "        ):",
            "            raise salt.crypt.AuthenticationError(",
            "                \"Pillar payload signature failed to validate.\"",
            "            )",
            "",
            "        # Make sure the signed key matches the key we used to decrypt the data.",
            "        data = salt.payload.Serial({}).loads(signed_msg[\"data\"])",
            "        if data[\"key\"] != ret[\"key\"]:",
            "            raise salt.crypt.AuthenticationError(\"Key verification failed.\")",
            "",
            "        # Validate the nonce.",
            "        if data[\"nonce\"] != nonce:",
            "            raise salt.crypt.AuthenticationError(\"Pillar nonce verification failed.\")",
            "        raise salt.ext.tornado.gen.Return(data[\"pillar\"])",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _crypted_transfer(self, load, tries=3, timeout=60):",
            "        \"\"\"",
            "        In case of authentication errors, try to renegotiate authentication",
            "        and retry the method.",
            "        Indeed, we can fail too early in case of a master restart during a",
            "        minion state execution call",
            "        \"\"\"",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def _do_transfer():",
            "            data = yield self.message_client.send(",
            "                self._package_load(self.auth.crypticle.dumps(load)),",
            "                timeout=timeout,",
            "                tries=tries,",
            "            )",
            "            # we may not have always data",
            "            # as for example for saltcall ret submission, this is a blind",
            "            # communication, we do not subscribe to return events, we just",
            "            # upload the results to the master",
            "            if data:",
            "                data = self.auth.crypticle.loads(data)",
            "                data = salt.transport.frame.decode_embedded_strs(data)",
            "            raise salt.ext.tornado.gen.Return(data)",
            "",
            "        if not self.auth.authenticated:",
            "            yield self.auth.authenticate()",
            "        try:",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "        except salt.crypt.AuthenticationError:",
            "            yield self.auth.authenticate()",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _uncrypted_transfer(self, load, tries=3, timeout=60):",
            "        ret = yield self.message_client.send(",
            "            self._package_load(load), timeout=timeout, tries=tries,",
            "        )",
            "",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def send(self, load, tries=3, timeout=60, raw=False):",
            "        \"\"\"",
            "        Send a request, return a future which will complete when we send the message",
            "        \"\"\"",
            "        try:",
            "            if self.crypt == \"clear\":",
            "                ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)",
            "            else:",
            "                ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout)",
            "        except salt.ext.tornado.iostream.StreamClosedError:",
            "            # Convert to 'SaltClientError' so that clients can handle this",
            "            # exception more appropriately.",
            "            raise SaltClientError(\"Connection to master lost\")",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "",
            "class AsyncTCPPubChannel(",
            "    salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel",
            "):",
            "    async_methods = [",
            "        \"send_id\",",
            "        \"connect_callback\",",
            "        \"connect\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __init__(self, opts, **kwargs):",
            "        self.opts = opts",
            "",
            "        self.serial = salt.payload.Serial(self.opts)",
            "",
            "        self.crypt = kwargs.get(\"crypt\", \"aes\")",
            "        self.io_loop = kwargs.get(\"io_loop\") or salt.ext.tornado.ioloop.IOLoop.current()",
            "        self.connected = False",
            "        self._closing = False",
            "        self._reconnected = False",
            "        self.message_client = None",
            "        self.event = salt.utils.event.get_event(\"minion\", opts=self.opts, listen=False)",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if self.message_client is not None:",
            "            self.message_client.close()",
            "            self.message_client = None",
            "        if self.event is not None:",
            "            self.event.destroy()",
            "            self.event = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _package_load(self, load):",
            "        return {",
            "            \"enc\": self.crypt,",
            "            \"load\": load,",
            "        }",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def send_id(self, tok, force_auth):",
            "        \"\"\"",
            "        Send the minion id to the master so that the master may better",
            "        track the connection state of the minion.",
            "        In case of authentication errors, try to renegotiate authentication",
            "        and retry the method.",
            "        \"\"\"",
            "        load = {\"id\": self.opts[\"id\"], \"tok\": tok}",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def _do_transfer():",
            "            msg = self._package_load(self.auth.crypticle.dumps(load))",
            "            package = salt.transport.frame.frame_msg(msg, header=None)",
            "            yield self.message_client.write_to_stream(package)",
            "            raise salt.ext.tornado.gen.Return(True)",
            "",
            "        if force_auth or not self.auth.authenticated:",
            "            count = 0",
            "            while (",
            "                count <= self.opts[\"tcp_authentication_retries\"]",
            "                or self.opts[\"tcp_authentication_retries\"] < 0",
            "            ):",
            "                try:",
            "                    yield self.auth.authenticate()",
            "                    break",
            "                except SaltClientError as exc:",
            "                    log.debug(exc)",
            "                    count += 1",
            "        try:",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "        except salt.crypt.AuthenticationError:",
            "            yield self.auth.authenticate()",
            "            ret = yield _do_transfer()",
            "            raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect_callback(self, result):",
            "        if self._closing:",
            "            return",
            "        # Force re-auth on reconnect since the master",
            "        # may have been restarted",
            "        yield self.send_id(self.tok, self._reconnected)",
            "        self.connected = True",
            "        self.event.fire_event({\"master\": self.opts[\"master\"]}, \"__master_connected\")",
            "        if self._reconnected:",
            "            # On reconnects, fire a master event to notify that the minion is",
            "            # available.",
            "            if self.opts.get(\"__role\") == \"syndic\":",
            "                data = \"Syndic {} started at {}\".format(self.opts[\"id\"], time.asctime())",
            "                tag = salt.utils.event.tagify([self.opts[\"id\"], \"start\"], \"syndic\")",
            "            else:",
            "                data = \"Minion {} started at {}\".format(self.opts[\"id\"], time.asctime())",
            "                tag = salt.utils.event.tagify([self.opts[\"id\"], \"start\"], \"minion\")",
            "            load = {",
            "                \"id\": self.opts[\"id\"],",
            "                \"cmd\": \"_minion_event\",",
            "                \"pretag\": None,",
            "                \"tok\": self.tok,",
            "                \"data\": data,",
            "                \"tag\": tag,",
            "            }",
            "            req_channel = salt.utils.asynchronous.SyncWrapper(",
            "                AsyncTCPReqChannel, (self.opts,), loop_kwarg=\"io_loop\",",
            "            )",
            "            try:",
            "                req_channel.send(load, timeout=60)",
            "            except salt.exceptions.SaltReqTimeoutError:",
            "                log.info(",
            "                    \"fire_master failed: master could not be contacted. Request timed out.\"",
            "                )",
            "            except Exception:  # pylint: disable=broad-except",
            "                log.info(\"fire_master failed: %s\", traceback.format_exc())",
            "            finally:",
            "                # SyncWrapper will call either close() or destroy(), whichever is available",
            "                del req_channel",
            "        else:",
            "            self._reconnected = True",
            "",
            "    def disconnect_callback(self):",
            "        if self._closing:",
            "            return",
            "        self.connected = False",
            "        self.event.fire_event({\"master\": self.opts[\"master\"]}, \"__master_disconnected\")",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect(self):",
            "        try:",
            "            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)",
            "            self.tok = self.auth.gen_token(b\"salt\")",
            "            if not self.auth.authenticated:",
            "                yield self.auth.authenticate()",
            "            if self.auth.authenticated:",
            "                # if this is changed from the default, we assume it was intentional",
            "                if int(self.opts.get(\"publish_port\", 4505)) != 4505:",
            "                    self.publish_port = self.opts.get(\"publish_port\")",
            "                # else take the relayed publish_port master reports",
            "                else:",
            "                    self.publish_port = self.auth.creds[\"publish_port\"]",
            "",
            "                self.message_client = SaltMessageClientPool(",
            "                    self.opts,",
            "                    args=(self.opts, self.opts[\"master_ip\"], int(self.publish_port)),",
            "                    kwargs={",
            "                        \"io_loop\": self.io_loop,",
            "                        \"connect_callback\": self.connect_callback,",
            "                        \"disconnect_callback\": self.disconnect_callback,",
            "                        \"source_ip\": self.opts.get(\"source_ip\"),",
            "                        \"source_port\": self.opts.get(\"source_publish_port\"),",
            "                    },",
            "                )",
            "                yield self.message_client.connect()  # wait for the client to be connected",
            "                self.connected = True",
            "        # TODO: better exception handling...",
            "        except KeyboardInterrupt:  # pylint: disable=try-except-raise",
            "            raise",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            if \"-|RETRY|-\" not in str(exc):",
            "                raise SaltClientError(",
            "                    \"Unable to sign_in to master: {}\".format(exc)",
            "                )  # TODO: better error message",
            "",
            "    def on_recv(self, callback):",
            "        \"\"\"",
            "        Register an on_recv callback",
            "        \"\"\"",
            "        if callback is None:",
            "            return self.message_client.on_recv(callback)",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def wrap_callback(body):",
            "            if not isinstance(body, dict):",
            "                # TODO: For some reason we need to decode here for things",
            "                #       to work. Fix this.",
            "                body = salt.utils.msgpack.loads(body)",
            "                body = salt.transport.frame.decode_embedded_strs(body)",
            "            ret = yield self._decode_payload(body)",
            "            callback(ret)",
            "",
            "        return self.message_client.on_recv(wrap_callback)",
            "",
            "",
            "class TCPReqServerChannel(",
            "    salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel",
            "):",
            "    # TODO: opts!",
            "    backlog = 5",
            "",
            "    def __init__(self, opts):",
            "        salt.transport.server.ReqServerChannel.__init__(self, opts)",
            "        self._socket = None",
            "        self.req_server = None",
            "",
            "    @property",
            "    def socket(self):",
            "        return self._socket",
            "",
            "    def close(self):",
            "        if self._socket is not None:",
            "            try:",
            "                self._socket.shutdown(socket.SHUT_RDWR)",
            "            except OSError as exc:",
            "                if exc.errno == errno.ENOTCONN:",
            "                    # We may try to shutdown a socket which is already disconnected.",
            "                    # Ignore this condition and continue.",
            "                    pass",
            "                else:",
            "                    raise",
            "            if self.req_server is None:",
            "                # We only close the socket if we don't have a req_server instance.",
            "                # If we did, because the req_server is also handling this socket, when we call",
            "                # req_server.stop(), tornado will give us an AssertionError because it's trying to",
            "                # match the socket.fileno() (after close it's -1) to the fd it holds on it's _sockets cache",
            "                # so it can remove the socket from the IOLoop handlers",
            "                self._socket.close()",
            "            self._socket = None",
            "        if self.req_server is not None:",
            "            try:",
            "                self.req_server.close()",
            "            except OSError as exc:",
            "                if exc.errno != 9:",
            "                    raise",
            "                log.exception(",
            "                    \"TCPReqServerChannel close generated an exception: %s\", str(exc)",
            "                )",
            "            self.req_server = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    def pre_fork(self, process_manager):",
            "        \"\"\"",
            "        Pre-fork we need to create the zmq router device",
            "        \"\"\"",
            "        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)",
            "        if USE_LOAD_BALANCER:",
            "            self.socket_queue = multiprocessing.Queue()",
            "            process_manager.add_process(",
            "                LoadBalancerServer, args=(self.opts, self.socket_queue)",
            "            )",
            "        elif not salt.utils.platform.is_windows():",
            "            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "            _set_tcp_keepalive(self._socket, self.opts)",
            "            self._socket.setblocking(0)",
            "            self._socket.bind((self.opts[\"interface\"], int(self.opts[\"ret_port\"])))",
            "",
            "    def post_fork(self, payload_handler, io_loop):",
            "        \"\"\"",
            "        After forking we need to create all of the local sockets to listen to the",
            "        router",
            "",
            "        payload_handler: function to call with your payloads",
            "        \"\"\"",
            "        if self.opts[\"pub_server_niceness\"] and not salt.utils.platform.is_windows():",
            "            log.info(",
            "                \"setting Publish daemon niceness to %i\",",
            "                self.opts[\"pub_server_niceness\"],",
            "            )",
            "            os.nice(self.opts[\"pub_server_niceness\"])",
            "",
            "        self.payload_handler = payload_handler",
            "        self.io_loop = io_loop",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        with salt.utils.asynchronous.current_ioloop(self.io_loop):",
            "            if USE_LOAD_BALANCER:",
            "                self.req_server = LoadBalancerWorker(",
            "                    self.socket_queue,",
            "                    self.handle_message,",
            "                    ssl_options=self.opts.get(\"ssl\"),",
            "                )",
            "            else:",
            "                if salt.utils.platform.is_windows():",
            "                    self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "                    self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "                    _set_tcp_keepalive(self._socket, self.opts)",
            "                    self._socket.setblocking(0)",
            "                    self._socket.bind(",
            "                        (self.opts[\"interface\"], int(self.opts[\"ret_port\"]))",
            "                    )",
            "                self.req_server = SaltMessageServer(",
            "                    self.handle_message,",
            "                    ssl_options=self.opts.get(\"ssl\"),",
            "                    io_loop=self.io_loop,",
            "                )",
            "                self.req_server.add_socket(self._socket)",
            "                self._socket.listen(self.backlog)",
            "        salt.transport.mixins.auth.AESReqServerMixin.post_fork(",
            "            self, payload_handler, io_loop",
            "        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def handle_message(self, stream, header, payload):",
            "        \"\"\"",
            "        Handle incoming messages from underlying tcp streams",
            "        \"\"\"",
            "        try:",
            "            try:",
            "                payload = self._decode_payload(payload)",
            "            except Exception:  # pylint: disable=broad-except",
            "                stream.write(salt.transport.frame.frame_msg(\"bad load\", header=header))",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            # TODO helper functions to normalize payload?",
            "            if not isinstance(payload, dict) or not isinstance(",
            "                payload.get(\"load\"), dict",
            "            ):",
            "                yield stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        \"payload and load must be a dict\", header=header",
            "                    )",
            "                )",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            try:",
            "                id_ = payload[\"load\"].get(\"id\", \"\")",
            "                if \"\\0\" in id_:",
            "                    log.error(\"Payload contains an id with a null byte: %s\", payload)",
            "                    stream.send(self.serial.dumps(\"bad load: id contains a null byte\"))",
            "                    raise salt.ext.tornado.gen.Return()",
            "            except TypeError:",
            "                log.error(\"Payload contains non-string id: %s\", payload)",
            "                stream.send(",
            "                    self.serial.dumps(\"bad load: id {} is not a string\".format(id_))",
            "                )",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            version = 0",
            "            if \"version\" in payload:",
            "                version = payload[\"version\"]",
            "",
            "            # intercept the \"_auth\" commands, since the main daemon shouldn't know",
            "            # anything about our key auth",
            "            if (",
            "                payload[\"enc\"] == \"clear\"",
            "                and payload.get(\"load\", {}).get(\"cmd\") == \"_auth\"",
            "            ):",
            "                yield stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        self._auth(payload[\"load\"]), header=header",
            "                    )",
            "                )",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            # TODO: test",
            "            try:",
            "                ret, req_opts = yield self.payload_handler(payload)",
            "            except Exception as e:  # pylint: disable=broad-except",
            "                # always attempt to return an error to the minion",
            "                stream.write(\"Some exception handling minion payload\")",
            "                log.error(",
            "                    \"Some exception handling a payload from minion\", exc_info=True",
            "                )",
            "                stream.close()",
            "                raise salt.ext.tornado.gen.Return()",
            "",
            "            req_fun = req_opts.get(\"fun\", \"send\")",
            "            if req_fun == \"send_clear\":",
            "                stream.write(salt.transport.frame.frame_msg(ret, header=header))",
            "            elif req_fun == \"send\":",
            "                stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        self.crypticle.dumps(ret), header=header",
            "                    )",
            "                )",
            "            elif req_fun == \"send_private\":",
            "                sign_messages = False",
            "                nonce = None",
            "                if version > 1:",
            "                    sign_messages = True",
            "                    nonce = payload[\"load\"].get(\"nonce\")",
            "                stream.write(",
            "                    salt.transport.frame.frame_msg(",
            "                        self._encrypt_private(",
            "                            ret, req_opts[\"key\"], req_opts[\"tgt\"], nonce, sign_messages,",
            "                        ),",
            "                        header=header,",
            "                    )",
            "                )",
            "            else:",
            "                log.error(\"Unknown req_fun %s\", req_fun)",
            "                # always attempt to return an error to the minion",
            "                stream.write(\"Server-side exception handling payload\")",
            "                stream.close()",
            "        except salt.ext.tornado.gen.Return:",
            "            raise",
            "        except salt.ext.tornado.iostream.StreamClosedError:",
            "            # Stream was closed. This could happen if the remote side",
            "            # closed the connection on its end (eg in a timeout or shutdown",
            "            # situation).",
            "            log.error(\"Connection was unexpectedly closed\", exc_info=True)",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            # Absorb any other exceptions",
            "            log.error(\"Unexpected exception occurred: %s\", exc, exc_info=True)",
            "",
            "        raise salt.ext.tornado.gen.Return()",
            "",
            "",
            "class SaltMessageServer(salt.ext.tornado.tcpserver.TCPServer):",
            "    \"\"\"",
            "    Raw TCP server which will receive all of the TCP streams and re-assemble",
            "    messages that are sent through to us",
            "    \"\"\"",
            "",
            "    def __init__(self, message_handler, *args, **kwargs):",
            "        io_loop = (",
            "            kwargs.pop(\"io_loop\", None) or salt.ext.tornado.ioloop.IOLoop.current()",
            "        )",
            "        self._closing = False",
            "        super().__init__(*args, **kwargs)",
            "        self.io_loop = io_loop",
            "        self.clients = []",
            "        self.message_handler = message_handler",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def handle_stream(self, stream, address):",
            "        \"\"\"",
            "        Handle incoming streams and add messages to the incoming queue",
            "        \"\"\"",
            "        log.trace(\"Req client %s connected\", address)",
            "        self.clients.append((stream, address))",
            "        unpacker = salt.utils.msgpack.Unpacker()",
            "        try:",
            "            while True:",
            "                wire_bytes = yield stream.read_bytes(4096, partial=True)",
            "                unpacker.feed(wire_bytes)",
            "                for framed_msg in unpacker:",
            "                    framed_msg = salt.transport.frame.decode_embedded_strs(framed_msg)",
            "                    header = framed_msg[\"head\"]",
            "                    self.io_loop.spawn_callback(",
            "                        self.message_handler, stream, header, framed_msg[\"body\"]",
            "                    )",
            "        except salt.ext.tornado.iostream.StreamClosedError:",
            "            log.trace(\"req client disconnected %s\", address)",
            "            self.remove_client((stream, address))",
            "        except Exception as e:  # pylint: disable=broad-except",
            "            log.trace(\"other master-side exception: %s\", e)",
            "            self.remove_client((stream, address))",
            "            stream.close()",
            "",
            "    def remove_client(self, client):",
            "        try:",
            "            self.clients.remove(client)",
            "        except ValueError:",
            "            log.trace(\"Message server client was not in list to remove\")",
            "",
            "    def shutdown(self):",
            "        \"\"\"",
            "        Shutdown the whole server",
            "        \"\"\"",
            "        salt.utils.versions.warn_until(",
            "            \"Phosphorus\",",
            "            \"Please stop calling {0}.{1}.shutdown() and instead call {0}.{1}.close()\".format(",
            "                __name__, self.__class__.__name__",
            "            ),",
            "        )",
            "        self.close()",
            "",
            "    def close(self):",
            "        \"\"\"",
            "        Close the server",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        for item in self.clients:",
            "            client, address = item",
            "            client.close()",
            "            self.remove_client(item)",
            "        try:",
            "            self.stop()",
            "        except OSError as exc:",
            "            if exc.errno != 9:",
            "                raise",
            "",
            "",
            "if USE_LOAD_BALANCER:",
            "",
            "    class LoadBalancerWorker(SaltMessageServer):",
            "        \"\"\"",
            "        This will receive TCP connections from 'LoadBalancerServer' via",
            "        a multiprocessing queue.",
            "        Since the queue is shared amongst workers, only one worker will handle",
            "        a given connection.",
            "        \"\"\"",
            "",
            "        def __init__(self, socket_queue, message_handler, *args, **kwargs):",
            "            super().__init__(message_handler, *args, **kwargs)",
            "            self.socket_queue = socket_queue",
            "            self._stop = threading.Event()",
            "            self.thread = threading.Thread(target=self.socket_queue_thread)",
            "            self.thread.start()",
            "",
            "        def stop(self):",
            "            salt.utils.versions.warn_until(",
            "                \"Phosphorus\",",
            "                \"Please stop calling {0}.{1}.stop() and instead call {0}.{1}.close()\".format(",
            "                    __name__, self.__class__.__name__",
            "                ),",
            "            )",
            "            self.close()",
            "",
            "        def close(self):",
            "            self._stop.set()",
            "            self.thread.join()",
            "            super().close()",
            "",
            "        def socket_queue_thread(self):",
            "            try:",
            "                while True:",
            "                    try:",
            "                        client_socket, address = self.socket_queue.get(True, 1)",
            "                    except queue.Empty:",
            "                        if self._stop.is_set():",
            "                            break",
            "                        continue",
            "                    # 'self.io_loop' initialized in super class",
            "                    # 'salt.ext.tornado.tcpserver.TCPServer'.",
            "                    # 'self._handle_connection' defined in same super class.",
            "                    self.io_loop.spawn_callback(",
            "                        self._handle_connection, client_socket, address",
            "                    )",
            "            except (KeyboardInterrupt, SystemExit):",
            "                pass",
            "",
            "",
            "class TCPClientKeepAlive(salt.ext.tornado.tcpclient.TCPClient):",
            "    \"\"\"",
            "    Override _create_stream() in TCPClient to enable keep alive support.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, resolver=None):",
            "        self.opts = opts",
            "        super().__init__(resolver=resolver)",
            "",
            "    def _create_stream(",
            "        self, max_buffer_size, af, addr, **kwargs",
            "    ):  # pylint: disable=unused-argument,arguments-differ",
            "        \"\"\"",
            "        Override _create_stream() in TCPClient.",
            "",
            "        Tornado 4.5 added the kwargs 'source_ip' and 'source_port'.",
            "        Due to this, use **kwargs to swallow these and any future",
            "        kwargs to maintain compatibility.",
            "        \"\"\"",
            "        # Always connect in plaintext; we'll convert to ssl if necessary",
            "        # after one connection has completed.",
            "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "        _set_tcp_keepalive(sock, self.opts)",
            "        stream = salt.ext.tornado.iostream.IOStream(",
            "            sock, max_buffer_size=max_buffer_size",
            "        )",
            "        if salt.ext.tornado.version_info < (5,):",
            "            return stream.connect(addr)",
            "        return stream, stream.connect(addr)",
            "",
            "",
            "class SaltMessageClientPool(salt.transport.MessageClientPool):",
            "    \"\"\"",
            "    Wrapper class of SaltMessageClient to avoid blocking waiting while writing data to socket.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, args=None, kwargs=None):",
            "        super().__init__(SaltMessageClient, opts, args=args, kwargs=kwargs)",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def close(self):",
            "        for message_client in self.message_clients:",
            "            message_client.close()",
            "        self.message_clients = []",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect(self):",
            "        futures = []",
            "        for message_client in self.message_clients:",
            "            futures.append(message_client.connect())",
            "        yield futures",
            "        raise salt.ext.tornado.gen.Return(None)",
            "",
            "    def on_recv(self, *args, **kwargs):",
            "        for message_client in self.message_clients:",
            "            message_client.on_recv(*args, **kwargs)",
            "",
            "    def send(self, *args, **kwargs):",
            "        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))",
            "        return message_clients[0].send(*args, **kwargs)",
            "",
            "    def write_to_stream(self, *args, **kwargs):",
            "        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))",
            "        return message_clients[0]._stream.write(*args, **kwargs)",
            "",
            "",
            "# TODO consolidate with IPCClient",
            "# TODO: limit in-flight messages.",
            "# TODO: singleton? Something to not re-create the tcp connection so much",
            "class SaltMessageClient:",
            "    \"\"\"",
            "    Low-level message sending client",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        opts,",
            "        host,",
            "        port,",
            "        io_loop=None,",
            "        resolver=None,",
            "        connect_callback=None,",
            "        disconnect_callback=None,",
            "        source_ip=None,",
            "        source_port=None,",
            "    ):",
            "        self.opts = opts",
            "        self.host = host",
            "        self.port = port",
            "        self.source_ip = source_ip",
            "        self.source_port = source_port",
            "        self.connect_callback = connect_callback",
            "        self.disconnect_callback = disconnect_callback",
            "",
            "        self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        with salt.utils.asynchronous.current_ioloop(self.io_loop):",
            "            self._tcp_client = TCPClientKeepAlive(opts, resolver=resolver)",
            "",
            "        self._mid = 1",
            "        self._max_messages = int((1 << 31) - 2)  # number of IDs before we wrap",
            "",
            "        # TODO: max queue size",
            "        self.send_queue = []  # queue of messages to be sent",
            "        self.send_future_map = {}  # mapping of request_id -> Future",
            "        self.send_timeout_map = {}  # request_id -> timeout_callback",
            "",
            "        self._read_until_future = None",
            "        self._on_recv = None",
            "        self._closing = False",
            "        self._connecting_future = self.connect()",
            "        self._stream_return_future = salt.ext.tornado.concurrent.Future()",
            "        self.io_loop.spawn_callback(self._stream_return)",
            "",
            "        self.backoff = opts.get(\"tcp_reconnect_backoff\", 1)",
            "",
            "    def _stop_io_loop(self):",
            "        if self.io_loop is not None:",
            "            self.io_loop.stop()",
            "",
            "    # TODO: timeout inflight sessions",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if hasattr(self, \"_stream\") and not self._stream.closed():",
            "            # If _stream_return() hasn't completed, it means the IO",
            "            # Loop is stopped (such as when using",
            "            # 'salt.utils.asynchronous.SyncWrapper'). Ensure that",
            "            # _stream_return() completes by restarting the IO Loop.",
            "            # This will prevent potential errors on shutdown.",
            "            try:",
            "                orig_loop = salt.ext.tornado.ioloop.IOLoop.current()",
            "                self.io_loop.make_current()",
            "                self._stream.close()",
            "                if self._read_until_future is not None:",
            "                    # This will prevent this message from showing up:",
            "                    # '[ERROR   ] Future exception was never retrieved:",
            "                    # StreamClosedError'",
            "                    # This happens because the logic is always waiting to read",
            "                    # the next message and the associated read future is marked",
            "                    # 'StreamClosedError' when the stream is closed.",
            "                    if self._read_until_future.done():",
            "                        self._read_until_future.exception()",
            "                    if (",
            "                        self.io_loop",
            "                        != salt.ext.tornado.ioloop.IOLoop.current(instance=False)",
            "                        or not self._stream_return_future.done()",
            "                    ):",
            "                        self.io_loop.add_future(",
            "                            self._stream_return_future,",
            "                            lambda future: self._stop_io_loop(),",
            "                        )",
            "                        self.io_loop.start()",
            "            except Exception as e:  # pylint: disable=broad-except",
            "                log.info(\"Exception caught in SaltMessageClient.close: %s\", str(e))",
            "            finally:",
            "                orig_loop.make_current()",
            "        self._tcp_client.close()",
            "        self.io_loop = None",
            "        self._read_until_future = None",
            "        # Clear callback references to allow the object that they belong to",
            "        # to be deleted.",
            "        self.connect_callback = None",
            "        self.disconnect_callback = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def connect(self):",
            "        \"\"\"",
            "        Ask for this client to reconnect to the origin",
            "        \"\"\"",
            "        if hasattr(self, \"_connecting_future\") and not self._connecting_future.done():",
            "            future = self._connecting_future",
            "        else:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            self._connecting_future = future",
            "            self.io_loop.add_callback(self._connect)",
            "",
            "            # Add the callback only when a new future is created",
            "            if self.connect_callback is not None:",
            "",
            "                def handle_future(future):",
            "                    response = future.result()",
            "                    self.io_loop.add_callback(self.connect_callback, response)",
            "",
            "                future.add_done_callback(handle_future)",
            "",
            "        return future",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _connect(self):",
            "        \"\"\"",
            "        Try to connect for the rest of time!",
            "        \"\"\"",
            "        while True:",
            "            if self._closing:",
            "                break",
            "            try:",
            "                kwargs = {}",
            "                if self.source_ip or self.source_port:",
            "                    if salt.ext.tornado.version_info >= (4, 5):",
            "                        ### source_ip and source_port are supported only in Tornado >= 4.5",
            "                        # See http://www.tornadoweb.org/en/stable/releases/v4.5.0.html",
            "                        # Otherwise will just ignore these args",
            "                        kwargs = {",
            "                            \"source_ip\": self.source_ip,",
            "                            \"source_port\": self.source_port,",
            "                        }",
            "                    else:",
            "                        log.warning(",
            "                            \"If you need a certain source IP/port, consider upgrading Tornado >= 4.5\"",
            "                        )",
            "                with salt.utils.asynchronous.current_ioloop(self.io_loop):",
            "                    self._stream = yield self._tcp_client.connect(",
            "                        self.host, self.port, ssl_options=self.opts.get(\"ssl\"), **kwargs",
            "                    )",
            "                self._connecting_future.set_result(True)",
            "                break",
            "            except Exception as exc:  # pylint: disable=broad-except",
            "                log.warning(",
            "                    \"TCP Message Client encountered an exception while connecting to %s:%s: %r, will reconnect in %d seconds\",",
            "                    self.host,",
            "                    self.port,",
            "                    exc,",
            "                    self.backoff,",
            "                )",
            "                yield salt.ext.tornado.gen.sleep(self.backoff)",
            "                # self._connecting_future.set_exception(exc)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _stream_return(self):",
            "        try:",
            "            while not self._closing and (",
            "                not self._connecting_future.done()",
            "                or self._connecting_future.result() is not True",
            "            ):",
            "                yield self._connecting_future",
            "            unpacker = salt.utils.msgpack.Unpacker()",
            "            while not self._closing:",
            "                try:",
            "                    self._read_until_future = self._stream.read_bytes(",
            "                        4096, partial=True",
            "                    )",
            "                    wire_bytes = yield self._read_until_future",
            "                    unpacker.feed(wire_bytes)",
            "                    for framed_msg in unpacker:",
            "                        framed_msg = salt.transport.frame.decode_embedded_strs(",
            "                            framed_msg",
            "                        )",
            "                        header = framed_msg[\"head\"]",
            "                        body = framed_msg[\"body\"]",
            "                        message_id = header.get(\"mid\")",
            "",
            "                        if message_id in self.send_future_map:",
            "                            self.send_future_map.pop(message_id).set_result(body)",
            "                            self.remove_message_timeout(message_id)",
            "                        else:",
            "                            if self._on_recv is not None:",
            "                                self.io_loop.spawn_callback(self._on_recv, header, body)",
            "                            else:",
            "                                log.error(",
            "                                    \"Got response for message_id %s that we are not tracking\",",
            "                                    message_id,",
            "                                )",
            "                except salt.ext.tornado.iostream.StreamClosedError as e:",
            "                    log.debug(",
            "                        \"tcp stream to %s:%s closed, unable to recv\",",
            "                        self.host,",
            "                        self.port,",
            "                    )",
            "                    for future in self.send_future_map.values():",
            "                        future.set_exception(e)",
            "                    self.send_future_map = {}",
            "                    if self._closing:",
            "                        return",
            "                    if self.disconnect_callback:",
            "                        self.disconnect_callback()",
            "                    # if the last connect finished, then we need to make a new one",
            "                    if self._connecting_future.done():",
            "                        self._connecting_future = self.connect()",
            "                    yield self._connecting_future",
            "                except TypeError:",
            "                    # This is an invalid transport",
            "                    if \"detect_mode\" in self.opts:",
            "                        log.info(",
            "                            \"There was an error trying to use TCP transport; \"",
            "                            \"attempting to fallback to another transport\"",
            "                        )",
            "                    else:",
            "                        raise SaltClientError",
            "                except Exception as e:  # pylint: disable=broad-except",
            "                    log.error(\"Exception parsing response\", exc_info=True)",
            "                    for future in self.send_future_map.values():",
            "                        future.set_exception(e)",
            "                    self.send_future_map = {}",
            "                    if self._closing:",
            "                        return",
            "                    if self.disconnect_callback:",
            "                        self.disconnect_callback()",
            "                    # if the last connect finished, then we need to make a new one",
            "                    if self._connecting_future.done():",
            "                        self._connecting_future = self.connect()",
            "                    yield self._connecting_future",
            "        finally:",
            "            self._stream_return_future.set_result(True)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _stream_send(self):",
            "        while (",
            "            not self._connecting_future.done()",
            "            or self._connecting_future.result() is not True",
            "        ):",
            "            yield self._connecting_future",
            "        while len(self.send_queue) > 0:",
            "            message_id, item = self.send_queue[0]",
            "            try:",
            "                yield self._stream.write(item)",
            "                del self.send_queue[0]",
            "            # if the connection is dead, lets fail this send, and make sure we",
            "            # attempt to reconnect",
            "            except salt.ext.tornado.iostream.StreamClosedError as e:",
            "                if message_id in self.send_future_map:",
            "                    self.send_future_map.pop(message_id).set_exception(e)",
            "                self.remove_message_timeout(message_id)",
            "                del self.send_queue[0]",
            "                if self._closing:",
            "                    return",
            "                if self.disconnect_callback:",
            "                    self.disconnect_callback()",
            "                # if the last connect finished, then we need to make a new one",
            "                if self._connecting_future.done():",
            "                    self._connecting_future = self.connect()",
            "                yield self._connecting_future",
            "",
            "    def _message_id(self):",
            "        wrap = False",
            "        while self._mid in self.send_future_map:",
            "            if self._mid >= self._max_messages:",
            "                if wrap:",
            "                    # this shouldn't ever happen, but just in case",
            "                    raise Exception(\"Unable to find available messageid\")",
            "                self._mid = 1",
            "                wrap = True",
            "            else:",
            "                self._mid += 1",
            "",
            "        return self._mid",
            "",
            "    # TODO: return a message object which takes care of multiplexing?",
            "    def on_recv(self, callback):",
            "        \"\"\"",
            "        Register a callback for received messages (that we didn't initiate)",
            "        \"\"\"",
            "        if callback is None:",
            "            self._on_recv = callback",
            "        else:",
            "",
            "            def wrap_recv(header, body):",
            "                callback(body)",
            "",
            "            self._on_recv = wrap_recv",
            "",
            "    def remove_message_timeout(self, message_id):",
            "        if message_id not in self.send_timeout_map:",
            "            return",
            "        timeout = self.send_timeout_map.pop(message_id)",
            "        self.io_loop.remove_timeout(timeout)",
            "",
            "    def timeout_message(self, message_id, msg):",
            "        if message_id in self.send_timeout_map:",
            "            del self.send_timeout_map[message_id]",
            "        if message_id in self.send_future_map:",
            "            future = self.send_future_map.pop(message_id)",
            "            # In a race condition the message might have been sent by the time",
            "            # we're timing it out. Make sure the future is not None",
            "            if future is not None:",
            "                if future.attempts < future.tries:",
            "                    future.attempts += 1",
            "",
            "                    log.debug(",
            "                        \"SaltReqTimeoutError, retrying. (%s/%s)\",",
            "                        future.attempts,",
            "                        future.tries,",
            "                    )",
            "                    self.send(",
            "                        msg, timeout=future.timeout, tries=future.tries, future=future,",
            "                    )",
            "",
            "                else:",
            "                    future.set_exception(SaltReqTimeoutError(\"Message timed out\"))",
            "",
            "    def send(self, msg, timeout=None, callback=None, raw=False, future=None, tries=3):",
            "        \"\"\"",
            "        Send given message, and return a future",
            "        \"\"\"",
            "        message_id = self._message_id()",
            "        header = {\"mid\": message_id}",
            "",
            "        if future is None:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            future.tries = tries",
            "            future.attempts = 0",
            "            future.timeout = timeout",
            "",
            "        if callback is not None:",
            "",
            "            def handle_future(future):",
            "                response = future.result()",
            "                self.io_loop.add_callback(callback, response)",
            "",
            "            future.add_done_callback(handle_future)",
            "        # Add this future to the mapping",
            "        self.send_future_map[message_id] = future",
            "",
            "        if self.opts.get(\"detect_mode\") is True:",
            "            timeout = 1",
            "",
            "        if timeout is not None:",
            "            send_timeout = self.io_loop.call_later(",
            "                timeout, self.timeout_message, message_id, msg",
            "            )",
            "            self.send_timeout_map[message_id] = send_timeout",
            "",
            "        # if we don't have a send queue, we need to spawn the callback to do the sending",
            "        if len(self.send_queue) == 0:",
            "            self.io_loop.spawn_callback(self._stream_send)",
            "        self.send_queue.append(",
            "            (message_id, salt.transport.frame.frame_msg(msg, header=header))",
            "        )",
            "        return future",
            "",
            "",
            "class Subscriber:",
            "    \"\"\"",
            "    Client object for use with the TCP publisher server",
            "    \"\"\"",
            "",
            "    def __init__(self, stream, address):",
            "        self.stream = stream",
            "        self.address = address",
            "        self._closing = False",
            "        self._read_until_future = None",
            "        self.id_ = None",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if not self.stream.closed():",
            "            self.stream.close()",
            "            if self._read_until_future is not None and self._read_until_future.done():",
            "                # This will prevent this message from showing up:",
            "                # '[ERROR   ] Future exception was never retrieved:",
            "                # StreamClosedError'",
            "                # This happens because the logic is always waiting to read",
            "                # the next message and the associated read future is marked",
            "                # 'StreamClosedError' when the stream is closed.",
            "                self._read_until_future.exception()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "",
            "class PubServer(salt.ext.tornado.tcpserver.TCPServer):",
            "    \"\"\"",
            "    TCP publisher",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, io_loop=None):",
            "        super().__init__(ssl_options=opts.get(\"ssl\"))",
            "        self.io_loop = io_loop",
            "        self.opts = opts",
            "        self._closing = False",
            "        self.clients = set()",
            "        self.aes_funcs = salt.master.AESFuncs(self.opts)",
            "        self.present = {}",
            "        self.event = None",
            "        self.presence_events = False",
            "        if self.opts.get(\"presence_events\", False):",
            "            tcp_only = True",
            "            for transport, _ in iter_transport_opts(self.opts):",
            "                if transport != \"tcp\":",
            "                    tcp_only = False",
            "            if tcp_only:",
            "                # Only when the transport is TCP only, the presence events will",
            "                # be handled here. Otherwise, it will be handled in the",
            "                # 'Maintenance' process.",
            "                self.presence_events = True",
            "",
            "        if self.presence_events:",
            "            self.event = salt.utils.event.get_event(",
            "                \"master\", opts=self.opts, listen=False",
            "            )",
            "        else:",
            "            self.event = None",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "        self._closing = True",
            "        if self.event is not None:",
            "            self.event.destroy()",
            "            self.event = None",
            "        if self.aes_funcs is not None:",
            "            self.aes_funcs.destroy()",
            "            self.aes_funcs = None",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _add_client_present(self, client):",
            "        id_ = client.id_",
            "        if id_ in self.present:",
            "            clients = self.present[id_]",
            "            clients.add(client)",
            "        else:",
            "            self.present[id_] = {client}",
            "            if self.presence_events:",
            "                data = {\"new\": [id_], \"lost\": []}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"change\", \"presence\")",
            "                )",
            "                data = {\"present\": list(self.present.keys())}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"present\", \"presence\")",
            "                )",
            "",
            "    def _remove_client_present(self, client):",
            "        id_ = client.id_",
            "        if id_ is None or id_ not in self.present:",
            "            # This is possible if _remove_client_present() is invoked",
            "            # before the minion's id is validated.",
            "            return",
            "",
            "        clients = self.present[id_]",
            "        if client not in clients:",
            "            # Since _remove_client_present() is potentially called from",
            "            # _stream_read() and/or publish_payload(), it is possible for",
            "            # it to be called twice, in which case we will get here.",
            "            # This is not an abnormal case, so no logging is required.",
            "            return",
            "",
            "        clients.remove(client)",
            "        if len(clients) == 0:",
            "            del self.present[id_]",
            "            if self.presence_events:",
            "                data = {\"new\": [], \"lost\": [id_]}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"change\", \"presence\")",
            "                )",
            "                data = {\"present\": list(self.present.keys())}",
            "                self.event.fire_event(",
            "                    data, salt.utils.event.tagify(\"present\", \"presence\")",
            "                )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _stream_read(self, client):",
            "        unpacker = salt.utils.msgpack.Unpacker()",
            "        while not self._closing:",
            "            try:",
            "                client._read_until_future = client.stream.read_bytes(4096, partial=True)",
            "                wire_bytes = yield client._read_until_future",
            "                unpacker.feed(wire_bytes)",
            "                for framed_msg in unpacker:",
            "                    framed_msg = salt.transport.frame.decode_embedded_strs(framed_msg)",
            "                    body = framed_msg[\"body\"]",
            "                    if body[\"enc\"] != \"aes\":",
            "                        # We only accept 'aes' encoded messages for 'id'",
            "                        continue",
            "                    crypticle = salt.crypt.Crypticle(",
            "                        self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "                    )",
            "                    load = crypticle.loads(body[\"load\"])",
            "                    load = salt.transport.frame.decode_embedded_strs(load)",
            "                    if not self.aes_funcs.verify_minion(load[\"id\"], load[\"tok\"]):",
            "                        continue",
            "                    client.id_ = load[\"id\"]",
            "                    self._add_client_present(client)",
            "            except salt.ext.tornado.iostream.StreamClosedError as e:",
            "                log.debug(\"tcp stream to %s closed, unable to recv\", client.address)",
            "                client.close()",
            "                self._remove_client_present(client)",
            "                self.clients.discard(client)",
            "                break",
            "            except Exception as e:  # pylint: disable=broad-except",
            "                log.error(",
            "                    \"Exception parsing response from %s\", client.address, exc_info=True",
            "                )",
            "                continue",
            "",
            "    def handle_stream(self, stream, address):",
            "        log.trace(\"Subscriber at %s connected\", address)",
            "        client = Subscriber(stream, address)",
            "        self.clients.add(client)",
            "        self.io_loop.spawn_callback(self._stream_read, client)",
            "",
            "    # TODO: ACK the publish through IPC",
            "    @salt.ext.tornado.gen.coroutine",
            "    def publish_payload(self, package, _):",
            "        log.debug(\"TCP PubServer sending payload: %s\", package)",
            "        payload = salt.transport.frame.frame_msg(package[\"payload\"])",
            "",
            "        to_remove = []",
            "        if \"topic_lst\" in package:",
            "            topic_lst = package[\"topic_lst\"]",
            "            for topic in topic_lst:",
            "                if topic in self.present:",
            "                    # This will rarely be a list of more than 1 item. It will",
            "                    # be more than 1 item if the minion disconnects from the",
            "                    # master in an unclean manner (eg cable yank), then",
            "                    # restarts and the master is yet to detect the disconnect",
            "                    # via TCP keep-alive.",
            "                    for client in self.present[topic]:",
            "                        try:",
            "                            # Write the packed str",
            "                            f = client.stream.write(payload)",
            "                            self.io_loop.add_future(f, lambda f: True)",
            "                        except salt.ext.tornado.iostream.StreamClosedError:",
            "                            to_remove.append(client)",
            "                else:",
            "                    log.debug(\"Publish target %s not connected\", topic)",
            "        else:",
            "            for client in self.clients:",
            "                try:",
            "                    # Write the packed str",
            "                    f = client.stream.write(payload)",
            "                    self.io_loop.add_future(f, lambda f: True)",
            "                except salt.ext.tornado.iostream.StreamClosedError:",
            "                    to_remove.append(client)",
            "        for client in to_remove:",
            "            log.debug(",
            "                \"Subscriber at %s has disconnected from publisher\", client.address",
            "            )",
            "            client.close()",
            "            self._remove_client_present(client)",
            "            self.clients.discard(client)",
            "        log.trace(\"TCP PubServer finished publishing payload\")",
            "",
            "",
            "class TCPPubServerChannel(salt.transport.server.PubServerChannel):",
            "    # TODO: opts!",
            "    # Based on default used in salt.ext.tornado.netutil.bind_sockets()",
            "    backlog = 128",
            "",
            "    def __init__(self, opts):",
            "        self.opts = opts",
            "        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?",
            "        self.ckminions = salt.utils.minions.CkMinions(opts)",
            "        self.io_loop = None",
            "",
            "    def __setstate__(self, state):",
            "        salt.master.SMaster.secrets = state[\"secrets\"]",
            "        self.__init__(state[\"opts\"])",
            "",
            "    def __getstate__(self):",
            "        return {\"opts\": self.opts, \"secrets\": salt.master.SMaster.secrets}",
            "",
            "    def _publish_daemon(self, **kwargs):",
            "        \"\"\"",
            "        Bind to the interface specified in the configuration file",
            "        \"\"\"",
            "        salt.utils.process.appendproctitle(self.__class__.__name__)",
            "",
            "        log_queue = kwargs.get(\"log_queue\")",
            "        if log_queue is not None:",
            "            salt.log.setup.set_multiprocessing_logging_queue(log_queue)",
            "        log_queue_level = kwargs.get(\"log_queue_level\")",
            "        if log_queue_level is not None:",
            "            salt.log.setup.set_multiprocessing_logging_level(log_queue_level)",
            "        salt.log.setup.setup_multiprocessing_logging(log_queue)",
            "",
            "        # Check if io_loop was set outside",
            "        if self.io_loop is None:",
            "            self.io_loop = salt.ext.tornado.ioloop.IOLoop.current()",
            "",
            "        # Spin up the publisher",
            "        pub_server = PubServer(self.opts, io_loop=self.io_loop)",
            "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)",
            "        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)",
            "        _set_tcp_keepalive(sock, self.opts)",
            "        sock.setblocking(0)",
            "        sock.bind((self.opts[\"interface\"], int(self.opts[\"publish_port\"])))",
            "        sock.listen(self.backlog)",
            "        # pub_server will take ownership of the socket",
            "        pub_server.add_socket(sock)",
            "",
            "        # Set up Salt IPC server",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = int(self.opts.get(\"tcp_master_publish_pull\", 4514))",
            "        else:",
            "            pull_uri = os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "",
            "        pull_sock = salt.transport.ipc.IPCMessageServer(",
            "            pull_uri, io_loop=self.io_loop, payload_handler=pub_server.publish_payload,",
            "        )",
            "",
            "        # Securely create socket",
            "        log.info(\"Starting the Salt Puller on %s\", pull_uri)",
            "        with salt.utils.files.set_umask(0o177):",
            "            pull_sock.start()",
            "",
            "        # run forever",
            "        try:",
            "            self.io_loop.start()",
            "        except (KeyboardInterrupt, SystemExit):",
            "            salt.log.setup.shutdown_multiprocessing_logging()",
            "        finally:",
            "            pull_sock.close()",
            "",
            "    def pre_fork(self, process_manager, kwargs=None):",
            "        \"\"\"",
            "        Do anything necessary pre-fork. Since this is on the master side this will",
            "        primarily be used to create IPC channels and create our daemon process to",
            "        do the actual publishing",
            "        \"\"\"",
            "        process_manager.add_process(self._publish_daemon, kwargs=kwargs)",
            "",
            "    def publish(self, load):",
            "        \"\"\"",
            "        Publish \"load\" to minions",
            "        \"\"\"",
            "        payload = {\"enc\": \"aes\"}",
            "",
            "        crypticle = salt.crypt.Crypticle(",
            "            self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "        )",
            "        payload[\"load\"] = crypticle.dumps(load)",
            "        if self.opts[\"sign_pub_messages\"]:",
            "            master_pem_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "            log.debug(\"Signing data packet\")",
            "            payload[\"sig\"] = salt.crypt.sign_message(master_pem_path, payload[\"load\"])",
            "        # Use the Salt IPC server",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = int(self.opts.get(\"tcp_master_publish_pull\", 4514))",
            "        else:",
            "            pull_uri = os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "        # TODO: switch to the actual asynchronous interface",
            "        # pub_sock = salt.transport.ipc.IPCMessageClient(self.opts, io_loop=self.io_loop)",
            "        pub_sock = salt.utils.asynchronous.SyncWrapper(",
            "            salt.transport.ipc.IPCMessageClient, (pull_uri,), loop_kwarg=\"io_loop\",",
            "        )",
            "        pub_sock.connect()",
            "",
            "        int_payload = {\"payload\": self.serial.dumps(payload)}",
            "",
            "        # add some targeting stuff for lists only (for now)",
            "        if load[\"tgt_type\"] == \"list\" and not self.opts.get(\"order_masters\", False):",
            "            if isinstance(load[\"tgt\"], str):",
            "                # Fetch a list of minions that match",
            "                _res = self.ckminions.check_minions(",
            "                    load[\"tgt\"], tgt_type=load[\"tgt_type\"]",
            "                )",
            "                match_ids = _res[\"minions\"]",
            "",
            "                log.debug(\"Publish Side Match: %s\", match_ids)",
            "                # Send list of miions thru so zmq can target them",
            "                int_payload[\"topic_lst\"] = match_ids",
            "            else:",
            "                int_payload[\"topic_lst\"] = load[\"tgt\"]",
            "        # Send it over IPC!",
            "        pub_sock.send(int_payload)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "390": [
                "AsyncTCPReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "391": [
                "AsyncTCPReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "392": [
                "AsyncTCPReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "836": [
                "TCPReqServerChannel",
                "handle_message"
            ]
        },
        "addLocation": [
            "salt.transport.tcp.AsyncTCPReqChannel.crypted_transfer_decode_dictentry",
            "salt.transport.tcp.AsyncTCPReqChannel._uncrypted_transfer",
            "helpdesk.models.FollowUp"
        ]
    },
    "salt/transport/zeromq.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " import signal"
            },
            "1": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " import sys"
            },
            "2": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " import threading"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 12,
                "PatchRowcode": "+import uuid"
            },
            "4": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 13,
                "PatchRowcode": " import weakref"
            },
            "5": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " from random import randint"
            },
            "6": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 338,
                "PatchRowcode": "         return {"
            },
            "8": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 339,
                "PatchRowcode": "             \"enc\": self.crypt,"
            },
            "9": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 340,
                "PatchRowcode": "             \"load\": load,"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+            \"version\": 2,"
            },
            "11": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": 342,
                "PatchRowcode": "         }"
            },
            "12": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": 343,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 344,
                "PatchRowcode": "     @salt.ext.tornado.gen.coroutine"
            },
            "14": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": 345,
                "PatchRowcode": "     def crypted_transfer_decode_dictentry("
            },
            "15": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 346,
                "PatchRowcode": "         self, load, dictkey=None, tries=3, timeout=60"
            },
            "16": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": 347,
                "PatchRowcode": "     ):"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 348,
                "PatchRowcode": "+        nonce = uuid.uuid4().hex"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 349,
                "PatchRowcode": "+        load[\"nonce\"] = nonce"
            },
            "19": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 350,
                "PatchRowcode": "         if not self.auth.authenticated:"
            },
            "20": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": 351,
                "PatchRowcode": "             # Return control back to the caller, continue when authentication succeeds"
            },
            "21": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": 352,
                "PatchRowcode": "             yield self.auth.authenticate()"
            },
            "22": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # Return control to the caller. When send() completes, resume by populating ret with the Future.result"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+        # Return control to the caller. When send() completes, resume by"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+        # populating ret with the Future.result"
            },
            "26": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 356,
                "PatchRowcode": "         ret = yield self.message_client.send("
            },
            "27": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": 357,
                "PatchRowcode": "             self._package_load(self.auth.crypticle.dumps(load)),"
            },
            "28": {
                "beforePatchRowNumber": 352,
                "afterPatchRowNumber": 358,
                "PatchRowcode": "             timeout=timeout,"
            },
            "29": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 359,
                "PatchRowcode": "             tries=tries,"
            },
            "30": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 360,
                "PatchRowcode": "         )"
            },
            "31": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        key = self.auth.get_keys()"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": 362,
                "PatchRowcode": "         if \"key\" not in ret:"
            },
            "34": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": 363,
                "PatchRowcode": "             # Reauth in the case our key is deleted on the master side."
            },
            "35": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 364,
                "PatchRowcode": "             yield self.auth.authenticate()"
            },
            "36": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": 367,
                "PatchRowcode": "                 timeout=timeout,"
            },
            "37": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": 368,
                "PatchRowcode": "                 tries=tries,"
            },
            "38": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": 369,
                "PatchRowcode": "             )"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 371,
                "PatchRowcode": "+        key = self.auth.get_keys()"
            },
            "41": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": 372,
                "PatchRowcode": "         if HAS_M2:"
            },
            "42": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 373,
                "PatchRowcode": "             aes = key.private_decrypt(ret[\"key\"], RSA.pkcs1_oaep_padding)"
            },
            "43": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "         else:"
            },
            "44": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 375,
                "PatchRowcode": "             cipher = PKCS1_OAEP.new(key)"
            },
            "45": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": 376,
                "PatchRowcode": "             aes = cipher.decrypt(ret[\"key\"])"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 377,
                "PatchRowcode": "+"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 378,
                "PatchRowcode": "+        # Decrypt using the public key."
            },
            "48": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": 379,
                "PatchRowcode": "         pcrypt = salt.crypt.Crypticle(self.opts, aes)"
            },
            "49": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        data = pcrypt.loads(ret[dictkey])"
            },
            "50": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        data = salt.transport.frame.decode_embedded_strs(data)"
            },
            "51": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        raise salt.ext.tornado.gen.Return(data)"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 380,
                "PatchRowcode": "+        signed_msg = pcrypt.loads(ret[dictkey])"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 381,
                "PatchRowcode": "+"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 382,
                "PatchRowcode": "+        # Validate the master's signature."
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 383,
                "PatchRowcode": "+        master_pubkey_path = os.path.join(self.opts[\"pki_dir\"], \"minion_master.pub\")"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 384,
                "PatchRowcode": "+        if not salt.crypt.verify_signature("
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 385,
                "PatchRowcode": "+            master_pubkey_path, signed_msg[\"data\"], signed_msg[\"sig\"]"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 386,
                "PatchRowcode": "+        ):"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 387,
                "PatchRowcode": "+            raise salt.crypt.AuthenticationError("
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 388,
                "PatchRowcode": "+                \"Pillar payload signature failed to validate.\""
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 389,
                "PatchRowcode": "+            )"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 390,
                "PatchRowcode": "+"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 391,
                "PatchRowcode": "+        # Make sure the signed key matches the key we used to decrypt the data."
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 392,
                "PatchRowcode": "+        data = salt.payload.Serial({}).loads(signed_msg[\"data\"])"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 393,
                "PatchRowcode": "+        if data[\"key\"] != ret[\"key\"]:"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 394,
                "PatchRowcode": "+            raise salt.crypt.AuthenticationError(\"Key verification failed.\")"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 395,
                "PatchRowcode": "+"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 396,
                "PatchRowcode": "+        # Validate the nonce."
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 397,
                "PatchRowcode": "+        if data[\"nonce\"] != nonce:"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 398,
                "PatchRowcode": "+            raise salt.crypt.AuthenticationError(\"Pillar nonce verification failed.\")"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 399,
                "PatchRowcode": "+        raise salt.ext.tornado.gen.Return(data[\"pillar\"])"
            },
            "72": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": 400,
                "PatchRowcode": " "
            },
            "73": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": 401,
                "PatchRowcode": "     @salt.ext.tornado.gen.coroutine"
            },
            "74": {
                "beforePatchRowNumber": 375,
                "afterPatchRowNumber": 402,
                "PatchRowcode": "     def _crypted_transfer(self, load, tries=3, timeout=60, raw=False):"
            },
            "75": {
                "beforePatchRowNumber": 862,
                "afterPatchRowNumber": 889,
                "PatchRowcode": "             )"
            },
            "76": {
                "beforePatchRowNumber": 863,
                "afterPatchRowNumber": 890,
                "PatchRowcode": "             raise salt.ext.tornado.gen.Return()"
            },
            "77": {
                "beforePatchRowNumber": 864,
                "afterPatchRowNumber": 891,
                "PatchRowcode": " "
            },
            "78": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 892,
                "PatchRowcode": "+        version = 0"
            },
            "79": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 893,
                "PatchRowcode": "+        if \"version\" in payload:"
            },
            "80": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 894,
                "PatchRowcode": "+            version = payload[\"version\"]"
            },
            "81": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 895,
                "PatchRowcode": "+"
            },
            "82": {
                "beforePatchRowNumber": 865,
                "afterPatchRowNumber": 896,
                "PatchRowcode": "         # intercept the \"_auth\" commands, since the main daemon shouldn't know"
            },
            "83": {
                "beforePatchRowNumber": 866,
                "afterPatchRowNumber": 897,
                "PatchRowcode": "         # anything about our key auth"
            },
            "84": {
                "beforePatchRowNumber": 867,
                "afterPatchRowNumber": 898,
                "PatchRowcode": "         if payload[\"enc\"] == \"clear\" and payload.get(\"load\", {}).get(\"cmd\") == \"_auth\":"
            },
            "85": {
                "beforePatchRowNumber": 885,
                "afterPatchRowNumber": 916,
                "PatchRowcode": "         elif req_fun == \"send\":"
            },
            "86": {
                "beforePatchRowNumber": 886,
                "afterPatchRowNumber": 917,
                "PatchRowcode": "             stream.send(self.serial.dumps(self.crypticle.dumps(ret)))"
            },
            "87": {
                "beforePatchRowNumber": 887,
                "afterPatchRowNumber": 918,
                "PatchRowcode": "         elif req_fun == \"send_private\":"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 919,
                "PatchRowcode": "+            sign_messages = False"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 920,
                "PatchRowcode": "+            nonce = None"
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 921,
                "PatchRowcode": "+            if version > 1:"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 922,
                "PatchRowcode": "+                sign_messages = True"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 923,
                "PatchRowcode": "+                nonce = payload[\"load\"][\"nonce\"]"
            },
            "93": {
                "beforePatchRowNumber": 888,
                "afterPatchRowNumber": 924,
                "PatchRowcode": "             stream.send("
            },
            "94": {
                "beforePatchRowNumber": 889,
                "afterPatchRowNumber": 925,
                "PatchRowcode": "                 self.serial.dumps("
            },
            "95": {
                "beforePatchRowNumber": 890,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    self._encrypt_private(ret, req_opts[\"key\"], req_opts[\"tgt\"],)"
            },
            "96": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 926,
                "PatchRowcode": "+                    self._encrypt_private("
            },
            "97": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 927,
                "PatchRowcode": "+                        ret, req_opts[\"key\"], req_opts[\"tgt\"], nonce, sign_messages,"
            },
            "98": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 928,
                "PatchRowcode": "+                    )"
            },
            "99": {
                "beforePatchRowNumber": 891,
                "afterPatchRowNumber": 929,
                "PatchRowcode": "                 )"
            },
            "100": {
                "beforePatchRowNumber": 892,
                "afterPatchRowNumber": 930,
                "PatchRowcode": "             )"
            },
            "101": {
                "beforePatchRowNumber": 893,
                "afterPatchRowNumber": 931,
                "PatchRowcode": "         else:"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Zeromq transport classes",
            "\"\"\"",
            "import copy",
            "import errno",
            "import hashlib",
            "import logging",
            "import os",
            "import signal",
            "import sys",
            "import threading",
            "import weakref",
            "from random import randint",
            "",
            "import salt.auth",
            "import salt.crypt",
            "import salt.ext.tornado",
            "import salt.ext.tornado.concurrent",
            "import salt.ext.tornado.gen",
            "import salt.ext.tornado.ioloop",
            "import salt.log.setup",
            "import salt.payload",
            "import salt.transport.client",
            "import salt.transport.mixins.auth",
            "import salt.transport.server",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.minions",
            "import salt.utils.process",
            "import salt.utils.stringutils",
            "import salt.utils.verify",
            "import salt.utils.versions",
            "import salt.utils.zeromq",
            "import zmq.error",
            "import zmq.eventloop.ioloop",
            "import zmq.eventloop.zmqstream",
            "from salt._compat import ipaddress",
            "from salt.exceptions import SaltException, SaltReqTimeoutError",
            "from salt.utils.zeromq import (",
            "    LIBZMQ_VERSION_INFO,",
            "    ZMQ_VERSION_INFO,",
            "    ZMQDefaultLoop,",
            "    install_zmq,",
            "    zmq,",
            ")",
            "",
            "try:",
            "    import zmq.utils.monitor",
            "",
            "    HAS_ZMQ_MONITOR = True",
            "except ImportError:",
            "    HAS_ZMQ_MONITOR = False",
            "",
            "",
            "try:",
            "    from M2Crypto import RSA",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "    try:",
            "        from Cryptodome.Cipher import PKCS1_OAEP",
            "    except ImportError:",
            "        from Crypto.Cipher import PKCS1_OAEP  # nosec",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def _get_master_uri(master_ip, master_port, source_ip=None, source_port=None):",
            "    \"\"\"",
            "    Return the ZeroMQ URI to connect the Minion to the Master.",
            "    It supports different source IP / port, given the ZeroMQ syntax:",
            "    // Connecting using a IP address and bind to an IP address",
            "    rc = zmq_connect(socket, \"tcp://192.168.1.17:5555;192.168.1.1:5555\"); assert (rc == 0);",
            "    Source: http://api.zeromq.org/4-1:zmq-tcp",
            "    \"\"\"",
            "    from salt.utils.zeromq import ip_bracket",
            "",
            "    master_uri = \"tcp://{master_ip}:{master_port}\".format(",
            "        master_ip=ip_bracket(master_ip), master_port=master_port",
            "    )",
            "",
            "    if source_ip or source_port:",
            "        if LIBZMQ_VERSION_INFO >= (4, 1, 6) and ZMQ_VERSION_INFO >= (16, 0, 1):",
            "            # The source:port syntax for ZeroMQ has been added in libzmq 4.1.6",
            "            # which is included in the pyzmq wheels starting with 16.0.1.",
            "            if source_ip and source_port:",
            "                master_uri = \"tcp://{source_ip}:{source_port};{master_ip}:{master_port}\".format(",
            "                    source_ip=ip_bracket(source_ip),",
            "                    source_port=source_port,",
            "                    master_ip=ip_bracket(master_ip),",
            "                    master_port=master_port,",
            "                )",
            "            elif source_ip and not source_port:",
            "                master_uri = \"tcp://{source_ip}:0;{master_ip}:{master_port}\".format(",
            "                    source_ip=ip_bracket(source_ip),",
            "                    master_ip=ip_bracket(master_ip),",
            "                    master_port=master_port,",
            "                )",
            "            elif source_port and not source_ip:",
            "                ip_any = (",
            "                    \"0.0.0.0\"",
            "                    if ipaddress.ip_address(master_ip).version == 4",
            "                    else ip_bracket(\"::\")",
            "                )",
            "                master_uri = \"tcp://{ip_any}:{source_port};{master_ip}:{master_port}\".format(",
            "                    ip_any=ip_any,",
            "                    source_port=source_port,",
            "                    master_ip=ip_bracket(master_ip),",
            "                    master_port=master_port,",
            "                )",
            "        else:",
            "            log.warning(",
            "                \"Unable to connect to the Master using a specific source IP / port\"",
            "            )",
            "            log.warning(\"Consider upgrading to pyzmq >= 16.0.1 and libzmq >= 4.1.6\")",
            "            log.warning(",
            "                \"Specific source IP / port for connecting to master returner port: configuraion ignored\"",
            "            )",
            "",
            "    return master_uri",
            "",
            "",
            "class AsyncZeroMQReqChannel(salt.transport.client.ReqChannel):",
            "    \"\"\"",
            "    Encapsulate sending routines to ZeroMQ.",
            "",
            "    ZMQ Channels default to 'crypt=aes'",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    # mapping of io_loop -> {key -> channel}",
            "    instance_map = weakref.WeakKeyDictionary()",
            "    async_methods = [",
            "        \"crypted_transfer_decode_dictentry\",",
            "        \"_crypted_transfer\",",
            "        \"_do_transfer\",",
            "        \"_uncrypted_transfer\",",
            "        \"send\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __new__(cls, opts, **kwargs):",
            "        \"\"\"",
            "        Only create one instance of channel per __key()",
            "        \"\"\"",
            "",
            "        # do we have any mapping for this io_loop",
            "        io_loop = kwargs.get(\"io_loop\")",
            "        if io_loop is None:",
            "            install_zmq()",
            "            io_loop = ZMQDefaultLoop.current()",
            "        if io_loop not in cls.instance_map:",
            "            cls.instance_map[io_loop] = weakref.WeakValueDictionary()",
            "        loop_instance_map = cls.instance_map[io_loop]",
            "",
            "        key = cls.__key(opts, **kwargs)",
            "        obj = loop_instance_map.get(key)",
            "        if obj is None:",
            "            log.debug(\"Initializing new AsyncZeroMQReqChannel for %s\", key)",
            "            # we need to make a local variable for this, as we are going to store",
            "            # it in a WeakValueDictionary-- which will remove the item if no one",
            "            # references it-- this forces a reference while we return to the caller",
            "            obj = object.__new__(cls)",
            "            obj.__singleton_init__(opts, **kwargs)",
            "            obj._instance_key = key",
            "            loop_instance_map[key] = obj",
            "            obj._refcount = 1",
            "            obj._refcount_lock = threading.RLock()",
            "            log.trace(",
            "                \"Inserted key into loop_instance_map id %s for key %s and process %s\",",
            "                id(loop_instance_map),",
            "                key,",
            "                os.getpid(),",
            "            )",
            "        else:",
            "            with obj._refcount_lock:",
            "                obj._refcount += 1",
            "            log.debug(\"Re-using AsyncZeroMQReqChannel for %s\", key)",
            "        return obj",
            "",
            "    def __deepcopy__(self, memo):",
            "        cls = self.__class__",
            "        # pylint: disable=too-many-function-args",
            "        result = cls.__new__(cls, copy.deepcopy(self.opts, memo))",
            "        # pylint: enable=too-many-function-args",
            "        memo[id(self)] = result",
            "        for key in self.__dict__:",
            "            if key in (\"_io_loop\", \"_refcount\", \"_refcount_lock\"):",
            "                continue",
            "                # The _io_loop has a thread Lock which will fail to be deep",
            "                # copied. Skip it because it will just be recreated on the",
            "                # new copy.",
            "            if key == \"message_client\":",
            "                # Recreate the message client because it will fail to be deep",
            "                # copied. The reason is the same as the io_loop skip above.",
            "                setattr(",
            "                    result,",
            "                    key,",
            "                    AsyncReqMessageClientPool(",
            "                        result.opts,",
            "                        args=(result.opts, self.master_uri,),",
            "                        kwargs={\"io_loop\": self._io_loop},",
            "                    ),",
            "                )",
            "",
            "                continue",
            "            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))",
            "        return result",
            "",
            "    @classmethod",
            "    def force_close_all_instances(cls):",
            "        \"\"\"",
            "        Will force close all instances",
            "",
            "        ZMQ can hang on quit if left to deconstruct on its own.",
            "        This because is deconstructs out of order.",
            "",
            "        :return: None",
            "        \"\"\"",
            "        for weak_dict in list(cls.instance_map.values()):",
            "            for instance in list(weak_dict.values()):",
            "                instance.close()",
            "",
            "    @classmethod",
            "    def __key(cls, opts, **kwargs):",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            kwargs.get(\"master_uri\", opts.get(\"master_uri\")),  # master ID",
            "            kwargs.get(\"crypt\", \"aes\"),  # TODO: use the same channel for crypt",
            "        )",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, **kwargs):",
            "        pass",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, **kwargs):",
            "        self.opts = dict(opts)",
            "        self.ttype = \"zeromq\"",
            "",
            "        # crypt defaults to 'aes'",
            "        self.crypt = kwargs.get(\"crypt\", \"aes\")",
            "",
            "        if \"master_uri\" in kwargs:",
            "            self.opts[\"master_uri\"] = kwargs[\"master_uri\"]",
            "",
            "        self._io_loop = kwargs.get(\"io_loop\")",
            "        if self._io_loop is None:",
            "            install_zmq()",
            "            self._io_loop = ZMQDefaultLoop.current()",
            "",
            "        if self.crypt != \"clear\":",
            "            # we don't need to worry about auth as a kwarg, since its a singleton",
            "            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self._io_loop)",
            "        log.debug(",
            "            \"Connecting the Minion to the Master URI (for the return server): %s\",",
            "            self.master_uri,",
            "        )",
            "        self.message_client = AsyncReqMessageClientPool(",
            "            self.opts,",
            "            args=(self.opts, self.master_uri,),",
            "            kwargs={\"io_loop\": self._io_loop},",
            "        )",
            "        self._closing = False",
            "",
            "    def close(self):",
            "        \"\"\"",
            "        Since the message_client creates sockets and assigns them to the IOLoop we have to",
            "        specifically destroy them, since we aren't the only ones with references to the FDs",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "",
            "        if self._refcount > 1:",
            "            # Decrease refcount",
            "            with self._refcount_lock:",
            "                self._refcount -= 1",
            "            log.debug(",
            "                \"This is not the last %s instance. Not closing yet.\",",
            "                self.__class__.__name__,",
            "            )",
            "            return",
            "",
            "        log.debug(\"Closing %s instance\", self.__class__.__name__)",
            "        self._closing = True",
            "        if hasattr(self, \"message_client\"):",
            "            self.message_client.close()",
            "",
            "        # Remove the entry from the instance map so that a closed entry may not",
            "        # be reused.",
            "        # This forces this operation even if the reference count of the entry",
            "        # has not yet gone to zero.",
            "        if self._io_loop in self.__class__.instance_map:",
            "            loop_instance_map = self.__class__.instance_map[self._io_loop]",
            "            if self._instance_key in loop_instance_map:",
            "                del loop_instance_map[self._instance_key]",
            "            if not loop_instance_map:",
            "                del self.__class__.instance_map[self._io_loop]",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        with self._refcount_lock:",
            "            # Make sure we actually close no matter if something",
            "            # went wrong with our ref counting",
            "            self._refcount = 1",
            "        try:",
            "            self.close()",
            "        except OSError as exc:",
            "            if exc.errno != errno.EBADF:",
            "                # If its not a bad file descriptor error, raise",
            "                raise",
            "",
            "    # pylint: enable=W1701",
            "",
            "    @property",
            "    def master_uri(self):",
            "        if \"master_uri\" in self.opts:",
            "            return self.opts[\"master_uri\"]",
            "",
            "        # if by chance master_uri is not there..",
            "        if \"master_ip\" in self.opts:",
            "            return _get_master_uri(",
            "                self.opts[\"master_ip\"],",
            "                self.opts[\"master_port\"],",
            "                source_ip=self.opts.get(\"source_ip\"),",
            "                source_port=self.opts.get(\"source_ret_port\"),",
            "            )",
            "",
            "        # if we've reached here something is very abnormal",
            "        raise SaltException(\"ReqChannel: missing master_uri/master_ip in self.opts\")",
            "",
            "    def _package_load(self, load):",
            "        return {",
            "            \"enc\": self.crypt,",
            "            \"load\": load,",
            "        }",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def crypted_transfer_decode_dictentry(",
            "        self, load, dictkey=None, tries=3, timeout=60",
            "    ):",
            "        if not self.auth.authenticated:",
            "            # Return control back to the caller, continue when authentication succeeds",
            "            yield self.auth.authenticate()",
            "        # Return control to the caller. When send() completes, resume by populating ret with the Future.result",
            "        ret = yield self.message_client.send(",
            "            self._package_load(self.auth.crypticle.dumps(load)),",
            "            timeout=timeout,",
            "            tries=tries,",
            "        )",
            "        key = self.auth.get_keys()",
            "        if \"key\" not in ret:",
            "            # Reauth in the case our key is deleted on the master side.",
            "            yield self.auth.authenticate()",
            "            ret = yield self.message_client.send(",
            "                self._package_load(self.auth.crypticle.dumps(load)),",
            "                timeout=timeout,",
            "                tries=tries,",
            "            )",
            "        if HAS_M2:",
            "            aes = key.private_decrypt(ret[\"key\"], RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(key)",
            "            aes = cipher.decrypt(ret[\"key\"])",
            "        pcrypt = salt.crypt.Crypticle(self.opts, aes)",
            "        data = pcrypt.loads(ret[dictkey])",
            "        data = salt.transport.frame.decode_embedded_strs(data)",
            "        raise salt.ext.tornado.gen.Return(data)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _crypted_transfer(self, load, tries=3, timeout=60, raw=False):",
            "        \"\"\"",
            "        Send a load across the wire, with encryption",
            "",
            "        In case of authentication errors, try to renegotiate authentication",
            "        and retry the method.",
            "",
            "        Indeed, we can fail too early in case of a master restart during a",
            "        minion state execution call",
            "",
            "        :param dict load: A load to send across the wire",
            "        :param int tries: The number of times to make before failure",
            "        :param int timeout: The number of seconds on a response before failing",
            "        \"\"\"",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def _do_transfer():",
            "            # Yield control to the caller. When send() completes, resume by populating data with the Future.result",
            "            data = yield self.message_client.send(",
            "                self._package_load(self.auth.crypticle.dumps(load)),",
            "                timeout=timeout,",
            "                tries=tries,",
            "            )",
            "            # we may not have always data",
            "            # as for example for saltcall ret submission, this is a blind",
            "            # communication, we do not subscribe to return events, we just",
            "            # upload the results to the master",
            "            if data:",
            "                data = self.auth.crypticle.loads(data, raw)",
            "            if not raw:",
            "                data = salt.transport.frame.decode_embedded_strs(data)",
            "            raise salt.ext.tornado.gen.Return(data)",
            "",
            "        if not self.auth.authenticated:",
            "            # Return control back to the caller, resume when authentication succeeds",
            "            yield self.auth.authenticate()",
            "        try:",
            "            # We did not get data back the first time. Retry.",
            "            ret = yield _do_transfer()",
            "        except salt.crypt.AuthenticationError:",
            "            # If auth error, return control back to the caller, continue when authentication succeeds",
            "            yield self.auth.authenticate()",
            "            ret = yield _do_transfer()",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _uncrypted_transfer(self, load, tries=3, timeout=60):",
            "        \"\"\"",
            "        Send a load across the wire in cleartext",
            "",
            "        :param dict load: A load to send across the wire",
            "        :param int tries: The number of times to make before failure",
            "        :param int timeout: The number of seconds on a response before failing",
            "        \"\"\"",
            "        ret = yield self.message_client.send(",
            "            self._package_load(load), timeout=timeout, tries=tries,",
            "        )",
            "",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def send(self, load, tries=3, timeout=60, raw=False):",
            "        \"\"\"",
            "        Send a request, return a future which will complete when we send the message",
            "        \"\"\"",
            "        if self.crypt == \"clear\":",
            "            ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)",
            "        else:",
            "            ret = yield self._crypted_transfer(",
            "                load, tries=tries, timeout=timeout, raw=raw",
            "            )",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "",
            "class AsyncZeroMQPubChannel(",
            "    salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel",
            "):",
            "    \"\"\"",
            "    A transport channel backed by ZeroMQ for a Salt Publisher to use to",
            "    publish commands to connected minions",
            "    \"\"\"",
            "",
            "    async_methods = [",
            "        \"connect\",",
            "        \"_decode_messages\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __init__(self, opts, **kwargs):",
            "        self.opts = opts",
            "        self.ttype = \"zeromq\"",
            "        self.io_loop = kwargs.get(\"io_loop\")",
            "        self._closing = False",
            "",
            "        if self.io_loop is None:",
            "            install_zmq()",
            "            self.io_loop = ZMQDefaultLoop.current()",
            "",
            "        self.hexid = hashlib.sha1(",
            "            salt.utils.stringutils.to_bytes(self.opts[\"id\"])",
            "        ).hexdigest()",
            "        self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.context = zmq.Context()",
            "        self._socket = self.context.socket(zmq.SUB)",
            "",
            "        if self.opts[\"zmq_filtering\"]:",
            "            # TODO: constants file for \"broadcast\"",
            "            self._socket.setsockopt(zmq.SUBSCRIBE, b\"broadcast\")",
            "            if self.opts.get(\"__role\") == \"syndic\":",
            "                self._socket.setsockopt(zmq.SUBSCRIBE, b\"syndic\")",
            "            else:",
            "                self._socket.setsockopt(",
            "                    zmq.SUBSCRIBE, salt.utils.stringutils.to_bytes(self.hexid)",
            "                )",
            "        else:",
            "            self._socket.setsockopt(zmq.SUBSCRIBE, b\"\")",
            "",
            "        self._socket.setsockopt(",
            "            zmq.IDENTITY, salt.utils.stringutils.to_bytes(self.opts[\"id\"])",
            "        )",
            "",
            "        # TODO: cleanup all the socket opts stuff",
            "        if hasattr(zmq, \"TCP_KEEPALIVE\"):",
            "            self._socket.setsockopt(zmq.TCP_KEEPALIVE, self.opts[\"tcp_keepalive\"])",
            "            self._socket.setsockopt(",
            "                zmq.TCP_KEEPALIVE_IDLE, self.opts[\"tcp_keepalive_idle\"]",
            "            )",
            "            self._socket.setsockopt(",
            "                zmq.TCP_KEEPALIVE_CNT, self.opts[\"tcp_keepalive_cnt\"]",
            "            )",
            "            self._socket.setsockopt(",
            "                zmq.TCP_KEEPALIVE_INTVL, self.opts[\"tcp_keepalive_intvl\"]",
            "            )",
            "",
            "        recon_delay = self.opts[\"recon_default\"]",
            "",
            "        if self.opts[\"recon_randomize\"]:",
            "            recon_delay = randint(",
            "                self.opts[\"recon_default\"],",
            "                self.opts[\"recon_default\"] + self.opts[\"recon_max\"],",
            "            )",
            "",
            "            log.debug(",
            "                \"Generated random reconnect delay between '%sms' and '%sms' (%s)\",",
            "                self.opts[\"recon_default\"],",
            "                self.opts[\"recon_default\"] + self.opts[\"recon_max\"],",
            "                recon_delay,",
            "            )",
            "",
            "        log.debug(\"Setting zmq_reconnect_ivl to '%sms'\", recon_delay)",
            "        self._socket.setsockopt(zmq.RECONNECT_IVL, recon_delay)",
            "",
            "        if hasattr(zmq, \"RECONNECT_IVL_MAX\"):",
            "            log.debug(",
            "                \"Setting zmq_reconnect_ivl_max to '%sms'\",",
            "                self.opts[\"recon_default\"] + self.opts[\"recon_max\"],",
            "            )",
            "",
            "            self._socket.setsockopt(zmq.RECONNECT_IVL_MAX, self.opts[\"recon_max\"])",
            "",
            "        if (self.opts[\"ipv6\"] is True or \":\" in self.opts[\"master_ip\"]) and hasattr(",
            "            zmq, \"IPV4ONLY\"",
            "        ):",
            "            # IPv6 sockets work for both IPv6 and IPv4 addresses",
            "            self._socket.setsockopt(zmq.IPV4ONLY, 0)",
            "",
            "        if HAS_ZMQ_MONITOR and self.opts[\"zmq_monitor\"]:",
            "            self._monitor = ZeroMQSocketMonitor(self._socket)",
            "            self._monitor.start_io_loop(self.io_loop)",
            "",
            "    def close(self):",
            "        if self._closing is True:",
            "            return",
            "",
            "        self._closing = True",
            "",
            "        if hasattr(self, \"_monitor\") and self._monitor is not None:",
            "            self._monitor.stop()",
            "            self._monitor = None",
            "        if hasattr(self, \"_stream\"):",
            "            self._stream.close(0)",
            "        elif hasattr(self, \"_socket\"):",
            "            self._socket.close(0)",
            "        if hasattr(self, \"context\") and self.context.closed is False:",
            "            self.context.term()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    # TODO: this is the time to see if we are connected, maybe use the req channel to guess?",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect(self):",
            "        if not self.auth.authenticated:",
            "            yield self.auth.authenticate()",
            "",
            "        # if this is changed from the default, we assume it was intentional",
            "        if int(self.opts.get(\"publish_port\", 4506)) != 4506:",
            "            self.publish_port = self.opts.get(\"publish_port\")",
            "        # else take the relayed publish_port master reports",
            "        else:",
            "            self.publish_port = self.auth.creds[\"publish_port\"]",
            "",
            "        log.debug(",
            "            \"Connecting the Minion to the Master publish port, using the URI: %s\",",
            "            self.master_pub,",
            "        )",
            "        self._socket.connect(self.master_pub)",
            "",
            "    @property",
            "    def master_pub(self):",
            "        \"\"\"",
            "        Return the master publish port",
            "        \"\"\"",
            "        return _get_master_uri(",
            "            self.opts[\"master_ip\"],",
            "            self.publish_port,",
            "            source_ip=self.opts.get(\"source_ip\"),",
            "            source_port=self.opts.get(\"source_publish_port\"),",
            "        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _decode_messages(self, messages):",
            "        \"\"\"",
            "        Take the zmq messages, decrypt/decode them into a payload",
            "",
            "        :param list messages: A list of messages to be decoded",
            "        \"\"\"",
            "        messages_len = len(messages)",
            "        # if it was one message, then its old style",
            "        if messages_len == 1:",
            "            payload = self.serial.loads(messages[0])",
            "        # 2 includes a header which says who should do it",
            "        elif messages_len == 2:",
            "            message_target = salt.utils.stringutils.to_str(messages[0])",
            "            if (",
            "                self.opts.get(\"__role\") != \"syndic\"",
            "                and message_target not in (\"broadcast\", self.hexid)",
            "            ) or (",
            "                self.opts.get(\"__role\") == \"syndic\"",
            "                and message_target not in (\"broadcast\", \"syndic\")",
            "            ):",
            "                log.debug(\"Publish received for not this minion: %s\", message_target)",
            "                raise salt.ext.tornado.gen.Return(None)",
            "            payload = self.serial.loads(messages[1])",
            "        else:",
            "            raise Exception(",
            "                (",
            "                    \"Invalid number of messages ({}) in zeromq pub\"",
            "                    \"message from master\"",
            "                ).format(len(messages_len))",
            "            )",
            "        # Yield control back to the caller. When the payload has been decoded, assign",
            "        # the decoded payload to 'ret' and resume operation",
            "        ret = yield self._decode_payload(payload)",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @property",
            "    def stream(self):",
            "        \"\"\"",
            "        Return the current zmqstream, creating one if necessary",
            "        \"\"\"",
            "        if not hasattr(self, \"_stream\"):",
            "            self._stream = zmq.eventloop.zmqstream.ZMQStream(",
            "                self._socket, io_loop=self.io_loop",
            "            )",
            "        return self._stream",
            "",
            "    def on_recv(self, callback):",
            "        \"\"\"",
            "        Register a callback for received messages (that we didn't initiate)",
            "",
            "        :param func callback: A function which should be called when data is received",
            "        \"\"\"",
            "        if callback is None:",
            "            return self.stream.on_recv(None)",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def wrap_callback(messages):",
            "            payload = yield self._decode_messages(messages)",
            "            if payload is not None:",
            "                callback(payload)",
            "",
            "        return self.stream.on_recv(wrap_callback)",
            "",
            "",
            "class ZeroMQReqServerChannel(",
            "    salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel",
            "):",
            "    def __init__(self, opts):",
            "        salt.transport.server.ReqServerChannel.__init__(self, opts)",
            "        self._closing = False",
            "        self._monitor = None",
            "        self._w_monitor = None",
            "",
            "    def zmq_device(self):",
            "        \"\"\"",
            "        Multiprocessing target for the zmq queue device",
            "        \"\"\"",
            "        self.__setup_signals()",
            "        salt.utils.process.appendproctitle(\"MWorkerQueue\")",
            "        self.context = zmq.Context(self.opts[\"worker_threads\"])",
            "        # Prepare the zeromq sockets",
            "        self.uri = \"tcp://{interface}:{ret_port}\".format(**self.opts)",
            "        self.clients = self.context.socket(zmq.ROUTER)",
            "        if self.opts[\"ipv6\"] is True and hasattr(zmq, \"IPV4ONLY\"):",
            "            # IPv6 sockets work for both IPv6 and IPv4 addresses",
            "            self.clients.setsockopt(zmq.IPV4ONLY, 0)",
            "        self.clients.setsockopt(zmq.BACKLOG, self.opts.get(\"zmq_backlog\", 1000))",
            "        self._start_zmq_monitor()",
            "        self.workers = self.context.socket(zmq.DEALER)",
            "",
            "        if self.opts[\"mworker_queue_niceness\"] and not salt.utils.platform.is_windows():",
            "            log.info(",
            "                \"setting mworker_queue niceness to %d\",",
            "                self.opts[\"mworker_queue_niceness\"],",
            "            )",
            "            os.nice(self.opts[\"mworker_queue_niceness\"])",
            "",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            self.w_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_workers\", 4515)",
            "            )",
            "        else:",
            "            self.w_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"workers.ipc\")",
            "            )",
            "",
            "        log.info(\"Setting up the master communication server\")",
            "        self.clients.bind(self.uri)",
            "        self.workers.bind(self.w_uri)",
            "",
            "        while True:",
            "            if self.clients.closed or self.workers.closed:",
            "                break",
            "            try:",
            "                zmq.device(zmq.QUEUE, self.clients, self.workers)",
            "            except zmq.ZMQError as exc:",
            "                if exc.errno == errno.EINTR:",
            "                    continue",
            "                raise",
            "            except (KeyboardInterrupt, SystemExit):",
            "                break",
            "",
            "    def close(self):",
            "        \"\"\"",
            "        Cleanly shutdown the router socket",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "        log.info(\"MWorkerQueue under PID %s is closing\", os.getpid())",
            "        self._closing = True",
            "        if getattr(self, \"_monitor\", None) is not None:",
            "            self._monitor.stop()",
            "            self._monitor = None",
            "        if getattr(self, \"_w_monitor\", None) is not None:",
            "            self._w_monitor.stop()",
            "            self._w_monitor = None",
            "        if hasattr(self, \"clients\") and self.clients.closed is False:",
            "            self.clients.close()",
            "        if hasattr(self, \"workers\") and self.workers.closed is False:",
            "            self.workers.close()",
            "        if hasattr(self, \"stream\"):",
            "            self.stream.close()",
            "        if hasattr(self, \"_socket\") and self._socket.closed is False:",
            "            self._socket.close()",
            "        if hasattr(self, \"context\") and self.context.closed is False:",
            "            self.context.term()",
            "",
            "    def pre_fork(self, process_manager):",
            "        \"\"\"",
            "        Pre-fork we need to create the zmq router device",
            "",
            "        :param func process_manager: An instance of salt.utils.process.ProcessManager",
            "        \"\"\"",
            "        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)",
            "        process_manager.add_process(self.zmq_device)",
            "",
            "    def _start_zmq_monitor(self):",
            "        \"\"\"",
            "        Starts ZMQ monitor for debugging purposes.",
            "        :return:",
            "        \"\"\"",
            "        # Socket monitor shall be used the only for debug",
            "        # purposes so using threading doesn't look too bad here",
            "",
            "        if HAS_ZMQ_MONITOR and self.opts[\"zmq_monitor\"]:",
            "            log.debug(\"Starting ZMQ monitor\")",
            "            import threading",
            "",
            "            self._w_monitor = ZeroMQSocketMonitor(self._socket)",
            "            threading.Thread(target=self._w_monitor.start_poll).start()",
            "            log.debug(\"ZMQ monitor has been started started\")",
            "",
            "    def post_fork(self, payload_handler, io_loop):",
            "        \"\"\"",
            "        After forking we need to create all of the local sockets to listen to the",
            "        router",
            "",
            "        :param func payload_handler: A function to called to handle incoming payloads as",
            "                                     they are picked up off the wire",
            "        :param IOLoop io_loop: An instance of a Tornado IOLoop, to handle event scheduling",
            "        \"\"\"",
            "        self.payload_handler = payload_handler",
            "        self.io_loop = io_loop",
            "",
            "        self.context = zmq.Context(1)",
            "        self._socket = self.context.socket(zmq.REP)",
            "        self._start_zmq_monitor()",
            "",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            self.w_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_workers\", 4515)",
            "            )",
            "        else:",
            "            self.w_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"workers.ipc\")",
            "            )",
            "        log.info(\"Worker binding to socket %s\", self.w_uri)",
            "        self._socket.connect(self.w_uri)",
            "",
            "        salt.transport.mixins.auth.AESReqServerMixin.post_fork(",
            "            self, payload_handler, io_loop",
            "        )",
            "",
            "        self.stream = zmq.eventloop.zmqstream.ZMQStream(",
            "            self._socket, io_loop=self.io_loop",
            "        )",
            "        self.stream.on_recv_stream(self.handle_message)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def handle_message(self, stream, payload):",
            "        \"\"\"",
            "        Handle incoming messages from underlying TCP streams",
            "",
            "        :stream ZMQStream stream: A ZeroMQ stream.",
            "        See http://zeromq.github.io/pyzmq/api/generated/zmq.eventloop.zmqstream.html",
            "",
            "        :param dict payload: A payload to process",
            "        \"\"\"",
            "        try:",
            "            payload = self.serial.loads(payload[0])",
            "            payload = self._decode_payload(payload)",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            exc_type = type(exc).__name__",
            "            if exc_type == \"AuthenticationError\":",
            "                log.debug(",
            "                    \"Minion failed to auth to master. Since the payload is \"",
            "                    \"encrypted, it is not known which minion failed to \"",
            "                    \"authenticate. It is likely that this is a transient \"",
            "                    \"failure due to the master rotating its public key.\"",
            "                )",
            "            else:",
            "                log.error(\"Bad load from minion: %s: %s\", exc_type, exc)",
            "            stream.send(self.serial.dumps(\"bad load\"))",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        # TODO helper functions to normalize payload?",
            "        if not isinstance(payload, dict) or not isinstance(payload.get(\"load\"), dict):",
            "            log.error(",
            "                \"payload and load must be a dict. Payload was: %s and load was %s\",",
            "                payload,",
            "                payload.get(\"load\"),",
            "            )",
            "            stream.send(self.serial.dumps(\"payload and load must be a dict\"))",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        try:",
            "            id_ = payload[\"load\"].get(\"id\", \"\")",
            "            if \"\\0\" in id_:",
            "                log.error(\"Payload contains an id with a null byte: %s\", payload)",
            "                stream.send(self.serial.dumps(\"bad load: id contains a null byte\"))",
            "                raise salt.ext.tornado.gen.Return()",
            "        except TypeError:",
            "            log.error(\"Payload contains non-string id: %s\", payload)",
            "            stream.send(",
            "                self.serial.dumps(\"bad load: id {} is not a string\".format(id_))",
            "            )",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        # intercept the \"_auth\" commands, since the main daemon shouldn't know",
            "        # anything about our key auth",
            "        if payload[\"enc\"] == \"clear\" and payload.get(\"load\", {}).get(\"cmd\") == \"_auth\":",
            "            stream.send(self.serial.dumps(self._auth(payload[\"load\"])))",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        # TODO: test",
            "        try:",
            "            # Take the payload_handler function that was registered when we created the channel",
            "            # and call it, returning control to the caller until it completes",
            "            ret, req_opts = yield self.payload_handler(payload)",
            "        except Exception as e:  # pylint: disable=broad-except",
            "            # always attempt to return an error to the minion",
            "            stream.send(\"Some exception handling minion payload\")",
            "            log.error(\"Some exception handling a payload from minion\", exc_info=True)",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        req_fun = req_opts.get(\"fun\", \"send\")",
            "        if req_fun == \"send_clear\":",
            "            stream.send(self.serial.dumps(ret))",
            "        elif req_fun == \"send\":",
            "            stream.send(self.serial.dumps(self.crypticle.dumps(ret)))",
            "        elif req_fun == \"send_private\":",
            "            stream.send(",
            "                self.serial.dumps(",
            "                    self._encrypt_private(ret, req_opts[\"key\"], req_opts[\"tgt\"],)",
            "                )",
            "            )",
            "        else:",
            "            log.error(\"Unknown req_fun %s\", req_fun)",
            "            # always attempt to return an error to the minion",
            "            stream.send(\"Server-side exception handling payload\")",
            "        raise salt.ext.tornado.gen.Return()",
            "",
            "    def __setup_signals(self):",
            "        signal.signal(signal.SIGINT, self._handle_signals)",
            "        signal.signal(signal.SIGTERM, self._handle_signals)",
            "",
            "    def _handle_signals(self, signum, sigframe):",
            "        msg = \"{} received a \".format(self.__class__.__name__)",
            "        if signum == signal.SIGINT:",
            "            msg += \"SIGINT\"",
            "        elif signum == signal.SIGTERM:",
            "            msg += \"SIGTERM\"",
            "        msg += \". Exiting\"",
            "        log.debug(msg)",
            "        self.close()",
            "        sys.exit(salt.defaults.exitcodes.EX_OK)",
            "",
            "",
            "def _set_tcp_keepalive(zmq_socket, opts):",
            "    \"\"\"",
            "    Ensure that TCP keepalives are set as specified in \"opts\".",
            "",
            "    Warning: Failure to set TCP keepalives on the salt-master can result in",
            "    not detecting the loss of a minion when the connection is lost or when",
            "    its host has been terminated without first closing the socket.",
            "    Salt's Presence System depends on this connection status to know if a minion",
            "    is \"present\".",
            "",
            "    Warning: Failure to set TCP keepalives on minions can result in frequent or",
            "    unexpected disconnects!",
            "    \"\"\"",
            "    if hasattr(zmq, \"TCP_KEEPALIVE\") and opts:",
            "        if \"tcp_keepalive\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE, opts[\"tcp_keepalive\"])",
            "        if \"tcp_keepalive_idle\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE_IDLE, opts[\"tcp_keepalive_idle\"])",
            "        if \"tcp_keepalive_cnt\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE_CNT, opts[\"tcp_keepalive_cnt\"])",
            "        if \"tcp_keepalive_intvl\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE_INTVL, opts[\"tcp_keepalive_intvl\"])",
            "",
            "",
            "class ZeroMQPubServerChannel(salt.transport.server.PubServerChannel):",
            "    \"\"\"",
            "    Encapsulate synchronous operations for a publisher channel",
            "    \"\"\"",
            "",
            "    _sock_data = threading.local()",
            "",
            "    def __init__(self, opts):",
            "        self.opts = opts",
            "        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?",
            "        self.ckminions = salt.utils.minions.CkMinions(self.opts)",
            "",
            "    def connect(self):",
            "        return salt.ext.tornado.gen.sleep(5)",
            "",
            "    def _publish_daemon(self, log_queue=None):",
            "        \"\"\"",
            "        Bind to the interface specified in the configuration file",
            "        \"\"\"",
            "        salt.utils.process.appendproctitle(self.__class__.__name__)",
            "",
            "        if self.opts[\"pub_server_niceness\"] and not salt.utils.platform.is_windows():",
            "            log.info(",
            "                \"setting Publish daemon niceness to %i\",",
            "                self.opts[\"pub_server_niceness\"],",
            "            )",
            "            os.nice(self.opts[\"pub_server_niceness\"])",
            "",
            "        if log_queue:",
            "            salt.log.setup.set_multiprocessing_logging_queue(log_queue)",
            "            salt.log.setup.setup_multiprocessing_logging(log_queue)",
            "",
            "        # Set up the context",
            "        context = zmq.Context(1)",
            "        # Prepare minion publish socket",
            "        pub_sock = context.socket(zmq.PUB)",
            "        _set_tcp_keepalive(pub_sock, self.opts)",
            "        # if 2.1 >= zmq < 3.0, we only have one HWM setting",
            "        try:",
            "            pub_sock.setsockopt(zmq.HWM, self.opts.get(\"pub_hwm\", 1000))",
            "        # in zmq >= 3.0, there are separate send and receive HWM settings",
            "        except AttributeError:",
            "            # Set the High Water Marks. For more information on HWM, see:",
            "            # http://api.zeromq.org/4-1:zmq-setsockopt",
            "            pub_sock.setsockopt(zmq.SNDHWM, self.opts.get(\"pub_hwm\", 1000))",
            "            pub_sock.setsockopt(zmq.RCVHWM, self.opts.get(\"pub_hwm\", 1000))",
            "        if self.opts[\"ipv6\"] is True and hasattr(zmq, \"IPV4ONLY\"):",
            "            # IPv6 sockets work for both IPv6 and IPv4 addresses",
            "            pub_sock.setsockopt(zmq.IPV4ONLY, 0)",
            "        pub_sock.setsockopt(zmq.BACKLOG, self.opts.get(\"zmq_backlog\", 1000))",
            "        pub_sock.setsockopt(zmq.LINGER, -1)",
            "        pub_uri = \"tcp://{interface}:{publish_port}\".format(**self.opts)",
            "        # Prepare minion pull socket",
            "        pull_sock = context.socket(zmq.PULL)",
            "        pull_sock.setsockopt(zmq.LINGER, -1)",
            "",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_publish_pull\", 4514)",
            "            )",
            "        else:",
            "            pull_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "            )",
            "        salt.utils.zeromq.check_ipc_path_max_len(pull_uri)",
            "",
            "        # Start the minion command publisher",
            "        log.info(\"Starting the Salt Publisher on %s\", pub_uri)",
            "        pub_sock.bind(pub_uri)",
            "",
            "        # Securely create socket",
            "        log.info(\"Starting the Salt Puller on %s\", pull_uri)",
            "        with salt.utils.files.set_umask(0o177):",
            "            pull_sock.bind(pull_uri)",
            "",
            "        try:",
            "            while True:",
            "                # Catch and handle EINTR from when this process is sent",
            "                # SIGUSR1 gracefully so we don't choke and die horribly",
            "                try:",
            "                    log.debug(\"Publish daemon getting data from puller %s\", pull_uri)",
            "                    package = pull_sock.recv()",
            "                    log.debug(\"Publish daemon received payload. size=%d\", len(package))",
            "",
            "                    unpacked_package = salt.payload.unpackage(package)",
            "                    unpacked_package = salt.transport.frame.decode_embedded_strs(",
            "                        unpacked_package",
            "                    )",
            "                    payload = unpacked_package[\"payload\"]",
            "                    log.trace(\"Accepted unpacked package from puller\")",
            "                    if self.opts[\"zmq_filtering\"]:",
            "                        # if you have a specific topic list, use that",
            "                        if \"topic_lst\" in unpacked_package:",
            "                            for topic in unpacked_package[\"topic_lst\"]:",
            "                                log.trace(",
            "                                    \"Sending filtered data over publisher %s\", pub_uri",
            "                                )",
            "                                # zmq filters are substring match, hash the topic",
            "                                # to avoid collisions",
            "                                htopic = salt.utils.stringutils.to_bytes(",
            "                                    hashlib.sha1(",
            "                                        salt.utils.stringutils.to_bytes(topic)",
            "                                    ).hexdigest()",
            "                                )",
            "                                pub_sock.send(htopic, flags=zmq.SNDMORE)",
            "                                pub_sock.send(payload)",
            "                                log.trace(\"Filtered data has been sent\")",
            "",
            "                            # Syndic broadcast",
            "                            if self.opts.get(\"order_masters\"):",
            "                                log.trace(\"Sending filtered data to syndic\")",
            "                                pub_sock.send(b\"syndic\", flags=zmq.SNDMORE)",
            "                                pub_sock.send(payload)",
            "                                log.trace(\"Filtered data has been sent to syndic\")",
            "                        # otherwise its a broadcast",
            "                        else:",
            "                            # TODO: constants file for \"broadcast\"",
            "                            log.trace(",
            "                                \"Sending broadcasted data over publisher %s\", pub_uri",
            "                            )",
            "                            pub_sock.send(b\"broadcast\", flags=zmq.SNDMORE)",
            "                            pub_sock.send(payload)",
            "                            log.trace(\"Broadcasted data has been sent\")",
            "                    else:",
            "                        log.trace(",
            "                            \"Sending ZMQ-unfiltered data over publisher %s\", pub_uri",
            "                        )",
            "                        pub_sock.send(payload)",
            "                        log.trace(\"Unfiltered data has been sent\")",
            "                except zmq.ZMQError as exc:",
            "                    if exc.errno == errno.EINTR:",
            "                        continue",
            "                    raise",
            "",
            "        except KeyboardInterrupt:",
            "            log.trace(\"Publish daemon caught Keyboard interupt, tearing down\")",
            "        # Cleanly close the sockets if we're shutting down",
            "        if pub_sock.closed is False:",
            "            pub_sock.close()",
            "        if pull_sock.closed is False:",
            "            pull_sock.close()",
            "        if context.closed is False:",
            "            context.term()",
            "",
            "    def pre_fork(self, process_manager, kwargs=None):",
            "        \"\"\"",
            "        Do anything necessary pre-fork. Since this is on the master side this will",
            "        primarily be used to create IPC channels and create our daemon process to",
            "        do the actual publishing",
            "",
            "        :param func process_manager: A ProcessManager, from salt.utils.process.ProcessManager",
            "        \"\"\"",
            "        process_manager.add_process(self._publish_daemon, kwargs=kwargs)",
            "",
            "    @property",
            "    def pub_sock(self):",
            "        \"\"\"",
            "        This thread's zmq publisher socket. This socket is stored on the class",
            "        so that multiple instantiations in the same thread will re-use a single",
            "        zmq socket.",
            "        \"\"\"",
            "        try:",
            "            return self._sock_data.sock",
            "        except AttributeError:",
            "            pass",
            "",
            "    def pub_connect(self):",
            "        \"\"\"",
            "        Create and connect this thread's zmq socket. If a publisher socket",
            "        already exists \"pub_close\" is called before creating and connecting a",
            "        new socket.",
            "        \"\"\"",
            "        if self.pub_sock:",
            "            self.pub_close()",
            "        ctx = zmq.Context.instance()",
            "        self._sock_data.sock = ctx.socket(zmq.PUSH)",
            "        self.pub_sock.setsockopt(zmq.LINGER, -1)",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_publish_pull\", 4514)",
            "            )",
            "        else:",
            "            pull_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "            )",
            "        log.debug(\"Connecting to pub server: %s\", pull_uri)",
            "        self.pub_sock.connect(pull_uri)",
            "        return self._sock_data.sock",
            "",
            "    def pub_close(self):",
            "        \"\"\"",
            "        Disconnect an existing publisher socket and remove it from the local",
            "        thread's cache.",
            "        \"\"\"",
            "        if hasattr(self._sock_data, \"sock\"):",
            "            self._sock_data.sock.close()",
            "            delattr(self._sock_data, \"sock\")",
            "",
            "    def publish(self, load):",
            "        \"\"\"",
            "        Publish \"load\" to minions. This send the load to the publisher daemon",
            "        process with does the actual sending to minions.",
            "",
            "        :param dict load: A load to be sent across the wire to minions",
            "        \"\"\"",
            "        payload = {\"enc\": \"aes\"}",
            "        crypticle = salt.crypt.Crypticle(",
            "            self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "        )",
            "        payload[\"load\"] = crypticle.dumps(load)",
            "        if self.opts[\"sign_pub_messages\"]:",
            "            master_pem_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "            log.debug(\"Signing data packet\")",
            "            payload[\"sig\"] = salt.crypt.sign_message(master_pem_path, payload[\"load\"])",
            "        int_payload = {\"payload\": self.serial.dumps(payload)}",
            "",
            "        # add some targeting stuff for lists only (for now)",
            "        if load[\"tgt_type\"] == \"list\":",
            "            int_payload[\"topic_lst\"] = load[\"tgt\"]",
            "",
            "        # If zmq_filtering is enabled, target matching has to happen master side",
            "        match_targets = [\"pcre\", \"glob\", \"list\"]",
            "        if self.opts[\"zmq_filtering\"] and load[\"tgt_type\"] in match_targets:",
            "            # Fetch a list of minions that match",
            "            _res = self.ckminions.check_minions(load[\"tgt\"], tgt_type=load[\"tgt_type\"])",
            "            match_ids = _res[\"minions\"]",
            "",
            "            log.debug(\"Publish Side Match: %s\", match_ids)",
            "            # Send list of miions thru so zmq can target them",
            "            int_payload[\"topic_lst\"] = match_ids",
            "        payload = self.serial.dumps(int_payload)",
            "        log.debug(",
            "            \"Sending payload to publish daemon. jid=%s size=%d\",",
            "            load.get(\"jid\", None),",
            "            len(payload),",
            "        )",
            "        if not self.pub_sock:",
            "            self.pub_connect()",
            "        self.pub_sock.send(payload)",
            "        log.debug(\"Sent payload to publish daemon.\")",
            "",
            "",
            "class AsyncReqMessageClientPool(salt.transport.MessageClientPool):",
            "    \"\"\"",
            "    Wrapper class of AsyncReqMessageClientPool to avoid blocking waiting while writing data to socket.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, args=None, kwargs=None):",
            "        self._closing = False",
            "        super().__init__(AsyncReqMessageClient, opts, args=args, kwargs=kwargs)",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "",
            "        self._closing = True",
            "        for message_client in self.message_clients:",
            "            message_client.close()",
            "        self.message_clients = []",
            "",
            "    def send(self, *args, **kwargs):",
            "        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))",
            "        return message_clients[0].send(*args, **kwargs)",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "",
            "# TODO: unit tests!",
            "class AsyncReqMessageClient:",
            "    \"\"\"",
            "    This class wraps the underlying zeromq REQ socket and gives a future-based",
            "    interface to sending and recieving messages. This works around the primary",
            "    limitation of serialized send/recv on the underlying socket by queueing the",
            "    message sends in this class. In the future if we decide to attempt to multiplex",
            "    we can manage a pool of REQ/REP sockets-- but for now we'll just do them in serial",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, addr, linger=0, io_loop=None):",
            "        \"\"\"",
            "        Create an asynchronous message client",
            "",
            "        :param dict opts: The salt opts dictionary",
            "        :param str addr: The interface IP address to bind to",
            "        :param int linger: The number of seconds to linger on a ZMQ socket. See",
            "                           http://api.zeromq.org/2-1:zmq-setsockopt [ZMQ_LINGER]",
            "        :param IOLoop io_loop: A Tornado IOLoop event scheduler [tornado.ioloop.IOLoop]",
            "        \"\"\"",
            "        self.opts = opts",
            "        self.addr = addr",
            "        self.linger = linger",
            "        if io_loop is None:",
            "            self.io_loop = salt.ext.tornado.ioloop.IOLoop.current()",
            "        else:",
            "            self.io_loop = io_loop",
            "",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.context = zmq.Context()",
            "",
            "        # wire up sockets",
            "        self._init_socket()",
            "",
            "        self.send_queue = []",
            "        # mapping of message -> future",
            "        self.send_future_map = {}",
            "",
            "        self.send_timeout_map = {}  # message -> timeout",
            "        self._closing = False",
            "",
            "    # TODO: timeout all in-flight sessions, or error",
            "    def close(self):",
            "        try:",
            "            if self._closing:",
            "                return",
            "        except AttributeError:",
            "            # We must have been called from __del__",
            "            # The python interpreter has nuked most attributes already",
            "            return",
            "        else:",
            "            self._closing = True",
            "            if hasattr(self, \"stream\") and self.stream is not None:",
            "                if ZMQ_VERSION_INFO < (14, 3, 0):",
            "                    # stream.close() doesn't work properly on pyzmq < 14.3.0",
            "                    if self.stream.socket:",
            "                        self.stream.socket.close()",
            "                    self.stream.io_loop.remove_handler(self.stream.socket)",
            "                    # set this to None, more hacks for messed up pyzmq",
            "                    self.stream.socket = None",
            "                    self.socket.close()",
            "                else:",
            "                    self.stream.close()",
            "                    self.socket = None",
            "                self.stream = None",
            "            if self.context.closed is False:",
            "                self.context.term()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _init_socket(self):",
            "        if hasattr(self, \"stream\"):",
            "            self.stream.close()  # pylint: disable=E0203",
            "            self.socket.close()  # pylint: disable=E0203",
            "            del self.stream",
            "            del self.socket",
            "",
            "        self.socket = self.context.socket(zmq.REQ)",
            "",
            "        # socket options",
            "        if hasattr(zmq, \"RECONNECT_IVL_MAX\"):",
            "            self.socket.setsockopt(zmq.RECONNECT_IVL_MAX, 5000)",
            "",
            "        _set_tcp_keepalive(self.socket, self.opts)",
            "        if self.addr.startswith(\"tcp://[\"):",
            "            # Hint PF type if bracket enclosed IPv6 address",
            "            if hasattr(zmq, \"IPV6\"):",
            "                self.socket.setsockopt(zmq.IPV6, 1)",
            "            elif hasattr(zmq, \"IPV4ONLY\"):",
            "                self.socket.setsockopt(zmq.IPV4ONLY, 0)",
            "        self.socket.linger = self.linger",
            "        log.debug(\"Trying to connect to: %s\", self.addr)",
            "        self.socket.connect(self.addr)",
            "        self.stream = zmq.eventloop.zmqstream.ZMQStream(",
            "            self.socket, io_loop=self.io_loop",
            "        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _internal_send_recv(self):",
            "        while len(self.send_queue) > 0:",
            "            message = self.send_queue[0]",
            "            future = self.send_future_map.get(message, None)",
            "            if future is None:",
            "                # Timedout",
            "                del self.send_queue[0]",
            "                continue",
            "",
            "            # send",
            "            def mark_future(msg):",
            "                if not future.done():",
            "                    data = self.serial.loads(msg[0])",
            "                    future.set_result(data)",
            "",
            "            self.stream.on_recv(mark_future)",
            "            self.stream.send(message)",
            "",
            "            try:",
            "                ret = yield future",
            "            except Exception as err:  # pylint: disable=broad-except",
            "                log.debug(\"Re-init ZMQ socket: %s\", err)",
            "                self._init_socket()  # re-init the zmq socket (no other way in zmq)",
            "                del self.send_queue[0]",
            "                continue",
            "            del self.send_queue[0]",
            "            self.send_future_map.pop(message, None)",
            "            self.remove_message_timeout(message)",
            "",
            "    def remove_message_timeout(self, message):",
            "        if message not in self.send_timeout_map:",
            "            return",
            "        timeout = self.send_timeout_map.pop(message, None)",
            "        if timeout is not None:",
            "            # Hasn't been already timedout",
            "            self.io_loop.remove_timeout(timeout)",
            "",
            "    def timeout_message(self, message):",
            "        \"\"\"",
            "        Handle a message timeout by removing it from the sending queue",
            "        and informing the caller",
            "",
            "        :raises: SaltReqTimeoutError",
            "        \"\"\"",
            "        future = self.send_future_map.pop(message, None)",
            "        # In a race condition the message might have been sent by the time",
            "        # we're timing it out. Make sure the future is not None",
            "        if future is not None:",
            "            del self.send_timeout_map[message]",
            "            if future.attempts < future.tries:",
            "                future.attempts += 1",
            "                log.debug(",
            "                    \"SaltReqTimeoutError, retrying. (%s/%s)\",",
            "                    future.attempts,",
            "                    future.tries,",
            "                )",
            "                self.send(",
            "                    message, timeout=future.timeout, tries=future.tries, future=future,",
            "                )",
            "",
            "            else:",
            "                future.set_exception(SaltReqTimeoutError(\"Message timed out\"))",
            "",
            "    def send(",
            "        self, message, timeout=None, tries=3, future=None, callback=None, raw=False",
            "    ):",
            "        \"\"\"",
            "        Return a future which will be completed when the message has a response",
            "        \"\"\"",
            "        if future is None:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            future.tries = tries",
            "            future.attempts = 0",
            "            future.timeout = timeout",
            "            # if a future wasn't passed in, we need to serialize the message",
            "            message = self.serial.dumps(message)",
            "        if callback is not None:",
            "",
            "            def handle_future(future):",
            "                response = future.result()",
            "                self.io_loop.add_callback(callback, response)",
            "",
            "            future.add_done_callback(handle_future)",
            "        # Add this future to the mapping",
            "        self.send_future_map[message] = future",
            "",
            "        if self.opts.get(\"detect_mode\") is True:",
            "            timeout = 1",
            "",
            "        if timeout is not None:",
            "            send_timeout = self.io_loop.call_later(",
            "                timeout, self.timeout_message, message",
            "            )",
            "            self.send_timeout_map[message] = send_timeout",
            "",
            "        if len(self.send_queue) == 0:",
            "            self.io_loop.spawn_callback(self._internal_send_recv)",
            "",
            "        self.send_queue.append(message)",
            "",
            "        return future",
            "",
            "",
            "class ZeroMQSocketMonitor:",
            "    __EVENT_MAP = None",
            "",
            "    def __init__(self, socket):",
            "        \"\"\"",
            "        Create ZMQ monitor sockets",
            "",
            "        More information:",
            "            http://api.zeromq.org/4-0:zmq-socket-monitor",
            "        \"\"\"",
            "        self._socket = socket",
            "        self._monitor_socket = self._socket.get_monitor_socket()",
            "        self._monitor_stream = None",
            "",
            "    def start_io_loop(self, io_loop):",
            "        log.trace(\"Event monitor start!\")",
            "        self._monitor_stream = zmq.eventloop.zmqstream.ZMQStream(",
            "            self._monitor_socket, io_loop=io_loop",
            "        )",
            "        self._monitor_stream.on_recv(self.monitor_callback)",
            "",
            "    def start_poll(self):",
            "        log.trace(\"Event monitor start!\")",
            "        try:",
            "            while self._monitor_socket is not None and self._monitor_socket.poll():",
            "                msg = self._monitor_socket.recv_multipart()",
            "                self.monitor_callback(msg)",
            "        except (AttributeError, zmq.error.ContextTerminated):",
            "            # We cannot log here because we'll get an interrupted system call in trying",
            "            # to flush the logging buffer as we terminate",
            "            pass",
            "",
            "    @property",
            "    def event_map(self):",
            "        if ZeroMQSocketMonitor.__EVENT_MAP is None:",
            "            event_map = {}",
            "            for name in dir(zmq):",
            "                if name.startswith(\"EVENT_\"):",
            "                    value = getattr(zmq, name)",
            "                    event_map[value] = name",
            "            ZeroMQSocketMonitor.__EVENT_MAP = event_map",
            "        return ZeroMQSocketMonitor.__EVENT_MAP",
            "",
            "    def monitor_callback(self, msg):",
            "        evt = zmq.utils.monitor.parse_monitor_message(msg)",
            "        evt[\"description\"] = self.event_map[evt[\"event\"]]",
            "        log.debug(\"ZeroMQ event: %s\", evt)",
            "        if evt[\"event\"] == zmq.EVENT_MONITOR_STOPPED:",
            "            self.stop()",
            "",
            "    def stop(self):",
            "        if self._socket is None:",
            "            return",
            "        self._socket.disable_monitor()",
            "        self._socket = None",
            "        self._monitor_socket = None",
            "        if self._monitor_stream is not None:",
            "            self._monitor_stream.close()",
            "            self._monitor_stream = None",
            "        log.trace(\"Event monitor done!\")"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Zeromq transport classes",
            "\"\"\"",
            "import copy",
            "import errno",
            "import hashlib",
            "import logging",
            "import os",
            "import signal",
            "import sys",
            "import threading",
            "import uuid",
            "import weakref",
            "from random import randint",
            "",
            "import salt.auth",
            "import salt.crypt",
            "import salt.ext.tornado",
            "import salt.ext.tornado.concurrent",
            "import salt.ext.tornado.gen",
            "import salt.ext.tornado.ioloop",
            "import salt.log.setup",
            "import salt.payload",
            "import salt.transport.client",
            "import salt.transport.mixins.auth",
            "import salt.transport.server",
            "import salt.utils.event",
            "import salt.utils.files",
            "import salt.utils.minions",
            "import salt.utils.process",
            "import salt.utils.stringutils",
            "import salt.utils.verify",
            "import salt.utils.versions",
            "import salt.utils.zeromq",
            "import zmq.error",
            "import zmq.eventloop.ioloop",
            "import zmq.eventloop.zmqstream",
            "from salt._compat import ipaddress",
            "from salt.exceptions import SaltException, SaltReqTimeoutError",
            "from salt.utils.zeromq import (",
            "    LIBZMQ_VERSION_INFO,",
            "    ZMQ_VERSION_INFO,",
            "    ZMQDefaultLoop,",
            "    install_zmq,",
            "    zmq,",
            ")",
            "",
            "try:",
            "    import zmq.utils.monitor",
            "",
            "    HAS_ZMQ_MONITOR = True",
            "except ImportError:",
            "    HAS_ZMQ_MONITOR = False",
            "",
            "",
            "try:",
            "    from M2Crypto import RSA",
            "",
            "    HAS_M2 = True",
            "except ImportError:",
            "    HAS_M2 = False",
            "    try:",
            "        from Cryptodome.Cipher import PKCS1_OAEP",
            "    except ImportError:",
            "        from Crypto.Cipher import PKCS1_OAEP  # nosec",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "def _get_master_uri(master_ip, master_port, source_ip=None, source_port=None):",
            "    \"\"\"",
            "    Return the ZeroMQ URI to connect the Minion to the Master.",
            "    It supports different source IP / port, given the ZeroMQ syntax:",
            "    // Connecting using a IP address and bind to an IP address",
            "    rc = zmq_connect(socket, \"tcp://192.168.1.17:5555;192.168.1.1:5555\"); assert (rc == 0);",
            "    Source: http://api.zeromq.org/4-1:zmq-tcp",
            "    \"\"\"",
            "    from salt.utils.zeromq import ip_bracket",
            "",
            "    master_uri = \"tcp://{master_ip}:{master_port}\".format(",
            "        master_ip=ip_bracket(master_ip), master_port=master_port",
            "    )",
            "",
            "    if source_ip or source_port:",
            "        if LIBZMQ_VERSION_INFO >= (4, 1, 6) and ZMQ_VERSION_INFO >= (16, 0, 1):",
            "            # The source:port syntax for ZeroMQ has been added in libzmq 4.1.6",
            "            # which is included in the pyzmq wheels starting with 16.0.1.",
            "            if source_ip and source_port:",
            "                master_uri = \"tcp://{source_ip}:{source_port};{master_ip}:{master_port}\".format(",
            "                    source_ip=ip_bracket(source_ip),",
            "                    source_port=source_port,",
            "                    master_ip=ip_bracket(master_ip),",
            "                    master_port=master_port,",
            "                )",
            "            elif source_ip and not source_port:",
            "                master_uri = \"tcp://{source_ip}:0;{master_ip}:{master_port}\".format(",
            "                    source_ip=ip_bracket(source_ip),",
            "                    master_ip=ip_bracket(master_ip),",
            "                    master_port=master_port,",
            "                )",
            "            elif source_port and not source_ip:",
            "                ip_any = (",
            "                    \"0.0.0.0\"",
            "                    if ipaddress.ip_address(master_ip).version == 4",
            "                    else ip_bracket(\"::\")",
            "                )",
            "                master_uri = \"tcp://{ip_any}:{source_port};{master_ip}:{master_port}\".format(",
            "                    ip_any=ip_any,",
            "                    source_port=source_port,",
            "                    master_ip=ip_bracket(master_ip),",
            "                    master_port=master_port,",
            "                )",
            "        else:",
            "            log.warning(",
            "                \"Unable to connect to the Master using a specific source IP / port\"",
            "            )",
            "            log.warning(\"Consider upgrading to pyzmq >= 16.0.1 and libzmq >= 4.1.6\")",
            "            log.warning(",
            "                \"Specific source IP / port for connecting to master returner port: configuraion ignored\"",
            "            )",
            "",
            "    return master_uri",
            "",
            "",
            "class AsyncZeroMQReqChannel(salt.transport.client.ReqChannel):",
            "    \"\"\"",
            "    Encapsulate sending routines to ZeroMQ.",
            "",
            "    ZMQ Channels default to 'crypt=aes'",
            "    \"\"\"",
            "",
            "    # This class is only a singleton per minion/master pair",
            "    # mapping of io_loop -> {key -> channel}",
            "    instance_map = weakref.WeakKeyDictionary()",
            "    async_methods = [",
            "        \"crypted_transfer_decode_dictentry\",",
            "        \"_crypted_transfer\",",
            "        \"_do_transfer\",",
            "        \"_uncrypted_transfer\",",
            "        \"send\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __new__(cls, opts, **kwargs):",
            "        \"\"\"",
            "        Only create one instance of channel per __key()",
            "        \"\"\"",
            "",
            "        # do we have any mapping for this io_loop",
            "        io_loop = kwargs.get(\"io_loop\")",
            "        if io_loop is None:",
            "            install_zmq()",
            "            io_loop = ZMQDefaultLoop.current()",
            "        if io_loop not in cls.instance_map:",
            "            cls.instance_map[io_loop] = weakref.WeakValueDictionary()",
            "        loop_instance_map = cls.instance_map[io_loop]",
            "",
            "        key = cls.__key(opts, **kwargs)",
            "        obj = loop_instance_map.get(key)",
            "        if obj is None:",
            "            log.debug(\"Initializing new AsyncZeroMQReqChannel for %s\", key)",
            "            # we need to make a local variable for this, as we are going to store",
            "            # it in a WeakValueDictionary-- which will remove the item if no one",
            "            # references it-- this forces a reference while we return to the caller",
            "            obj = object.__new__(cls)",
            "            obj.__singleton_init__(opts, **kwargs)",
            "            obj._instance_key = key",
            "            loop_instance_map[key] = obj",
            "            obj._refcount = 1",
            "            obj._refcount_lock = threading.RLock()",
            "            log.trace(",
            "                \"Inserted key into loop_instance_map id %s for key %s and process %s\",",
            "                id(loop_instance_map),",
            "                key,",
            "                os.getpid(),",
            "            )",
            "        else:",
            "            with obj._refcount_lock:",
            "                obj._refcount += 1",
            "            log.debug(\"Re-using AsyncZeroMQReqChannel for %s\", key)",
            "        return obj",
            "",
            "    def __deepcopy__(self, memo):",
            "        cls = self.__class__",
            "        # pylint: disable=too-many-function-args",
            "        result = cls.__new__(cls, copy.deepcopy(self.opts, memo))",
            "        # pylint: enable=too-many-function-args",
            "        memo[id(self)] = result",
            "        for key in self.__dict__:",
            "            if key in (\"_io_loop\", \"_refcount\", \"_refcount_lock\"):",
            "                continue",
            "                # The _io_loop has a thread Lock which will fail to be deep",
            "                # copied. Skip it because it will just be recreated on the",
            "                # new copy.",
            "            if key == \"message_client\":",
            "                # Recreate the message client because it will fail to be deep",
            "                # copied. The reason is the same as the io_loop skip above.",
            "                setattr(",
            "                    result,",
            "                    key,",
            "                    AsyncReqMessageClientPool(",
            "                        result.opts,",
            "                        args=(result.opts, self.master_uri,),",
            "                        kwargs={\"io_loop\": self._io_loop},",
            "                    ),",
            "                )",
            "",
            "                continue",
            "            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))",
            "        return result",
            "",
            "    @classmethod",
            "    def force_close_all_instances(cls):",
            "        \"\"\"",
            "        Will force close all instances",
            "",
            "        ZMQ can hang on quit if left to deconstruct on its own.",
            "        This because is deconstructs out of order.",
            "",
            "        :return: None",
            "        \"\"\"",
            "        for weak_dict in list(cls.instance_map.values()):",
            "            for instance in list(weak_dict.values()):",
            "                instance.close()",
            "",
            "    @classmethod",
            "    def __key(cls, opts, **kwargs):",
            "        return (",
            "            opts[\"pki_dir\"],  # where the keys are stored",
            "            opts[\"id\"],  # minion ID",
            "            kwargs.get(\"master_uri\", opts.get(\"master_uri\")),  # master ID",
            "            kwargs.get(\"crypt\", \"aes\"),  # TODO: use the same channel for crypt",
            "        )",
            "",
            "    # has to remain empty for singletons, since __init__ will *always* be called",
            "    def __init__(self, opts, **kwargs):",
            "        pass",
            "",
            "    # an init for the singleton instance to call",
            "    def __singleton_init__(self, opts, **kwargs):",
            "        self.opts = dict(opts)",
            "        self.ttype = \"zeromq\"",
            "",
            "        # crypt defaults to 'aes'",
            "        self.crypt = kwargs.get(\"crypt\", \"aes\")",
            "",
            "        if \"master_uri\" in kwargs:",
            "            self.opts[\"master_uri\"] = kwargs[\"master_uri\"]",
            "",
            "        self._io_loop = kwargs.get(\"io_loop\")",
            "        if self._io_loop is None:",
            "            install_zmq()",
            "            self._io_loop = ZMQDefaultLoop.current()",
            "",
            "        if self.crypt != \"clear\":",
            "            # we don't need to worry about auth as a kwarg, since its a singleton",
            "            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self._io_loop)",
            "        log.debug(",
            "            \"Connecting the Minion to the Master URI (for the return server): %s\",",
            "            self.master_uri,",
            "        )",
            "        self.message_client = AsyncReqMessageClientPool(",
            "            self.opts,",
            "            args=(self.opts, self.master_uri,),",
            "            kwargs={\"io_loop\": self._io_loop},",
            "        )",
            "        self._closing = False",
            "",
            "    def close(self):",
            "        \"\"\"",
            "        Since the message_client creates sockets and assigns them to the IOLoop we have to",
            "        specifically destroy them, since we aren't the only ones with references to the FDs",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "",
            "        if self._refcount > 1:",
            "            # Decrease refcount",
            "            with self._refcount_lock:",
            "                self._refcount -= 1",
            "            log.debug(",
            "                \"This is not the last %s instance. Not closing yet.\",",
            "                self.__class__.__name__,",
            "            )",
            "            return",
            "",
            "        log.debug(\"Closing %s instance\", self.__class__.__name__)",
            "        self._closing = True",
            "        if hasattr(self, \"message_client\"):",
            "            self.message_client.close()",
            "",
            "        # Remove the entry from the instance map so that a closed entry may not",
            "        # be reused.",
            "        # This forces this operation even if the reference count of the entry",
            "        # has not yet gone to zero.",
            "        if self._io_loop in self.__class__.instance_map:",
            "            loop_instance_map = self.__class__.instance_map[self._io_loop]",
            "            if self._instance_key in loop_instance_map:",
            "                del loop_instance_map[self._instance_key]",
            "            if not loop_instance_map:",
            "                del self.__class__.instance_map[self._io_loop]",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        with self._refcount_lock:",
            "            # Make sure we actually close no matter if something",
            "            # went wrong with our ref counting",
            "            self._refcount = 1",
            "        try:",
            "            self.close()",
            "        except OSError as exc:",
            "            if exc.errno != errno.EBADF:",
            "                # If its not a bad file descriptor error, raise",
            "                raise",
            "",
            "    # pylint: enable=W1701",
            "",
            "    @property",
            "    def master_uri(self):",
            "        if \"master_uri\" in self.opts:",
            "            return self.opts[\"master_uri\"]",
            "",
            "        # if by chance master_uri is not there..",
            "        if \"master_ip\" in self.opts:",
            "            return _get_master_uri(",
            "                self.opts[\"master_ip\"],",
            "                self.opts[\"master_port\"],",
            "                source_ip=self.opts.get(\"source_ip\"),",
            "                source_port=self.opts.get(\"source_ret_port\"),",
            "            )",
            "",
            "        # if we've reached here something is very abnormal",
            "        raise SaltException(\"ReqChannel: missing master_uri/master_ip in self.opts\")",
            "",
            "    def _package_load(self, load):",
            "        return {",
            "            \"enc\": self.crypt,",
            "            \"load\": load,",
            "            \"version\": 2,",
            "        }",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def crypted_transfer_decode_dictentry(",
            "        self, load, dictkey=None, tries=3, timeout=60",
            "    ):",
            "        nonce = uuid.uuid4().hex",
            "        load[\"nonce\"] = nonce",
            "        if not self.auth.authenticated:",
            "            # Return control back to the caller, continue when authentication succeeds",
            "            yield self.auth.authenticate()",
            "",
            "        # Return control to the caller. When send() completes, resume by",
            "        # populating ret with the Future.result",
            "        ret = yield self.message_client.send(",
            "            self._package_load(self.auth.crypticle.dumps(load)),",
            "            timeout=timeout,",
            "            tries=tries,",
            "        )",
            "",
            "        if \"key\" not in ret:",
            "            # Reauth in the case our key is deleted on the master side.",
            "            yield self.auth.authenticate()",
            "            ret = yield self.message_client.send(",
            "                self._package_load(self.auth.crypticle.dumps(load)),",
            "                timeout=timeout,",
            "                tries=tries,",
            "            )",
            "",
            "        key = self.auth.get_keys()",
            "        if HAS_M2:",
            "            aes = key.private_decrypt(ret[\"key\"], RSA.pkcs1_oaep_padding)",
            "        else:",
            "            cipher = PKCS1_OAEP.new(key)",
            "            aes = cipher.decrypt(ret[\"key\"])",
            "",
            "        # Decrypt using the public key.",
            "        pcrypt = salt.crypt.Crypticle(self.opts, aes)",
            "        signed_msg = pcrypt.loads(ret[dictkey])",
            "",
            "        # Validate the master's signature.",
            "        master_pubkey_path = os.path.join(self.opts[\"pki_dir\"], \"minion_master.pub\")",
            "        if not salt.crypt.verify_signature(",
            "            master_pubkey_path, signed_msg[\"data\"], signed_msg[\"sig\"]",
            "        ):",
            "            raise salt.crypt.AuthenticationError(",
            "                \"Pillar payload signature failed to validate.\"",
            "            )",
            "",
            "        # Make sure the signed key matches the key we used to decrypt the data.",
            "        data = salt.payload.Serial({}).loads(signed_msg[\"data\"])",
            "        if data[\"key\"] != ret[\"key\"]:",
            "            raise salt.crypt.AuthenticationError(\"Key verification failed.\")",
            "",
            "        # Validate the nonce.",
            "        if data[\"nonce\"] != nonce:",
            "            raise salt.crypt.AuthenticationError(\"Pillar nonce verification failed.\")",
            "        raise salt.ext.tornado.gen.Return(data[\"pillar\"])",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _crypted_transfer(self, load, tries=3, timeout=60, raw=False):",
            "        \"\"\"",
            "        Send a load across the wire, with encryption",
            "",
            "        In case of authentication errors, try to renegotiate authentication",
            "        and retry the method.",
            "",
            "        Indeed, we can fail too early in case of a master restart during a",
            "        minion state execution call",
            "",
            "        :param dict load: A load to send across the wire",
            "        :param int tries: The number of times to make before failure",
            "        :param int timeout: The number of seconds on a response before failing",
            "        \"\"\"",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def _do_transfer():",
            "            # Yield control to the caller. When send() completes, resume by populating data with the Future.result",
            "            data = yield self.message_client.send(",
            "                self._package_load(self.auth.crypticle.dumps(load)),",
            "                timeout=timeout,",
            "                tries=tries,",
            "            )",
            "            # we may not have always data",
            "            # as for example for saltcall ret submission, this is a blind",
            "            # communication, we do not subscribe to return events, we just",
            "            # upload the results to the master",
            "            if data:",
            "                data = self.auth.crypticle.loads(data, raw)",
            "            if not raw:",
            "                data = salt.transport.frame.decode_embedded_strs(data)",
            "            raise salt.ext.tornado.gen.Return(data)",
            "",
            "        if not self.auth.authenticated:",
            "            # Return control back to the caller, resume when authentication succeeds",
            "            yield self.auth.authenticate()",
            "        try:",
            "            # We did not get data back the first time. Retry.",
            "            ret = yield _do_transfer()",
            "        except salt.crypt.AuthenticationError:",
            "            # If auth error, return control back to the caller, continue when authentication succeeds",
            "            yield self.auth.authenticate()",
            "            ret = yield _do_transfer()",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _uncrypted_transfer(self, load, tries=3, timeout=60):",
            "        \"\"\"",
            "        Send a load across the wire in cleartext",
            "",
            "        :param dict load: A load to send across the wire",
            "        :param int tries: The number of times to make before failure",
            "        :param int timeout: The number of seconds on a response before failing",
            "        \"\"\"",
            "        ret = yield self.message_client.send(",
            "            self._package_load(load), timeout=timeout, tries=tries,",
            "        )",
            "",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def send(self, load, tries=3, timeout=60, raw=False):",
            "        \"\"\"",
            "        Send a request, return a future which will complete when we send the message",
            "        \"\"\"",
            "        if self.crypt == \"clear\":",
            "            ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)",
            "        else:",
            "            ret = yield self._crypted_transfer(",
            "                load, tries=tries, timeout=timeout, raw=raw",
            "            )",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "",
            "class AsyncZeroMQPubChannel(",
            "    salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel",
            "):",
            "    \"\"\"",
            "    A transport channel backed by ZeroMQ for a Salt Publisher to use to",
            "    publish commands to connected minions",
            "    \"\"\"",
            "",
            "    async_methods = [",
            "        \"connect\",",
            "        \"_decode_messages\",",
            "    ]",
            "    close_methods = [",
            "        \"close\",",
            "    ]",
            "",
            "    def __init__(self, opts, **kwargs):",
            "        self.opts = opts",
            "        self.ttype = \"zeromq\"",
            "        self.io_loop = kwargs.get(\"io_loop\")",
            "        self._closing = False",
            "",
            "        if self.io_loop is None:",
            "            install_zmq()",
            "            self.io_loop = ZMQDefaultLoop.current()",
            "",
            "        self.hexid = hashlib.sha1(",
            "            salt.utils.stringutils.to_bytes(self.opts[\"id\"])",
            "        ).hexdigest()",
            "        self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.context = zmq.Context()",
            "        self._socket = self.context.socket(zmq.SUB)",
            "",
            "        if self.opts[\"zmq_filtering\"]:",
            "            # TODO: constants file for \"broadcast\"",
            "            self._socket.setsockopt(zmq.SUBSCRIBE, b\"broadcast\")",
            "            if self.opts.get(\"__role\") == \"syndic\":",
            "                self._socket.setsockopt(zmq.SUBSCRIBE, b\"syndic\")",
            "            else:",
            "                self._socket.setsockopt(",
            "                    zmq.SUBSCRIBE, salt.utils.stringutils.to_bytes(self.hexid)",
            "                )",
            "        else:",
            "            self._socket.setsockopt(zmq.SUBSCRIBE, b\"\")",
            "",
            "        self._socket.setsockopt(",
            "            zmq.IDENTITY, salt.utils.stringutils.to_bytes(self.opts[\"id\"])",
            "        )",
            "",
            "        # TODO: cleanup all the socket opts stuff",
            "        if hasattr(zmq, \"TCP_KEEPALIVE\"):",
            "            self._socket.setsockopt(zmq.TCP_KEEPALIVE, self.opts[\"tcp_keepalive\"])",
            "            self._socket.setsockopt(",
            "                zmq.TCP_KEEPALIVE_IDLE, self.opts[\"tcp_keepalive_idle\"]",
            "            )",
            "            self._socket.setsockopt(",
            "                zmq.TCP_KEEPALIVE_CNT, self.opts[\"tcp_keepalive_cnt\"]",
            "            )",
            "            self._socket.setsockopt(",
            "                zmq.TCP_KEEPALIVE_INTVL, self.opts[\"tcp_keepalive_intvl\"]",
            "            )",
            "",
            "        recon_delay = self.opts[\"recon_default\"]",
            "",
            "        if self.opts[\"recon_randomize\"]:",
            "            recon_delay = randint(",
            "                self.opts[\"recon_default\"],",
            "                self.opts[\"recon_default\"] + self.opts[\"recon_max\"],",
            "            )",
            "",
            "            log.debug(",
            "                \"Generated random reconnect delay between '%sms' and '%sms' (%s)\",",
            "                self.opts[\"recon_default\"],",
            "                self.opts[\"recon_default\"] + self.opts[\"recon_max\"],",
            "                recon_delay,",
            "            )",
            "",
            "        log.debug(\"Setting zmq_reconnect_ivl to '%sms'\", recon_delay)",
            "        self._socket.setsockopt(zmq.RECONNECT_IVL, recon_delay)",
            "",
            "        if hasattr(zmq, \"RECONNECT_IVL_MAX\"):",
            "            log.debug(",
            "                \"Setting zmq_reconnect_ivl_max to '%sms'\",",
            "                self.opts[\"recon_default\"] + self.opts[\"recon_max\"],",
            "            )",
            "",
            "            self._socket.setsockopt(zmq.RECONNECT_IVL_MAX, self.opts[\"recon_max\"])",
            "",
            "        if (self.opts[\"ipv6\"] is True or \":\" in self.opts[\"master_ip\"]) and hasattr(",
            "            zmq, \"IPV4ONLY\"",
            "        ):",
            "            # IPv6 sockets work for both IPv6 and IPv4 addresses",
            "            self._socket.setsockopt(zmq.IPV4ONLY, 0)",
            "",
            "        if HAS_ZMQ_MONITOR and self.opts[\"zmq_monitor\"]:",
            "            self._monitor = ZeroMQSocketMonitor(self._socket)",
            "            self._monitor.start_io_loop(self.io_loop)",
            "",
            "    def close(self):",
            "        if self._closing is True:",
            "            return",
            "",
            "        self._closing = True",
            "",
            "        if hasattr(self, \"_monitor\") and self._monitor is not None:",
            "            self._monitor.stop()",
            "            self._monitor = None",
            "        if hasattr(self, \"_stream\"):",
            "            self._stream.close(0)",
            "        elif hasattr(self, \"_socket\"):",
            "            self._socket.close(0)",
            "        if hasattr(self, \"context\") and self.context.closed is False:",
            "            self.context.term()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "    # TODO: this is the time to see if we are connected, maybe use the req channel to guess?",
            "    @salt.ext.tornado.gen.coroutine",
            "    def connect(self):",
            "        if not self.auth.authenticated:",
            "            yield self.auth.authenticate()",
            "",
            "        # if this is changed from the default, we assume it was intentional",
            "        if int(self.opts.get(\"publish_port\", 4506)) != 4506:",
            "            self.publish_port = self.opts.get(\"publish_port\")",
            "        # else take the relayed publish_port master reports",
            "        else:",
            "            self.publish_port = self.auth.creds[\"publish_port\"]",
            "",
            "        log.debug(",
            "            \"Connecting the Minion to the Master publish port, using the URI: %s\",",
            "            self.master_pub,",
            "        )",
            "        self._socket.connect(self.master_pub)",
            "",
            "    @property",
            "    def master_pub(self):",
            "        \"\"\"",
            "        Return the master publish port",
            "        \"\"\"",
            "        return _get_master_uri(",
            "            self.opts[\"master_ip\"],",
            "            self.publish_port,",
            "            source_ip=self.opts.get(\"source_ip\"),",
            "            source_port=self.opts.get(\"source_publish_port\"),",
            "        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _decode_messages(self, messages):",
            "        \"\"\"",
            "        Take the zmq messages, decrypt/decode them into a payload",
            "",
            "        :param list messages: A list of messages to be decoded",
            "        \"\"\"",
            "        messages_len = len(messages)",
            "        # if it was one message, then its old style",
            "        if messages_len == 1:",
            "            payload = self.serial.loads(messages[0])",
            "        # 2 includes a header which says who should do it",
            "        elif messages_len == 2:",
            "            message_target = salt.utils.stringutils.to_str(messages[0])",
            "            if (",
            "                self.opts.get(\"__role\") != \"syndic\"",
            "                and message_target not in (\"broadcast\", self.hexid)",
            "            ) or (",
            "                self.opts.get(\"__role\") == \"syndic\"",
            "                and message_target not in (\"broadcast\", \"syndic\")",
            "            ):",
            "                log.debug(\"Publish received for not this minion: %s\", message_target)",
            "                raise salt.ext.tornado.gen.Return(None)",
            "            payload = self.serial.loads(messages[1])",
            "        else:",
            "            raise Exception(",
            "                (",
            "                    \"Invalid number of messages ({}) in zeromq pub\"",
            "                    \"message from master\"",
            "                ).format(len(messages_len))",
            "            )",
            "        # Yield control back to the caller. When the payload has been decoded, assign",
            "        # the decoded payload to 'ret' and resume operation",
            "        ret = yield self._decode_payload(payload)",
            "        raise salt.ext.tornado.gen.Return(ret)",
            "",
            "    @property",
            "    def stream(self):",
            "        \"\"\"",
            "        Return the current zmqstream, creating one if necessary",
            "        \"\"\"",
            "        if not hasattr(self, \"_stream\"):",
            "            self._stream = zmq.eventloop.zmqstream.ZMQStream(",
            "                self._socket, io_loop=self.io_loop",
            "            )",
            "        return self._stream",
            "",
            "    def on_recv(self, callback):",
            "        \"\"\"",
            "        Register a callback for received messages (that we didn't initiate)",
            "",
            "        :param func callback: A function which should be called when data is received",
            "        \"\"\"",
            "        if callback is None:",
            "            return self.stream.on_recv(None)",
            "",
            "        @salt.ext.tornado.gen.coroutine",
            "        def wrap_callback(messages):",
            "            payload = yield self._decode_messages(messages)",
            "            if payload is not None:",
            "                callback(payload)",
            "",
            "        return self.stream.on_recv(wrap_callback)",
            "",
            "",
            "class ZeroMQReqServerChannel(",
            "    salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel",
            "):",
            "    def __init__(self, opts):",
            "        salt.transport.server.ReqServerChannel.__init__(self, opts)",
            "        self._closing = False",
            "        self._monitor = None",
            "        self._w_monitor = None",
            "",
            "    def zmq_device(self):",
            "        \"\"\"",
            "        Multiprocessing target for the zmq queue device",
            "        \"\"\"",
            "        self.__setup_signals()",
            "        salt.utils.process.appendproctitle(\"MWorkerQueue\")",
            "        self.context = zmq.Context(self.opts[\"worker_threads\"])",
            "        # Prepare the zeromq sockets",
            "        self.uri = \"tcp://{interface}:{ret_port}\".format(**self.opts)",
            "        self.clients = self.context.socket(zmq.ROUTER)",
            "        if self.opts[\"ipv6\"] is True and hasattr(zmq, \"IPV4ONLY\"):",
            "            # IPv6 sockets work for both IPv6 and IPv4 addresses",
            "            self.clients.setsockopt(zmq.IPV4ONLY, 0)",
            "        self.clients.setsockopt(zmq.BACKLOG, self.opts.get(\"zmq_backlog\", 1000))",
            "        self._start_zmq_monitor()",
            "        self.workers = self.context.socket(zmq.DEALER)",
            "",
            "        if self.opts[\"mworker_queue_niceness\"] and not salt.utils.platform.is_windows():",
            "            log.info(",
            "                \"setting mworker_queue niceness to %d\",",
            "                self.opts[\"mworker_queue_niceness\"],",
            "            )",
            "            os.nice(self.opts[\"mworker_queue_niceness\"])",
            "",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            self.w_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_workers\", 4515)",
            "            )",
            "        else:",
            "            self.w_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"workers.ipc\")",
            "            )",
            "",
            "        log.info(\"Setting up the master communication server\")",
            "        self.clients.bind(self.uri)",
            "        self.workers.bind(self.w_uri)",
            "",
            "        while True:",
            "            if self.clients.closed or self.workers.closed:",
            "                break",
            "            try:",
            "                zmq.device(zmq.QUEUE, self.clients, self.workers)",
            "            except zmq.ZMQError as exc:",
            "                if exc.errno == errno.EINTR:",
            "                    continue",
            "                raise",
            "            except (KeyboardInterrupt, SystemExit):",
            "                break",
            "",
            "    def close(self):",
            "        \"\"\"",
            "        Cleanly shutdown the router socket",
            "        \"\"\"",
            "        if self._closing:",
            "            return",
            "        log.info(\"MWorkerQueue under PID %s is closing\", os.getpid())",
            "        self._closing = True",
            "        if getattr(self, \"_monitor\", None) is not None:",
            "            self._monitor.stop()",
            "            self._monitor = None",
            "        if getattr(self, \"_w_monitor\", None) is not None:",
            "            self._w_monitor.stop()",
            "            self._w_monitor = None",
            "        if hasattr(self, \"clients\") and self.clients.closed is False:",
            "            self.clients.close()",
            "        if hasattr(self, \"workers\") and self.workers.closed is False:",
            "            self.workers.close()",
            "        if hasattr(self, \"stream\"):",
            "            self.stream.close()",
            "        if hasattr(self, \"_socket\") and self._socket.closed is False:",
            "            self._socket.close()",
            "        if hasattr(self, \"context\") and self.context.closed is False:",
            "            self.context.term()",
            "",
            "    def pre_fork(self, process_manager):",
            "        \"\"\"",
            "        Pre-fork we need to create the zmq router device",
            "",
            "        :param func process_manager: An instance of salt.utils.process.ProcessManager",
            "        \"\"\"",
            "        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)",
            "        process_manager.add_process(self.zmq_device)",
            "",
            "    def _start_zmq_monitor(self):",
            "        \"\"\"",
            "        Starts ZMQ monitor for debugging purposes.",
            "        :return:",
            "        \"\"\"",
            "        # Socket monitor shall be used the only for debug",
            "        # purposes so using threading doesn't look too bad here",
            "",
            "        if HAS_ZMQ_MONITOR and self.opts[\"zmq_monitor\"]:",
            "            log.debug(\"Starting ZMQ monitor\")",
            "            import threading",
            "",
            "            self._w_monitor = ZeroMQSocketMonitor(self._socket)",
            "            threading.Thread(target=self._w_monitor.start_poll).start()",
            "            log.debug(\"ZMQ monitor has been started started\")",
            "",
            "    def post_fork(self, payload_handler, io_loop):",
            "        \"\"\"",
            "        After forking we need to create all of the local sockets to listen to the",
            "        router",
            "",
            "        :param func payload_handler: A function to called to handle incoming payloads as",
            "                                     they are picked up off the wire",
            "        :param IOLoop io_loop: An instance of a Tornado IOLoop, to handle event scheduling",
            "        \"\"\"",
            "        self.payload_handler = payload_handler",
            "        self.io_loop = io_loop",
            "",
            "        self.context = zmq.Context(1)",
            "        self._socket = self.context.socket(zmq.REP)",
            "        self._start_zmq_monitor()",
            "",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            self.w_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_workers\", 4515)",
            "            )",
            "        else:",
            "            self.w_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"workers.ipc\")",
            "            )",
            "        log.info(\"Worker binding to socket %s\", self.w_uri)",
            "        self._socket.connect(self.w_uri)",
            "",
            "        salt.transport.mixins.auth.AESReqServerMixin.post_fork(",
            "            self, payload_handler, io_loop",
            "        )",
            "",
            "        self.stream = zmq.eventloop.zmqstream.ZMQStream(",
            "            self._socket, io_loop=self.io_loop",
            "        )",
            "        self.stream.on_recv_stream(self.handle_message)",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def handle_message(self, stream, payload):",
            "        \"\"\"",
            "        Handle incoming messages from underlying TCP streams",
            "",
            "        :stream ZMQStream stream: A ZeroMQ stream.",
            "        See http://zeromq.github.io/pyzmq/api/generated/zmq.eventloop.zmqstream.html",
            "",
            "        :param dict payload: A payload to process",
            "        \"\"\"",
            "        try:",
            "            payload = self.serial.loads(payload[0])",
            "            payload = self._decode_payload(payload)",
            "        except Exception as exc:  # pylint: disable=broad-except",
            "            exc_type = type(exc).__name__",
            "            if exc_type == \"AuthenticationError\":",
            "                log.debug(",
            "                    \"Minion failed to auth to master. Since the payload is \"",
            "                    \"encrypted, it is not known which minion failed to \"",
            "                    \"authenticate. It is likely that this is a transient \"",
            "                    \"failure due to the master rotating its public key.\"",
            "                )",
            "            else:",
            "                log.error(\"Bad load from minion: %s: %s\", exc_type, exc)",
            "            stream.send(self.serial.dumps(\"bad load\"))",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        # TODO helper functions to normalize payload?",
            "        if not isinstance(payload, dict) or not isinstance(payload.get(\"load\"), dict):",
            "            log.error(",
            "                \"payload and load must be a dict. Payload was: %s and load was %s\",",
            "                payload,",
            "                payload.get(\"load\"),",
            "            )",
            "            stream.send(self.serial.dumps(\"payload and load must be a dict\"))",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        try:",
            "            id_ = payload[\"load\"].get(\"id\", \"\")",
            "            if \"\\0\" in id_:",
            "                log.error(\"Payload contains an id with a null byte: %s\", payload)",
            "                stream.send(self.serial.dumps(\"bad load: id contains a null byte\"))",
            "                raise salt.ext.tornado.gen.Return()",
            "        except TypeError:",
            "            log.error(\"Payload contains non-string id: %s\", payload)",
            "            stream.send(",
            "                self.serial.dumps(\"bad load: id {} is not a string\".format(id_))",
            "            )",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        version = 0",
            "        if \"version\" in payload:",
            "            version = payload[\"version\"]",
            "",
            "        # intercept the \"_auth\" commands, since the main daemon shouldn't know",
            "        # anything about our key auth",
            "        if payload[\"enc\"] == \"clear\" and payload.get(\"load\", {}).get(\"cmd\") == \"_auth\":",
            "            stream.send(self.serial.dumps(self._auth(payload[\"load\"])))",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        # TODO: test",
            "        try:",
            "            # Take the payload_handler function that was registered when we created the channel",
            "            # and call it, returning control to the caller until it completes",
            "            ret, req_opts = yield self.payload_handler(payload)",
            "        except Exception as e:  # pylint: disable=broad-except",
            "            # always attempt to return an error to the minion",
            "            stream.send(\"Some exception handling minion payload\")",
            "            log.error(\"Some exception handling a payload from minion\", exc_info=True)",
            "            raise salt.ext.tornado.gen.Return()",
            "",
            "        req_fun = req_opts.get(\"fun\", \"send\")",
            "        if req_fun == \"send_clear\":",
            "            stream.send(self.serial.dumps(ret))",
            "        elif req_fun == \"send\":",
            "            stream.send(self.serial.dumps(self.crypticle.dumps(ret)))",
            "        elif req_fun == \"send_private\":",
            "            sign_messages = False",
            "            nonce = None",
            "            if version > 1:",
            "                sign_messages = True",
            "                nonce = payload[\"load\"][\"nonce\"]",
            "            stream.send(",
            "                self.serial.dumps(",
            "                    self._encrypt_private(",
            "                        ret, req_opts[\"key\"], req_opts[\"tgt\"], nonce, sign_messages,",
            "                    )",
            "                )",
            "            )",
            "        else:",
            "            log.error(\"Unknown req_fun %s\", req_fun)",
            "            # always attempt to return an error to the minion",
            "            stream.send(\"Server-side exception handling payload\")",
            "        raise salt.ext.tornado.gen.Return()",
            "",
            "    def __setup_signals(self):",
            "        signal.signal(signal.SIGINT, self._handle_signals)",
            "        signal.signal(signal.SIGTERM, self._handle_signals)",
            "",
            "    def _handle_signals(self, signum, sigframe):",
            "        msg = \"{} received a \".format(self.__class__.__name__)",
            "        if signum == signal.SIGINT:",
            "            msg += \"SIGINT\"",
            "        elif signum == signal.SIGTERM:",
            "            msg += \"SIGTERM\"",
            "        msg += \". Exiting\"",
            "        log.debug(msg)",
            "        self.close()",
            "        sys.exit(salt.defaults.exitcodes.EX_OK)",
            "",
            "",
            "def _set_tcp_keepalive(zmq_socket, opts):",
            "    \"\"\"",
            "    Ensure that TCP keepalives are set as specified in \"opts\".",
            "",
            "    Warning: Failure to set TCP keepalives on the salt-master can result in",
            "    not detecting the loss of a minion when the connection is lost or when",
            "    its host has been terminated without first closing the socket.",
            "    Salt's Presence System depends on this connection status to know if a minion",
            "    is \"present\".",
            "",
            "    Warning: Failure to set TCP keepalives on minions can result in frequent or",
            "    unexpected disconnects!",
            "    \"\"\"",
            "    if hasattr(zmq, \"TCP_KEEPALIVE\") and opts:",
            "        if \"tcp_keepalive\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE, opts[\"tcp_keepalive\"])",
            "        if \"tcp_keepalive_idle\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE_IDLE, opts[\"tcp_keepalive_idle\"])",
            "        if \"tcp_keepalive_cnt\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE_CNT, opts[\"tcp_keepalive_cnt\"])",
            "        if \"tcp_keepalive_intvl\" in opts:",
            "            zmq_socket.setsockopt(zmq.TCP_KEEPALIVE_INTVL, opts[\"tcp_keepalive_intvl\"])",
            "",
            "",
            "class ZeroMQPubServerChannel(salt.transport.server.PubServerChannel):",
            "    \"\"\"",
            "    Encapsulate synchronous operations for a publisher channel",
            "    \"\"\"",
            "",
            "    _sock_data = threading.local()",
            "",
            "    def __init__(self, opts):",
            "        self.opts = opts",
            "        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?",
            "        self.ckminions = salt.utils.minions.CkMinions(self.opts)",
            "",
            "    def connect(self):",
            "        return salt.ext.tornado.gen.sleep(5)",
            "",
            "    def _publish_daemon(self, log_queue=None):",
            "        \"\"\"",
            "        Bind to the interface specified in the configuration file",
            "        \"\"\"",
            "        salt.utils.process.appendproctitle(self.__class__.__name__)",
            "",
            "        if self.opts[\"pub_server_niceness\"] and not salt.utils.platform.is_windows():",
            "            log.info(",
            "                \"setting Publish daemon niceness to %i\",",
            "                self.opts[\"pub_server_niceness\"],",
            "            )",
            "            os.nice(self.opts[\"pub_server_niceness\"])",
            "",
            "        if log_queue:",
            "            salt.log.setup.set_multiprocessing_logging_queue(log_queue)",
            "            salt.log.setup.setup_multiprocessing_logging(log_queue)",
            "",
            "        # Set up the context",
            "        context = zmq.Context(1)",
            "        # Prepare minion publish socket",
            "        pub_sock = context.socket(zmq.PUB)",
            "        _set_tcp_keepalive(pub_sock, self.opts)",
            "        # if 2.1 >= zmq < 3.0, we only have one HWM setting",
            "        try:",
            "            pub_sock.setsockopt(zmq.HWM, self.opts.get(\"pub_hwm\", 1000))",
            "        # in zmq >= 3.0, there are separate send and receive HWM settings",
            "        except AttributeError:",
            "            # Set the High Water Marks. For more information on HWM, see:",
            "            # http://api.zeromq.org/4-1:zmq-setsockopt",
            "            pub_sock.setsockopt(zmq.SNDHWM, self.opts.get(\"pub_hwm\", 1000))",
            "            pub_sock.setsockopt(zmq.RCVHWM, self.opts.get(\"pub_hwm\", 1000))",
            "        if self.opts[\"ipv6\"] is True and hasattr(zmq, \"IPV4ONLY\"):",
            "            # IPv6 sockets work for both IPv6 and IPv4 addresses",
            "            pub_sock.setsockopt(zmq.IPV4ONLY, 0)",
            "        pub_sock.setsockopt(zmq.BACKLOG, self.opts.get(\"zmq_backlog\", 1000))",
            "        pub_sock.setsockopt(zmq.LINGER, -1)",
            "        pub_uri = \"tcp://{interface}:{publish_port}\".format(**self.opts)",
            "        # Prepare minion pull socket",
            "        pull_sock = context.socket(zmq.PULL)",
            "        pull_sock.setsockopt(zmq.LINGER, -1)",
            "",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_publish_pull\", 4514)",
            "            )",
            "        else:",
            "            pull_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "            )",
            "        salt.utils.zeromq.check_ipc_path_max_len(pull_uri)",
            "",
            "        # Start the minion command publisher",
            "        log.info(\"Starting the Salt Publisher on %s\", pub_uri)",
            "        pub_sock.bind(pub_uri)",
            "",
            "        # Securely create socket",
            "        log.info(\"Starting the Salt Puller on %s\", pull_uri)",
            "        with salt.utils.files.set_umask(0o177):",
            "            pull_sock.bind(pull_uri)",
            "",
            "        try:",
            "            while True:",
            "                # Catch and handle EINTR from when this process is sent",
            "                # SIGUSR1 gracefully so we don't choke and die horribly",
            "                try:",
            "                    log.debug(\"Publish daemon getting data from puller %s\", pull_uri)",
            "                    package = pull_sock.recv()",
            "                    log.debug(\"Publish daemon received payload. size=%d\", len(package))",
            "",
            "                    unpacked_package = salt.payload.unpackage(package)",
            "                    unpacked_package = salt.transport.frame.decode_embedded_strs(",
            "                        unpacked_package",
            "                    )",
            "                    payload = unpacked_package[\"payload\"]",
            "                    log.trace(\"Accepted unpacked package from puller\")",
            "                    if self.opts[\"zmq_filtering\"]:",
            "                        # if you have a specific topic list, use that",
            "                        if \"topic_lst\" in unpacked_package:",
            "                            for topic in unpacked_package[\"topic_lst\"]:",
            "                                log.trace(",
            "                                    \"Sending filtered data over publisher %s\", pub_uri",
            "                                )",
            "                                # zmq filters are substring match, hash the topic",
            "                                # to avoid collisions",
            "                                htopic = salt.utils.stringutils.to_bytes(",
            "                                    hashlib.sha1(",
            "                                        salt.utils.stringutils.to_bytes(topic)",
            "                                    ).hexdigest()",
            "                                )",
            "                                pub_sock.send(htopic, flags=zmq.SNDMORE)",
            "                                pub_sock.send(payload)",
            "                                log.trace(\"Filtered data has been sent\")",
            "",
            "                            # Syndic broadcast",
            "                            if self.opts.get(\"order_masters\"):",
            "                                log.trace(\"Sending filtered data to syndic\")",
            "                                pub_sock.send(b\"syndic\", flags=zmq.SNDMORE)",
            "                                pub_sock.send(payload)",
            "                                log.trace(\"Filtered data has been sent to syndic\")",
            "                        # otherwise its a broadcast",
            "                        else:",
            "                            # TODO: constants file for \"broadcast\"",
            "                            log.trace(",
            "                                \"Sending broadcasted data over publisher %s\", pub_uri",
            "                            )",
            "                            pub_sock.send(b\"broadcast\", flags=zmq.SNDMORE)",
            "                            pub_sock.send(payload)",
            "                            log.trace(\"Broadcasted data has been sent\")",
            "                    else:",
            "                        log.trace(",
            "                            \"Sending ZMQ-unfiltered data over publisher %s\", pub_uri",
            "                        )",
            "                        pub_sock.send(payload)",
            "                        log.trace(\"Unfiltered data has been sent\")",
            "                except zmq.ZMQError as exc:",
            "                    if exc.errno == errno.EINTR:",
            "                        continue",
            "                    raise",
            "",
            "        except KeyboardInterrupt:",
            "            log.trace(\"Publish daemon caught Keyboard interupt, tearing down\")",
            "        # Cleanly close the sockets if we're shutting down",
            "        if pub_sock.closed is False:",
            "            pub_sock.close()",
            "        if pull_sock.closed is False:",
            "            pull_sock.close()",
            "        if context.closed is False:",
            "            context.term()",
            "",
            "    def pre_fork(self, process_manager, kwargs=None):",
            "        \"\"\"",
            "        Do anything necessary pre-fork. Since this is on the master side this will",
            "        primarily be used to create IPC channels and create our daemon process to",
            "        do the actual publishing",
            "",
            "        :param func process_manager: A ProcessManager, from salt.utils.process.ProcessManager",
            "        \"\"\"",
            "        process_manager.add_process(self._publish_daemon, kwargs=kwargs)",
            "",
            "    @property",
            "    def pub_sock(self):",
            "        \"\"\"",
            "        This thread's zmq publisher socket. This socket is stored on the class",
            "        so that multiple instantiations in the same thread will re-use a single",
            "        zmq socket.",
            "        \"\"\"",
            "        try:",
            "            return self._sock_data.sock",
            "        except AttributeError:",
            "            pass",
            "",
            "    def pub_connect(self):",
            "        \"\"\"",
            "        Create and connect this thread's zmq socket. If a publisher socket",
            "        already exists \"pub_close\" is called before creating and connecting a",
            "        new socket.",
            "        \"\"\"",
            "        if self.pub_sock:",
            "            self.pub_close()",
            "        ctx = zmq.Context.instance()",
            "        self._sock_data.sock = ctx.socket(zmq.PUSH)",
            "        self.pub_sock.setsockopt(zmq.LINGER, -1)",
            "        if self.opts.get(\"ipc_mode\", \"\") == \"tcp\":",
            "            pull_uri = \"tcp://127.0.0.1:{}\".format(",
            "                self.opts.get(\"tcp_master_publish_pull\", 4514)",
            "            )",
            "        else:",
            "            pull_uri = \"ipc://{}\".format(",
            "                os.path.join(self.opts[\"sock_dir\"], \"publish_pull.ipc\")",
            "            )",
            "        log.debug(\"Connecting to pub server: %s\", pull_uri)",
            "        self.pub_sock.connect(pull_uri)",
            "        return self._sock_data.sock",
            "",
            "    def pub_close(self):",
            "        \"\"\"",
            "        Disconnect an existing publisher socket and remove it from the local",
            "        thread's cache.",
            "        \"\"\"",
            "        if hasattr(self._sock_data, \"sock\"):",
            "            self._sock_data.sock.close()",
            "            delattr(self._sock_data, \"sock\")",
            "",
            "    def publish(self, load):",
            "        \"\"\"",
            "        Publish \"load\" to minions. This send the load to the publisher daemon",
            "        process with does the actual sending to minions.",
            "",
            "        :param dict load: A load to be sent across the wire to minions",
            "        \"\"\"",
            "        payload = {\"enc\": \"aes\"}",
            "        crypticle = salt.crypt.Crypticle(",
            "            self.opts, salt.master.SMaster.secrets[\"aes\"][\"secret\"].value",
            "        )",
            "        payload[\"load\"] = crypticle.dumps(load)",
            "        if self.opts[\"sign_pub_messages\"]:",
            "            master_pem_path = os.path.join(self.opts[\"pki_dir\"], \"master.pem\")",
            "            log.debug(\"Signing data packet\")",
            "            payload[\"sig\"] = salt.crypt.sign_message(master_pem_path, payload[\"load\"])",
            "        int_payload = {\"payload\": self.serial.dumps(payload)}",
            "",
            "        # add some targeting stuff for lists only (for now)",
            "        if load[\"tgt_type\"] == \"list\":",
            "            int_payload[\"topic_lst\"] = load[\"tgt\"]",
            "",
            "        # If zmq_filtering is enabled, target matching has to happen master side",
            "        match_targets = [\"pcre\", \"glob\", \"list\"]",
            "        if self.opts[\"zmq_filtering\"] and load[\"tgt_type\"] in match_targets:",
            "            # Fetch a list of minions that match",
            "            _res = self.ckminions.check_minions(load[\"tgt\"], tgt_type=load[\"tgt_type\"])",
            "            match_ids = _res[\"minions\"]",
            "",
            "            log.debug(\"Publish Side Match: %s\", match_ids)",
            "            # Send list of miions thru so zmq can target them",
            "            int_payload[\"topic_lst\"] = match_ids",
            "        payload = self.serial.dumps(int_payload)",
            "        log.debug(",
            "            \"Sending payload to publish daemon. jid=%s size=%d\",",
            "            load.get(\"jid\", None),",
            "            len(payload),",
            "        )",
            "        if not self.pub_sock:",
            "            self.pub_connect()",
            "        self.pub_sock.send(payload)",
            "        log.debug(\"Sent payload to publish daemon.\")",
            "",
            "",
            "class AsyncReqMessageClientPool(salt.transport.MessageClientPool):",
            "    \"\"\"",
            "    Wrapper class of AsyncReqMessageClientPool to avoid blocking waiting while writing data to socket.",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, args=None, kwargs=None):",
            "        self._closing = False",
            "        super().__init__(AsyncReqMessageClient, opts, args=args, kwargs=kwargs)",
            "",
            "    def close(self):",
            "        if self._closing:",
            "            return",
            "",
            "        self._closing = True",
            "        for message_client in self.message_clients:",
            "            message_client.close()",
            "        self.message_clients = []",
            "",
            "    def send(self, *args, **kwargs):",
            "        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))",
            "        return message_clients[0].send(*args, **kwargs)",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, *args):",
            "        self.close()",
            "",
            "",
            "# TODO: unit tests!",
            "class AsyncReqMessageClient:",
            "    \"\"\"",
            "    This class wraps the underlying zeromq REQ socket and gives a future-based",
            "    interface to sending and recieving messages. This works around the primary",
            "    limitation of serialized send/recv on the underlying socket by queueing the",
            "    message sends in this class. In the future if we decide to attempt to multiplex",
            "    we can manage a pool of REQ/REP sockets-- but for now we'll just do them in serial",
            "    \"\"\"",
            "",
            "    def __init__(self, opts, addr, linger=0, io_loop=None):",
            "        \"\"\"",
            "        Create an asynchronous message client",
            "",
            "        :param dict opts: The salt opts dictionary",
            "        :param str addr: The interface IP address to bind to",
            "        :param int linger: The number of seconds to linger on a ZMQ socket. See",
            "                           http://api.zeromq.org/2-1:zmq-setsockopt [ZMQ_LINGER]",
            "        :param IOLoop io_loop: A Tornado IOLoop event scheduler [tornado.ioloop.IOLoop]",
            "        \"\"\"",
            "        self.opts = opts",
            "        self.addr = addr",
            "        self.linger = linger",
            "        if io_loop is None:",
            "            self.io_loop = salt.ext.tornado.ioloop.IOLoop.current()",
            "        else:",
            "            self.io_loop = io_loop",
            "",
            "        self.serial = salt.payload.Serial(self.opts)",
            "        self.context = zmq.Context()",
            "",
            "        # wire up sockets",
            "        self._init_socket()",
            "",
            "        self.send_queue = []",
            "        # mapping of message -> future",
            "        self.send_future_map = {}",
            "",
            "        self.send_timeout_map = {}  # message -> timeout",
            "        self._closing = False",
            "",
            "    # TODO: timeout all in-flight sessions, or error",
            "    def close(self):",
            "        try:",
            "            if self._closing:",
            "                return",
            "        except AttributeError:",
            "            # We must have been called from __del__",
            "            # The python interpreter has nuked most attributes already",
            "            return",
            "        else:",
            "            self._closing = True",
            "            if hasattr(self, \"stream\") and self.stream is not None:",
            "                if ZMQ_VERSION_INFO < (14, 3, 0):",
            "                    # stream.close() doesn't work properly on pyzmq < 14.3.0",
            "                    if self.stream.socket:",
            "                        self.stream.socket.close()",
            "                    self.stream.io_loop.remove_handler(self.stream.socket)",
            "                    # set this to None, more hacks for messed up pyzmq",
            "                    self.stream.socket = None",
            "                    self.socket.close()",
            "                else:",
            "                    self.stream.close()",
            "                    self.socket = None",
            "                self.stream = None",
            "            if self.context.closed is False:",
            "                self.context.term()",
            "",
            "    # pylint: disable=W1701",
            "    def __del__(self):",
            "        self.close()",
            "",
            "    # pylint: enable=W1701",
            "",
            "    def _init_socket(self):",
            "        if hasattr(self, \"stream\"):",
            "            self.stream.close()  # pylint: disable=E0203",
            "            self.socket.close()  # pylint: disable=E0203",
            "            del self.stream",
            "            del self.socket",
            "",
            "        self.socket = self.context.socket(zmq.REQ)",
            "",
            "        # socket options",
            "        if hasattr(zmq, \"RECONNECT_IVL_MAX\"):",
            "            self.socket.setsockopt(zmq.RECONNECT_IVL_MAX, 5000)",
            "",
            "        _set_tcp_keepalive(self.socket, self.opts)",
            "        if self.addr.startswith(\"tcp://[\"):",
            "            # Hint PF type if bracket enclosed IPv6 address",
            "            if hasattr(zmq, \"IPV6\"):",
            "                self.socket.setsockopt(zmq.IPV6, 1)",
            "            elif hasattr(zmq, \"IPV4ONLY\"):",
            "                self.socket.setsockopt(zmq.IPV4ONLY, 0)",
            "        self.socket.linger = self.linger",
            "        log.debug(\"Trying to connect to: %s\", self.addr)",
            "        self.socket.connect(self.addr)",
            "        self.stream = zmq.eventloop.zmqstream.ZMQStream(",
            "            self.socket, io_loop=self.io_loop",
            "        )",
            "",
            "    @salt.ext.tornado.gen.coroutine",
            "    def _internal_send_recv(self):",
            "        while len(self.send_queue) > 0:",
            "            message = self.send_queue[0]",
            "            future = self.send_future_map.get(message, None)",
            "            if future is None:",
            "                # Timedout",
            "                del self.send_queue[0]",
            "                continue",
            "",
            "            # send",
            "            def mark_future(msg):",
            "                if not future.done():",
            "                    data = self.serial.loads(msg[0])",
            "                    future.set_result(data)",
            "",
            "            self.stream.on_recv(mark_future)",
            "            self.stream.send(message)",
            "",
            "            try:",
            "                ret = yield future",
            "            except Exception as err:  # pylint: disable=broad-except",
            "                log.debug(\"Re-init ZMQ socket: %s\", err)",
            "                self._init_socket()  # re-init the zmq socket (no other way in zmq)",
            "                del self.send_queue[0]",
            "                continue",
            "            del self.send_queue[0]",
            "            self.send_future_map.pop(message, None)",
            "            self.remove_message_timeout(message)",
            "",
            "    def remove_message_timeout(self, message):",
            "        if message not in self.send_timeout_map:",
            "            return",
            "        timeout = self.send_timeout_map.pop(message, None)",
            "        if timeout is not None:",
            "            # Hasn't been already timedout",
            "            self.io_loop.remove_timeout(timeout)",
            "",
            "    def timeout_message(self, message):",
            "        \"\"\"",
            "        Handle a message timeout by removing it from the sending queue",
            "        and informing the caller",
            "",
            "        :raises: SaltReqTimeoutError",
            "        \"\"\"",
            "        future = self.send_future_map.pop(message, None)",
            "        # In a race condition the message might have been sent by the time",
            "        # we're timing it out. Make sure the future is not None",
            "        if future is not None:",
            "            del self.send_timeout_map[message]",
            "            if future.attempts < future.tries:",
            "                future.attempts += 1",
            "                log.debug(",
            "                    \"SaltReqTimeoutError, retrying. (%s/%s)\",",
            "                    future.attempts,",
            "                    future.tries,",
            "                )",
            "                self.send(",
            "                    message, timeout=future.timeout, tries=future.tries, future=future,",
            "                )",
            "",
            "            else:",
            "                future.set_exception(SaltReqTimeoutError(\"Message timed out\"))",
            "",
            "    def send(",
            "        self, message, timeout=None, tries=3, future=None, callback=None, raw=False",
            "    ):",
            "        \"\"\"",
            "        Return a future which will be completed when the message has a response",
            "        \"\"\"",
            "        if future is None:",
            "            future = salt.ext.tornado.concurrent.Future()",
            "            future.tries = tries",
            "            future.attempts = 0",
            "            future.timeout = timeout",
            "            # if a future wasn't passed in, we need to serialize the message",
            "            message = self.serial.dumps(message)",
            "        if callback is not None:",
            "",
            "            def handle_future(future):",
            "                response = future.result()",
            "                self.io_loop.add_callback(callback, response)",
            "",
            "            future.add_done_callback(handle_future)",
            "        # Add this future to the mapping",
            "        self.send_future_map[message] = future",
            "",
            "        if self.opts.get(\"detect_mode\") is True:",
            "            timeout = 1",
            "",
            "        if timeout is not None:",
            "            send_timeout = self.io_loop.call_later(",
            "                timeout, self.timeout_message, message",
            "            )",
            "            self.send_timeout_map[message] = send_timeout",
            "",
            "        if len(self.send_queue) == 0:",
            "            self.io_loop.spawn_callback(self._internal_send_recv)",
            "",
            "        self.send_queue.append(message)",
            "",
            "        return future",
            "",
            "",
            "class ZeroMQSocketMonitor:",
            "    __EVENT_MAP = None",
            "",
            "    def __init__(self, socket):",
            "        \"\"\"",
            "        Create ZMQ monitor sockets",
            "",
            "        More information:",
            "            http://api.zeromq.org/4-0:zmq-socket-monitor",
            "        \"\"\"",
            "        self._socket = socket",
            "        self._monitor_socket = self._socket.get_monitor_socket()",
            "        self._monitor_stream = None",
            "",
            "    def start_io_loop(self, io_loop):",
            "        log.trace(\"Event monitor start!\")",
            "        self._monitor_stream = zmq.eventloop.zmqstream.ZMQStream(",
            "            self._monitor_socket, io_loop=io_loop",
            "        )",
            "        self._monitor_stream.on_recv(self.monitor_callback)",
            "",
            "    def start_poll(self):",
            "        log.trace(\"Event monitor start!\")",
            "        try:",
            "            while self._monitor_socket is not None and self._monitor_socket.poll():",
            "                msg = self._monitor_socket.recv_multipart()",
            "                self.monitor_callback(msg)",
            "        except (AttributeError, zmq.error.ContextTerminated):",
            "            # We cannot log here because we'll get an interrupted system call in trying",
            "            # to flush the logging buffer as we terminate",
            "            pass",
            "",
            "    @property",
            "    def event_map(self):",
            "        if ZeroMQSocketMonitor.__EVENT_MAP is None:",
            "            event_map = {}",
            "            for name in dir(zmq):",
            "                if name.startswith(\"EVENT_\"):",
            "                    value = getattr(zmq, name)",
            "                    event_map[value] = name",
            "            ZeroMQSocketMonitor.__EVENT_MAP = event_map",
            "        return ZeroMQSocketMonitor.__EVENT_MAP",
            "",
            "    def monitor_callback(self, msg):",
            "        evt = zmq.utils.monitor.parse_monitor_message(msg)",
            "        evt[\"description\"] = self.event_map[evt[\"event\"]]",
            "        log.debug(\"ZeroMQ event: %s\", evt)",
            "        if evt[\"event\"] == zmq.EVENT_MONITOR_STOPPED:",
            "            self.stop()",
            "",
            "    def stop(self):",
            "        if self._socket is None:",
            "            return",
            "        self._socket.disable_monitor()",
            "        self._socket = None",
            "        self._monitor_socket = None",
            "        if self._monitor_stream is not None:",
            "            self._monitor_stream.close()",
            "            self._monitor_stream = None",
            "        log.trace(\"Event monitor done!\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "349": [
                "AsyncZeroMQReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "355": [
                "AsyncZeroMQReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "370": [
                "AsyncZeroMQReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "371": [
                "AsyncZeroMQReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "372": [
                "AsyncZeroMQReqChannel",
                "crypted_transfer_decode_dictentry"
            ],
            "890": [
                "ZeroMQReqServerChannel",
                "handle_message"
            ]
        },
        "addLocation": [
            "helpdesk.models.FollowUp",
            "salt.transport.zeromq.AsyncZeroMQReqChannel._uncrypted_transfer",
            "salt.transport.zeromq.AsyncZeroMQReqChannel.crypted_transfer_decode_dictentry"
        ]
    }
}