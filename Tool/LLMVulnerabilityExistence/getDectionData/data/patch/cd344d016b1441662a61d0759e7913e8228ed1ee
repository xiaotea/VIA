{
    "src/fides/api/service/connectors/saas/authenticated_client.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from functools import wraps"
            },
            "1": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from time import sleep"
            },
            "2": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from typing import TYPE_CHECKING, Any, Callable, List, Optional, Union"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+from urllib.parse import urlparse"
            },
            "4": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " from loguru import logger"
            },
            "6": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from requests import PreparedRequest, Request, Response, Session"
            },
            "7": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 21,
                "PatchRowcode": "     RateLimiterPeriod,"
            },
            "8": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 22,
                "PatchRowcode": "     RateLimiterRequest,"
            },
            "9": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " )"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+from fides.api.util.saas_util import deny_unsafe_hosts"
            },
            "11": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " from fides.config import CONFIG"
            },
            "12": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " if TYPE_CHECKING:"
            },
            "14": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "         Builds and executes an authenticated request."
            },
            "15": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "         Optionally ignores:"
            },
            "16": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": 199,
                "PatchRowcode": "           - all non-2xx/3xx responses if ignore_errors is set to True"
            },
            "17": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-          - no non-2xx/3xx repsones if ignore_errors is set to False"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 200,
                "PatchRowcode": "+          - no non-2xx/3xx responses if ignore_errors is set to False"
            },
            "19": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": 201,
                "PatchRowcode": "           - specific non-2xx/3xx responses if ignore_errors is set to a list of status codes"
            },
            "20": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 202,
                "PatchRowcode": "         \"\"\""
            },
            "21": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 203,
                "PatchRowcode": "         rate_limit_requests = self.build_rate_limit_requests()"
            },
            "22": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 206,
                "PatchRowcode": "         prepared_request: PreparedRequest = self.get_authenticated_request("
            },
            "23": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 207,
                "PatchRowcode": "             request_params"
            },
            "24": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": 208,
                "PatchRowcode": "         )"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+        if not prepared_request.url:"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+            raise ValueError(\"The URL for the prepared request is missing.\")"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+        # extract the hostname from the complete URL and verify its safety"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+        deny_unsafe_hosts(urlparse(prepared_request.url).netloc)"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 214,
                "PatchRowcode": "+"
            },
            "31": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": 215,
                "PatchRowcode": "         response = self.session.send(prepared_request)"
            },
            "32": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 216,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 217,
                "PatchRowcode": "         log_request_and_response_for_debugging("
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "import email",
            "import re",
            "import time",
            "from functools import wraps",
            "from time import sleep",
            "from typing import TYPE_CHECKING, Any, Callable, List, Optional, Union",
            "",
            "from loguru import logger",
            "from requests import PreparedRequest, Request, Response, Session",
            "",
            "from fides.api.common_exceptions import (",
            "    ClientUnsuccessfulException,",
            "    ConnectionException,",
            "    FidesopsException,",
            ")",
            "from fides.api.service.connectors.limiter.rate_limiter import (",
            "    RateLimiter,",
            "    RateLimiterPeriod,",
            "    RateLimiterRequest,",
            ")",
            "from fides.config import CONFIG",
            "",
            "if TYPE_CHECKING:",
            "    from fides.api.models.connectionconfig import ConnectionConfig",
            "    from fides.api.schemas.limiter.rate_limit_config import RateLimitConfig",
            "    from fides.api.schemas.saas.saas_config import ClientConfig",
            "    from fides.api.schemas.saas.shared_schemas import SaaSRequestParams",
            "",
            "",
            "class AuthenticatedClient:",
            "    \"\"\"",
            "    A helper class to build authenticated HTTP requests based on",
            "    authentication and parameter configurations.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        uri: str,",
            "        configuration: ConnectionConfig,",
            "        client_config: ClientConfig,",
            "        rate_limit_config: Optional[RateLimitConfig] = None,",
            "    ):",
            "        self.session = Session()",
            "        self.uri = uri",
            "        self.configuration = configuration",
            "        self.client_config = client_config",
            "        self.rate_limit_config = rate_limit_config",
            "",
            "    def get_authenticated_request(",
            "        self, request_params: SaaSRequestParams",
            "    ) -> PreparedRequest:",
            "        \"\"\"",
            "        Returns an authenticated request based on the client config and",
            "        incoming path, headers, query, and body params.",
            "        \"\"\"",
            "",
            "        from fides.api.service.authentication.authentication_strategy import (  # pylint: disable=R0401",
            "            AuthenticationStrategy,",
            "        )",
            "",
            "        req: PreparedRequest = Request(",
            "            method=request_params.method,",
            "            url=f\"{self.uri}{request_params.path}\",",
            "            headers=request_params.headers,",
            "            params=request_params.query_params,",
            "            data=request_params.body,",
            "        ).prepare()",
            "",
            "        # add authentication if provided",
            "        if self.client_config.authentication:",
            "            auth_strategy = AuthenticationStrategy.get_strategy(",
            "                self.client_config.authentication.strategy,",
            "                self.client_config.authentication.configuration,",
            "            )",
            "            return auth_strategy.add_authentication(req, self.configuration)",
            "",
            "        # otherwise just return the prepared request",
            "        return req",
            "",
            "    def retry_send(  # type: ignore",
            "        retry_count: int,",
            "        backoff_factor: float,",
            "        retry_status_codes: List[int] = [429, 502, 503, 504],",
            "    ) -> Callable:",
            "        \"\"\"",
            "        Retry decorator for http requests, backing off exponentially or listening to server retry-after header",
            "",
            "        Exponential backoff factor uses the following formula:",
            "        backoff_factor * (2 ** (retry_attempt))",
            "        For an backoff_factor of 1 it will sleep for 2,4,8 seconds",
            "",
            "        General exceptions are not retried. RequestFailureResponseException exceptions are only retried",
            "        if the status code is in retry_status_codes.",
            "        \"\"\"",
            "",
            "        def decorator(func: Callable) -> Callable:",
            "            @wraps(func)",
            "            def result(*args: Any, **kwargs: Any) -> Response:",
            "                self = args[0]",
            "                last_exception: Optional[Union[BaseException, Exception]] = None",
            "",
            "                for attempt in range(retry_count + 1):",
            "                    sleep_time = backoff_factor * (2 ** (attempt + 1))",
            "                    try:",
            "                        return func(*args, **kwargs)",
            "                    except (",
            "                        RequestFailureResponseException",
            "                    ) as exc:  # pylint: disable=W0703",
            "                        response: Response = exc.response",
            "                        status_code: int = response.status_code",
            "                        last_exception = ClientUnsuccessfulException(",
            "                            status_code=status_code",
            "                        )",
            "",
            "                        if status_code not in retry_status_codes:",
            "                            break",
            "",
            "                        # override sleep time if retry after header is found",
            "                        retry_after_time = get_retry_after(response)",
            "                        sleep_time = (",
            "                            retry_after_time if retry_after_time else sleep_time",
            "                        )",
            "                    except Exception as exc:  # pylint: disable=W0703",
            "                        dev_mode_log = f\" with error: {exc}\" if CONFIG.dev_mode else \"\"",
            "                        last_exception = ConnectionException(",
            "                            f\"Operational Error connecting to '{self.configuration.key}'{dev_mode_log}\"",
            "                        )",
            "                        # requests library can raise ConnectionError, Timeout or TooManyRedirects",
            "                        # we will not retry these as they don't usually point to intermittent issues",
            "                        break",
            "",
            "                    if attempt < retry_count:",
            "                        logger.warning(",
            "                            \"Retrying http request in {} seconds\", sleep_time",
            "                        )",
            "                        sleep(sleep_time)",
            "",
            "                raise last_exception  # type: ignore",
            "",
            "            return result",
            "",
            "        return decorator",
            "",
            "    def build_rate_limit_requests(self) -> List[RateLimiterRequest]:",
            "        \"\"\"",
            "        Builds rate limit request objects for client's rate limit config",
            "",
            "        Returns empty list if a rate limit config is not provided or is not enabled",
            "        \"\"\"",
            "        if not self.rate_limit_config or not self.rate_limit_config.enabled:",
            "            return []",
            "",
            "        rate_limit_requests = [",
            "            RateLimiterRequest(",
            "                key=rate_limit.custom_key or self.configuration.key,",
            "                rate_limit=rate_limit.rate,",
            "                period=RateLimiterPeriod[rate_limit.period.name.upper()],",
            "            )",
            "            for rate_limit in (self.rate_limit_config.limits or [])",
            "        ]",
            "        return rate_limit_requests",
            "",
            "    def _should_ignore_error(",
            "        self,",
            "        status_code: int,",
            "        errors_to_ignore: Optional[Union[bool, List[int]]] = False,",
            "    ) -> bool:",
            "        \"\"\"Should an error of `status_code` be ignored?\"\"\"",
            "        if errors_to_ignore is False:",
            "            # `errors_to_ignore` is a bool and explicitly set to False so Fides should not",
            "            # ignore any errors",
            "            return False",
            "",
            "        if errors_to_ignore is True:",
            "            # `errors_to_ignore` is a bool and explicitly set to True so Fides should ignore",
            "            # all errors",
            "            return True",
            "",
            "        if isinstance(errors_to_ignore, list):",
            "            # `errors_to_ignore` is a list of status codes so Fides should ignore the error",
            "            # if the status code is within the list",
            "            return status_code in errors_to_ignore",
            "",
            "        return False",
            "",
            "    @retry_send(retry_count=3, backoff_factor=1.0)  # pylint: disable=E1124",
            "    def send(",
            "        self,",
            "        request_params: SaaSRequestParams,",
            "        ignore_errors: Optional[Union[bool, List[int]]] = False,",
            "    ) -> Response:",
            "        \"\"\"",
            "        Builds and executes an authenticated request.",
            "        Optionally ignores:",
            "          - all non-2xx/3xx responses if ignore_errors is set to True",
            "          - no non-2xx/3xx repsones if ignore_errors is set to False",
            "          - specific non-2xx/3xx responses if ignore_errors is set to a list of status codes",
            "        \"\"\"",
            "        rate_limit_requests = self.build_rate_limit_requests()",
            "        RateLimiter().limit(rate_limit_requests)",
            "",
            "        prepared_request: PreparedRequest = self.get_authenticated_request(",
            "            request_params",
            "        )",
            "        response = self.session.send(prepared_request)",
            "",
            "        log_request_and_response_for_debugging(",
            "            prepared_request, response",
            "        )  # Dev mode only",
            "",
            "        if not response.ok:",
            "            if self._should_ignore_error(",
            "                status_code=response.status_code,",
            "                errors_to_ignore=ignore_errors,",
            "            ):",
            "                logger.info(",
            "                    \"Ignoring errors on response with status code {} as configured.\",",
            "                    response.status_code,",
            "                )",
            "                return response",
            "            raise RequestFailureResponseException(response=response)",
            "        return response",
            "",
            "",
            "class RequestFailureResponseException(FidesopsException):",
            "    \"\"\"Exception class which preserves http response\"\"\"",
            "",
            "    response: Response",
            "",
            "    def __init__(self, response: Response):",
            "        super().__init__(\"Received failure response from server\")",
            "        self.response = response",
            "",
            "",
            "def log_request_and_response_for_debugging(",
            "    prepared_request: PreparedRequest, response: Response",
            ") -> None:",
            "    \"\"\"Log SaaS request and response in dev mode only\"\"\"",
            "    if CONFIG.dev_mode:",
            "        logger.info(",
            "            \"\\n\\n-----------SAAS REQUEST-----------\"",
            "            \"\\n{} {}\"",
            "            \"\\nheaders: {}\"",
            "            \"\\nbody: {}\"",
            "            \"\\nresponse: {}\",",
            "            prepared_request.method,",
            "            prepared_request.url,",
            "            prepared_request.headers,",
            "            prepared_request.body,",
            "            response._content,  # pylint: disable=W0212",
            "        )",
            "",
            "",
            "def get_retry_after(response: Response, max_retry_after: int = 300) -> Optional[float]:",
            "    \"\"\"Given a Response object, parses Retry-After header and calculates how long we should sleep for\"\"\"",
            "    retry_after = response.headers.get(\"Retry-After\", None)",
            "",
            "    if retry_after is None:",
            "        return None",
            "",
            "    seconds: float",
            "    # if a number value is provided the server is telling us to sleep for X seconds",
            "    if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):",
            "        seconds = int(retry_after)",
            "    # else we will attempt to parse a timestamp and diff with current time",
            "    else:",
            "        retry_date_tuple = email.utils.parsedate_tz(retry_after)",
            "        if retry_date_tuple is None:",
            "            return None",
            "",
            "        retry_date = email.utils.mktime_tz(retry_date_tuple)",
            "        seconds = retry_date - time.time()",
            "",
            "    seconds = max(seconds, 0)",
            "    return min(seconds, max_retry_after)"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import email",
            "import re",
            "import time",
            "from functools import wraps",
            "from time import sleep",
            "from typing import TYPE_CHECKING, Any, Callable, List, Optional, Union",
            "from urllib.parse import urlparse",
            "",
            "from loguru import logger",
            "from requests import PreparedRequest, Request, Response, Session",
            "",
            "from fides.api.common_exceptions import (",
            "    ClientUnsuccessfulException,",
            "    ConnectionException,",
            "    FidesopsException,",
            ")",
            "from fides.api.service.connectors.limiter.rate_limiter import (",
            "    RateLimiter,",
            "    RateLimiterPeriod,",
            "    RateLimiterRequest,",
            ")",
            "from fides.api.util.saas_util import deny_unsafe_hosts",
            "from fides.config import CONFIG",
            "",
            "if TYPE_CHECKING:",
            "    from fides.api.models.connectionconfig import ConnectionConfig",
            "    from fides.api.schemas.limiter.rate_limit_config import RateLimitConfig",
            "    from fides.api.schemas.saas.saas_config import ClientConfig",
            "    from fides.api.schemas.saas.shared_schemas import SaaSRequestParams",
            "",
            "",
            "class AuthenticatedClient:",
            "    \"\"\"",
            "    A helper class to build authenticated HTTP requests based on",
            "    authentication and parameter configurations.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        uri: str,",
            "        configuration: ConnectionConfig,",
            "        client_config: ClientConfig,",
            "        rate_limit_config: Optional[RateLimitConfig] = None,",
            "    ):",
            "        self.session = Session()",
            "        self.uri = uri",
            "        self.configuration = configuration",
            "        self.client_config = client_config",
            "        self.rate_limit_config = rate_limit_config",
            "",
            "    def get_authenticated_request(",
            "        self, request_params: SaaSRequestParams",
            "    ) -> PreparedRequest:",
            "        \"\"\"",
            "        Returns an authenticated request based on the client config and",
            "        incoming path, headers, query, and body params.",
            "        \"\"\"",
            "",
            "        from fides.api.service.authentication.authentication_strategy import (  # pylint: disable=R0401",
            "            AuthenticationStrategy,",
            "        )",
            "",
            "        req: PreparedRequest = Request(",
            "            method=request_params.method,",
            "            url=f\"{self.uri}{request_params.path}\",",
            "            headers=request_params.headers,",
            "            params=request_params.query_params,",
            "            data=request_params.body,",
            "        ).prepare()",
            "",
            "        # add authentication if provided",
            "        if self.client_config.authentication:",
            "            auth_strategy = AuthenticationStrategy.get_strategy(",
            "                self.client_config.authentication.strategy,",
            "                self.client_config.authentication.configuration,",
            "            )",
            "            return auth_strategy.add_authentication(req, self.configuration)",
            "",
            "        # otherwise just return the prepared request",
            "        return req",
            "",
            "    def retry_send(  # type: ignore",
            "        retry_count: int,",
            "        backoff_factor: float,",
            "        retry_status_codes: List[int] = [429, 502, 503, 504],",
            "    ) -> Callable:",
            "        \"\"\"",
            "        Retry decorator for http requests, backing off exponentially or listening to server retry-after header",
            "",
            "        Exponential backoff factor uses the following formula:",
            "        backoff_factor * (2 ** (retry_attempt))",
            "        For an backoff_factor of 1 it will sleep for 2,4,8 seconds",
            "",
            "        General exceptions are not retried. RequestFailureResponseException exceptions are only retried",
            "        if the status code is in retry_status_codes.",
            "        \"\"\"",
            "",
            "        def decorator(func: Callable) -> Callable:",
            "            @wraps(func)",
            "            def result(*args: Any, **kwargs: Any) -> Response:",
            "                self = args[0]",
            "                last_exception: Optional[Union[BaseException, Exception]] = None",
            "",
            "                for attempt in range(retry_count + 1):",
            "                    sleep_time = backoff_factor * (2 ** (attempt + 1))",
            "                    try:",
            "                        return func(*args, **kwargs)",
            "                    except (",
            "                        RequestFailureResponseException",
            "                    ) as exc:  # pylint: disable=W0703",
            "                        response: Response = exc.response",
            "                        status_code: int = response.status_code",
            "                        last_exception = ClientUnsuccessfulException(",
            "                            status_code=status_code",
            "                        )",
            "",
            "                        if status_code not in retry_status_codes:",
            "                            break",
            "",
            "                        # override sleep time if retry after header is found",
            "                        retry_after_time = get_retry_after(response)",
            "                        sleep_time = (",
            "                            retry_after_time if retry_after_time else sleep_time",
            "                        )",
            "                    except Exception as exc:  # pylint: disable=W0703",
            "                        dev_mode_log = f\" with error: {exc}\" if CONFIG.dev_mode else \"\"",
            "                        last_exception = ConnectionException(",
            "                            f\"Operational Error connecting to '{self.configuration.key}'{dev_mode_log}\"",
            "                        )",
            "                        # requests library can raise ConnectionError, Timeout or TooManyRedirects",
            "                        # we will not retry these as they don't usually point to intermittent issues",
            "                        break",
            "",
            "                    if attempt < retry_count:",
            "                        logger.warning(",
            "                            \"Retrying http request in {} seconds\", sleep_time",
            "                        )",
            "                        sleep(sleep_time)",
            "",
            "                raise last_exception  # type: ignore",
            "",
            "            return result",
            "",
            "        return decorator",
            "",
            "    def build_rate_limit_requests(self) -> List[RateLimiterRequest]:",
            "        \"\"\"",
            "        Builds rate limit request objects for client's rate limit config",
            "",
            "        Returns empty list if a rate limit config is not provided or is not enabled",
            "        \"\"\"",
            "        if not self.rate_limit_config or not self.rate_limit_config.enabled:",
            "            return []",
            "",
            "        rate_limit_requests = [",
            "            RateLimiterRequest(",
            "                key=rate_limit.custom_key or self.configuration.key,",
            "                rate_limit=rate_limit.rate,",
            "                period=RateLimiterPeriod[rate_limit.period.name.upper()],",
            "            )",
            "            for rate_limit in (self.rate_limit_config.limits or [])",
            "        ]",
            "        return rate_limit_requests",
            "",
            "    def _should_ignore_error(",
            "        self,",
            "        status_code: int,",
            "        errors_to_ignore: Optional[Union[bool, List[int]]] = False,",
            "    ) -> bool:",
            "        \"\"\"Should an error of `status_code` be ignored?\"\"\"",
            "        if errors_to_ignore is False:",
            "            # `errors_to_ignore` is a bool and explicitly set to False so Fides should not",
            "            # ignore any errors",
            "            return False",
            "",
            "        if errors_to_ignore is True:",
            "            # `errors_to_ignore` is a bool and explicitly set to True so Fides should ignore",
            "            # all errors",
            "            return True",
            "",
            "        if isinstance(errors_to_ignore, list):",
            "            # `errors_to_ignore` is a list of status codes so Fides should ignore the error",
            "            # if the status code is within the list",
            "            return status_code in errors_to_ignore",
            "",
            "        return False",
            "",
            "    @retry_send(retry_count=3, backoff_factor=1.0)  # pylint: disable=E1124",
            "    def send(",
            "        self,",
            "        request_params: SaaSRequestParams,",
            "        ignore_errors: Optional[Union[bool, List[int]]] = False,",
            "    ) -> Response:",
            "        \"\"\"",
            "        Builds and executes an authenticated request.",
            "        Optionally ignores:",
            "          - all non-2xx/3xx responses if ignore_errors is set to True",
            "          - no non-2xx/3xx responses if ignore_errors is set to False",
            "          - specific non-2xx/3xx responses if ignore_errors is set to a list of status codes",
            "        \"\"\"",
            "        rate_limit_requests = self.build_rate_limit_requests()",
            "        RateLimiter().limit(rate_limit_requests)",
            "",
            "        prepared_request: PreparedRequest = self.get_authenticated_request(",
            "            request_params",
            "        )",
            "        if not prepared_request.url:",
            "            raise ValueError(\"The URL for the prepared request is missing.\")",
            "",
            "        # extract the hostname from the complete URL and verify its safety",
            "        deny_unsafe_hosts(urlparse(prepared_request.url).netloc)",
            "",
            "        response = self.session.send(prepared_request)",
            "",
            "        log_request_and_response_for_debugging(",
            "            prepared_request, response",
            "        )  # Dev mode only",
            "",
            "        if not response.ok:",
            "            if self._should_ignore_error(",
            "                status_code=response.status_code,",
            "                errors_to_ignore=ignore_errors,",
            "            ):",
            "                logger.info(",
            "                    \"Ignoring errors on response with status code {} as configured.\",",
            "                    response.status_code,",
            "                )",
            "                return response",
            "            raise RequestFailureResponseException(response=response)",
            "        return response",
            "",
            "",
            "class RequestFailureResponseException(FidesopsException):",
            "    \"\"\"Exception class which preserves http response\"\"\"",
            "",
            "    response: Response",
            "",
            "    def __init__(self, response: Response):",
            "        super().__init__(\"Received failure response from server\")",
            "        self.response = response",
            "",
            "",
            "def log_request_and_response_for_debugging(",
            "    prepared_request: PreparedRequest, response: Response",
            ") -> None:",
            "    \"\"\"Log SaaS request and response in dev mode only\"\"\"",
            "    if CONFIG.dev_mode:",
            "        logger.info(",
            "            \"\\n\\n-----------SAAS REQUEST-----------\"",
            "            \"\\n{} {}\"",
            "            \"\\nheaders: {}\"",
            "            \"\\nbody: {}\"",
            "            \"\\nresponse: {}\",",
            "            prepared_request.method,",
            "            prepared_request.url,",
            "            prepared_request.headers,",
            "            prepared_request.body,",
            "            response._content,  # pylint: disable=W0212",
            "        )",
            "",
            "",
            "def get_retry_after(response: Response, max_retry_after: int = 300) -> Optional[float]:",
            "    \"\"\"Given a Response object, parses Retry-After header and calculates how long we should sleep for\"\"\"",
            "    retry_after = response.headers.get(\"Retry-After\", None)",
            "",
            "    if retry_after is None:",
            "        return None",
            "",
            "    seconds: float",
            "    # if a number value is provided the server is telling us to sleep for X seconds",
            "    if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):",
            "        seconds = int(retry_after)",
            "    # else we will attempt to parse a timestamp and diff with current time",
            "    else:",
            "        retry_date_tuple = email.utils.parsedate_tz(retry_after)",
            "        if retry_date_tuple is None:",
            "            return None",
            "",
            "        retry_date = email.utils.mktime_tz(retry_date_tuple)",
            "        seconds = retry_date - time.time()",
            "",
            "    seconds = max(seconds, 0)",
            "    return min(seconds, max_retry_after)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "198": [
                "AuthenticatedClient",
                "send"
            ]
        },
        "addLocation": []
    },
    "src/fides/api/util/saas_util.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 2,
                "afterPatchRowNumber": 2,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " import json"
            },
            "2": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " import re"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 5,
                "PatchRowcode": "+import socket"
            },
            "4": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 6,
                "PatchRowcode": " from collections import defaultdict, deque"
            },
            "5": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-from typing import Any, Dict, List, Optional, Set, Tuple"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 7,
                "PatchRowcode": "+from ipaddress import IPv4Address, IPv6Address, ip_address"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 8,
                "PatchRowcode": "+from typing import Any, Dict, List, Optional, Set, Tuple, Union"
            },
            "8": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " import pydash"
            },
            "10": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " import yaml"
            },
            "11": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " from fides.api.models.privacy_request import PrivacyRequest"
            },
            "12": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 18,
                "PatchRowcode": " from fides.api.schemas.saas.saas_config import SaaSRequest"
            },
            "13": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " from fides.api.schemas.saas.shared_schemas import SaaSRequestParams"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+from fides.config import CONFIG"
            },
            "15": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " from fides.config.helpers import load_file"
            },
            "16": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " FIDESOPS_GROUPED_INPUTS = \"fidesops_grouped_inputs\""
            },
            "18": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " CUSTOM_PRIVACY_REQUEST_FIELDS = \"custom_privacy_request_fields\""
            },
            "19": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "20": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 29,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+def deny_unsafe_hosts(host: str) -> str:"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+    \"\"\""
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+    Verify that the provided host isn't a potentially unsafe one."
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+    WARNING: IPv6 is _not_ supported and will throw an exception!"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+    \"\"\""
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+    if CONFIG.dev_mode:"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+        return host"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+    try:"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+        host_ip: Union[IPv4Address, IPv6Address] = ip_address("
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 41,
                "PatchRowcode": "+            socket.gethostbyname(host)"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 42,
                "PatchRowcode": "+        )"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 43,
                "PatchRowcode": "+    except socket.gaierror:"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 44,
                "PatchRowcode": "+        raise ValueError(f\"Failed to resolve hostname: {host}\")"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 45,
                "PatchRowcode": "+"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 46,
                "PatchRowcode": "+    if host_ip.is_link_local or host_ip.is_loopback:"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 47,
                "PatchRowcode": "+        raise ValueError(f\"Host '{host}' with IP Address '{host_ip}' is not safe!\")"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 48,
                "PatchRowcode": "+    return host"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 49,
                "PatchRowcode": "+"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 50,
                "PatchRowcode": "+"
            },
            "42": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " def load_yaml_as_string(filename: str) -> str:"
            },
            "43": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 52,
                "PatchRowcode": "     yaml_file = load_file([filename])"
            },
            "44": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 53,
                "PatchRowcode": "     with open(yaml_file, \"r\", encoding=\"utf-8\") as file:"
            }
        },
        "frontPatchFile": [
            "from __future__ import annotations",
            "",
            "import json",
            "import re",
            "from collections import defaultdict, deque",
            "from typing import Any, Dict, List, Optional, Set, Tuple",
            "",
            "import pydash",
            "import yaml",
            "from multidimensional_urlencode import urlencode as multidimensional_urlencode",
            "",
            "from fides.api.common_exceptions import FidesopsException, ValidationError",
            "from fides.api.cryptography.cryptographic_util import bytes_to_b64_str",
            "from fides.api.graph.config import Collection, CollectionAddress, Field, GraphDataset",
            "from fides.api.models.privacy_request import PrivacyRequest",
            "from fides.api.schemas.saas.saas_config import SaaSRequest",
            "from fides.api.schemas.saas.shared_schemas import SaaSRequestParams",
            "from fides.config.helpers import load_file",
            "",
            "FIDESOPS_GROUPED_INPUTS = \"fidesops_grouped_inputs\"",
            "PRIVACY_REQUEST_ID = \"privacy_request_id\"",
            "MASKED_OBJECT_FIELDS = \"masked_object_fields\"",
            "ALL_OBJECT_FIELDS = \"all_object_fields\"",
            "CUSTOM_PRIVACY_REQUEST_FIELDS = \"custom_privacy_request_fields\"",
            "",
            "",
            "def load_yaml_as_string(filename: str) -> str:",
            "    yaml_file = load_file([filename])",
            "    with open(yaml_file, \"r\", encoding=\"utf-8\") as file:",
            "        return file.read()",
            "",
            "",
            "def load_config(filename: str) -> Dict:",
            "    \"\"\"Loads the SaaS config from provided filename\"\"\"",
            "    yaml_file = load_file([filename])",
            "    with open(yaml_file, \"r\", encoding=\"utf-8\") as file:",
            "        return yaml.safe_load(file).get(\"saas_config\", [])",
            "",
            "",
            "def load_config_from_string(string: str) -> Dict:",
            "    \"\"\"Loads the SaaS config dict from the yaml string\"\"\"",
            "    try:",
            "        return yaml.safe_load(string)[\"saas_config\"]",
            "    except:",
            "        raise ValidationError(",
            "            \"Config contents do not contain a 'saas_config' key at the root level. For example, check formatting, specifically indentation.\"",
            "        )",
            "",
            "",
            "def load_as_string(filename: str) -> str:",
            "    file_path = load_file([filename])",
            "    with open(file_path, \"r\", encoding=\"utf-8\") as file:",
            "        return file.read()",
            "",
            "",
            "def replace_config_placeholders(",
            "    config: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the SaaS config from the yaml string and replaces any string with the given value\"\"\"",
            "    yaml_str: str = config.replace(string_to_replace, replacement)",
            "    return load_config_from_string(yaml_str)",
            "",
            "",
            "def load_config_with_replacement(",
            "    filename: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the saas config from the yaml file and replaces any string with the given value\"\"\"",
            "    yaml_str: str = load_yaml_as_string(filename).replace(",
            "        string_to_replace, replacement",
            "    )",
            "    return load_config_from_string(yaml_str)",
            "",
            "",
            "def load_datasets(filename: str) -> Dict:",
            "    \"\"\"Loads the datasets in the provided filename\"\"\"",
            "    yaml_file = load_file([filename])",
            "    with open(yaml_file, \"r\", encoding=\"utf-8\") as file:",
            "        return yaml.safe_load(file).get(\"dataset\", [])",
            "",
            "",
            "def load_dataset_from_string(string: str) -> Dict:",
            "    \"\"\"Loads the dataset dict from the yaml string\"\"\"",
            "    try:",
            "        return yaml.safe_load(string)[\"dataset\"][0]",
            "    except:",
            "        raise ValidationError(",
            "            \"Dataset contents do not contain a 'dataset' key at the root level. For example, check formatting, specifically indentation.\"",
            "        )",
            "",
            "",
            "def replace_dataset_placeholders(",
            "    dataset: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the dataset from the yaml string and replaces any string with the given value\"\"\"",
            "    yaml_str: str = dataset.replace(string_to_replace, replacement)",
            "    return load_dataset_from_string(yaml_str)",
            "",
            "",
            "def load_dataset_with_replacement(",
            "    filename: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the dataset from the yaml file and replaces any string with the given value\"\"\"",
            "    yaml_str: str = load_yaml_as_string(filename).replace(",
            "        string_to_replace, replacement",
            "    )",
            "    return yaml.safe_load(yaml_str).get(\"dataset\", [])",
            "",
            "",
            "def merge_fields(target: Field, source: Field) -> Field:",
            "    \"\"\"Replaces source references and identities if they are available from the target\"\"\"",
            "    if source.references is not None:",
            "        target.references = source.references",
            "    if source.identity is not None:",
            "        target.identity = source.identity",
            "    return target",
            "",
            "",
            "def extract_fields(aggregate: Dict, collections: List[Collection]) -> None:",
            "    \"\"\"",
            "    Takes all of the Fields in the given Collection and places them into an",
            "    dictionary (dict[collection.name][field.name]) merging Fields when necessary",
            "    \"\"\"",
            "    for collection in collections:",
            "        field_dict = aggregate[collection.name]",
            "        for field in collection.fields:",
            "            if field_dict.get(field.name):",
            "                field_dict[field.name] = merge_fields(field_dict[field.name], field)",
            "            else:",
            "                field_dict[field.name] = field",
            "",
            "",
            "def get_collection_grouped_inputs(",
            "    collections: List[Collection], name: str",
            ") -> Optional[Set[str]]:",
            "    \"\"\"Get collection grouped inputs\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    if not collection:",
            "        return set()",
            "    return collection.grouped_inputs",
            "",
            "",
            "def get_collection_skip_processing(collections: List[Collection], name: str) -> bool:",
            "    \"\"\"If specified, return skip_processing value\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    return bool(collection.skip_processing) if collection else False",
            "",
            "",
            "def get_collection_after(",
            "    collections: List[Collection], name: str",
            ") -> Set[CollectionAddress]:",
            "    \"\"\"If specified, return the collections that need to be read before the current collection for saas configs\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    if not collection:",
            "        return set()",
            "    return collection.after",
            "",
            "",
            "def get_collection_erase_after(",
            "    collections: List[Collection], name: str",
            ") -> Set[CollectionAddress]:",
            "    \"\"\"If specified, return the collections that need to be erased before the current collection for saas configs\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    if not collection:",
            "        return set()",
            "    return collection.erase_after",
            "",
            "",
            "def merge_datasets(dataset: GraphDataset, config_dataset: GraphDataset) -> GraphDataset:",
            "    \"\"\"",
            "    Merges all Collections and Fields from the \"config_dataset\" into the \"dataset\".",
            "    In the event of a collection/field name collision, the target field",
            "    will inherit the identity and field references. This is by design since",
            "    dataset references for SaaS connectors should not have any references.",
            "    \"\"\"",
            "    field_aggregate: Dict[str, Dict] = defaultdict(dict)",
            "    extract_fields(field_aggregate, dataset.collections)",
            "    extract_fields(field_aggregate, config_dataset.collections)",
            "",
            "    collections = []",
            "    for collection_name, field_dict in field_aggregate.items():",
            "        skip_processing: bool = get_collection_skip_processing(",
            "            config_dataset.collections, collection_name",
            "        )",
            "        if skip_processing:",
            "            continue",
            "",
            "        collections.append(",
            "            Collection(",
            "                name=collection_name,",
            "                fields=list(field_dict.values()),",
            "                grouped_inputs=get_collection_grouped_inputs(",
            "                    config_dataset.collections, collection_name",
            "                ),",
            "                after=get_collection_after(config_dataset.collections, collection_name),",
            "                erase_after=get_collection_erase_after(",
            "                    config_dataset.collections, collection_name",
            "                ),",
            "            )",
            "        )",
            "",
            "    return GraphDataset(",
            "        name=dataset.name,",
            "        collections=collections,",
            "        connection_key=dataset.connection_key,",
            "    )",
            "",
            "",
            "def unflatten_dict(flat_dict: Dict[str, Any], separator: str = \".\") -> Dict[str, Any]:",
            "    \"\"\"",
            "    Converts a dictionary of paths/values into a nested dictionary",
            "",
            "    example:",
            "",
            "    {\"A.B\": \"1\", \"A.C\": \"2\"}",
            "",
            "    becomes",
            "",
            "    {",
            "        \"A\": {",
            "            \"B\": \"1\",",
            "            \"C\": \"2\"",
            "        }",
            "    }",
            "    \"\"\"",
            "    output: Dict[Any, Any] = {}",
            "    queue = deque(flat_dict.items())",
            "",
            "    while queue:",
            "        path, value = queue.popleft()",
            "        keys = path.split(separator)",
            "        target = output",
            "        for i, current_key in enumerate(keys[:-1]):",
            "            next_key = keys[i + 1]",
            "            if next_key.isdigit():",
            "                target = target.setdefault(current_key, [])",
            "            else:",
            "                if isinstance(target, dict):",
            "                    target = target.setdefault(current_key, {})",
            "                elif isinstance(target, list):",
            "                    while len(target) <= int(current_key):",
            "                        target.append({})",
            "                    target = target[int(current_key)]",
            "        try:",
            "            if isinstance(target, list):",
            "                target.append(value)",
            "            else:",
            "                # If the value is a dictionary, add its components to the queue for processing",
            "                if isinstance(value, dict):",
            "                    target = target.setdefault(keys[-1], {})",
            "                    for inner_key, inner_value in value.items():",
            "                        new_key = f\"{path}{separator}{inner_key}\"",
            "                        queue.append((new_key, inner_value))",
            "                else:",
            "                    target[keys[-1]] = value",
            "        except TypeError as exc:",
            "            raise FidesopsException(",
            "                f\"Error unflattening dictionary, conflicting levels detected: {exc}\"",
            "            )",
            "    return output",
            "",
            "",
            "def format_body(",
            "    headers: Dict[str, Any],",
            "    body: Optional[str],",
            ") -> Tuple[Dict[str, Any], Optional[str]]:",
            "    \"\"\"",
            "    Builds the appropriately formatted body based on the content type,",
            "    adding application/json to the headers if a content type is not provided.",
            "    \"\"\"",
            "",
            "    if body is None:",
            "        return headers, None",
            "",
            "    content_type = next(",
            "        (",
            "            value",
            "            for header, value in headers.items()",
            "            if header.lower() == \"content-type\"",
            "        ),",
            "        None,",
            "    )",
            "",
            "    # add Content-Type: application/json if a content type is not provided",
            "    if content_type is None:",
            "        content_type = \"application/json\"",
            "        headers[\"Content-Type\"] = content_type",
            "",
            "    if content_type == \"application/json\":",
            "        output = body",
            "    elif content_type == \"application/x-www-form-urlencoded\":",
            "        output = multidimensional_urlencode(json.loads(body))",
            "    elif content_type == \"text/plain\":",
            "        output = body",
            "    else:",
            "        raise FidesopsException(f\"Unsupported Content-Type: {content_type}\")",
            "",
            "    return headers, output",
            "",
            "",
            "def assign_placeholders(value: Any, param_values: Dict[str, Any]) -> Optional[Any]:",
            "    \"\"\"",
            "    Finds all the placeholders (indicated by <>) in the passed in value",
            "    and replaces them with the actual param values",
            "",
            "    Returns None if any of the placeholders cannot be found in the param_values",
            "    \"\"\"",
            "    if value and isinstance(value, str):",
            "        placeholders = re.findall(\"<([^<>]+)>\", value)",
            "        for full_placeholder in placeholders:",
            "            is_optional = full_placeholder.endswith(\"?\")",
            "            placeholder_key = full_placeholder[:-1] if is_optional else full_placeholder",
            "",
            "            placeholder_value = pydash.get(param_values, placeholder_key)",
            "",
            "            # removes outer {} wrapper from body for greater flexibility in custom body config",
            "            if isinstance(placeholder_value, dict):",
            "                placeholder_value = json.dumps(placeholder_value)[1:-1]",
            "",
            "            if placeholder_value is not None:",
            "                value = value.replace(f\"<{full_placeholder}>\", str(placeholder_value))",
            "            elif is_optional:",
            "                value = value.replace(f'\"<{full_placeholder}>\"', \"null\")",
            "            else:",
            "                return None",
            "    return value",
            "",
            "",
            "def map_param_values(",
            "    action: str,",
            "    context: str,",
            "    current_request: SaaSRequest,",
            "    param_values: Dict[str, Any],",
            ") -> SaaSRequestParams:",
            "    \"\"\"",
            "    Visits path, headers, query, and body params in the current request and replaces",
            "    the placeholders with the request param values.",
            "",
            "    The action and context parameters provide more information for the logs",
            "",
            "    For example:",
            "        - action: 'read', context: 'transactions collection'",
            "        - action: 'refresh', context: 'Outreach Connector OAuth2'",
            "    \"\"\"",
            "",
            "    path = assign_placeholders(current_request.path, param_values)",
            "    if path is None:",
            "        raise ValueError(",
            "            f\"At least one param_value references an invalid field for the '{action}' request of {context}.\"",
            "        )",
            "",
            "    headers: Dict[str, Any] = {}",
            "    for header in current_request.headers or []:",
            "        header_value = assign_placeholders(header.value, param_values)",
            "        # only create header if placeholders were replaced with actual values",
            "        if header_value is not None:",
            "            headers[header.name] = assign_placeholders(header.value, param_values)",
            "",
            "    query_params: Dict[str, Any] = {}",
            "    for query_param in current_request.query_params or []:",
            "        query_param_value = assign_placeholders(query_param.value, param_values)",
            "        # only create query param if placeholders were replaced with actual values",
            "        if query_param_value is not None:",
            "            query_params[query_param.name] = query_param_value",
            "",
            "    body = assign_placeholders(current_request.body, param_values)",
            "    # if we declared a body and it's None after assigning placeholders we should error the request",
            "    if current_request.body and body is None:",
            "        raise ValueError(",
            "            f\"Unable to replace placeholders in body for the '{action}' request of {context}\"",
            "        )",
            "",
            "    # format the body based on the content type",
            "    updated_headers, formatted_body = format_body(headers, body)",
            "",
            "    return SaaSRequestParams(",
            "        method=current_request.method,",
            "        path=path,",
            "        headers=updated_headers,",
            "        query_params=query_params,",
            "        body=formatted_body,",
            "    )",
            "",
            "",
            "def get_identity(privacy_request: Optional[PrivacyRequest]) -> Optional[str]:",
            "    \"\"\"",
            "    Returns a single identity or raises an exception if more than one identity is defined",
            "    \"\"\"",
            "",
            "    if not privacy_request:",
            "        return None",
            "",
            "    identities: List[str] = []",
            "    identity_data: Dict[str, Any] = privacy_request.get_cached_identity_data()",
            "    # filters out keys where associated value is None or empty str",
            "    identities = list({k for k, v in identity_data.items() if v})",
            "    if len(identities) > 1:",
            "        raise FidesopsException(",
            "            \"Only one identity can be specified for SaaS connector traversal\"",
            "        )",
            "    return identities[0] if identities else None",
            "",
            "",
            "def encode_file_contents(file_path: str) -> str:",
            "    \"\"\"",
            "    Read file binary and b64 encode it.",
            "    \"\"\"",
            "    file_path = load_file([file_path])",
            "    with open(file_path, \"rb\") as file:",
            "        return bytes_to_b64_str(file.read())",
            "",
            "",
            "def to_pascal_case(s: str) -> str:",
            "    s = s.title()",
            "    s = s.replace(\"_\", \"\")",
            "    return s",
            "",
            "",
            "def replace_version(saas_config: str, new_version: str) -> str:",
            "    \"\"\"",
            "    Replace the version number in the given saas_config string with the provided new_version.",
            "    \"\"\"",
            "    version_pattern = r\"version:\\s*[\\d\\.]+\"",
            "    updated_config = re.sub(",
            "        version_pattern, f\"version: {new_version}\", saas_config, count=1",
            "    )",
            "    return updated_config"
        ],
        "afterPatchFile": [
            "from __future__ import annotations",
            "",
            "import json",
            "import re",
            "import socket",
            "from collections import defaultdict, deque",
            "from ipaddress import IPv4Address, IPv6Address, ip_address",
            "from typing import Any, Dict, List, Optional, Set, Tuple, Union",
            "",
            "import pydash",
            "import yaml",
            "from multidimensional_urlencode import urlencode as multidimensional_urlencode",
            "",
            "from fides.api.common_exceptions import FidesopsException, ValidationError",
            "from fides.api.cryptography.cryptographic_util import bytes_to_b64_str",
            "from fides.api.graph.config import Collection, CollectionAddress, Field, GraphDataset",
            "from fides.api.models.privacy_request import PrivacyRequest",
            "from fides.api.schemas.saas.saas_config import SaaSRequest",
            "from fides.api.schemas.saas.shared_schemas import SaaSRequestParams",
            "from fides.config import CONFIG",
            "from fides.config.helpers import load_file",
            "",
            "FIDESOPS_GROUPED_INPUTS = \"fidesops_grouped_inputs\"",
            "PRIVACY_REQUEST_ID = \"privacy_request_id\"",
            "MASKED_OBJECT_FIELDS = \"masked_object_fields\"",
            "ALL_OBJECT_FIELDS = \"all_object_fields\"",
            "CUSTOM_PRIVACY_REQUEST_FIELDS = \"custom_privacy_request_fields\"",
            "",
            "",
            "def deny_unsafe_hosts(host: str) -> str:",
            "    \"\"\"",
            "    Verify that the provided host isn't a potentially unsafe one.",
            "",
            "    WARNING: IPv6 is _not_ supported and will throw an exception!",
            "    \"\"\"",
            "    if CONFIG.dev_mode:",
            "        return host",
            "",
            "    try:",
            "        host_ip: Union[IPv4Address, IPv6Address] = ip_address(",
            "            socket.gethostbyname(host)",
            "        )",
            "    except socket.gaierror:",
            "        raise ValueError(f\"Failed to resolve hostname: {host}\")",
            "",
            "    if host_ip.is_link_local or host_ip.is_loopback:",
            "        raise ValueError(f\"Host '{host}' with IP Address '{host_ip}' is not safe!\")",
            "    return host",
            "",
            "",
            "def load_yaml_as_string(filename: str) -> str:",
            "    yaml_file = load_file([filename])",
            "    with open(yaml_file, \"r\", encoding=\"utf-8\") as file:",
            "        return file.read()",
            "",
            "",
            "def load_config(filename: str) -> Dict:",
            "    \"\"\"Loads the SaaS config from provided filename\"\"\"",
            "    yaml_file = load_file([filename])",
            "    with open(yaml_file, \"r\", encoding=\"utf-8\") as file:",
            "        return yaml.safe_load(file).get(\"saas_config\", [])",
            "",
            "",
            "def load_config_from_string(string: str) -> Dict:",
            "    \"\"\"Loads the SaaS config dict from the yaml string\"\"\"",
            "    try:",
            "        return yaml.safe_load(string)[\"saas_config\"]",
            "    except:",
            "        raise ValidationError(",
            "            \"Config contents do not contain a 'saas_config' key at the root level. For example, check formatting, specifically indentation.\"",
            "        )",
            "",
            "",
            "def load_as_string(filename: str) -> str:",
            "    file_path = load_file([filename])",
            "    with open(file_path, \"r\", encoding=\"utf-8\") as file:",
            "        return file.read()",
            "",
            "",
            "def replace_config_placeholders(",
            "    config: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the SaaS config from the yaml string and replaces any string with the given value\"\"\"",
            "    yaml_str: str = config.replace(string_to_replace, replacement)",
            "    return load_config_from_string(yaml_str)",
            "",
            "",
            "def load_config_with_replacement(",
            "    filename: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the saas config from the yaml file and replaces any string with the given value\"\"\"",
            "    yaml_str: str = load_yaml_as_string(filename).replace(",
            "        string_to_replace, replacement",
            "    )",
            "    return load_config_from_string(yaml_str)",
            "",
            "",
            "def load_datasets(filename: str) -> Dict:",
            "    \"\"\"Loads the datasets in the provided filename\"\"\"",
            "    yaml_file = load_file([filename])",
            "    with open(yaml_file, \"r\", encoding=\"utf-8\") as file:",
            "        return yaml.safe_load(file).get(\"dataset\", [])",
            "",
            "",
            "def load_dataset_from_string(string: str) -> Dict:",
            "    \"\"\"Loads the dataset dict from the yaml string\"\"\"",
            "    try:",
            "        return yaml.safe_load(string)[\"dataset\"][0]",
            "    except:",
            "        raise ValidationError(",
            "            \"Dataset contents do not contain a 'dataset' key at the root level. For example, check formatting, specifically indentation.\"",
            "        )",
            "",
            "",
            "def replace_dataset_placeholders(",
            "    dataset: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the dataset from the yaml string and replaces any string with the given value\"\"\"",
            "    yaml_str: str = dataset.replace(string_to_replace, replacement)",
            "    return load_dataset_from_string(yaml_str)",
            "",
            "",
            "def load_dataset_with_replacement(",
            "    filename: str, string_to_replace: str, replacement: str",
            ") -> Dict:",
            "    \"\"\"Loads the dataset from the yaml file and replaces any string with the given value\"\"\"",
            "    yaml_str: str = load_yaml_as_string(filename).replace(",
            "        string_to_replace, replacement",
            "    )",
            "    return yaml.safe_load(yaml_str).get(\"dataset\", [])",
            "",
            "",
            "def merge_fields(target: Field, source: Field) -> Field:",
            "    \"\"\"Replaces source references and identities if they are available from the target\"\"\"",
            "    if source.references is not None:",
            "        target.references = source.references",
            "    if source.identity is not None:",
            "        target.identity = source.identity",
            "    return target",
            "",
            "",
            "def extract_fields(aggregate: Dict, collections: List[Collection]) -> None:",
            "    \"\"\"",
            "    Takes all of the Fields in the given Collection and places them into an",
            "    dictionary (dict[collection.name][field.name]) merging Fields when necessary",
            "    \"\"\"",
            "    for collection in collections:",
            "        field_dict = aggregate[collection.name]",
            "        for field in collection.fields:",
            "            if field_dict.get(field.name):",
            "                field_dict[field.name] = merge_fields(field_dict[field.name], field)",
            "            else:",
            "                field_dict[field.name] = field",
            "",
            "",
            "def get_collection_grouped_inputs(",
            "    collections: List[Collection], name: str",
            ") -> Optional[Set[str]]:",
            "    \"\"\"Get collection grouped inputs\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    if not collection:",
            "        return set()",
            "    return collection.grouped_inputs",
            "",
            "",
            "def get_collection_skip_processing(collections: List[Collection], name: str) -> bool:",
            "    \"\"\"If specified, return skip_processing value\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    return bool(collection.skip_processing) if collection else False",
            "",
            "",
            "def get_collection_after(",
            "    collections: List[Collection], name: str",
            ") -> Set[CollectionAddress]:",
            "    \"\"\"If specified, return the collections that need to be read before the current collection for saas configs\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    if not collection:",
            "        return set()",
            "    return collection.after",
            "",
            "",
            "def get_collection_erase_after(",
            "    collections: List[Collection], name: str",
            ") -> Set[CollectionAddress]:",
            "    \"\"\"If specified, return the collections that need to be erased before the current collection for saas configs\"\"\"",
            "    collection: Collection | None = next(",
            "        (collect for collect in collections if collect.name == name), None",
            "    )",
            "    if not collection:",
            "        return set()",
            "    return collection.erase_after",
            "",
            "",
            "def merge_datasets(dataset: GraphDataset, config_dataset: GraphDataset) -> GraphDataset:",
            "    \"\"\"",
            "    Merges all Collections and Fields from the \"config_dataset\" into the \"dataset\".",
            "    In the event of a collection/field name collision, the target field",
            "    will inherit the identity and field references. This is by design since",
            "    dataset references for SaaS connectors should not have any references.",
            "    \"\"\"",
            "    field_aggregate: Dict[str, Dict] = defaultdict(dict)",
            "    extract_fields(field_aggregate, dataset.collections)",
            "    extract_fields(field_aggregate, config_dataset.collections)",
            "",
            "    collections = []",
            "    for collection_name, field_dict in field_aggregate.items():",
            "        skip_processing: bool = get_collection_skip_processing(",
            "            config_dataset.collections, collection_name",
            "        )",
            "        if skip_processing:",
            "            continue",
            "",
            "        collections.append(",
            "            Collection(",
            "                name=collection_name,",
            "                fields=list(field_dict.values()),",
            "                grouped_inputs=get_collection_grouped_inputs(",
            "                    config_dataset.collections, collection_name",
            "                ),",
            "                after=get_collection_after(config_dataset.collections, collection_name),",
            "                erase_after=get_collection_erase_after(",
            "                    config_dataset.collections, collection_name",
            "                ),",
            "            )",
            "        )",
            "",
            "    return GraphDataset(",
            "        name=dataset.name,",
            "        collections=collections,",
            "        connection_key=dataset.connection_key,",
            "    )",
            "",
            "",
            "def unflatten_dict(flat_dict: Dict[str, Any], separator: str = \".\") -> Dict[str, Any]:",
            "    \"\"\"",
            "    Converts a dictionary of paths/values into a nested dictionary",
            "",
            "    example:",
            "",
            "    {\"A.B\": \"1\", \"A.C\": \"2\"}",
            "",
            "    becomes",
            "",
            "    {",
            "        \"A\": {",
            "            \"B\": \"1\",",
            "            \"C\": \"2\"",
            "        }",
            "    }",
            "    \"\"\"",
            "    output: Dict[Any, Any] = {}",
            "    queue = deque(flat_dict.items())",
            "",
            "    while queue:",
            "        path, value = queue.popleft()",
            "        keys = path.split(separator)",
            "        target = output",
            "        for i, current_key in enumerate(keys[:-1]):",
            "            next_key = keys[i + 1]",
            "            if next_key.isdigit():",
            "                target = target.setdefault(current_key, [])",
            "            else:",
            "                if isinstance(target, dict):",
            "                    target = target.setdefault(current_key, {})",
            "                elif isinstance(target, list):",
            "                    while len(target) <= int(current_key):",
            "                        target.append({})",
            "                    target = target[int(current_key)]",
            "        try:",
            "            if isinstance(target, list):",
            "                target.append(value)",
            "            else:",
            "                # If the value is a dictionary, add its components to the queue for processing",
            "                if isinstance(value, dict):",
            "                    target = target.setdefault(keys[-1], {})",
            "                    for inner_key, inner_value in value.items():",
            "                        new_key = f\"{path}{separator}{inner_key}\"",
            "                        queue.append((new_key, inner_value))",
            "                else:",
            "                    target[keys[-1]] = value",
            "        except TypeError as exc:",
            "            raise FidesopsException(",
            "                f\"Error unflattening dictionary, conflicting levels detected: {exc}\"",
            "            )",
            "    return output",
            "",
            "",
            "def format_body(",
            "    headers: Dict[str, Any],",
            "    body: Optional[str],",
            ") -> Tuple[Dict[str, Any], Optional[str]]:",
            "    \"\"\"",
            "    Builds the appropriately formatted body based on the content type,",
            "    adding application/json to the headers if a content type is not provided.",
            "    \"\"\"",
            "",
            "    if body is None:",
            "        return headers, None",
            "",
            "    content_type = next(",
            "        (",
            "            value",
            "            for header, value in headers.items()",
            "            if header.lower() == \"content-type\"",
            "        ),",
            "        None,",
            "    )",
            "",
            "    # add Content-Type: application/json if a content type is not provided",
            "    if content_type is None:",
            "        content_type = \"application/json\"",
            "        headers[\"Content-Type\"] = content_type",
            "",
            "    if content_type == \"application/json\":",
            "        output = body",
            "    elif content_type == \"application/x-www-form-urlencoded\":",
            "        output = multidimensional_urlencode(json.loads(body))",
            "    elif content_type == \"text/plain\":",
            "        output = body",
            "    else:",
            "        raise FidesopsException(f\"Unsupported Content-Type: {content_type}\")",
            "",
            "    return headers, output",
            "",
            "",
            "def assign_placeholders(value: Any, param_values: Dict[str, Any]) -> Optional[Any]:",
            "    \"\"\"",
            "    Finds all the placeholders (indicated by <>) in the passed in value",
            "    and replaces them with the actual param values",
            "",
            "    Returns None if any of the placeholders cannot be found in the param_values",
            "    \"\"\"",
            "    if value and isinstance(value, str):",
            "        placeholders = re.findall(\"<([^<>]+)>\", value)",
            "        for full_placeholder in placeholders:",
            "            is_optional = full_placeholder.endswith(\"?\")",
            "            placeholder_key = full_placeholder[:-1] if is_optional else full_placeholder",
            "",
            "            placeholder_value = pydash.get(param_values, placeholder_key)",
            "",
            "            # removes outer {} wrapper from body for greater flexibility in custom body config",
            "            if isinstance(placeholder_value, dict):",
            "                placeholder_value = json.dumps(placeholder_value)[1:-1]",
            "",
            "            if placeholder_value is not None:",
            "                value = value.replace(f\"<{full_placeholder}>\", str(placeholder_value))",
            "            elif is_optional:",
            "                value = value.replace(f'\"<{full_placeholder}>\"', \"null\")",
            "            else:",
            "                return None",
            "    return value",
            "",
            "",
            "def map_param_values(",
            "    action: str,",
            "    context: str,",
            "    current_request: SaaSRequest,",
            "    param_values: Dict[str, Any],",
            ") -> SaaSRequestParams:",
            "    \"\"\"",
            "    Visits path, headers, query, and body params in the current request and replaces",
            "    the placeholders with the request param values.",
            "",
            "    The action and context parameters provide more information for the logs",
            "",
            "    For example:",
            "        - action: 'read', context: 'transactions collection'",
            "        - action: 'refresh', context: 'Outreach Connector OAuth2'",
            "    \"\"\"",
            "",
            "    path = assign_placeholders(current_request.path, param_values)",
            "    if path is None:",
            "        raise ValueError(",
            "            f\"At least one param_value references an invalid field for the '{action}' request of {context}.\"",
            "        )",
            "",
            "    headers: Dict[str, Any] = {}",
            "    for header in current_request.headers or []:",
            "        header_value = assign_placeholders(header.value, param_values)",
            "        # only create header if placeholders were replaced with actual values",
            "        if header_value is not None:",
            "            headers[header.name] = assign_placeholders(header.value, param_values)",
            "",
            "    query_params: Dict[str, Any] = {}",
            "    for query_param in current_request.query_params or []:",
            "        query_param_value = assign_placeholders(query_param.value, param_values)",
            "        # only create query param if placeholders were replaced with actual values",
            "        if query_param_value is not None:",
            "            query_params[query_param.name] = query_param_value",
            "",
            "    body = assign_placeholders(current_request.body, param_values)",
            "    # if we declared a body and it's None after assigning placeholders we should error the request",
            "    if current_request.body and body is None:",
            "        raise ValueError(",
            "            f\"Unable to replace placeholders in body for the '{action}' request of {context}\"",
            "        )",
            "",
            "    # format the body based on the content type",
            "    updated_headers, formatted_body = format_body(headers, body)",
            "",
            "    return SaaSRequestParams(",
            "        method=current_request.method,",
            "        path=path,",
            "        headers=updated_headers,",
            "        query_params=query_params,",
            "        body=formatted_body,",
            "    )",
            "",
            "",
            "def get_identity(privacy_request: Optional[PrivacyRequest]) -> Optional[str]:",
            "    \"\"\"",
            "    Returns a single identity or raises an exception if more than one identity is defined",
            "    \"\"\"",
            "",
            "    if not privacy_request:",
            "        return None",
            "",
            "    identities: List[str] = []",
            "    identity_data: Dict[str, Any] = privacy_request.get_cached_identity_data()",
            "    # filters out keys where associated value is None or empty str",
            "    identities = list({k for k, v in identity_data.items() if v})",
            "    if len(identities) > 1:",
            "        raise FidesopsException(",
            "            \"Only one identity can be specified for SaaS connector traversal\"",
            "        )",
            "    return identities[0] if identities else None",
            "",
            "",
            "def encode_file_contents(file_path: str) -> str:",
            "    \"\"\"",
            "    Read file binary and b64 encode it.",
            "    \"\"\"",
            "    file_path = load_file([file_path])",
            "    with open(file_path, \"rb\") as file:",
            "        return bytes_to_b64_str(file.read())",
            "",
            "",
            "def to_pascal_case(s: str) -> str:",
            "    s = s.title()",
            "    s = s.replace(\"_\", \"\")",
            "    return s",
            "",
            "",
            "def replace_version(saas_config: str, new_version: str) -> str:",
            "    \"\"\"",
            "    Replace the version number in the given saas_config string with the provided new_version.",
            "    \"\"\"",
            "    version_pattern = r\"version:\\s*[\\d\\.]+\"",
            "    updated_config = re.sub(",
            "        version_pattern, f\"version: {new_version}\", saas_config, count=1",
            "    )",
            "    return updated_config"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "6": []
        },
        "addLocation": []
    }
}