{
    "airflow/models/dagbag.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 640,
                "afterPatchRowNumber": 640,
                "PatchRowcode": "         from airflow.security.permissions import DAG_ACTIONS, resource_name_for_dag"
            },
            "1": {
                "beforePatchRowNumber": 641,
                "afterPatchRowNumber": 641,
                "PatchRowcode": "         from airflow.www.fab_security.sqla.models import Action, Permission, Resource"
            },
            "2": {
                "beforePatchRowNumber": 642,
                "afterPatchRowNumber": 642,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 643,
                "PatchRowcode": "+        root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 644,
                "PatchRowcode": "+"
            },
            "5": {
                "beforePatchRowNumber": 643,
                "afterPatchRowNumber": 645,
                "PatchRowcode": "         def needs_perms(dag_id: str) -> bool:"
            },
            "6": {
                "beforePatchRowNumber": 644,
                "afterPatchRowNumber": 646,
                "PatchRowcode": "             dag_resource_name = resource_name_for_dag(dag_id)"
            },
            "7": {
                "beforePatchRowNumber": 645,
                "afterPatchRowNumber": 647,
                "PatchRowcode": "             for permission_name in DAG_ACTIONS:"
            },
            "8": {
                "beforePatchRowNumber": 654,
                "afterPatchRowNumber": 656,
                "PatchRowcode": "                     return True"
            },
            "9": {
                "beforePatchRowNumber": 655,
                "afterPatchRowNumber": 657,
                "PatchRowcode": "             return False"
            },
            "10": {
                "beforePatchRowNumber": 656,
                "afterPatchRowNumber": 658,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 657,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if dag.access_control or needs_perms(dag.dag_id):"
            },
            "12": {
                "beforePatchRowNumber": 658,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            self.log.debug(\"Syncing DAG permissions: %s to the DB\", dag.dag_id)"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 659,
                "PatchRowcode": "+        if dag.access_control or needs_perms(root_dag_id):"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 660,
                "PatchRowcode": "+            self.log.debug(\"Syncing DAG permissions: %s to the DB\", root_dag_id)"
            },
            "15": {
                "beforePatchRowNumber": 659,
                "afterPatchRowNumber": 661,
                "PatchRowcode": "             from airflow.www.security import ApplessAirflowSecurityManager"
            },
            "16": {
                "beforePatchRowNumber": 660,
                "afterPatchRowNumber": 662,
                "PatchRowcode": " "
            },
            "17": {
                "beforePatchRowNumber": 661,
                "afterPatchRowNumber": 663,
                "PatchRowcode": "             security_manager = ApplessAirflowSecurityManager(session=session)"
            },
            "18": {
                "beforePatchRowNumber": 662,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            security_manager.sync_perm_for_dag(dag.dag_id, dag.access_control)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 664,
                "PatchRowcode": "+            security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)"
            }
        },
        "frontPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "",
            "import hashlib",
            "import importlib",
            "import importlib.machinery",
            "import importlib.util",
            "import os",
            "import sys",
            "import textwrap",
            "import traceback",
            "import warnings",
            "import zipfile",
            "from datetime import datetime, timedelta",
            "from typing import TYPE_CHECKING, Dict, List, NamedTuple, Optional, Union",
            "",
            "from sqlalchemy.exc import OperationalError",
            "from sqlalchemy.orm import Session",
            "from tabulate import tabulate",
            "",
            "from airflow import settings",
            "from airflow.configuration import conf",
            "from airflow.exceptions import (",
            "    AirflowClusterPolicyViolation,",
            "    AirflowDagCycleException,",
            "    AirflowDagDuplicatedIdException,",
            "    AirflowTimetableInvalid,",
            "    ParamValidationError,",
            ")",
            "from airflow.stats import Stats",
            "from airflow.utils import timezone",
            "from airflow.utils.dag_cycle_tester import check_cycle",
            "from airflow.utils.docs import get_docs_url",
            "from airflow.utils.file import correct_maybe_zipped, list_py_file_paths, might_contain_dag",
            "from airflow.utils.log.logging_mixin import LoggingMixin",
            "from airflow.utils.retries import MAX_DB_RETRIES, run_with_db_retries",
            "from airflow.utils.session import provide_session",
            "from airflow.utils.timeout import timeout",
            "",
            "if TYPE_CHECKING:",
            "    import pathlib",
            "",
            "",
            "class FileLoadStat(NamedTuple):",
            "    \"\"\"Information about single file\"\"\"",
            "",
            "    file: str",
            "    duration: timedelta",
            "    dag_num: int",
            "    task_num: int",
            "    dags: str",
            "",
            "",
            "class DagBag(LoggingMixin):",
            "    \"\"\"",
            "    A dagbag is a collection of dags, parsed out of a folder tree and has high",
            "    level configuration settings, like what database to use as a backend and",
            "    what executor to use to fire off tasks. This makes it easier to run",
            "    distinct environments for say production and development, tests, or for",
            "    different teams or security profiles. What would have been system level",
            "    settings are now dagbag level so that one system can run multiple,",
            "    independent settings sets.",
            "",
            "    :param dag_folder: the folder to scan to find DAGs",
            "    :param include_examples: whether to include the examples that ship",
            "        with airflow or not",
            "    :param include_smart_sensor: whether to include the smart sensor native",
            "        DAGs that create the smart sensor operators for whole cluster",
            "    :param read_dags_from_db: Read DAGs from DB if ``True`` is passed.",
            "        If ``False`` DAGs are read from python files.",
            "    :param load_op_links: Should the extra operator link be loaded via plugins when",
            "        de-serializing the DAG? This flag is set to False in Scheduler so that Extra Operator links",
            "        are not loaded to not run User code in Scheduler.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        dag_folder: Union[str, \"pathlib.Path\", None] = None,",
            "        include_examples: bool = conf.getboolean('core', 'LOAD_EXAMPLES'),",
            "        include_smart_sensor: bool = conf.getboolean('smart_sensor', 'USE_SMART_SENSOR'),",
            "        safe_mode: bool = conf.getboolean('core', 'DAG_DISCOVERY_SAFE_MODE'),",
            "        read_dags_from_db: bool = False,",
            "        store_serialized_dags: Optional[bool] = None,",
            "        load_op_links: bool = True,",
            "    ):",
            "        # Avoid circular import",
            "        from airflow.models.dag import DAG",
            "",
            "        super().__init__()",
            "",
            "        if store_serialized_dags:",
            "            warnings.warn(",
            "                \"The store_serialized_dags parameter has been deprecated. \"",
            "                \"You should pass the read_dags_from_db parameter.\",",
            "                DeprecationWarning,",
            "                stacklevel=2,",
            "            )",
            "            read_dags_from_db = store_serialized_dags",
            "",
            "        dag_folder = dag_folder or settings.DAGS_FOLDER",
            "        self.dag_folder = dag_folder",
            "        self.dags: Dict[str, DAG] = {}",
            "        # the file's last modified timestamp when we last read it",
            "        self.file_last_changed: Dict[str, datetime] = {}",
            "        self.import_errors: Dict[str, str] = {}",
            "        self.has_logged = False",
            "        self.read_dags_from_db = read_dags_from_db",
            "        # Only used by read_dags_from_db=True",
            "        self.dags_last_fetched: Dict[str, datetime] = {}",
            "        # Only used by SchedulerJob to compare the dag_hash to identify change in DAGs",
            "        self.dags_hash: Dict[str, str] = {}",
            "",
            "        self.dagbag_import_error_tracebacks = conf.getboolean('core', 'dagbag_import_error_tracebacks')",
            "        self.dagbag_import_error_traceback_depth = conf.getint('core', 'dagbag_import_error_traceback_depth')",
            "        self.collect_dags(",
            "            dag_folder=dag_folder,",
            "            include_examples=include_examples,",
            "            include_smart_sensor=include_smart_sensor,",
            "            safe_mode=safe_mode,",
            "        )",
            "        # Should the extra operator link be loaded via plugins?",
            "        # This flag is set to False in Scheduler so that Extra Operator links are not loaded",
            "        self.load_op_links = load_op_links",
            "",
            "    def size(self) -> int:",
            "        \"\"\":return: the amount of dags contained in this dagbag\"\"\"",
            "        return len(self.dags)",
            "",
            "    @property",
            "    def store_serialized_dags(self) -> bool:",
            "        \"\"\"Whether or not to read dags from DB\"\"\"",
            "        warnings.warn(",
            "            \"The store_serialized_dags property has been deprecated. Use read_dags_from_db instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        return self.read_dags_from_db",
            "",
            "    @property",
            "    def dag_ids(self) -> List[str]:",
            "        \"\"\"",
            "        :return: a list of DAG IDs in this bag",
            "        :rtype: List[unicode]",
            "        \"\"\"",
            "        return list(self.dags.keys())",
            "",
            "    @provide_session",
            "    def get_dag(self, dag_id, session: Session = None):",
            "        \"\"\"",
            "        Gets the DAG out of the dictionary, and refreshes it if expired",
            "",
            "        :param dag_id: DAG Id",
            "        \"\"\"",
            "        # Avoid circular import",
            "        from airflow.models.dag import DagModel",
            "",
            "        if self.read_dags_from_db:",
            "            # Import here so that serialized dag is only imported when serialization is enabled",
            "            from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "            if dag_id not in self.dags:",
            "                # Load from DB if not (yet) in the bag",
            "                self._add_dag_from_db(dag_id=dag_id, session=session)",
            "                return self.dags.get(dag_id)",
            "",
            "            # If DAG is in the DagBag, check the following",
            "            # 1. if time has come to check if DAG is updated (controlled by min_serialized_dag_fetch_secs)",
            "            # 2. check the last_updated column in SerializedDag table to see if Serialized DAG is updated",
            "            # 3. if (2) is yes, fetch the Serialized DAG.",
            "            # 4. if (2) returns None (i.e. Serialized DAG is deleted), remove dag from dagbag",
            "            # if it exists and return None.",
            "            min_serialized_dag_fetch_secs = timedelta(seconds=settings.MIN_SERIALIZED_DAG_FETCH_INTERVAL)",
            "            if (",
            "                dag_id in self.dags_last_fetched",
            "                and timezone.utcnow() > self.dags_last_fetched[dag_id] + min_serialized_dag_fetch_secs",
            "            ):",
            "                sd_last_updated_datetime = SerializedDagModel.get_last_updated_datetime(",
            "                    dag_id=dag_id,",
            "                    session=session,",
            "                )",
            "                if not sd_last_updated_datetime:",
            "                    self.log.warning(\"Serialized DAG %s no longer exists\", dag_id)",
            "                    del self.dags[dag_id]",
            "                    del self.dags_last_fetched[dag_id]",
            "                    del self.dags_hash[dag_id]",
            "                    return None",
            "",
            "                if sd_last_updated_datetime > self.dags_last_fetched[dag_id]:",
            "                    self._add_dag_from_db(dag_id=dag_id, session=session)",
            "",
            "            return self.dags.get(dag_id)",
            "",
            "        # If asking for a known subdag, we want to refresh the parent",
            "        dag = None",
            "        root_dag_id = dag_id",
            "        if dag_id in self.dags:",
            "            dag = self.dags[dag_id]",
            "            if dag.parent_dag:",
            "                root_dag_id = dag.parent_dag.dag_id",
            "",
            "        # If DAG Model is absent, we can't check last_expired property. Is the DAG not yet synchronized?",
            "        orm_dag = DagModel.get_current(root_dag_id, session=session)",
            "        if not orm_dag:",
            "            return self.dags.get(dag_id)",
            "",
            "        # If the dag corresponding to root_dag_id is absent or expired",
            "        is_missing = root_dag_id not in self.dags",
            "        is_expired = orm_dag.last_expired and dag and dag.last_loaded < orm_dag.last_expired",
            "        if is_expired:",
            "            # Remove associated dags so we can re-add them.",
            "            self.dags = {",
            "                key: dag",
            "                for key, dag in self.dags.items()",
            "                if root_dag_id != key and not (dag.parent_dag and root_dag_id == dag.parent_dag.dag_id)",
            "            }",
            "        if is_missing or is_expired:",
            "            # Reprocess source file.",
            "            found_dags = self.process_file(",
            "                filepath=correct_maybe_zipped(orm_dag.fileloc), only_if_updated=False",
            "            )",
            "",
            "            # If the source file no longer exports `dag_id`, delete it from self.dags",
            "            if found_dags and dag_id in [found_dag.dag_id for found_dag in found_dags]:",
            "                return self.dags[dag_id]",
            "            elif dag_id in self.dags:",
            "                del self.dags[dag_id]",
            "        return self.dags.get(dag_id)",
            "",
            "    def _add_dag_from_db(self, dag_id: str, session: Session):",
            "        \"\"\"Add DAG to DagBag from DB\"\"\"",
            "        from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "        row = SerializedDagModel.get(dag_id, session)",
            "        if not row:",
            "            return None",
            "",
            "        row.load_op_links = self.load_op_links",
            "        dag = row.dag",
            "        for subdag in dag.subdags:",
            "            self.dags[subdag.dag_id] = subdag",
            "        self.dags[dag.dag_id] = dag",
            "        self.dags_last_fetched[dag.dag_id] = timezone.utcnow()",
            "        self.dags_hash[dag.dag_id] = row.dag_hash",
            "",
            "    def process_file(self, filepath, only_if_updated=True, safe_mode=True):",
            "        \"\"\"",
            "        Given a path to a python module or zip file, this method imports",
            "        the module and look for dag objects within it.",
            "        \"\"\"",
            "        # if the source file no longer exists in the DB or in the filesystem,",
            "        # return an empty list",
            "        # todo: raise exception?",
            "        if filepath is None or not os.path.isfile(filepath):",
            "            return []",
            "",
            "        try:",
            "            # This failed before in what may have been a git sync",
            "            # race condition",
            "            file_last_changed_on_disk = datetime.fromtimestamp(os.path.getmtime(filepath))",
            "            if (",
            "                only_if_updated",
            "                and filepath in self.file_last_changed",
            "                and file_last_changed_on_disk == self.file_last_changed[filepath]",
            "            ):",
            "                return []",
            "        except Exception as e:",
            "            self.log.exception(e)",
            "            return []",
            "",
            "        if filepath.endswith(\".py\") or not zipfile.is_zipfile(filepath):",
            "            mods = self._load_modules_from_file(filepath, safe_mode)",
            "        else:",
            "            mods = self._load_modules_from_zip(filepath, safe_mode)",
            "",
            "        found_dags = self._process_modules(filepath, mods, file_last_changed_on_disk)",
            "",
            "        self.file_last_changed[filepath] = file_last_changed_on_disk",
            "        return found_dags",
            "",
            "    def _load_modules_from_file(self, filepath, safe_mode):",
            "        if not might_contain_dag(filepath, safe_mode):",
            "            # Don't want to spam user with skip messages",
            "            if not self.has_logged:",
            "                self.has_logged = True",
            "                self.log.info(\"File %s assumed to contain no DAGs. Skipping.\", filepath)",
            "            return []",
            "",
            "        self.log.debug(\"Importing %s\", filepath)",
            "        org_mod_name, _ = os.path.splitext(os.path.split(filepath)[-1])",
            "        path_hash = hashlib.sha1(filepath.encode('utf-8')).hexdigest()",
            "        mod_name = f'unusual_prefix_{path_hash}_{org_mod_name}'",
            "",
            "        if mod_name in sys.modules:",
            "            del sys.modules[mod_name]",
            "",
            "        def parse(mod_name, filepath):",
            "            try:",
            "                loader = importlib.machinery.SourceFileLoader(mod_name, filepath)",
            "                spec = importlib.util.spec_from_loader(mod_name, loader)",
            "                new_module = importlib.util.module_from_spec(spec)",
            "                sys.modules[spec.name] = new_module",
            "                loader.exec_module(new_module)",
            "                return [new_module]",
            "            except Exception as e:",
            "                self.log.exception(\"Failed to import: %s\", filepath)",
            "                if self.dagbag_import_error_tracebacks:",
            "                    self.import_errors[filepath] = traceback.format_exc(",
            "                        limit=-self.dagbag_import_error_traceback_depth",
            "                    )",
            "                else:",
            "                    self.import_errors[filepath] = str(e)",
            "                return []",
            "",
            "        dagbag_import_timeout = settings.get_dagbag_import_timeout(filepath)",
            "",
            "        if not isinstance(dagbag_import_timeout, (int, float)):",
            "            raise TypeError(",
            "                f'Value ({dagbag_import_timeout}) from get_dagbag_import_timeout must be int or float'",
            "            )",
            "",
            "        if dagbag_import_timeout <= 0:  # no parsing timeout",
            "            return parse(mod_name, filepath)",
            "",
            "        timeout_msg = (",
            "            f\"DagBag import timeout for {filepath} after {dagbag_import_timeout}s.\\n\"",
            "            \"Please take a look at these docs to improve your DAG import time:\\n\"",
            "            f\"* {get_docs_url('best-practices.html#top-level-python-code')}\\n\"",
            "            f\"* {get_docs_url('best-practices.html#reducing-dag-complexity')}\"",
            "        )",
            "        with timeout(dagbag_import_timeout, error_message=timeout_msg):",
            "            return parse(mod_name, filepath)",
            "",
            "    def _load_modules_from_zip(self, filepath, safe_mode):",
            "        mods = []",
            "        with zipfile.ZipFile(filepath) as current_zip_file:",
            "            for zip_info in current_zip_file.infolist():",
            "                head, _ = os.path.split(zip_info.filename)",
            "                mod_name, ext = os.path.splitext(zip_info.filename)",
            "                if ext not in [\".py\", \".pyc\"]:",
            "                    continue",
            "                if head:",
            "                    continue",
            "",
            "                if mod_name == '__init__':",
            "                    self.log.warning(\"Found __init__.%s at root of %s\", ext, filepath)",
            "",
            "                self.log.debug(\"Reading %s from %s\", zip_info.filename, filepath)",
            "",
            "                if not might_contain_dag(zip_info.filename, safe_mode, current_zip_file):",
            "                    # todo: create ignore list",
            "                    # Don't want to spam user with skip messages",
            "                    if not self.has_logged:",
            "                        self.has_logged = True",
            "                        self.log.info(",
            "                            \"File %s:%s assumed to contain no DAGs. Skipping.\", filepath, zip_info.filename",
            "                        )",
            "                    continue",
            "",
            "                if mod_name in sys.modules:",
            "                    del sys.modules[mod_name]",
            "",
            "                try:",
            "                    sys.path.insert(0, filepath)",
            "                    current_module = importlib.import_module(mod_name)",
            "                    mods.append(current_module)",
            "                except Exception as e:",
            "                    fileloc = os.path.join(filepath, zip_info.filename)",
            "                    self.log.exception(\"Failed to import: %s\", fileloc)",
            "                    if self.dagbag_import_error_tracebacks:",
            "                        self.import_errors[fileloc] = traceback.format_exc(",
            "                            limit=-self.dagbag_import_error_traceback_depth",
            "                        )",
            "                    else:",
            "                        self.import_errors[fileloc] = str(e)",
            "                finally:",
            "                    if sys.path[0] == filepath:",
            "                        del sys.path[0]",
            "        return mods",
            "",
            "    def _process_modules(self, filepath, mods, file_last_changed_on_disk):",
            "        from airflow.models.dag import DAG  # Avoid circular import",
            "",
            "        top_level_dags = ((o, m) for m in mods for o in m.__dict__.values() if isinstance(o, DAG))",
            "",
            "        found_dags = []",
            "",
            "        for (dag, mod) in top_level_dags:",
            "            dag.fileloc = mod.__file__",
            "            try:",
            "                dag.timetable.validate()",
            "                # validate dag params",
            "                dag.params.validate()",
            "                self.bag_dag(dag=dag, root_dag=dag)",
            "                found_dags.append(dag)",
            "                found_dags += dag.subdags",
            "            except AirflowTimetableInvalid as exception:",
            "                self.log.exception(\"Failed to bag_dag: %s\", dag.fileloc)",
            "                self.import_errors[dag.fileloc] = f\"Invalid timetable expression: {exception}\"",
            "                self.file_last_changed[dag.fileloc] = file_last_changed_on_disk",
            "            except (",
            "                AirflowDagCycleException,",
            "                AirflowDagDuplicatedIdException,",
            "                AirflowClusterPolicyViolation,",
            "                ParamValidationError,",
            "            ) as exception:",
            "                self.log.exception(\"Failed to bag_dag: %s\", dag.fileloc)",
            "                self.import_errors[dag.fileloc] = str(exception)",
            "                self.file_last_changed[dag.fileloc] = file_last_changed_on_disk",
            "        return found_dags",
            "",
            "    def bag_dag(self, dag, root_dag):",
            "        \"\"\"",
            "        Adds the DAG into the bag, recurses into sub dags.",
            "",
            "        :raises: AirflowDagCycleException if a cycle is detected in this dag or its subdags.",
            "        :raises: AirflowDagDuplicatedIdException if this dag or its subdags already exists in the bag.",
            "        \"\"\"",
            "        self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)",
            "",
            "    def _bag_dag(self, *, dag, root_dag, recursive):",
            "        \"\"\"Actual implementation of bagging a dag.",
            "",
            "        The only purpose of this is to avoid exposing ``recursive`` in ``bag_dag()``,",
            "        intended to only be used by the ``_bag_dag()`` implementation.",
            "        \"\"\"",
            "        check_cycle(dag)  # throws if a task cycle is found",
            "",
            "        dag.resolve_template_files()",
            "        dag.last_loaded = timezone.utcnow()",
            "",
            "        # Check policies",
            "        settings.dag_policy(dag)",
            "",
            "        for task in dag.tasks:",
            "            settings.task_policy(task)",
            "",
            "        subdags = dag.subdags",
            "",
            "        try:",
            "            # DAG.subdags automatically performs DFS search, so we don't recurse",
            "            # into further _bag_dag() calls.",
            "            if recursive:",
            "                for subdag in subdags:",
            "                    subdag.fileloc = dag.fileloc",
            "                    subdag.parent_dag = dag",
            "                    self._bag_dag(dag=subdag, root_dag=root_dag, recursive=False)",
            "",
            "            prev_dag = self.dags.get(dag.dag_id)",
            "            if prev_dag and prev_dag.fileloc != dag.fileloc:",
            "                raise AirflowDagDuplicatedIdException(",
            "                    dag_id=dag.dag_id,",
            "                    incoming=dag.fileloc,",
            "                    existing=self.dags[dag.dag_id].fileloc,",
            "                )",
            "            self.dags[dag.dag_id] = dag",
            "            self.log.debug('Loaded DAG %s', dag)",
            "        except (AirflowDagCycleException, AirflowDagDuplicatedIdException):",
            "            # There was an error in bagging the dag. Remove it from the list of dags",
            "            self.log.exception('Exception bagging dag: %s', dag.dag_id)",
            "            # Only necessary at the root level since DAG.subdags automatically",
            "            # performs DFS to search through all subdags",
            "            if recursive:",
            "                for subdag in subdags:",
            "                    if subdag.dag_id in self.dags:",
            "                        del self.dags[subdag.dag_id]",
            "            raise",
            "",
            "    def collect_dags(",
            "        self,",
            "        dag_folder: Union[str, \"pathlib.Path\", None] = None,",
            "        only_if_updated: bool = True,",
            "        include_examples: bool = conf.getboolean('core', 'LOAD_EXAMPLES'),",
            "        include_smart_sensor: bool = conf.getboolean('smart_sensor', 'USE_SMART_SENSOR'),",
            "        safe_mode: bool = conf.getboolean('core', 'DAG_DISCOVERY_SAFE_MODE'),",
            "    ):",
            "        \"\"\"",
            "        Given a file path or a folder, this method looks for python modules,",
            "        imports them and adds them to the dagbag collection.",
            "",
            "        Note that if a ``.airflowignore`` file is found while processing",
            "        the directory, it will behave much like a ``.gitignore``,",
            "        ignoring files that match any of the patterns specified",
            "        in the file.",
            "",
            "        **Note**: The patterns in ``.airflowignore`` are interpreted as either",
            "        un-anchored regexes or gitignore-like glob expressions, depending on",
            "        the ``DAG_IGNORE_FILE_SYNTAX`` configuration parameter.",
            "        \"\"\"",
            "        if self.read_dags_from_db:",
            "            return",
            "",
            "        self.log.info(\"Filling up the DagBag from %s\", dag_folder)",
            "        dag_folder = dag_folder or self.dag_folder",
            "        # Used to store stats around DagBag processing",
            "        stats = []",
            "",
            "        # Ensure dag_folder is a str -- it may have been a pathlib.Path",
            "        dag_folder = correct_maybe_zipped(str(dag_folder))",
            "        for filepath in list_py_file_paths(",
            "            dag_folder,",
            "            safe_mode=safe_mode,",
            "            include_examples=include_examples,",
            "            include_smart_sensor=include_smart_sensor,",
            "        ):",
            "            try:",
            "                file_parse_start_dttm = timezone.utcnow()",
            "                found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)",
            "",
            "                file_parse_end_dttm = timezone.utcnow()",
            "                stats.append(",
            "                    FileLoadStat(",
            "                        file=filepath.replace(settings.DAGS_FOLDER, ''),",
            "                        duration=file_parse_end_dttm - file_parse_start_dttm,",
            "                        dag_num=len(found_dags),",
            "                        task_num=sum(len(dag.tasks) for dag in found_dags),",
            "                        dags=str([dag.dag_id for dag in found_dags]),",
            "                    )",
            "                )",
            "            except Exception as e:",
            "                self.log.exception(e)",
            "",
            "        self.dagbag_stats = sorted(stats, key=lambda x: x.duration, reverse=True)",
            "",
            "    def collect_dags_from_db(self):",
            "        \"\"\"Collects DAGs from database.\"\"\"",
            "        from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "        with Stats.timer('collect_db_dags'):",
            "            self.log.info(\"Filling up the DagBag from database\")",
            "",
            "            # The dagbag contains all rows in serialized_dag table. Deleted DAGs are deleted",
            "            # from the table by the scheduler job.",
            "            self.dags = SerializedDagModel.read_all_dags()",
            "",
            "            # Adds subdags.",
            "            # DAG post-processing steps such as self.bag_dag and croniter are not needed as",
            "            # they are done by scheduler before serialization.",
            "            subdags = {}",
            "            for dag in self.dags.values():",
            "                for subdag in dag.subdags:",
            "                    subdags[subdag.dag_id] = subdag",
            "            self.dags.update(subdags)",
            "",
            "    def dagbag_report(self):",
            "        \"\"\"Prints a report around DagBag loading stats\"\"\"",
            "        stats = self.dagbag_stats",
            "        dag_folder = self.dag_folder",
            "        duration = sum((o.duration for o in stats), timedelta()).total_seconds()",
            "        dag_num = sum(o.dag_num for o in stats)",
            "        task_num = sum(o.task_num for o in stats)",
            "        table = tabulate(stats, headers=\"keys\")",
            "",
            "        report = textwrap.dedent(",
            "            f\"\"\"\\n",
            "        -------------------------------------------------------------------",
            "        DagBag loading stats for {dag_folder}",
            "        -------------------------------------------------------------------",
            "        Number of DAGs: {dag_num}",
            "        Total task number: {task_num}",
            "        DagBag parsing time: {duration}",
            "        {table}",
            "        \"\"\"",
            "        )",
            "        return report",
            "",
            "    @provide_session",
            "    def sync_to_db(self, session: Session = None):",
            "        \"\"\"Save attributes about list of DAG to the DB.\"\"\"",
            "        # To avoid circular import - airflow.models.dagbag -> airflow.models.dag -> airflow.models.dagbag",
            "        from airflow.models.dag import DAG",
            "        from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "        def _serialize_dag_capturing_errors(dag, session):",
            "            \"\"\"",
            "            Try to serialize the dag to the DB, but make a note of any errors.",
            "",
            "            We can't place them directly in import_errors, as this may be retried, and work the next time",
            "            \"\"\"",
            "            if dag.is_subdag:",
            "                return []",
            "            try:",
            "                # We can't use bulk_write_to_db as we want to capture each error individually",
            "                dag_was_updated = SerializedDagModel.write_dag(",
            "                    dag,",
            "                    min_update_interval=settings.MIN_SERIALIZED_DAG_UPDATE_INTERVAL,",
            "                    session=session,",
            "                )",
            "                if dag_was_updated:",
            "                    self._sync_perm_for_dag(dag, session=session)",
            "                return []",
            "            except OperationalError:",
            "                raise",
            "            except Exception:",
            "                self.log.exception(\"Failed to write serialized DAG: %s\", dag.full_filepath)",
            "                return [(dag.fileloc, traceback.format_exc(limit=-self.dagbag_import_error_traceback_depth))]",
            "",
            "        # Retry 'DAG.bulk_write_to_db' & 'SerializedDagModel.bulk_sync_to_db' in case",
            "        # of any Operational Errors",
            "        # In case of failures, provide_session handles rollback",
            "        for attempt in run_with_db_retries(logger=self.log):",
            "            with attempt:",
            "                serialize_errors = []",
            "                self.log.debug(",
            "                    \"Running dagbag.sync_to_db with retries. Try %d of %d\",",
            "                    attempt.retry_state.attempt_number,",
            "                    MAX_DB_RETRIES,",
            "                )",
            "                self.log.debug(\"Calling the DAG.bulk_sync_to_db method\")",
            "                try:",
            "                    # Write Serialized DAGs to DB, capturing errors",
            "                    for dag in self.dags.values():",
            "                        serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))",
            "",
            "                    DAG.bulk_write_to_db(self.dags.values(), session=session)",
            "                except OperationalError:",
            "                    session.rollback()",
            "                    raise",
            "                # Only now we are \"complete\" do we update import_errors - don't want to record errors from",
            "                # previous failed attempts",
            "                self.import_errors.update(dict(serialize_errors))",
            "",
            "    @provide_session",
            "    def _sync_perm_for_dag(self, dag, session: Session = None):",
            "        \"\"\"Sync DAG specific permissions, if necessary\"\"\"",
            "        from airflow.security.permissions import DAG_ACTIONS, resource_name_for_dag",
            "        from airflow.www.fab_security.sqla.models import Action, Permission, Resource",
            "",
            "        def needs_perms(dag_id: str) -> bool:",
            "            dag_resource_name = resource_name_for_dag(dag_id)",
            "            for permission_name in DAG_ACTIONS:",
            "                if not (",
            "                    session.query(Permission)",
            "                    .join(Action)",
            "                    .join(Resource)",
            "                    .filter(Action.name == permission_name)",
            "                    .filter(Resource.name == dag_resource_name)",
            "                    .one_or_none()",
            "                ):",
            "                    return True",
            "            return False",
            "",
            "        if dag.access_control or needs_perms(dag.dag_id):",
            "            self.log.debug(\"Syncing DAG permissions: %s to the DB\", dag.dag_id)",
            "            from airflow.www.security import ApplessAirflowSecurityManager",
            "",
            "            security_manager = ApplessAirflowSecurityManager(session=session)",
            "            security_manager.sync_perm_for_dag(dag.dag_id, dag.access_control)"
        ],
        "afterPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "",
            "import hashlib",
            "import importlib",
            "import importlib.machinery",
            "import importlib.util",
            "import os",
            "import sys",
            "import textwrap",
            "import traceback",
            "import warnings",
            "import zipfile",
            "from datetime import datetime, timedelta",
            "from typing import TYPE_CHECKING, Dict, List, NamedTuple, Optional, Union",
            "",
            "from sqlalchemy.exc import OperationalError",
            "from sqlalchemy.orm import Session",
            "from tabulate import tabulate",
            "",
            "from airflow import settings",
            "from airflow.configuration import conf",
            "from airflow.exceptions import (",
            "    AirflowClusterPolicyViolation,",
            "    AirflowDagCycleException,",
            "    AirflowDagDuplicatedIdException,",
            "    AirflowTimetableInvalid,",
            "    ParamValidationError,",
            ")",
            "from airflow.stats import Stats",
            "from airflow.utils import timezone",
            "from airflow.utils.dag_cycle_tester import check_cycle",
            "from airflow.utils.docs import get_docs_url",
            "from airflow.utils.file import correct_maybe_zipped, list_py_file_paths, might_contain_dag",
            "from airflow.utils.log.logging_mixin import LoggingMixin",
            "from airflow.utils.retries import MAX_DB_RETRIES, run_with_db_retries",
            "from airflow.utils.session import provide_session",
            "from airflow.utils.timeout import timeout",
            "",
            "if TYPE_CHECKING:",
            "    import pathlib",
            "",
            "",
            "class FileLoadStat(NamedTuple):",
            "    \"\"\"Information about single file\"\"\"",
            "",
            "    file: str",
            "    duration: timedelta",
            "    dag_num: int",
            "    task_num: int",
            "    dags: str",
            "",
            "",
            "class DagBag(LoggingMixin):",
            "    \"\"\"",
            "    A dagbag is a collection of dags, parsed out of a folder tree and has high",
            "    level configuration settings, like what database to use as a backend and",
            "    what executor to use to fire off tasks. This makes it easier to run",
            "    distinct environments for say production and development, tests, or for",
            "    different teams or security profiles. What would have been system level",
            "    settings are now dagbag level so that one system can run multiple,",
            "    independent settings sets.",
            "",
            "    :param dag_folder: the folder to scan to find DAGs",
            "    :param include_examples: whether to include the examples that ship",
            "        with airflow or not",
            "    :param include_smart_sensor: whether to include the smart sensor native",
            "        DAGs that create the smart sensor operators for whole cluster",
            "    :param read_dags_from_db: Read DAGs from DB if ``True`` is passed.",
            "        If ``False`` DAGs are read from python files.",
            "    :param load_op_links: Should the extra operator link be loaded via plugins when",
            "        de-serializing the DAG? This flag is set to False in Scheduler so that Extra Operator links",
            "        are not loaded to not run User code in Scheduler.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        dag_folder: Union[str, \"pathlib.Path\", None] = None,",
            "        include_examples: bool = conf.getboolean('core', 'LOAD_EXAMPLES'),",
            "        include_smart_sensor: bool = conf.getboolean('smart_sensor', 'USE_SMART_SENSOR'),",
            "        safe_mode: bool = conf.getboolean('core', 'DAG_DISCOVERY_SAFE_MODE'),",
            "        read_dags_from_db: bool = False,",
            "        store_serialized_dags: Optional[bool] = None,",
            "        load_op_links: bool = True,",
            "    ):",
            "        # Avoid circular import",
            "        from airflow.models.dag import DAG",
            "",
            "        super().__init__()",
            "",
            "        if store_serialized_dags:",
            "            warnings.warn(",
            "                \"The store_serialized_dags parameter has been deprecated. \"",
            "                \"You should pass the read_dags_from_db parameter.\",",
            "                DeprecationWarning,",
            "                stacklevel=2,",
            "            )",
            "            read_dags_from_db = store_serialized_dags",
            "",
            "        dag_folder = dag_folder or settings.DAGS_FOLDER",
            "        self.dag_folder = dag_folder",
            "        self.dags: Dict[str, DAG] = {}",
            "        # the file's last modified timestamp when we last read it",
            "        self.file_last_changed: Dict[str, datetime] = {}",
            "        self.import_errors: Dict[str, str] = {}",
            "        self.has_logged = False",
            "        self.read_dags_from_db = read_dags_from_db",
            "        # Only used by read_dags_from_db=True",
            "        self.dags_last_fetched: Dict[str, datetime] = {}",
            "        # Only used by SchedulerJob to compare the dag_hash to identify change in DAGs",
            "        self.dags_hash: Dict[str, str] = {}",
            "",
            "        self.dagbag_import_error_tracebacks = conf.getboolean('core', 'dagbag_import_error_tracebacks')",
            "        self.dagbag_import_error_traceback_depth = conf.getint('core', 'dagbag_import_error_traceback_depth')",
            "        self.collect_dags(",
            "            dag_folder=dag_folder,",
            "            include_examples=include_examples,",
            "            include_smart_sensor=include_smart_sensor,",
            "            safe_mode=safe_mode,",
            "        )",
            "        # Should the extra operator link be loaded via plugins?",
            "        # This flag is set to False in Scheduler so that Extra Operator links are not loaded",
            "        self.load_op_links = load_op_links",
            "",
            "    def size(self) -> int:",
            "        \"\"\":return: the amount of dags contained in this dagbag\"\"\"",
            "        return len(self.dags)",
            "",
            "    @property",
            "    def store_serialized_dags(self) -> bool:",
            "        \"\"\"Whether or not to read dags from DB\"\"\"",
            "        warnings.warn(",
            "            \"The store_serialized_dags property has been deprecated. Use read_dags_from_db instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        return self.read_dags_from_db",
            "",
            "    @property",
            "    def dag_ids(self) -> List[str]:",
            "        \"\"\"",
            "        :return: a list of DAG IDs in this bag",
            "        :rtype: List[unicode]",
            "        \"\"\"",
            "        return list(self.dags.keys())",
            "",
            "    @provide_session",
            "    def get_dag(self, dag_id, session: Session = None):",
            "        \"\"\"",
            "        Gets the DAG out of the dictionary, and refreshes it if expired",
            "",
            "        :param dag_id: DAG Id",
            "        \"\"\"",
            "        # Avoid circular import",
            "        from airflow.models.dag import DagModel",
            "",
            "        if self.read_dags_from_db:",
            "            # Import here so that serialized dag is only imported when serialization is enabled",
            "            from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "            if dag_id not in self.dags:",
            "                # Load from DB if not (yet) in the bag",
            "                self._add_dag_from_db(dag_id=dag_id, session=session)",
            "                return self.dags.get(dag_id)",
            "",
            "            # If DAG is in the DagBag, check the following",
            "            # 1. if time has come to check if DAG is updated (controlled by min_serialized_dag_fetch_secs)",
            "            # 2. check the last_updated column in SerializedDag table to see if Serialized DAG is updated",
            "            # 3. if (2) is yes, fetch the Serialized DAG.",
            "            # 4. if (2) returns None (i.e. Serialized DAG is deleted), remove dag from dagbag",
            "            # if it exists and return None.",
            "            min_serialized_dag_fetch_secs = timedelta(seconds=settings.MIN_SERIALIZED_DAG_FETCH_INTERVAL)",
            "            if (",
            "                dag_id in self.dags_last_fetched",
            "                and timezone.utcnow() > self.dags_last_fetched[dag_id] + min_serialized_dag_fetch_secs",
            "            ):",
            "                sd_last_updated_datetime = SerializedDagModel.get_last_updated_datetime(",
            "                    dag_id=dag_id,",
            "                    session=session,",
            "                )",
            "                if not sd_last_updated_datetime:",
            "                    self.log.warning(\"Serialized DAG %s no longer exists\", dag_id)",
            "                    del self.dags[dag_id]",
            "                    del self.dags_last_fetched[dag_id]",
            "                    del self.dags_hash[dag_id]",
            "                    return None",
            "",
            "                if sd_last_updated_datetime > self.dags_last_fetched[dag_id]:",
            "                    self._add_dag_from_db(dag_id=dag_id, session=session)",
            "",
            "            return self.dags.get(dag_id)",
            "",
            "        # If asking for a known subdag, we want to refresh the parent",
            "        dag = None",
            "        root_dag_id = dag_id",
            "        if dag_id in self.dags:",
            "            dag = self.dags[dag_id]",
            "            if dag.parent_dag:",
            "                root_dag_id = dag.parent_dag.dag_id",
            "",
            "        # If DAG Model is absent, we can't check last_expired property. Is the DAG not yet synchronized?",
            "        orm_dag = DagModel.get_current(root_dag_id, session=session)",
            "        if not orm_dag:",
            "            return self.dags.get(dag_id)",
            "",
            "        # If the dag corresponding to root_dag_id is absent or expired",
            "        is_missing = root_dag_id not in self.dags",
            "        is_expired = orm_dag.last_expired and dag and dag.last_loaded < orm_dag.last_expired",
            "        if is_expired:",
            "            # Remove associated dags so we can re-add them.",
            "            self.dags = {",
            "                key: dag",
            "                for key, dag in self.dags.items()",
            "                if root_dag_id != key and not (dag.parent_dag and root_dag_id == dag.parent_dag.dag_id)",
            "            }",
            "        if is_missing or is_expired:",
            "            # Reprocess source file.",
            "            found_dags = self.process_file(",
            "                filepath=correct_maybe_zipped(orm_dag.fileloc), only_if_updated=False",
            "            )",
            "",
            "            # If the source file no longer exports `dag_id`, delete it from self.dags",
            "            if found_dags and dag_id in [found_dag.dag_id for found_dag in found_dags]:",
            "                return self.dags[dag_id]",
            "            elif dag_id in self.dags:",
            "                del self.dags[dag_id]",
            "        return self.dags.get(dag_id)",
            "",
            "    def _add_dag_from_db(self, dag_id: str, session: Session):",
            "        \"\"\"Add DAG to DagBag from DB\"\"\"",
            "        from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "        row = SerializedDagModel.get(dag_id, session)",
            "        if not row:",
            "            return None",
            "",
            "        row.load_op_links = self.load_op_links",
            "        dag = row.dag",
            "        for subdag in dag.subdags:",
            "            self.dags[subdag.dag_id] = subdag",
            "        self.dags[dag.dag_id] = dag",
            "        self.dags_last_fetched[dag.dag_id] = timezone.utcnow()",
            "        self.dags_hash[dag.dag_id] = row.dag_hash",
            "",
            "    def process_file(self, filepath, only_if_updated=True, safe_mode=True):",
            "        \"\"\"",
            "        Given a path to a python module or zip file, this method imports",
            "        the module and look for dag objects within it.",
            "        \"\"\"",
            "        # if the source file no longer exists in the DB or in the filesystem,",
            "        # return an empty list",
            "        # todo: raise exception?",
            "        if filepath is None or not os.path.isfile(filepath):",
            "            return []",
            "",
            "        try:",
            "            # This failed before in what may have been a git sync",
            "            # race condition",
            "            file_last_changed_on_disk = datetime.fromtimestamp(os.path.getmtime(filepath))",
            "            if (",
            "                only_if_updated",
            "                and filepath in self.file_last_changed",
            "                and file_last_changed_on_disk == self.file_last_changed[filepath]",
            "            ):",
            "                return []",
            "        except Exception as e:",
            "            self.log.exception(e)",
            "            return []",
            "",
            "        if filepath.endswith(\".py\") or not zipfile.is_zipfile(filepath):",
            "            mods = self._load_modules_from_file(filepath, safe_mode)",
            "        else:",
            "            mods = self._load_modules_from_zip(filepath, safe_mode)",
            "",
            "        found_dags = self._process_modules(filepath, mods, file_last_changed_on_disk)",
            "",
            "        self.file_last_changed[filepath] = file_last_changed_on_disk",
            "        return found_dags",
            "",
            "    def _load_modules_from_file(self, filepath, safe_mode):",
            "        if not might_contain_dag(filepath, safe_mode):",
            "            # Don't want to spam user with skip messages",
            "            if not self.has_logged:",
            "                self.has_logged = True",
            "                self.log.info(\"File %s assumed to contain no DAGs. Skipping.\", filepath)",
            "            return []",
            "",
            "        self.log.debug(\"Importing %s\", filepath)",
            "        org_mod_name, _ = os.path.splitext(os.path.split(filepath)[-1])",
            "        path_hash = hashlib.sha1(filepath.encode('utf-8')).hexdigest()",
            "        mod_name = f'unusual_prefix_{path_hash}_{org_mod_name}'",
            "",
            "        if mod_name in sys.modules:",
            "            del sys.modules[mod_name]",
            "",
            "        def parse(mod_name, filepath):",
            "            try:",
            "                loader = importlib.machinery.SourceFileLoader(mod_name, filepath)",
            "                spec = importlib.util.spec_from_loader(mod_name, loader)",
            "                new_module = importlib.util.module_from_spec(spec)",
            "                sys.modules[spec.name] = new_module",
            "                loader.exec_module(new_module)",
            "                return [new_module]",
            "            except Exception as e:",
            "                self.log.exception(\"Failed to import: %s\", filepath)",
            "                if self.dagbag_import_error_tracebacks:",
            "                    self.import_errors[filepath] = traceback.format_exc(",
            "                        limit=-self.dagbag_import_error_traceback_depth",
            "                    )",
            "                else:",
            "                    self.import_errors[filepath] = str(e)",
            "                return []",
            "",
            "        dagbag_import_timeout = settings.get_dagbag_import_timeout(filepath)",
            "",
            "        if not isinstance(dagbag_import_timeout, (int, float)):",
            "            raise TypeError(",
            "                f'Value ({dagbag_import_timeout}) from get_dagbag_import_timeout must be int or float'",
            "            )",
            "",
            "        if dagbag_import_timeout <= 0:  # no parsing timeout",
            "            return parse(mod_name, filepath)",
            "",
            "        timeout_msg = (",
            "            f\"DagBag import timeout for {filepath} after {dagbag_import_timeout}s.\\n\"",
            "            \"Please take a look at these docs to improve your DAG import time:\\n\"",
            "            f\"* {get_docs_url('best-practices.html#top-level-python-code')}\\n\"",
            "            f\"* {get_docs_url('best-practices.html#reducing-dag-complexity')}\"",
            "        )",
            "        with timeout(dagbag_import_timeout, error_message=timeout_msg):",
            "            return parse(mod_name, filepath)",
            "",
            "    def _load_modules_from_zip(self, filepath, safe_mode):",
            "        mods = []",
            "        with zipfile.ZipFile(filepath) as current_zip_file:",
            "            for zip_info in current_zip_file.infolist():",
            "                head, _ = os.path.split(zip_info.filename)",
            "                mod_name, ext = os.path.splitext(zip_info.filename)",
            "                if ext not in [\".py\", \".pyc\"]:",
            "                    continue",
            "                if head:",
            "                    continue",
            "",
            "                if mod_name == '__init__':",
            "                    self.log.warning(\"Found __init__.%s at root of %s\", ext, filepath)",
            "",
            "                self.log.debug(\"Reading %s from %s\", zip_info.filename, filepath)",
            "",
            "                if not might_contain_dag(zip_info.filename, safe_mode, current_zip_file):",
            "                    # todo: create ignore list",
            "                    # Don't want to spam user with skip messages",
            "                    if not self.has_logged:",
            "                        self.has_logged = True",
            "                        self.log.info(",
            "                            \"File %s:%s assumed to contain no DAGs. Skipping.\", filepath, zip_info.filename",
            "                        )",
            "                    continue",
            "",
            "                if mod_name in sys.modules:",
            "                    del sys.modules[mod_name]",
            "",
            "                try:",
            "                    sys.path.insert(0, filepath)",
            "                    current_module = importlib.import_module(mod_name)",
            "                    mods.append(current_module)",
            "                except Exception as e:",
            "                    fileloc = os.path.join(filepath, zip_info.filename)",
            "                    self.log.exception(\"Failed to import: %s\", fileloc)",
            "                    if self.dagbag_import_error_tracebacks:",
            "                        self.import_errors[fileloc] = traceback.format_exc(",
            "                            limit=-self.dagbag_import_error_traceback_depth",
            "                        )",
            "                    else:",
            "                        self.import_errors[fileloc] = str(e)",
            "                finally:",
            "                    if sys.path[0] == filepath:",
            "                        del sys.path[0]",
            "        return mods",
            "",
            "    def _process_modules(self, filepath, mods, file_last_changed_on_disk):",
            "        from airflow.models.dag import DAG  # Avoid circular import",
            "",
            "        top_level_dags = ((o, m) for m in mods for o in m.__dict__.values() if isinstance(o, DAG))",
            "",
            "        found_dags = []",
            "",
            "        for (dag, mod) in top_level_dags:",
            "            dag.fileloc = mod.__file__",
            "            try:",
            "                dag.timetable.validate()",
            "                # validate dag params",
            "                dag.params.validate()",
            "                self.bag_dag(dag=dag, root_dag=dag)",
            "                found_dags.append(dag)",
            "                found_dags += dag.subdags",
            "            except AirflowTimetableInvalid as exception:",
            "                self.log.exception(\"Failed to bag_dag: %s\", dag.fileloc)",
            "                self.import_errors[dag.fileloc] = f\"Invalid timetable expression: {exception}\"",
            "                self.file_last_changed[dag.fileloc] = file_last_changed_on_disk",
            "            except (",
            "                AirflowDagCycleException,",
            "                AirflowDagDuplicatedIdException,",
            "                AirflowClusterPolicyViolation,",
            "                ParamValidationError,",
            "            ) as exception:",
            "                self.log.exception(\"Failed to bag_dag: %s\", dag.fileloc)",
            "                self.import_errors[dag.fileloc] = str(exception)",
            "                self.file_last_changed[dag.fileloc] = file_last_changed_on_disk",
            "        return found_dags",
            "",
            "    def bag_dag(self, dag, root_dag):",
            "        \"\"\"",
            "        Adds the DAG into the bag, recurses into sub dags.",
            "",
            "        :raises: AirflowDagCycleException if a cycle is detected in this dag or its subdags.",
            "        :raises: AirflowDagDuplicatedIdException if this dag or its subdags already exists in the bag.",
            "        \"\"\"",
            "        self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)",
            "",
            "    def _bag_dag(self, *, dag, root_dag, recursive):",
            "        \"\"\"Actual implementation of bagging a dag.",
            "",
            "        The only purpose of this is to avoid exposing ``recursive`` in ``bag_dag()``,",
            "        intended to only be used by the ``_bag_dag()`` implementation.",
            "        \"\"\"",
            "        check_cycle(dag)  # throws if a task cycle is found",
            "",
            "        dag.resolve_template_files()",
            "        dag.last_loaded = timezone.utcnow()",
            "",
            "        # Check policies",
            "        settings.dag_policy(dag)",
            "",
            "        for task in dag.tasks:",
            "            settings.task_policy(task)",
            "",
            "        subdags = dag.subdags",
            "",
            "        try:",
            "            # DAG.subdags automatically performs DFS search, so we don't recurse",
            "            # into further _bag_dag() calls.",
            "            if recursive:",
            "                for subdag in subdags:",
            "                    subdag.fileloc = dag.fileloc",
            "                    subdag.parent_dag = dag",
            "                    self._bag_dag(dag=subdag, root_dag=root_dag, recursive=False)",
            "",
            "            prev_dag = self.dags.get(dag.dag_id)",
            "            if prev_dag and prev_dag.fileloc != dag.fileloc:",
            "                raise AirflowDagDuplicatedIdException(",
            "                    dag_id=dag.dag_id,",
            "                    incoming=dag.fileloc,",
            "                    existing=self.dags[dag.dag_id].fileloc,",
            "                )",
            "            self.dags[dag.dag_id] = dag",
            "            self.log.debug('Loaded DAG %s', dag)",
            "        except (AirflowDagCycleException, AirflowDagDuplicatedIdException):",
            "            # There was an error in bagging the dag. Remove it from the list of dags",
            "            self.log.exception('Exception bagging dag: %s', dag.dag_id)",
            "            # Only necessary at the root level since DAG.subdags automatically",
            "            # performs DFS to search through all subdags",
            "            if recursive:",
            "                for subdag in subdags:",
            "                    if subdag.dag_id in self.dags:",
            "                        del self.dags[subdag.dag_id]",
            "            raise",
            "",
            "    def collect_dags(",
            "        self,",
            "        dag_folder: Union[str, \"pathlib.Path\", None] = None,",
            "        only_if_updated: bool = True,",
            "        include_examples: bool = conf.getboolean('core', 'LOAD_EXAMPLES'),",
            "        include_smart_sensor: bool = conf.getboolean('smart_sensor', 'USE_SMART_SENSOR'),",
            "        safe_mode: bool = conf.getboolean('core', 'DAG_DISCOVERY_SAFE_MODE'),",
            "    ):",
            "        \"\"\"",
            "        Given a file path or a folder, this method looks for python modules,",
            "        imports them and adds them to the dagbag collection.",
            "",
            "        Note that if a ``.airflowignore`` file is found while processing",
            "        the directory, it will behave much like a ``.gitignore``,",
            "        ignoring files that match any of the patterns specified",
            "        in the file.",
            "",
            "        **Note**: The patterns in ``.airflowignore`` are interpreted as either",
            "        un-anchored regexes or gitignore-like glob expressions, depending on",
            "        the ``DAG_IGNORE_FILE_SYNTAX`` configuration parameter.",
            "        \"\"\"",
            "        if self.read_dags_from_db:",
            "            return",
            "",
            "        self.log.info(\"Filling up the DagBag from %s\", dag_folder)",
            "        dag_folder = dag_folder or self.dag_folder",
            "        # Used to store stats around DagBag processing",
            "        stats = []",
            "",
            "        # Ensure dag_folder is a str -- it may have been a pathlib.Path",
            "        dag_folder = correct_maybe_zipped(str(dag_folder))",
            "        for filepath in list_py_file_paths(",
            "            dag_folder,",
            "            safe_mode=safe_mode,",
            "            include_examples=include_examples,",
            "            include_smart_sensor=include_smart_sensor,",
            "        ):",
            "            try:",
            "                file_parse_start_dttm = timezone.utcnow()",
            "                found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)",
            "",
            "                file_parse_end_dttm = timezone.utcnow()",
            "                stats.append(",
            "                    FileLoadStat(",
            "                        file=filepath.replace(settings.DAGS_FOLDER, ''),",
            "                        duration=file_parse_end_dttm - file_parse_start_dttm,",
            "                        dag_num=len(found_dags),",
            "                        task_num=sum(len(dag.tasks) for dag in found_dags),",
            "                        dags=str([dag.dag_id for dag in found_dags]),",
            "                    )",
            "                )",
            "            except Exception as e:",
            "                self.log.exception(e)",
            "",
            "        self.dagbag_stats = sorted(stats, key=lambda x: x.duration, reverse=True)",
            "",
            "    def collect_dags_from_db(self):",
            "        \"\"\"Collects DAGs from database.\"\"\"",
            "        from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "        with Stats.timer('collect_db_dags'):",
            "            self.log.info(\"Filling up the DagBag from database\")",
            "",
            "            # The dagbag contains all rows in serialized_dag table. Deleted DAGs are deleted",
            "            # from the table by the scheduler job.",
            "            self.dags = SerializedDagModel.read_all_dags()",
            "",
            "            # Adds subdags.",
            "            # DAG post-processing steps such as self.bag_dag and croniter are not needed as",
            "            # they are done by scheduler before serialization.",
            "            subdags = {}",
            "            for dag in self.dags.values():",
            "                for subdag in dag.subdags:",
            "                    subdags[subdag.dag_id] = subdag",
            "            self.dags.update(subdags)",
            "",
            "    def dagbag_report(self):",
            "        \"\"\"Prints a report around DagBag loading stats\"\"\"",
            "        stats = self.dagbag_stats",
            "        dag_folder = self.dag_folder",
            "        duration = sum((o.duration for o in stats), timedelta()).total_seconds()",
            "        dag_num = sum(o.dag_num for o in stats)",
            "        task_num = sum(o.task_num for o in stats)",
            "        table = tabulate(stats, headers=\"keys\")",
            "",
            "        report = textwrap.dedent(",
            "            f\"\"\"\\n",
            "        -------------------------------------------------------------------",
            "        DagBag loading stats for {dag_folder}",
            "        -------------------------------------------------------------------",
            "        Number of DAGs: {dag_num}",
            "        Total task number: {task_num}",
            "        DagBag parsing time: {duration}",
            "        {table}",
            "        \"\"\"",
            "        )",
            "        return report",
            "",
            "    @provide_session",
            "    def sync_to_db(self, session: Session = None):",
            "        \"\"\"Save attributes about list of DAG to the DB.\"\"\"",
            "        # To avoid circular import - airflow.models.dagbag -> airflow.models.dag -> airflow.models.dagbag",
            "        from airflow.models.dag import DAG",
            "        from airflow.models.serialized_dag import SerializedDagModel",
            "",
            "        def _serialize_dag_capturing_errors(dag, session):",
            "            \"\"\"",
            "            Try to serialize the dag to the DB, but make a note of any errors.",
            "",
            "            We can't place them directly in import_errors, as this may be retried, and work the next time",
            "            \"\"\"",
            "            if dag.is_subdag:",
            "                return []",
            "            try:",
            "                # We can't use bulk_write_to_db as we want to capture each error individually",
            "                dag_was_updated = SerializedDagModel.write_dag(",
            "                    dag,",
            "                    min_update_interval=settings.MIN_SERIALIZED_DAG_UPDATE_INTERVAL,",
            "                    session=session,",
            "                )",
            "                if dag_was_updated:",
            "                    self._sync_perm_for_dag(dag, session=session)",
            "                return []",
            "            except OperationalError:",
            "                raise",
            "            except Exception:",
            "                self.log.exception(\"Failed to write serialized DAG: %s\", dag.full_filepath)",
            "                return [(dag.fileloc, traceback.format_exc(limit=-self.dagbag_import_error_traceback_depth))]",
            "",
            "        # Retry 'DAG.bulk_write_to_db' & 'SerializedDagModel.bulk_sync_to_db' in case",
            "        # of any Operational Errors",
            "        # In case of failures, provide_session handles rollback",
            "        for attempt in run_with_db_retries(logger=self.log):",
            "            with attempt:",
            "                serialize_errors = []",
            "                self.log.debug(",
            "                    \"Running dagbag.sync_to_db with retries. Try %d of %d\",",
            "                    attempt.retry_state.attempt_number,",
            "                    MAX_DB_RETRIES,",
            "                )",
            "                self.log.debug(\"Calling the DAG.bulk_sync_to_db method\")",
            "                try:",
            "                    # Write Serialized DAGs to DB, capturing errors",
            "                    for dag in self.dags.values():",
            "                        serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))",
            "",
            "                    DAG.bulk_write_to_db(self.dags.values(), session=session)",
            "                except OperationalError:",
            "                    session.rollback()",
            "                    raise",
            "                # Only now we are \"complete\" do we update import_errors - don't want to record errors from",
            "                # previous failed attempts",
            "                self.import_errors.update(dict(serialize_errors))",
            "",
            "    @provide_session",
            "    def _sync_perm_for_dag(self, dag, session: Session = None):",
            "        \"\"\"Sync DAG specific permissions, if necessary\"\"\"",
            "        from airflow.security.permissions import DAG_ACTIONS, resource_name_for_dag",
            "        from airflow.www.fab_security.sqla.models import Action, Permission, Resource",
            "",
            "        root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id",
            "",
            "        def needs_perms(dag_id: str) -> bool:",
            "            dag_resource_name = resource_name_for_dag(dag_id)",
            "            for permission_name in DAG_ACTIONS:",
            "                if not (",
            "                    session.query(Permission)",
            "                    .join(Action)",
            "                    .join(Resource)",
            "                    .filter(Action.name == permission_name)",
            "                    .filter(Resource.name == dag_resource_name)",
            "                    .one_or_none()",
            "                ):",
            "                    return True",
            "            return False",
            "",
            "        if dag.access_control or needs_perms(root_dag_id):",
            "            self.log.debug(\"Syncing DAG permissions: %s to the DB\", root_dag_id)",
            "            from airflow.www.security import ApplessAirflowSecurityManager",
            "",
            "            security_manager = ApplessAirflowSecurityManager(session=session)",
            "            security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2"
        ],
        "dele_reviseLocation": {
            "657": [
                "DagBag",
                "_sync_perm_for_dag"
            ],
            "658": [
                "DagBag",
                "_sync_perm_for_dag"
            ],
            "662": [
                "DagBag",
                "_sync_perm_for_dag"
            ]
        },
        "addLocation": [
            "jwt.api_jwt"
        ]
    },
    "airflow/security/permissions.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 66,
                "afterPatchRowNumber": 66,
                "PatchRowcode": " DAG_ACTIONS = {ACTION_CAN_READ, ACTION_CAN_EDIT, ACTION_CAN_DELETE}"
            },
            "1": {
                "beforePatchRowNumber": 67,
                "afterPatchRowNumber": 67,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 68,
                "afterPatchRowNumber": 68,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 69,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-def resource_name_for_dag(dag_id):"
            },
            "4": {
                "beforePatchRowNumber": 70,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Returns the resource name for a DAG id.\"\"\""
            },
            "5": {
                "beforePatchRowNumber": 71,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if dag_id == RESOURCE_DAG:"
            },
            "6": {
                "beforePatchRowNumber": 72,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return dag_id"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+def resource_name_for_dag(root_dag_id: str) -> str:"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+    \"\"\"Returns the resource name for a DAG id."
            },
            "9": {
                "beforePatchRowNumber": 73,
                "afterPatchRowNumber": 71,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 74,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    if dag_id.startswith(RESOURCE_DAG_PREFIX):"
            },
            "11": {
                "beforePatchRowNumber": 75,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return dag_id"
            },
            "12": {
                "beforePatchRowNumber": 76,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "13": {
                "beforePatchRowNumber": 77,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    # To account for SubDags"
            },
            "14": {
                "beforePatchRowNumber": 78,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    root_dag_id = dag_id.split(\".\")[0]"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+    Note that since a sub-DAG should follow the permission of its"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+    parent DAG, you should pass ``DagModel.root_dag_id`` to this function,"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+    for a subdag. A normal dag should pass the ``DagModel.dag_id``."
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+    \"\"\""
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+    if root_dag_id == RESOURCE_DAG:"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+        return root_dag_id"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+    if root_dag_id.startswith(RESOURCE_DAG_PREFIX):"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+        return root_dag_id"
            },
            "23": {
                "beforePatchRowNumber": 79,
                "afterPatchRowNumber": 80,
                "PatchRowcode": "     return f\"{RESOURCE_DAG_PREFIX}{root_dag_id}\""
            }
        },
        "frontPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "",
            "# Resource Constants",
            "RESOURCE_ACTION = \"Permissions\"",
            "RESOURCE_ADMIN_MENU = \"Admin\"",
            "RESOURCE_AIRFLOW = \"Airflow\"",
            "RESOURCE_AUDIT_LOG = \"Audit Logs\"",
            "RESOURCE_BROWSE_MENU = \"Browse\"",
            "RESOURCE_DAG = \"DAGs\"",
            "RESOURCE_DAG_PREFIX = \"DAG:\"",
            "RESOURCE_LOGIN = \"Logins\"",
            "RESOURCE_DOCS_MENU = \"Docs\"",
            "RESOURCE_DOCS = \"Documentation\"",
            "RESOURCE_CONFIG = \"Configurations\"",
            "RESOURCE_CONNECTION = \"Connections\"",
            "RESOURCE_DAG_DEPENDENCIES = \"DAG Dependencies\"",
            "RESOURCE_DAG_CODE = \"DAG Code\"",
            "RESOURCE_DAG_RUN = \"DAG Runs\"",
            "RESOURCE_IMPORT_ERROR = \"ImportError\"",
            "RESOURCE_JOB = \"Jobs\"",
            "RESOURCE_MY_PASSWORD = \"My Password\"",
            "RESOURCE_MY_PROFILE = \"My Profile\"",
            "RESOURCE_PASSWORD = \"Passwords\"",
            "RESOURCE_PERMISSION = \"Permission Views\"  # Refers to a Perm <-> View mapping, not an MVC View.",
            "RESOURCE_POOL = \"Pools\"",
            "RESOURCE_PLUGIN = \"Plugins\"",
            "RESOURCE_PROVIDER = \"Providers\"",
            "RESOURCE_RESOURCE = \"View Menus\"",
            "RESOURCE_ROLE = \"Roles\"",
            "RESOURCE_SLA_MISS = \"SLA Misses\"",
            "RESOURCE_TASK_INSTANCE = \"Task Instances\"",
            "RESOURCE_TASK_LOG = \"Task Logs\"",
            "RESOURCE_TASK_RESCHEDULE = \"Task Reschedules\"",
            "RESOURCE_TRIGGER = \"Triggers\"",
            "RESOURCE_USER = \"Users\"",
            "RESOURCE_USER_STATS_CHART = \"User Stats Chart\"",
            "RESOURCE_VARIABLE = \"Variables\"",
            "RESOURCE_WEBSITE = \"Website\"",
            "RESOURCE_XCOM = \"XComs\"",
            "",
            "",
            "# Action Constants",
            "ACTION_CAN_CREATE = \"can_create\"",
            "ACTION_CAN_READ = \"can_read\"",
            "ACTION_CAN_EDIT = \"can_edit\"",
            "ACTION_CAN_DELETE = \"can_delete\"",
            "ACTION_CAN_ACCESS_MENU = \"menu_access\"",
            "DEPRECATED_ACTION_CAN_DAG_READ = \"can_dag_read\"",
            "DEPRECATED_ACTION_CAN_DAG_EDIT = \"can_dag_edit\"",
            "",
            "DAG_ACTIONS = {ACTION_CAN_READ, ACTION_CAN_EDIT, ACTION_CAN_DELETE}",
            "",
            "",
            "def resource_name_for_dag(dag_id):",
            "    \"\"\"Returns the resource name for a DAG id.\"\"\"",
            "    if dag_id == RESOURCE_DAG:",
            "        return dag_id",
            "",
            "    if dag_id.startswith(RESOURCE_DAG_PREFIX):",
            "        return dag_id",
            "",
            "    # To account for SubDags",
            "    root_dag_id = dag_id.split(\".\")[0]",
            "    return f\"{RESOURCE_DAG_PREFIX}{root_dag_id}\""
        ],
        "afterPatchFile": [
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "",
            "# Resource Constants",
            "RESOURCE_ACTION = \"Permissions\"",
            "RESOURCE_ADMIN_MENU = \"Admin\"",
            "RESOURCE_AIRFLOW = \"Airflow\"",
            "RESOURCE_AUDIT_LOG = \"Audit Logs\"",
            "RESOURCE_BROWSE_MENU = \"Browse\"",
            "RESOURCE_DAG = \"DAGs\"",
            "RESOURCE_DAG_PREFIX = \"DAG:\"",
            "RESOURCE_LOGIN = \"Logins\"",
            "RESOURCE_DOCS_MENU = \"Docs\"",
            "RESOURCE_DOCS = \"Documentation\"",
            "RESOURCE_CONFIG = \"Configurations\"",
            "RESOURCE_CONNECTION = \"Connections\"",
            "RESOURCE_DAG_DEPENDENCIES = \"DAG Dependencies\"",
            "RESOURCE_DAG_CODE = \"DAG Code\"",
            "RESOURCE_DAG_RUN = \"DAG Runs\"",
            "RESOURCE_IMPORT_ERROR = \"ImportError\"",
            "RESOURCE_JOB = \"Jobs\"",
            "RESOURCE_MY_PASSWORD = \"My Password\"",
            "RESOURCE_MY_PROFILE = \"My Profile\"",
            "RESOURCE_PASSWORD = \"Passwords\"",
            "RESOURCE_PERMISSION = \"Permission Views\"  # Refers to a Perm <-> View mapping, not an MVC View.",
            "RESOURCE_POOL = \"Pools\"",
            "RESOURCE_PLUGIN = \"Plugins\"",
            "RESOURCE_PROVIDER = \"Providers\"",
            "RESOURCE_RESOURCE = \"View Menus\"",
            "RESOURCE_ROLE = \"Roles\"",
            "RESOURCE_SLA_MISS = \"SLA Misses\"",
            "RESOURCE_TASK_INSTANCE = \"Task Instances\"",
            "RESOURCE_TASK_LOG = \"Task Logs\"",
            "RESOURCE_TASK_RESCHEDULE = \"Task Reschedules\"",
            "RESOURCE_TRIGGER = \"Triggers\"",
            "RESOURCE_USER = \"Users\"",
            "RESOURCE_USER_STATS_CHART = \"User Stats Chart\"",
            "RESOURCE_VARIABLE = \"Variables\"",
            "RESOURCE_WEBSITE = \"Website\"",
            "RESOURCE_XCOM = \"XComs\"",
            "",
            "",
            "# Action Constants",
            "ACTION_CAN_CREATE = \"can_create\"",
            "ACTION_CAN_READ = \"can_read\"",
            "ACTION_CAN_EDIT = \"can_edit\"",
            "ACTION_CAN_DELETE = \"can_delete\"",
            "ACTION_CAN_ACCESS_MENU = \"menu_access\"",
            "DEPRECATED_ACTION_CAN_DAG_READ = \"can_dag_read\"",
            "DEPRECATED_ACTION_CAN_DAG_EDIT = \"can_dag_edit\"",
            "",
            "DAG_ACTIONS = {ACTION_CAN_READ, ACTION_CAN_EDIT, ACTION_CAN_DELETE}",
            "",
            "",
            "def resource_name_for_dag(root_dag_id: str) -> str:",
            "    \"\"\"Returns the resource name for a DAG id.",
            "",
            "    Note that since a sub-DAG should follow the permission of its",
            "    parent DAG, you should pass ``DagModel.root_dag_id`` to this function,",
            "    for a subdag. A normal dag should pass the ``DagModel.dag_id``.",
            "    \"\"\"",
            "    if root_dag_id == RESOURCE_DAG:",
            "        return root_dag_id",
            "    if root_dag_id.startswith(RESOURCE_DAG_PREFIX):",
            "        return root_dag_id",
            "    return f\"{RESOURCE_DAG_PREFIX}{root_dag_id}\""
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0"
        ],
        "dele_reviseLocation": {
            "69": [
                "resource_name_for_dag"
            ],
            "70": [
                "resource_name_for_dag"
            ],
            "71": [
                "resource_name_for_dag"
            ],
            "72": [
                "resource_name_for_dag"
            ],
            "74": [
                "resource_name_for_dag"
            ],
            "75": [
                "resource_name_for_dag"
            ],
            "76": [
                "resource_name_for_dag"
            ],
            "77": [
                "resource_name_for_dag"
            ],
            "78": [
                "resource_name_for_dag"
            ]
        },
        "addLocation": []
    },
    "airflow/www/security.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": 200,
                "PatchRowcode": "             view.datamodel = CustomSQLAInterface(view.datamodel.obj)"
            },
            "1": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": 201,
                "PatchRowcode": "         self.perms = None"
            },
            "2": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": 202,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 203,
                "PatchRowcode": "+    def _get_root_dag_id(self, dag_id):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 204,
                "PatchRowcode": "+        if '.' in dag_id:"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 205,
                "PatchRowcode": "+            dm = ("
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 206,
                "PatchRowcode": "+                self.get_session.query(DagModel.dag_id, DagModel.root_dag_id)"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 207,
                "PatchRowcode": "+                .filter(DagModel.dag_id == dag_id)"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 208,
                "PatchRowcode": "+                .first()"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 209,
                "PatchRowcode": "+            )"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 210,
                "PatchRowcode": "+            return dm.root_dag_id or dm.dag_id"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 211,
                "PatchRowcode": "+        return dag_id"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 212,
                "PatchRowcode": "+"
            },
            "13": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": 213,
                "PatchRowcode": "     def init_role(self, role_name, perms):"
            },
            "14": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": 214,
                "PatchRowcode": "         \"\"\""
            },
            "15": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": 215,
                "PatchRowcode": "         Initialize the role with actions and related resources."
            },
            "16": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": 350,
                "PatchRowcode": "     def can_access_some_dags(self, action: str, dag_id: Optional[str] = None) -> bool:"
            },
            "17": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": 351,
                "PatchRowcode": "         \"\"\"Checks if user has read or write access to some dags.\"\"\""
            },
            "18": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 352,
                "PatchRowcode": "         if dag_id and dag_id != '~':"
            },
            "19": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            return self.has_access(action, permissions.resource_name_for_dag(dag_id))"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+            root_dag_id = self._get_root_dag_id(dag_id)"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+            return self.has_access(action, permissions.resource_name_for_dag(root_dag_id))"
            },
            "22": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": 355,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": 356,
                "PatchRowcode": "         user = g.user"
            },
            "24": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": 357,
                "PatchRowcode": "         if action == permissions.ACTION_CAN_READ:"
            },
            "25": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": 360,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": 361,
                "PatchRowcode": "     def can_read_dag(self, dag_id, user=None) -> bool:"
            },
            "27": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": 362,
                "PatchRowcode": "         \"\"\"Determines whether a user has DAG read access.\"\"\""
            },
            "28": {
                "beforePatchRowNumber": 352,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        dag_resource_name = permissions.resource_name_for_dag(dag_id)"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+        root_dag_id = self._get_root_dag_id(dag_id)"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+        dag_resource_name = permissions.resource_name_for_dag(root_dag_id)"
            },
            "31": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": 365,
                "PatchRowcode": "         return self.has_access(permissions.ACTION_CAN_READ, dag_resource_name, user=user)"
            },
            "32": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 366,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": 367,
                "PatchRowcode": "     def can_edit_dag(self, dag_id, user=None) -> bool:"
            },
            "34": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": 368,
                "PatchRowcode": "         \"\"\"Determines whether a user has DAG edit access.\"\"\""
            },
            "35": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        dag_resource_name = permissions.resource_name_for_dag(dag_id)"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+        root_dag_id = self._get_root_dag_id(dag_id)"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+        dag_resource_name = permissions.resource_name_for_dag(root_dag_id)"
            },
            "38": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 371,
                "PatchRowcode": "         return self.has_access(permissions.ACTION_CAN_EDIT, dag_resource_name, user=user)"
            },
            "39": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": 372,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": 360,
                "afterPatchRowNumber": 373,
                "PatchRowcode": "     def can_delete_dag(self, dag_id, user=None) -> bool:"
            },
            "41": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": 374,
                "PatchRowcode": "         \"\"\"Determines whether a user has DAG delete access.\"\"\""
            },
            "42": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        dag_resource_name = permissions.resource_name_for_dag(dag_id)"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 375,
                "PatchRowcode": "+        root_dag_id = self._get_root_dag_id(dag_id)"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 376,
                "PatchRowcode": "+        dag_resource_name = permissions.resource_name_for_dag(root_dag_id)"
            },
            "45": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": 377,
                "PatchRowcode": "         return self.has_access(permissions.ACTION_CAN_DELETE, dag_resource_name, user=user)"
            },
            "46": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": 378,
                "PatchRowcode": " "
            },
            "47": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": 379,
                "PatchRowcode": "     def prefixed_dag_id(self, dag_id):"
            },
            "48": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "             DeprecationWarning,"
            },
            "49": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "             stacklevel=2,"
            },
            "50": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "         )"
            },
            "51": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        return permissions.resource_name_for_dag(dag_id)"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 387,
                "PatchRowcode": "+        root_dag_id = self._get_root_dag_id(dag_id)"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 388,
                "PatchRowcode": "+        return permissions.resource_name_for_dag(root_dag_id)"
            },
            "54": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": 389,
                "PatchRowcode": " "
            },
            "55": {
                "beforePatchRowNumber": 375,
                "afterPatchRowNumber": 390,
                "PatchRowcode": "     def is_dag_resource(self, resource_name):"
            },
            "56": {
                "beforePatchRowNumber": 376,
                "afterPatchRowNumber": 391,
                "PatchRowcode": "         \"\"\"Determines if a resource belongs to a DAG or all DAGs.\"\"\""
            },
            "57": {
                "beforePatchRowNumber": 530,
                "afterPatchRowNumber": 545,
                "PatchRowcode": "         dags = dagbag.dags.values()"
            },
            "58": {
                "beforePatchRowNumber": 531,
                "afterPatchRowNumber": 546,
                "PatchRowcode": " "
            },
            "59": {
                "beforePatchRowNumber": 532,
                "afterPatchRowNumber": 547,
                "PatchRowcode": "         for dag in dags:"
            },
            "60": {
                "beforePatchRowNumber": 533,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            dag_resource_name = permissions.resource_name_for_dag(dag.dag_id)"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 548,
                "PatchRowcode": "+            root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 549,
                "PatchRowcode": "+            dag_resource_name = permissions.resource_name_for_dag(root_dag_id)"
            },
            "63": {
                "beforePatchRowNumber": 534,
                "afterPatchRowNumber": 550,
                "PatchRowcode": "             for action_name in self.DAG_ACTIONS:"
            },
            "64": {
                "beforePatchRowNumber": 535,
                "afterPatchRowNumber": 551,
                "PatchRowcode": "                 if (action_name, dag_resource_name) not in perms:"
            },
            "65": {
                "beforePatchRowNumber": 536,
                "afterPatchRowNumber": 552,
                "PatchRowcode": "                     self._merge_perm(action_name, dag_resource_name)"
            },
            "66": {
                "beforePatchRowNumber": 615,
                "afterPatchRowNumber": 631,
                "PatchRowcode": "         :param access_control: a dict where each key is a rolename and"
            },
            "67": {
                "beforePatchRowNumber": 616,
                "afterPatchRowNumber": 632,
                "PatchRowcode": "             each value is a set() of action names (e.g. {'can_read'})"
            },
            "68": {
                "beforePatchRowNumber": 617,
                "afterPatchRowNumber": 633,
                "PatchRowcode": "         \"\"\""
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 634,
                "PatchRowcode": "+"
            },
            "70": {
                "beforePatchRowNumber": 618,
                "afterPatchRowNumber": 635,
                "PatchRowcode": "         dag_resource_name = permissions.resource_name_for_dag(dag_id)"
            },
            "71": {
                "beforePatchRowNumber": 619,
                "afterPatchRowNumber": 636,
                "PatchRowcode": " "
            },
            "72": {
                "beforePatchRowNumber": 620,
                "afterPatchRowNumber": 637,
                "PatchRowcode": "         def _get_or_create_dag_permission(action_name: str) -> Optional[Permission]:"
            }
        },
        "frontPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "#",
            "",
            "import warnings",
            "from typing import Dict, Optional, Sequence, Set, Tuple",
            "",
            "from flask import g",
            "from sqlalchemy import or_",
            "from sqlalchemy.orm import joinedload",
            "",
            "from airflow.exceptions import AirflowException",
            "from airflow.models import DagBag, DagModel",
            "from airflow.security import permissions",
            "from airflow.utils.log.logging_mixin import LoggingMixin",
            "from airflow.utils.session import provide_session",
            "from airflow.www.fab_security.sqla.manager import SecurityManager",
            "from airflow.www.fab_security.sqla.models import Permission, Resource, Role, User",
            "from airflow.www.utils import CustomSQLAInterface",
            "from airflow.www.views import (",
            "    ActionModelView,",
            "    CustomResetMyPasswordView,",
            "    CustomResetPasswordView,",
            "    CustomRoleModelView,",
            "    CustomUserDBModelView,",
            "    CustomUserInfoEditView,",
            "    CustomUserLDAPModelView,",
            "    CustomUserOAuthModelView,",
            "    CustomUserOIDModelView,",
            "    CustomUserRemoteUserModelView,",
            "    CustomUserStatsChartView,",
            "    PermissionPairModelView,",
            "    ResourceModelView,",
            ")",
            "",
            "EXISTING_ROLES = {",
            "    'Admin',",
            "    'Viewer',",
            "    'User',",
            "    'Op',",
            "    'Public',",
            "}",
            "",
            "",
            "class AirflowSecurityManager(SecurityManager, LoggingMixin):",
            "    \"\"\"Custom security manager, which introduces a permission model adapted to Airflow\"\"\"",
            "",
            "    ###########################################################################",
            "    #                               PERMISSIONS",
            "    ###########################################################################",
            "",
            "    # [START security_viewer_perms]",
            "    VIEWER_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_AUDIT_LOG),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_DEPENDENCIES),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_CODE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_IMPORT_ERROR),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_JOB),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_MY_PASSWORD),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_MY_PASSWORD),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_MY_PROFILE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_MY_PROFILE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_PLUGIN),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_SLA_MISS),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_LOG),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_XCOM),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_BROWSE_MENU),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DAG_DEPENDENCIES),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DOCS),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DOCS_MENU),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_JOB),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_AUDIT_LOG),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_PLUGIN),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_SLA_MISS),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_TASK_INSTANCE),",
            "    ]",
            "    # [END security_viewer_perms]",
            "",
            "    # [START security_user_perms]",
            "    USER_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG_RUN),",
            "    ]",
            "    # [END security_user_perms]",
            "",
            "    # [START security_op_perms]",
            "    OP_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_CONFIG),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_ADMIN_MENU),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_CONFIG),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_XCOM),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_PROVIDER),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_XCOM),",
            "    ]",
            "    # [END security_op_perms]",
            "",
            "    ADMIN_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_RESCHEDULE),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_TASK_RESCHEDULE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TRIGGER),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_TRIGGER),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_PASSWORD),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_PASSWORD),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_ROLE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_ROLE),",
            "    ]",
            "",
            "    # global resource for dag-level access",
            "    DAG_RESOURCES = {permissions.RESOURCE_DAG}",
            "    DAG_ACTIONS = permissions.DAG_ACTIONS",
            "",
            "    ###########################################################################",
            "    #                     DEFAULT ROLE CONFIGURATIONS",
            "    ###########################################################################",
            "",
            "    ROLE_CONFIGS = [",
            "        {'role': 'Public', 'perms': []},",
            "        {'role': 'Viewer', 'perms': VIEWER_PERMISSIONS},",
            "        {",
            "            'role': 'User',",
            "            'perms': VIEWER_PERMISSIONS + USER_PERMISSIONS,",
            "        },",
            "        {",
            "            'role': 'Op',",
            "            'perms': VIEWER_PERMISSIONS + USER_PERMISSIONS + OP_PERMISSIONS,",
            "        },",
            "        {",
            "            'role': 'Admin',",
            "            'perms': VIEWER_PERMISSIONS + USER_PERMISSIONS + OP_PERMISSIONS + ADMIN_PERMISSIONS,",
            "        },",
            "    ]",
            "",
            "    actionmodelview = ActionModelView",
            "    permissionmodelview = PermissionPairModelView",
            "    rolemodelview = CustomRoleModelView",
            "    resourcemodelview = ResourceModelView",
            "    userdbmodelview = CustomUserDBModelView",
            "    resetmypasswordview = CustomResetMyPasswordView",
            "    resetpasswordview = CustomResetPasswordView",
            "    userinfoeditview = CustomUserInfoEditView",
            "    userldapmodelview = CustomUserLDAPModelView",
            "    useroauthmodelview = CustomUserOAuthModelView",
            "    userremoteusermodelview = CustomUserRemoteUserModelView",
            "    useroidmodelview = CustomUserOIDModelView",
            "    userstatschartview = CustomUserStatsChartView",
            "",
            "    def __init__(self, appbuilder):",
            "        super().__init__(appbuilder)",
            "",
            "        # Go and fix up the SQLAInterface used from the stock one to our subclass.",
            "        # This is needed to support the \"hack\" where we had to edit",
            "        # FieldConverter.conversion_table in place in airflow.www.utils",
            "        for attr in dir(self):",
            "            if not attr.endswith('view'):",
            "                continue",
            "            view = getattr(self, attr, None)",
            "            if not view or not getattr(view, 'datamodel', None):",
            "                continue",
            "            view.datamodel = CustomSQLAInterface(view.datamodel.obj)",
            "        self.perms = None",
            "",
            "    def init_role(self, role_name, perms):",
            "        \"\"\"",
            "        Initialize the role with actions and related resources.",
            "        :param role_name:",
            "        :param perms:",
            "        :return:",
            "        \"\"\"",
            "        warnings.warn(",
            "            \"`init_role` has been deprecated. Please use `bulk_sync_roles` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        self.bulk_sync_roles([{'role': role_name, 'perms': perms}])",
            "",
            "    def bulk_sync_roles(self, roles):",
            "        \"\"\"Sync the provided roles and permissions.\"\"\"",
            "        existing_roles = self._get_all_roles_with_permissions()",
            "        non_dag_perms = self._get_all_non_dag_permissions()",
            "",
            "        for config in roles:",
            "            role_name = config['role']",
            "            perms = config['perms']",
            "            role = existing_roles.get(role_name) or self.add_role(role_name)",
            "",
            "            for action_name, resource_name in perms:",
            "                perm = non_dag_perms.get((action_name, resource_name)) or self.create_permission(",
            "                    action_name, resource_name",
            "                )",
            "",
            "                if perm not in role.permissions:",
            "                    self.add_permission_to_role(role, perm)",
            "",
            "    def delete_role(self, role_name):",
            "        \"\"\"",
            "        Delete the given Role",
            "",
            "        :param role_name: the name of a role in the ab_role table",
            "        \"\"\"",
            "        session = self.get_session",
            "        role = session.query(Role).filter(Role.name == role_name).first()",
            "        if role:",
            "            self.log.info(\"Deleting role '%s'\", role_name)",
            "            session.delete(role)",
            "            session.commit()",
            "        else:",
            "            raise AirflowException(f\"Role named '{role_name}' does not exist\")",
            "",
            "    @staticmethod",
            "    def get_user_roles(user=None):",
            "        \"\"\"",
            "        Get all the roles associated with the user.",
            "",
            "        :param user: the ab_user in FAB model.",
            "        :return: a list of roles associated with the user.",
            "        \"\"\"",
            "        if user is None:",
            "            user = g.user",
            "        return user.roles",
            "",
            "    def get_readable_dags(self, user):",
            "        \"\"\"Gets the DAGs readable by authenticated user.\"\"\"",
            "        warnings.warn(",
            "            \"`get_readable_dags` has been deprecated. Please use `get_readable_dag_ids` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        with warnings.catch_warnings():",
            "            warnings.simplefilter(\"ignore\", DeprecationWarning)",
            "            return self.get_accessible_dags([permissions.ACTION_CAN_READ], user)",
            "",
            "    def get_editable_dags(self, user):",
            "        \"\"\"Gets the DAGs editable by authenticated user.\"\"\"",
            "        warnings.warn(",
            "            \"`get_editable_dags` has been deprecated. Please use `get_editable_dag_ids` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        with warnings.catch_warnings():",
            "            warnings.simplefilter(\"ignore\", DeprecationWarning)",
            "            return self.get_accessible_dags([permissions.ACTION_CAN_EDIT], user)",
            "",
            "    @provide_session",
            "    def get_accessible_dags(self, user_actions, user, session=None):",
            "        warnings.warn(",
            "            \"`get_accessible_dags` has been deprecated. Please use `get_accessible_dag_ids` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=3,",
            "        )",
            "        dag_ids = self.get_accessible_dag_ids(user, user_actions, session)",
            "        return session.query(DagModel).filter(DagModel.dag_id.in_(dag_ids))",
            "",
            "    def get_readable_dag_ids(self, user) -> Set[str]:",
            "        \"\"\"Gets the DAG IDs readable by authenticated user.\"\"\"",
            "        return self.get_accessible_dag_ids(user, [permissions.ACTION_CAN_READ])",
            "",
            "    def get_editable_dag_ids(self, user) -> Set[str]:",
            "        \"\"\"Gets the DAG IDs editable by authenticated user.\"\"\"",
            "        return self.get_accessible_dag_ids(user, [permissions.ACTION_CAN_EDIT])",
            "",
            "    @provide_session",
            "    def get_accessible_dag_ids(self, user, user_actions=None, session=None) -> Set[str]:",
            "        \"\"\"Generic function to get readable or writable DAGs for user.\"\"\"",
            "        if not user_actions:",
            "            user_actions = [permissions.ACTION_CAN_EDIT, permissions.ACTION_CAN_READ]",
            "",
            "        if user.is_anonymous:",
            "            roles = user.roles",
            "        else:",
            "            user_query = (",
            "                session.query(User)",
            "                .options(",
            "                    joinedload(User.roles)",
            "                    .subqueryload(Role.permissions)",
            "                    .options(joinedload(Permission.action), joinedload(Permission.resource))",
            "                )",
            "                .filter(User.id == user.id)",
            "                .first()",
            "            )",
            "            roles = user_query.roles",
            "",
            "        resources = set()",
            "        for role in roles:",
            "            for permission in role.permissions:",
            "                action = permission.action.name",
            "                if action not in user_actions:",
            "                    continue",
            "",
            "                resource = permission.resource.name",
            "                if resource == permissions.RESOURCE_DAG:",
            "                    return {dag.dag_id for dag in session.query(DagModel.dag_id)}",
            "",
            "                if resource.startswith(permissions.RESOURCE_DAG_PREFIX):",
            "                    resources.add(resource[len(permissions.RESOURCE_DAG_PREFIX) :])",
            "                else:",
            "                    resources.add(resource)",
            "        return {dag.dag_id for dag in session.query(DagModel.dag_id).filter(DagModel.dag_id.in_(resources))}",
            "",
            "    def can_access_some_dags(self, action: str, dag_id: Optional[str] = None) -> bool:",
            "        \"\"\"Checks if user has read or write access to some dags.\"\"\"",
            "        if dag_id and dag_id != '~':",
            "            return self.has_access(action, permissions.resource_name_for_dag(dag_id))",
            "",
            "        user = g.user",
            "        if action == permissions.ACTION_CAN_READ:",
            "            return any(self.get_readable_dag_ids(user))",
            "        return any(self.get_editable_dag_ids(user))",
            "",
            "    def can_read_dag(self, dag_id, user=None) -> bool:",
            "        \"\"\"Determines whether a user has DAG read access.\"\"\"",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "        return self.has_access(permissions.ACTION_CAN_READ, dag_resource_name, user=user)",
            "",
            "    def can_edit_dag(self, dag_id, user=None) -> bool:",
            "        \"\"\"Determines whether a user has DAG edit access.\"\"\"",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "        return self.has_access(permissions.ACTION_CAN_EDIT, dag_resource_name, user=user)",
            "",
            "    def can_delete_dag(self, dag_id, user=None) -> bool:",
            "        \"\"\"Determines whether a user has DAG delete access.\"\"\"",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "        return self.has_access(permissions.ACTION_CAN_DELETE, dag_resource_name, user=user)",
            "",
            "    def prefixed_dag_id(self, dag_id):",
            "        \"\"\"Returns the permission name for a DAG id.\"\"\"",
            "        warnings.warn(",
            "            \"`prefixed_dag_id` has been deprecated. \"",
            "            \"Please use `airflow.security.permissions.resource_name_for_dag` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        return permissions.resource_name_for_dag(dag_id)",
            "",
            "    def is_dag_resource(self, resource_name):",
            "        \"\"\"Determines if a resource belongs to a DAG or all DAGs.\"\"\"",
            "        if resource_name == permissions.RESOURCE_DAG:",
            "            return True",
            "        return resource_name.startswith(permissions.RESOURCE_DAG_PREFIX)",
            "",
            "    def has_access(self, action_name, resource_name, user=None) -> bool:",
            "        \"\"\"",
            "        Verify whether a given user could perform a certain action",
            "        (e.g can_read, can_write, can_delete) on the given resource.",
            "",
            "        :param action_name: action_name on resource (e.g can_read, can_edit).",
            "        :param resource_name: name of view-menu or resource.",
            "        :param user: user name",
            "        :return: Whether user could perform certain action on the resource.",
            "        :rtype bool",
            "        \"\"\"",
            "        if not user:",
            "            user = g.user",
            "        if (action_name, resource_name) in user.perms:",
            "            return True",
            "",
            "        if self.is_dag_resource(resource_name):",
            "            if (action_name, permissions.RESOURCE_DAG) in user.perms:",
            "                return True",
            "            return (action_name, resource_name) in user.perms",
            "",
            "        return False",
            "",
            "    def _has_role(self, role_name_or_list, user):",
            "        \"\"\"Whether the user has this role name\"\"\"",
            "        if not isinstance(role_name_or_list, list):",
            "            role_name_or_list = [role_name_or_list]",
            "        return any(r.name in role_name_or_list for r in user.roles)",
            "",
            "    def has_all_dags_access(self, user):",
            "        \"\"\"",
            "        Has all the dag access in any of the 3 cases:",
            "        1. Role needs to be in (Admin, Viewer, User, Op).",
            "        2. Has can_read action on dags resource.",
            "        3. Has can_edit action on dags resource.",
            "        \"\"\"",
            "        if not user:",
            "            user = g.user",
            "        return (",
            "            self._has_role(['Admin', 'Viewer', 'Op', 'User'], user)",
            "            or self.has_access(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG, user)",
            "            or self.has_access(permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG, user)",
            "        )",
            "",
            "    def clean_perms(self):",
            "        \"\"\"FAB leaves faulty permissions that need to be cleaned up\"\"\"",
            "        self.log.debug('Cleaning faulty perms')",
            "        sesh = self.get_session",
            "        perms = sesh.query(Permission).filter(",
            "            or_(",
            "                Permission.action == None,  # noqa",
            "                Permission.resource == None,  # noqa",
            "            )",
            "        )",
            "        # Since FAB doesn't define ON DELETE CASCADE on these tables, we need",
            "        # to delete the _object_ so that SQLA knows to delete the many-to-many",
            "        # relationship object too. :(",
            "",
            "        deleted_count = 0",
            "        for perm in perms:",
            "            sesh.delete(perm)",
            "            deleted_count += 1",
            "        sesh.commit()",
            "        if deleted_count:",
            "            self.log.info('Deleted %s faulty permissions', deleted_count)",
            "",
            "    def _merge_perm(self, action_name, resource_name):",
            "        \"\"\"",
            "        Add the new (action, resource) to assoc_permission_role if it doesn't exist.",
            "        It will add the related entry to ab_permission and ab_resource two meta tables as well.",
            "",
            "        :param action_name: Name of the action",
            "        :param resource_name: Name of the resource",
            "        :return:",
            "        \"\"\"",
            "        action = self.get_action(action_name)",
            "        resource = self.get_resource(resource_name)",
            "        perm = None",
            "        if action and resource:",
            "            perm = (",
            "                self.get_session.query(self.permission_model)",
            "                .filter_by(action=action, resource=resource)",
            "                .first()",
            "            )",
            "        if not perm and action_name and resource_name:",
            "            self.create_permission(action_name, resource_name)",
            "",
            "    def add_homepage_access_to_custom_roles(self):",
            "        \"\"\"",
            "        Add Website.can_read access to all custom roles.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        website_permission = self.create_permission(permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE)",
            "        custom_roles = [role for role in self.get_all_roles() if role.name not in EXISTING_ROLES]",
            "        for role in custom_roles:",
            "            self.add_permission_to_role(role, website_permission)",
            "",
            "        self.get_session.commit()",
            "",
            "    def get_all_permissions(self) -> Set[Tuple[str, str]]:",
            "        \"\"\"Returns all permissions as a set of tuples with the action and resource names\"\"\"",
            "        return set(",
            "            self.get_session.query(self.permission_model)",
            "            .join(self.permission_model.action)",
            "            .join(self.permission_model.resource)",
            "            .with_entities(self.action_model.name, self.resource_model.name)",
            "            .all()",
            "        )",
            "",
            "    def _get_all_non_dag_permissions(self) -> Dict[Tuple[str, str], Permission]:",
            "        \"\"\"",
            "        Returns a dict with a key of (action_name, resource_name) and value of permission",
            "        with all permissions except those that are for specific DAGs.",
            "        \"\"\"",
            "        return {",
            "            (action_name, resource_name): viewmodel",
            "            for action_name, resource_name, viewmodel in (",
            "                self.get_session.query(self.permission_model)",
            "                .join(self.permission_model.action)",
            "                .join(self.permission_model.resource)",
            "                .filter(~self.resource_model.name.like(f\"{permissions.RESOURCE_DAG_PREFIX}%\"))",
            "                .with_entities(self.action_model.name, self.resource_model.name, self.permission_model)",
            "                .all()",
            "            )",
            "        }",
            "",
            "    def _get_all_roles_with_permissions(self) -> Dict[str, Role]:",
            "        \"\"\"Returns a dict with a key of role name and value of role with early loaded permissions\"\"\"",
            "        return {",
            "            r.name: r",
            "            for r in (",
            "                self.get_session.query(self.role_model).options(joinedload(self.role_model.permissions)).all()",
            "            )",
            "        }",
            "",
            "    def create_dag_specific_permissions(self) -> None:",
            "        \"\"\"",
            "        Creates 'can_read', 'can_edit', and 'can_delete' permissions for all",
            "        DAGs, along with any `access_control` permissions provided in them.",
            "",
            "        This does iterate through ALL the DAGs, which can be slow. See `sync_perm_for_dag`",
            "        if you only need to sync a single DAG.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        perms = self.get_all_permissions()",
            "        dagbag = DagBag(read_dags_from_db=True)",
            "        dagbag.collect_dags_from_db()",
            "        dags = dagbag.dags.values()",
            "",
            "        for dag in dags:",
            "            dag_resource_name = permissions.resource_name_for_dag(dag.dag_id)",
            "            for action_name in self.DAG_ACTIONS:",
            "                if (action_name, dag_resource_name) not in perms:",
            "                    self._merge_perm(action_name, dag_resource_name)",
            "",
            "            if dag.access_control:",
            "                self.sync_perm_for_dag(dag_resource_name, dag.access_control)",
            "",
            "    def update_admin_permission(self):",
            "        \"\"\"",
            "        Admin should have all the permissions, except the dag permissions.",
            "        because Admin already has Dags permission.",
            "        Add the missing ones to the table for admin.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        dag_resources = (",
            "            self.get_session.query(Resource)",
            "            .filter(Resource.name.like(f\"{permissions.RESOURCE_DAG_PREFIX}%\"))",
            "            .all()",
            "        )",
            "        resource_ids = [resource.id for resource in dag_resources]",
            "        perms = self.get_session.query(Permission).filter(~Permission.resource_id.in_(resource_ids)).all()",
            "",
            "        perms = [p for p in perms if p.action and p.resource]",
            "",
            "        admin = self.find_role('Admin')",
            "        admin.permissions = list(set(admin.permissions) | set(perms))",
            "",
            "        self.get_session.commit()",
            "",
            "    def sync_roles(self):",
            "        \"\"\"",
            "        1. Init the default role(Admin, Viewer, User, Op, public)",
            "           with related permissions.",
            "        2. Init the custom role(dag-user) with related permissions.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        # Create global all-dag permissions",
            "        self.create_perm_vm_for_all_dag()",
            "",
            "        # Sync the default roles (Admin, Viewer, User, Op, public) with related permissions",
            "        self.bulk_sync_roles(self.ROLE_CONFIGS)",
            "",
            "        self.add_homepage_access_to_custom_roles()",
            "        # init existing roles, the rest role could be created through UI.",
            "        self.update_admin_permission()",
            "        self.clean_perms()",
            "",
            "    def sync_resource_permissions(self, perms=None):",
            "        \"\"\"Populates resource-based permissions.\"\"\"",
            "        if not perms:",
            "            return",
            "",
            "        for action_name, resource_name in perms:",
            "            self.create_resource(resource_name)",
            "            self.create_permission(action_name, resource_name)",
            "",
            "    def sync_perm_for_dag(self, dag_id, access_control=None):",
            "        \"\"\"",
            "        Sync permissions for given dag id. The dag id surely exists in our dag bag",
            "        as only / refresh button or DagBag will call this function",
            "",
            "        :param dag_id: the ID of the DAG whose permissions should be updated",
            "        :param access_control: a dict where each key is a rolename and",
            "            each value is a set() of action names (e.g.,",
            "            {'can_read'}",
            "        :return:",
            "        \"\"\"",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "        for dag_action_name in self.DAG_ACTIONS:",
            "            self.create_permission(dag_action_name, dag_resource_name)",
            "",
            "        if access_control:",
            "            self._sync_dag_view_permissions(dag_resource_name, access_control)",
            "",
            "    def _sync_dag_view_permissions(self, dag_id, access_control):",
            "        \"\"\"",
            "        Set the access policy on the given DAG's ViewModel.",
            "",
            "        :param dag_id: the ID of the DAG whose permissions should be updated",
            "        :param access_control: a dict where each key is a rolename and",
            "            each value is a set() of action names (e.g. {'can_read'})",
            "        \"\"\"",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "",
            "        def _get_or_create_dag_permission(action_name: str) -> Optional[Permission]:",
            "            perm = self.get_permission(action_name, dag_resource_name)",
            "            if not perm:",
            "                self.log.info(\"Creating new action '%s' on resource '%s'\", action_name, dag_resource_name)",
            "                perm = self.create_permission(action_name, dag_resource_name)",
            "",
            "            return perm",
            "",
            "        def _revoke_stale_permissions(resource: Resource):",
            "            existing_dag_perms = self.get_resource_permissions(resource)",
            "            for perm in existing_dag_perms:",
            "                non_admin_roles = [role for role in perm.role if role.name != 'Admin']",
            "                for role in non_admin_roles:",
            "                    target_perms_for_role = access_control.get(role.name, {})",
            "                    if perm.action.name not in target_perms_for_role:",
            "                        self.log.info(",
            "                            \"Revoking '%s' on DAG '%s' for role '%s'\",",
            "                            perm.action,",
            "                            dag_resource_name,",
            "                            role.name,",
            "                        )",
            "                        self.remove_permission_from_role(role, perm)",
            "",
            "        resource = self.get_resource(dag_resource_name)",
            "        if resource:",
            "            _revoke_stale_permissions(resource)",
            "",
            "        for rolename, action_names in access_control.items():",
            "            role = self.find_role(rolename)",
            "            if not role:",
            "                raise AirflowException(",
            "                    f\"The access_control mapping for DAG '{dag_id}' includes a role named \"",
            "                    f\"'{rolename}', but that role does not exist\"",
            "                )",
            "",
            "            action_names = set(action_names)",
            "            invalid_action_names = action_names - self.DAG_ACTIONS",
            "            if invalid_action_names:",
            "                raise AirflowException(",
            "                    f\"The access_control map for DAG '{dag_resource_name}' includes \"",
            "                    f\"the following invalid permissions: {invalid_action_names}; \"",
            "                    f\"The set of valid permissions is: {self.DAG_ACTIONS}\"",
            "                )",
            "",
            "            for action_name in action_names:",
            "                dag_perm = _get_or_create_dag_permission(action_name)",
            "                if dag_perm:",
            "                    self.add_permission_to_role(role, dag_perm)",
            "",
            "    def create_perm_vm_for_all_dag(self):",
            "        \"\"\"Create perm-vm if not exist and insert into FAB security model for all-dags.\"\"\"",
            "        # create perm for global logical dag",
            "        for resource_name in self.DAG_RESOURCES:",
            "            for action_name in self.DAG_ACTIONS:",
            "                self._merge_perm(action_name, resource_name)",
            "",
            "    def check_authorization(",
            "        self, perms: Optional[Sequence[Tuple[str, str]]] = None, dag_id: Optional[str] = None",
            "    ) -> bool:",
            "        \"\"\"Checks that the logged in user has the specified permissions.\"\"\"",
            "        if not perms:",
            "            return True",
            "",
            "        for perm in perms:",
            "            if perm in (",
            "                (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
            "                (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG),",
            "                (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG),",
            "            ):",
            "                can_access_all_dags = self.has_access(*perm)",
            "                if can_access_all_dags:",
            "                    continue",
            "",
            "                action = perm[0]",
            "                if self.can_access_some_dags(action, dag_id):",
            "                    continue",
            "                return False",
            "",
            "            elif not self.has_access(*perm):",
            "                return False",
            "",
            "        return True",
            "",
            "",
            "class ApplessAirflowSecurityManager(AirflowSecurityManager):",
            "    \"\"\"Security Manager that doesn't need the whole flask app\"\"\"",
            "",
            "    def __init__(self, session=None):",
            "        self.session = session",
            "",
            "    @property",
            "    def get_session(self):",
            "        return self.session"
        ],
        "afterPatchFile": [
            "#",
            "# Licensed to the Apache Software Foundation (ASF) under one",
            "# or more contributor license agreements.  See the NOTICE file",
            "# distributed with this work for additional information",
            "# regarding copyright ownership.  The ASF licenses this file",
            "# to you under the Apache License, Version 2.0 (the",
            "# \"License\"); you may not use this file except in compliance",
            "# with the License.  You may obtain a copy of the License at",
            "#",
            "#   http://www.apache.org/licenses/LICENSE-2.0",
            "#",
            "# Unless required by applicable law or agreed to in writing,",
            "# software distributed under the License is distributed on an",
            "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
            "# KIND, either express or implied.  See the License for the",
            "# specific language governing permissions and limitations",
            "# under the License.",
            "#",
            "",
            "import warnings",
            "from typing import Dict, Optional, Sequence, Set, Tuple",
            "",
            "from flask import g",
            "from sqlalchemy import or_",
            "from sqlalchemy.orm import joinedload",
            "",
            "from airflow.exceptions import AirflowException",
            "from airflow.models import DagBag, DagModel",
            "from airflow.security import permissions",
            "from airflow.utils.log.logging_mixin import LoggingMixin",
            "from airflow.utils.session import provide_session",
            "from airflow.www.fab_security.sqla.manager import SecurityManager",
            "from airflow.www.fab_security.sqla.models import Permission, Resource, Role, User",
            "from airflow.www.utils import CustomSQLAInterface",
            "from airflow.www.views import (",
            "    ActionModelView,",
            "    CustomResetMyPasswordView,",
            "    CustomResetPasswordView,",
            "    CustomRoleModelView,",
            "    CustomUserDBModelView,",
            "    CustomUserInfoEditView,",
            "    CustomUserLDAPModelView,",
            "    CustomUserOAuthModelView,",
            "    CustomUserOIDModelView,",
            "    CustomUserRemoteUserModelView,",
            "    CustomUserStatsChartView,",
            "    PermissionPairModelView,",
            "    ResourceModelView,",
            ")",
            "",
            "EXISTING_ROLES = {",
            "    'Admin',",
            "    'Viewer',",
            "    'User',",
            "    'Op',",
            "    'Public',",
            "}",
            "",
            "",
            "class AirflowSecurityManager(SecurityManager, LoggingMixin):",
            "    \"\"\"Custom security manager, which introduces a permission model adapted to Airflow\"\"\"",
            "",
            "    ###########################################################################",
            "    #                               PERMISSIONS",
            "    ###########################################################################",
            "",
            "    # [START security_viewer_perms]",
            "    VIEWER_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_AUDIT_LOG),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_DEPENDENCIES),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_CODE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_IMPORT_ERROR),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_JOB),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_MY_PASSWORD),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_MY_PASSWORD),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_MY_PROFILE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_MY_PROFILE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_PLUGIN),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_SLA_MISS),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_LOG),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_XCOM),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_BROWSE_MENU),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DAG_DEPENDENCIES),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DOCS),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_DOCS_MENU),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_JOB),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_AUDIT_LOG),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_PLUGIN),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_SLA_MISS),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_TASK_INSTANCE),",
            "    ]",
            "    # [END security_viewer_perms]",
            "",
            "    # [START security_user_perms]",
            "    USER_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_TASK_INSTANCE),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG_RUN),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG_RUN),",
            "    ]",
            "    # [END security_user_perms]",
            "",
            "    # [START security_op_perms]",
            "    OP_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_CONFIG),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_ADMIN_MENU),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_CONFIG),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_XCOM),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_CONNECTION),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_POOL),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_PROVIDER),",
            "        (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_VARIABLE),",
            "        (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_XCOM),",
            "    ]",
            "    # [END security_op_perms]",
            "",
            "    ADMIN_PERMISSIONS = [",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TASK_RESCHEDULE),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_TASK_RESCHEDULE),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_TRIGGER),",
            "        (permissions.ACTION_CAN_ACCESS_MENU, permissions.RESOURCE_TRIGGER),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_PASSWORD),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_PASSWORD),",
            "        (permissions.ACTION_CAN_READ, permissions.RESOURCE_ROLE),",
            "        (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_ROLE),",
            "    ]",
            "",
            "    # global resource for dag-level access",
            "    DAG_RESOURCES = {permissions.RESOURCE_DAG}",
            "    DAG_ACTIONS = permissions.DAG_ACTIONS",
            "",
            "    ###########################################################################",
            "    #                     DEFAULT ROLE CONFIGURATIONS",
            "    ###########################################################################",
            "",
            "    ROLE_CONFIGS = [",
            "        {'role': 'Public', 'perms': []},",
            "        {'role': 'Viewer', 'perms': VIEWER_PERMISSIONS},",
            "        {",
            "            'role': 'User',",
            "            'perms': VIEWER_PERMISSIONS + USER_PERMISSIONS,",
            "        },",
            "        {",
            "            'role': 'Op',",
            "            'perms': VIEWER_PERMISSIONS + USER_PERMISSIONS + OP_PERMISSIONS,",
            "        },",
            "        {",
            "            'role': 'Admin',",
            "            'perms': VIEWER_PERMISSIONS + USER_PERMISSIONS + OP_PERMISSIONS + ADMIN_PERMISSIONS,",
            "        },",
            "    ]",
            "",
            "    actionmodelview = ActionModelView",
            "    permissionmodelview = PermissionPairModelView",
            "    rolemodelview = CustomRoleModelView",
            "    resourcemodelview = ResourceModelView",
            "    userdbmodelview = CustomUserDBModelView",
            "    resetmypasswordview = CustomResetMyPasswordView",
            "    resetpasswordview = CustomResetPasswordView",
            "    userinfoeditview = CustomUserInfoEditView",
            "    userldapmodelview = CustomUserLDAPModelView",
            "    useroauthmodelview = CustomUserOAuthModelView",
            "    userremoteusermodelview = CustomUserRemoteUserModelView",
            "    useroidmodelview = CustomUserOIDModelView",
            "    userstatschartview = CustomUserStatsChartView",
            "",
            "    def __init__(self, appbuilder):",
            "        super().__init__(appbuilder)",
            "",
            "        # Go and fix up the SQLAInterface used from the stock one to our subclass.",
            "        # This is needed to support the \"hack\" where we had to edit",
            "        # FieldConverter.conversion_table in place in airflow.www.utils",
            "        for attr in dir(self):",
            "            if not attr.endswith('view'):",
            "                continue",
            "            view = getattr(self, attr, None)",
            "            if not view or not getattr(view, 'datamodel', None):",
            "                continue",
            "            view.datamodel = CustomSQLAInterface(view.datamodel.obj)",
            "        self.perms = None",
            "",
            "    def _get_root_dag_id(self, dag_id):",
            "        if '.' in dag_id:",
            "            dm = (",
            "                self.get_session.query(DagModel.dag_id, DagModel.root_dag_id)",
            "                .filter(DagModel.dag_id == dag_id)",
            "                .first()",
            "            )",
            "            return dm.root_dag_id or dm.dag_id",
            "        return dag_id",
            "",
            "    def init_role(self, role_name, perms):",
            "        \"\"\"",
            "        Initialize the role with actions and related resources.",
            "        :param role_name:",
            "        :param perms:",
            "        :return:",
            "        \"\"\"",
            "        warnings.warn(",
            "            \"`init_role` has been deprecated. Please use `bulk_sync_roles` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        self.bulk_sync_roles([{'role': role_name, 'perms': perms}])",
            "",
            "    def bulk_sync_roles(self, roles):",
            "        \"\"\"Sync the provided roles and permissions.\"\"\"",
            "        existing_roles = self._get_all_roles_with_permissions()",
            "        non_dag_perms = self._get_all_non_dag_permissions()",
            "",
            "        for config in roles:",
            "            role_name = config['role']",
            "            perms = config['perms']",
            "            role = existing_roles.get(role_name) or self.add_role(role_name)",
            "",
            "            for action_name, resource_name in perms:",
            "                perm = non_dag_perms.get((action_name, resource_name)) or self.create_permission(",
            "                    action_name, resource_name",
            "                )",
            "",
            "                if perm not in role.permissions:",
            "                    self.add_permission_to_role(role, perm)",
            "",
            "    def delete_role(self, role_name):",
            "        \"\"\"",
            "        Delete the given Role",
            "",
            "        :param role_name: the name of a role in the ab_role table",
            "        \"\"\"",
            "        session = self.get_session",
            "        role = session.query(Role).filter(Role.name == role_name).first()",
            "        if role:",
            "            self.log.info(\"Deleting role '%s'\", role_name)",
            "            session.delete(role)",
            "            session.commit()",
            "        else:",
            "            raise AirflowException(f\"Role named '{role_name}' does not exist\")",
            "",
            "    @staticmethod",
            "    def get_user_roles(user=None):",
            "        \"\"\"",
            "        Get all the roles associated with the user.",
            "",
            "        :param user: the ab_user in FAB model.",
            "        :return: a list of roles associated with the user.",
            "        \"\"\"",
            "        if user is None:",
            "            user = g.user",
            "        return user.roles",
            "",
            "    def get_readable_dags(self, user):",
            "        \"\"\"Gets the DAGs readable by authenticated user.\"\"\"",
            "        warnings.warn(",
            "            \"`get_readable_dags` has been deprecated. Please use `get_readable_dag_ids` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        with warnings.catch_warnings():",
            "            warnings.simplefilter(\"ignore\", DeprecationWarning)",
            "            return self.get_accessible_dags([permissions.ACTION_CAN_READ], user)",
            "",
            "    def get_editable_dags(self, user):",
            "        \"\"\"Gets the DAGs editable by authenticated user.\"\"\"",
            "        warnings.warn(",
            "            \"`get_editable_dags` has been deprecated. Please use `get_editable_dag_ids` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        with warnings.catch_warnings():",
            "            warnings.simplefilter(\"ignore\", DeprecationWarning)",
            "            return self.get_accessible_dags([permissions.ACTION_CAN_EDIT], user)",
            "",
            "    @provide_session",
            "    def get_accessible_dags(self, user_actions, user, session=None):",
            "        warnings.warn(",
            "            \"`get_accessible_dags` has been deprecated. Please use `get_accessible_dag_ids` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=3,",
            "        )",
            "        dag_ids = self.get_accessible_dag_ids(user, user_actions, session)",
            "        return session.query(DagModel).filter(DagModel.dag_id.in_(dag_ids))",
            "",
            "    def get_readable_dag_ids(self, user) -> Set[str]:",
            "        \"\"\"Gets the DAG IDs readable by authenticated user.\"\"\"",
            "        return self.get_accessible_dag_ids(user, [permissions.ACTION_CAN_READ])",
            "",
            "    def get_editable_dag_ids(self, user) -> Set[str]:",
            "        \"\"\"Gets the DAG IDs editable by authenticated user.\"\"\"",
            "        return self.get_accessible_dag_ids(user, [permissions.ACTION_CAN_EDIT])",
            "",
            "    @provide_session",
            "    def get_accessible_dag_ids(self, user, user_actions=None, session=None) -> Set[str]:",
            "        \"\"\"Generic function to get readable or writable DAGs for user.\"\"\"",
            "        if not user_actions:",
            "            user_actions = [permissions.ACTION_CAN_EDIT, permissions.ACTION_CAN_READ]",
            "",
            "        if user.is_anonymous:",
            "            roles = user.roles",
            "        else:",
            "            user_query = (",
            "                session.query(User)",
            "                .options(",
            "                    joinedload(User.roles)",
            "                    .subqueryload(Role.permissions)",
            "                    .options(joinedload(Permission.action), joinedload(Permission.resource))",
            "                )",
            "                .filter(User.id == user.id)",
            "                .first()",
            "            )",
            "            roles = user_query.roles",
            "",
            "        resources = set()",
            "        for role in roles:",
            "            for permission in role.permissions:",
            "                action = permission.action.name",
            "                if action not in user_actions:",
            "                    continue",
            "",
            "                resource = permission.resource.name",
            "                if resource == permissions.RESOURCE_DAG:",
            "                    return {dag.dag_id for dag in session.query(DagModel.dag_id)}",
            "",
            "                if resource.startswith(permissions.RESOURCE_DAG_PREFIX):",
            "                    resources.add(resource[len(permissions.RESOURCE_DAG_PREFIX) :])",
            "                else:",
            "                    resources.add(resource)",
            "        return {dag.dag_id for dag in session.query(DagModel.dag_id).filter(DagModel.dag_id.in_(resources))}",
            "",
            "    def can_access_some_dags(self, action: str, dag_id: Optional[str] = None) -> bool:",
            "        \"\"\"Checks if user has read or write access to some dags.\"\"\"",
            "        if dag_id and dag_id != '~':",
            "            root_dag_id = self._get_root_dag_id(dag_id)",
            "            return self.has_access(action, permissions.resource_name_for_dag(root_dag_id))",
            "",
            "        user = g.user",
            "        if action == permissions.ACTION_CAN_READ:",
            "            return any(self.get_readable_dag_ids(user))",
            "        return any(self.get_editable_dag_ids(user))",
            "",
            "    def can_read_dag(self, dag_id, user=None) -> bool:",
            "        \"\"\"Determines whether a user has DAG read access.\"\"\"",
            "        root_dag_id = self._get_root_dag_id(dag_id)",
            "        dag_resource_name = permissions.resource_name_for_dag(root_dag_id)",
            "        return self.has_access(permissions.ACTION_CAN_READ, dag_resource_name, user=user)",
            "",
            "    def can_edit_dag(self, dag_id, user=None) -> bool:",
            "        \"\"\"Determines whether a user has DAG edit access.\"\"\"",
            "        root_dag_id = self._get_root_dag_id(dag_id)",
            "        dag_resource_name = permissions.resource_name_for_dag(root_dag_id)",
            "        return self.has_access(permissions.ACTION_CAN_EDIT, dag_resource_name, user=user)",
            "",
            "    def can_delete_dag(self, dag_id, user=None) -> bool:",
            "        \"\"\"Determines whether a user has DAG delete access.\"\"\"",
            "        root_dag_id = self._get_root_dag_id(dag_id)",
            "        dag_resource_name = permissions.resource_name_for_dag(root_dag_id)",
            "        return self.has_access(permissions.ACTION_CAN_DELETE, dag_resource_name, user=user)",
            "",
            "    def prefixed_dag_id(self, dag_id):",
            "        \"\"\"Returns the permission name for a DAG id.\"\"\"",
            "        warnings.warn(",
            "            \"`prefixed_dag_id` has been deprecated. \"",
            "            \"Please use `airflow.security.permissions.resource_name_for_dag` instead.\",",
            "            DeprecationWarning,",
            "            stacklevel=2,",
            "        )",
            "        root_dag_id = self._get_root_dag_id(dag_id)",
            "        return permissions.resource_name_for_dag(root_dag_id)",
            "",
            "    def is_dag_resource(self, resource_name):",
            "        \"\"\"Determines if a resource belongs to a DAG or all DAGs.\"\"\"",
            "        if resource_name == permissions.RESOURCE_DAG:",
            "            return True",
            "        return resource_name.startswith(permissions.RESOURCE_DAG_PREFIX)",
            "",
            "    def has_access(self, action_name, resource_name, user=None) -> bool:",
            "        \"\"\"",
            "        Verify whether a given user could perform a certain action",
            "        (e.g can_read, can_write, can_delete) on the given resource.",
            "",
            "        :param action_name: action_name on resource (e.g can_read, can_edit).",
            "        :param resource_name: name of view-menu or resource.",
            "        :param user: user name",
            "        :return: Whether user could perform certain action on the resource.",
            "        :rtype bool",
            "        \"\"\"",
            "        if not user:",
            "            user = g.user",
            "        if (action_name, resource_name) in user.perms:",
            "            return True",
            "",
            "        if self.is_dag_resource(resource_name):",
            "            if (action_name, permissions.RESOURCE_DAG) in user.perms:",
            "                return True",
            "            return (action_name, resource_name) in user.perms",
            "",
            "        return False",
            "",
            "    def _has_role(self, role_name_or_list, user):",
            "        \"\"\"Whether the user has this role name\"\"\"",
            "        if not isinstance(role_name_or_list, list):",
            "            role_name_or_list = [role_name_or_list]",
            "        return any(r.name in role_name_or_list for r in user.roles)",
            "",
            "    def has_all_dags_access(self, user):",
            "        \"\"\"",
            "        Has all the dag access in any of the 3 cases:",
            "        1. Role needs to be in (Admin, Viewer, User, Op).",
            "        2. Has can_read action on dags resource.",
            "        3. Has can_edit action on dags resource.",
            "        \"\"\"",
            "        if not user:",
            "            user = g.user",
            "        return (",
            "            self._has_role(['Admin', 'Viewer', 'Op', 'User'], user)",
            "            or self.has_access(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG, user)",
            "            or self.has_access(permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG, user)",
            "        )",
            "",
            "    def clean_perms(self):",
            "        \"\"\"FAB leaves faulty permissions that need to be cleaned up\"\"\"",
            "        self.log.debug('Cleaning faulty perms')",
            "        sesh = self.get_session",
            "        perms = sesh.query(Permission).filter(",
            "            or_(",
            "                Permission.action == None,  # noqa",
            "                Permission.resource == None,  # noqa",
            "            )",
            "        )",
            "        # Since FAB doesn't define ON DELETE CASCADE on these tables, we need",
            "        # to delete the _object_ so that SQLA knows to delete the many-to-many",
            "        # relationship object too. :(",
            "",
            "        deleted_count = 0",
            "        for perm in perms:",
            "            sesh.delete(perm)",
            "            deleted_count += 1",
            "        sesh.commit()",
            "        if deleted_count:",
            "            self.log.info('Deleted %s faulty permissions', deleted_count)",
            "",
            "    def _merge_perm(self, action_name, resource_name):",
            "        \"\"\"",
            "        Add the new (action, resource) to assoc_permission_role if it doesn't exist.",
            "        It will add the related entry to ab_permission and ab_resource two meta tables as well.",
            "",
            "        :param action_name: Name of the action",
            "        :param resource_name: Name of the resource",
            "        :return:",
            "        \"\"\"",
            "        action = self.get_action(action_name)",
            "        resource = self.get_resource(resource_name)",
            "        perm = None",
            "        if action and resource:",
            "            perm = (",
            "                self.get_session.query(self.permission_model)",
            "                .filter_by(action=action, resource=resource)",
            "                .first()",
            "            )",
            "        if not perm and action_name and resource_name:",
            "            self.create_permission(action_name, resource_name)",
            "",
            "    def add_homepage_access_to_custom_roles(self):",
            "        \"\"\"",
            "        Add Website.can_read access to all custom roles.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        website_permission = self.create_permission(permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE)",
            "        custom_roles = [role for role in self.get_all_roles() if role.name not in EXISTING_ROLES]",
            "        for role in custom_roles:",
            "            self.add_permission_to_role(role, website_permission)",
            "",
            "        self.get_session.commit()",
            "",
            "    def get_all_permissions(self) -> Set[Tuple[str, str]]:",
            "        \"\"\"Returns all permissions as a set of tuples with the action and resource names\"\"\"",
            "        return set(",
            "            self.get_session.query(self.permission_model)",
            "            .join(self.permission_model.action)",
            "            .join(self.permission_model.resource)",
            "            .with_entities(self.action_model.name, self.resource_model.name)",
            "            .all()",
            "        )",
            "",
            "    def _get_all_non_dag_permissions(self) -> Dict[Tuple[str, str], Permission]:",
            "        \"\"\"",
            "        Returns a dict with a key of (action_name, resource_name) and value of permission",
            "        with all permissions except those that are for specific DAGs.",
            "        \"\"\"",
            "        return {",
            "            (action_name, resource_name): viewmodel",
            "            for action_name, resource_name, viewmodel in (",
            "                self.get_session.query(self.permission_model)",
            "                .join(self.permission_model.action)",
            "                .join(self.permission_model.resource)",
            "                .filter(~self.resource_model.name.like(f\"{permissions.RESOURCE_DAG_PREFIX}%\"))",
            "                .with_entities(self.action_model.name, self.resource_model.name, self.permission_model)",
            "                .all()",
            "            )",
            "        }",
            "",
            "    def _get_all_roles_with_permissions(self) -> Dict[str, Role]:",
            "        \"\"\"Returns a dict with a key of role name and value of role with early loaded permissions\"\"\"",
            "        return {",
            "            r.name: r",
            "            for r in (",
            "                self.get_session.query(self.role_model).options(joinedload(self.role_model.permissions)).all()",
            "            )",
            "        }",
            "",
            "    def create_dag_specific_permissions(self) -> None:",
            "        \"\"\"",
            "        Creates 'can_read', 'can_edit', and 'can_delete' permissions for all",
            "        DAGs, along with any `access_control` permissions provided in them.",
            "",
            "        This does iterate through ALL the DAGs, which can be slow. See `sync_perm_for_dag`",
            "        if you only need to sync a single DAG.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        perms = self.get_all_permissions()",
            "        dagbag = DagBag(read_dags_from_db=True)",
            "        dagbag.collect_dags_from_db()",
            "        dags = dagbag.dags.values()",
            "",
            "        for dag in dags:",
            "            root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id",
            "            dag_resource_name = permissions.resource_name_for_dag(root_dag_id)",
            "            for action_name in self.DAG_ACTIONS:",
            "                if (action_name, dag_resource_name) not in perms:",
            "                    self._merge_perm(action_name, dag_resource_name)",
            "",
            "            if dag.access_control:",
            "                self.sync_perm_for_dag(dag_resource_name, dag.access_control)",
            "",
            "    def update_admin_permission(self):",
            "        \"\"\"",
            "        Admin should have all the permissions, except the dag permissions.",
            "        because Admin already has Dags permission.",
            "        Add the missing ones to the table for admin.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        dag_resources = (",
            "            self.get_session.query(Resource)",
            "            .filter(Resource.name.like(f\"{permissions.RESOURCE_DAG_PREFIX}%\"))",
            "            .all()",
            "        )",
            "        resource_ids = [resource.id for resource in dag_resources]",
            "        perms = self.get_session.query(Permission).filter(~Permission.resource_id.in_(resource_ids)).all()",
            "",
            "        perms = [p for p in perms if p.action and p.resource]",
            "",
            "        admin = self.find_role('Admin')",
            "        admin.permissions = list(set(admin.permissions) | set(perms))",
            "",
            "        self.get_session.commit()",
            "",
            "    def sync_roles(self):",
            "        \"\"\"",
            "        1. Init the default role(Admin, Viewer, User, Op, public)",
            "           with related permissions.",
            "        2. Init the custom role(dag-user) with related permissions.",
            "",
            "        :return: None.",
            "        \"\"\"",
            "        # Create global all-dag permissions",
            "        self.create_perm_vm_for_all_dag()",
            "",
            "        # Sync the default roles (Admin, Viewer, User, Op, public) with related permissions",
            "        self.bulk_sync_roles(self.ROLE_CONFIGS)",
            "",
            "        self.add_homepage_access_to_custom_roles()",
            "        # init existing roles, the rest role could be created through UI.",
            "        self.update_admin_permission()",
            "        self.clean_perms()",
            "",
            "    def sync_resource_permissions(self, perms=None):",
            "        \"\"\"Populates resource-based permissions.\"\"\"",
            "        if not perms:",
            "            return",
            "",
            "        for action_name, resource_name in perms:",
            "            self.create_resource(resource_name)",
            "            self.create_permission(action_name, resource_name)",
            "",
            "    def sync_perm_for_dag(self, dag_id, access_control=None):",
            "        \"\"\"",
            "        Sync permissions for given dag id. The dag id surely exists in our dag bag",
            "        as only / refresh button or DagBag will call this function",
            "",
            "        :param dag_id: the ID of the DAG whose permissions should be updated",
            "        :param access_control: a dict where each key is a rolename and",
            "            each value is a set() of action names (e.g.,",
            "            {'can_read'}",
            "        :return:",
            "        \"\"\"",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "        for dag_action_name in self.DAG_ACTIONS:",
            "            self.create_permission(dag_action_name, dag_resource_name)",
            "",
            "        if access_control:",
            "            self._sync_dag_view_permissions(dag_resource_name, access_control)",
            "",
            "    def _sync_dag_view_permissions(self, dag_id, access_control):",
            "        \"\"\"",
            "        Set the access policy on the given DAG's ViewModel.",
            "",
            "        :param dag_id: the ID of the DAG whose permissions should be updated",
            "        :param access_control: a dict where each key is a rolename and",
            "            each value is a set() of action names (e.g. {'can_read'})",
            "        \"\"\"",
            "",
            "        dag_resource_name = permissions.resource_name_for_dag(dag_id)",
            "",
            "        def _get_or_create_dag_permission(action_name: str) -> Optional[Permission]:",
            "            perm = self.get_permission(action_name, dag_resource_name)",
            "            if not perm:",
            "                self.log.info(\"Creating new action '%s' on resource '%s'\", action_name, dag_resource_name)",
            "                perm = self.create_permission(action_name, dag_resource_name)",
            "",
            "            return perm",
            "",
            "        def _revoke_stale_permissions(resource: Resource):",
            "            existing_dag_perms = self.get_resource_permissions(resource)",
            "            for perm in existing_dag_perms:",
            "                non_admin_roles = [role for role in perm.role if role.name != 'Admin']",
            "                for role in non_admin_roles:",
            "                    target_perms_for_role = access_control.get(role.name, {})",
            "                    if perm.action.name not in target_perms_for_role:",
            "                        self.log.info(",
            "                            \"Revoking '%s' on DAG '%s' for role '%s'\",",
            "                            perm.action,",
            "                            dag_resource_name,",
            "                            role.name,",
            "                        )",
            "                        self.remove_permission_from_role(role, perm)",
            "",
            "        resource = self.get_resource(dag_resource_name)",
            "        if resource:",
            "            _revoke_stale_permissions(resource)",
            "",
            "        for rolename, action_names in access_control.items():",
            "            role = self.find_role(rolename)",
            "            if not role:",
            "                raise AirflowException(",
            "                    f\"The access_control mapping for DAG '{dag_id}' includes a role named \"",
            "                    f\"'{rolename}', but that role does not exist\"",
            "                )",
            "",
            "            action_names = set(action_names)",
            "            invalid_action_names = action_names - self.DAG_ACTIONS",
            "            if invalid_action_names:",
            "                raise AirflowException(",
            "                    f\"The access_control map for DAG '{dag_resource_name}' includes \"",
            "                    f\"the following invalid permissions: {invalid_action_names}; \"",
            "                    f\"The set of valid permissions is: {self.DAG_ACTIONS}\"",
            "                )",
            "",
            "            for action_name in action_names:",
            "                dag_perm = _get_or_create_dag_permission(action_name)",
            "                if dag_perm:",
            "                    self.add_permission_to_role(role, dag_perm)",
            "",
            "    def create_perm_vm_for_all_dag(self):",
            "        \"\"\"Create perm-vm if not exist and insert into FAB security model for all-dags.\"\"\"",
            "        # create perm for global logical dag",
            "        for resource_name in self.DAG_RESOURCES:",
            "            for action_name in self.DAG_ACTIONS:",
            "                self._merge_perm(action_name, resource_name)",
            "",
            "    def check_authorization(",
            "        self, perms: Optional[Sequence[Tuple[str, str]]] = None, dag_id: Optional[str] = None",
            "    ) -> bool:",
            "        \"\"\"Checks that the logged in user has the specified permissions.\"\"\"",
            "        if not perms:",
            "            return True",
            "",
            "        for perm in perms:",
            "            if perm in (",
            "                (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
            "                (permissions.ACTION_CAN_EDIT, permissions.RESOURCE_DAG),",
            "                (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_DAG),",
            "            ):",
            "                can_access_all_dags = self.has_access(*perm)",
            "                if can_access_all_dags:",
            "                    continue",
            "",
            "                action = perm[0]",
            "                if self.can_access_some_dags(action, dag_id):",
            "                    continue",
            "                return False",
            "",
            "            elif not self.has_access(*perm):",
            "                return False",
            "",
            "        return True",
            "",
            "",
            "class ApplessAirflowSecurityManager(AirflowSecurityManager):",
            "    \"\"\"Security Manager that doesn't need the whole flask app\"\"\"",
            "",
            "    def __init__(self, session=None):",
            "        self.session = session",
            "",
            "    @property",
            "    def get_session(self):",
            "        return self.session"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "343": [
                "AirflowSecurityManager",
                "can_access_some_dags"
            ],
            "352": [
                "AirflowSecurityManager",
                "can_read_dag"
            ],
            "357": [
                "AirflowSecurityManager",
                "can_edit_dag"
            ],
            "362": [
                "AirflowSecurityManager",
                "can_delete_dag"
            ],
            "373": [
                "AirflowSecurityManager",
                "prefixed_dag_id"
            ],
            "533": [
                "AirflowSecurityManager",
                "create_dag_specific_permissions"
            ]
        },
        "addLocation": [
            "airflow.www.security.AirflowSecurityManager.can_edit_dag",
            "airflow.www.security.AirflowSecurityManager.can_delete_dag",
            "airflow.www.security.AirflowSecurityManager.VIEWER_PERMISSIONS",
            "airflow.www.security.AirflowSecurityManager.USER_PERMISSIONS",
            "airflow.www.security.AirflowSecurityManager.prefixed_dag_id",
            "airflow.www.security.AirflowSecurityManager.ADMIN_PERMISSIONS",
            "airflow.www.security.AirflowSecurityManager.can_read_dag",
            "airflow.www.security.AirflowSecurityManager.can_access_some_dags",
            "airflow.www.security.AirflowSecurityManager.OP_PERMISSIONS",
            "airflow.www.security.AirflowSecurityManager.self",
            "airflow.www.security.AirflowSecurityManager.ROLE_CONFIGS",
            "jwt.api_jwt"
        ]
    }
}