{
    "dulwich/index.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 431,
                "afterPatchRowNumber": 431,
                "PatchRowcode": "             os.chmod(target_path, mode)"
            },
            "1": {
                "beforePatchRowNumber": 432,
                "afterPatchRowNumber": 432,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 433,
                "afterPatchRowNumber": 433,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 434,
                "PatchRowcode": "+def validate_path_default(path):"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 435,
                "PatchRowcode": "+    \"\"\"Default path validator that just checks for .git/.\"\"\""
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 436,
                "PatchRowcode": "+    return not path.startswith(\".git/\")"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 437,
                "PatchRowcode": "+"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 438,
                "PatchRowcode": "+"
            },
            "8": {
                "beforePatchRowNumber": 434,
                "afterPatchRowNumber": 439,
                "PatchRowcode": " def build_index_from_tree(prefix, index_path, object_store, tree_id,"
            },
            "9": {
                "beforePatchRowNumber": 435,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                          honor_filemode=True):"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 440,
                "PatchRowcode": "+                          honor_filemode=True,"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 441,
                "PatchRowcode": "+                          validate_path=validate_path_default):"
            },
            "12": {
                "beforePatchRowNumber": 436,
                "afterPatchRowNumber": 442,
                "PatchRowcode": "     \"\"\"Generate and materialize index from a tree"
            },
            "13": {
                "beforePatchRowNumber": 437,
                "afterPatchRowNumber": 443,
                "PatchRowcode": " "
            },
            "14": {
                "beforePatchRowNumber": 438,
                "afterPatchRowNumber": 444,
                "PatchRowcode": "     :param tree_id: Tree to materialize"
            },
            "15": {
                "beforePatchRowNumber": 441,
                "afterPatchRowNumber": 447,
                "PatchRowcode": "     :param object_store: Non-empty object store holding tree contents"
            },
            "16": {
                "beforePatchRowNumber": 442,
                "afterPatchRowNumber": 448,
                "PatchRowcode": "     :param honor_filemode: An optional flag to honor core.filemode setting in"
            },
            "17": {
                "beforePatchRowNumber": 443,
                "afterPatchRowNumber": 449,
                "PatchRowcode": "         config file, default is core.filemode=True, change executable bit"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 450,
                "PatchRowcode": "+    :param validate_path: Function to validate paths to check out;"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 451,
                "PatchRowcode": "+        default just refuses filenames starting with .git/."
            },
            "20": {
                "beforePatchRowNumber": 444,
                "afterPatchRowNumber": 452,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 445,
                "afterPatchRowNumber": 453,
                "PatchRowcode": "     :note:: existing index is wiped and contents are not merged"
            },
            "22": {
                "beforePatchRowNumber": 446,
                "afterPatchRowNumber": 454,
                "PatchRowcode": "         in a working dir. Suiteable only for fresh clones."
            },
            "23": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 457,
                "PatchRowcode": "     index = Index(index_path)"
            },
            "24": {
                "beforePatchRowNumber": 450,
                "afterPatchRowNumber": 458,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 451,
                "afterPatchRowNumber": 459,
                "PatchRowcode": "     for entry in object_store.iter_tree_contents(tree_id):"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 460,
                "PatchRowcode": "+        if not validate_path(entry.path):"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 461,
                "PatchRowcode": "+            continue"
            },
            "28": {
                "beforePatchRowNumber": 452,
                "afterPatchRowNumber": 462,
                "PatchRowcode": "         full_path = os.path.join(prefix, entry.path)"
            },
            "29": {
                "beforePatchRowNumber": 453,
                "afterPatchRowNumber": 463,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 454,
                "afterPatchRowNumber": 464,
                "PatchRowcode": "         if not os.path.exists(os.path.dirname(full_path)):"
            }
        },
        "frontPatchFile": [
            "# index.py -- File parser/writer for the git index file",
            "# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>",
            "#",
            "# This program is free software; you can redistribute it and/or",
            "# modify it under the terms of the GNU General Public License",
            "# as published by the Free Software Foundation; version 2",
            "# of the License or (at your opinion) any later version of the license.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program; if not, write to the Free Software",
            "# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,",
            "# MA  02110-1301, USA.",
            "",
            "\"\"\"Parser for the git index file format.\"\"\"",
            "",
            "import collections",
            "import errno",
            "import os",
            "import stat",
            "import struct",
            "",
            "from dulwich.file import GitFile",
            "from dulwich.objects import (",
            "    Blob,",
            "    S_IFGITLINK,",
            "    S_ISGITLINK,",
            "    Tree,",
            "    hex_to_sha,",
            "    sha_to_hex,",
            "    )",
            "from dulwich.pack import (",
            "    SHA1Reader,",
            "    SHA1Writer,",
            "    )",
            "",
            "",
            "IndexEntry = collections.namedtuple(",
            "    'IndexEntry', [",
            "        'ctime', 'mtime', 'dev', 'ino', 'mode', 'uid', 'gid', 'size', 'sha',",
            "        'flags'])",
            "",
            "",
            "def pathsplit(path):",
            "    \"\"\"Split a /-delimited path into a directory part and a basename.",
            "",
            "    :param path: The path to split.",
            "    :return: Tuple with directory name and basename",
            "    \"\"\"",
            "    try:",
            "        (dirname, basename) = path.rsplit(\"/\", 1)",
            "    except ValueError:",
            "        return (\"\", path)",
            "    else:",
            "        return (dirname, basename)",
            "",
            "",
            "def pathjoin(*args):",
            "    \"\"\"Join a /-delimited path.",
            "",
            "    \"\"\"",
            "    return \"/\".join([p for p in args if p])",
            "",
            "",
            "def read_cache_time(f):",
            "    \"\"\"Read a cache time.",
            "",
            "    :param f: File-like object to read from",
            "    :return: Tuple with seconds and nanoseconds",
            "    \"\"\"",
            "    return struct.unpack(\">LL\", f.read(8))",
            "",
            "",
            "def write_cache_time(f, t):",
            "    \"\"\"Write a cache time.",
            "",
            "    :param f: File-like object to write to",
            "    :param t: Time to write (as int, float or tuple with secs and nsecs)",
            "    \"\"\"",
            "    if isinstance(t, int):",
            "        t = (t, 0)",
            "    elif isinstance(t, float):",
            "        (secs, nsecs) = divmod(t, 1.0)",
            "        t = (int(secs), int(nsecs * 1000000000))",
            "    elif not isinstance(t, tuple):",
            "        raise TypeError(t)",
            "    f.write(struct.pack(\">LL\", *t))",
            "",
            "",
            "def read_cache_entry(f):",
            "    \"\"\"Read an entry from a cache file.",
            "",
            "    :param f: File-like object to read from",
            "    :return: tuple with: device, inode, mode, uid, gid, size, sha, flags",
            "    \"\"\"",
            "    beginoffset = f.tell()",
            "    ctime = read_cache_time(f)",
            "    mtime = read_cache_time(f)",
            "    (dev, ino, mode, uid, gid, size, sha, flags, ) = \\",
            "        struct.unpack(\">LLLLLL20sH\", f.read(20 + 4 * 6 + 2))",
            "    name = f.read((flags & 0x0fff))",
            "    # Padding:",
            "    real_size = ((f.tell() - beginoffset + 8) & ~7)",
            "    f.read((beginoffset + real_size) - f.tell())",
            "    return (name, ctime, mtime, dev, ino, mode, uid, gid, size,",
            "            sha_to_hex(sha), flags & ~0x0fff)",
            "",
            "",
            "def write_cache_entry(f, entry):",
            "    \"\"\"Write an index entry to a file.",
            "",
            "    :param f: File object",
            "    :param entry: Entry to write, tuple with:",
            "        (name, ctime, mtime, dev, ino, mode, uid, gid, size, sha, flags)",
            "    \"\"\"",
            "    beginoffset = f.tell()",
            "    (name, ctime, mtime, dev, ino, mode, uid, gid, size, sha, flags) = entry",
            "    write_cache_time(f, ctime)",
            "    write_cache_time(f, mtime)",
            "    flags = len(name) | (flags &~ 0x0fff)",
            "    f.write(struct.pack(\">LLLLLL20sH\", dev & 0xFFFFFFFF, ino & 0xFFFFFFFF, mode, uid, gid, size, hex_to_sha(sha), flags))",
            "    f.write(name)",
            "    real_size = ((f.tell() - beginoffset + 8) & ~7)",
            "    f.write(\"\\0\" * ((beginoffset + real_size) - f.tell()))",
            "",
            "",
            "def read_index(f):",
            "    \"\"\"Read an index file, yielding the individual entries.\"\"\"",
            "    header = f.read(4)",
            "    if header != \"DIRC\":",
            "        raise AssertionError(\"Invalid index file header: %r\" % header)",
            "    (version, num_entries) = struct.unpack(\">LL\", f.read(4 * 2))",
            "    assert version in (1, 2)",
            "    for i in range(num_entries):",
            "        yield read_cache_entry(f)",
            "",
            "",
            "def read_index_dict(f):",
            "    \"\"\"Read an index file and return it as a dictionary.",
            "",
            "    :param f: File object to read from",
            "    \"\"\"",
            "    ret = {}",
            "    for x in read_index(f):",
            "        ret[x[0]] = IndexEntry(*x[1:])",
            "    return ret",
            "",
            "",
            "def write_index(f, entries):",
            "    \"\"\"Write an index file.",
            "",
            "    :param f: File-like object to write to",
            "    :param entries: Iterable over the entries to write",
            "    \"\"\"",
            "    f.write(\"DIRC\")",
            "    f.write(struct.pack(\">LL\", 2, len(entries)))",
            "    for x in entries:",
            "        write_cache_entry(f, x)",
            "",
            "",
            "def write_index_dict(f, entries):",
            "    \"\"\"Write an index file based on the contents of a dictionary.",
            "",
            "    \"\"\"",
            "    entries_list = []",
            "    for name in sorted(entries):",
            "        entries_list.append((name,) + tuple(entries[name]))",
            "    write_index(f, entries_list)",
            "",
            "",
            "def cleanup_mode(mode):",
            "    \"\"\"Cleanup a mode value.",
            "",
            "    This will return a mode that can be stored in a tree object.",
            "",
            "    :param mode: Mode to clean up.",
            "    \"\"\"",
            "    if stat.S_ISLNK(mode):",
            "        return stat.S_IFLNK",
            "    elif stat.S_ISDIR(mode):",
            "        return stat.S_IFDIR",
            "    elif S_ISGITLINK(mode):",
            "        return S_IFGITLINK",
            "    ret = stat.S_IFREG | 0o644",
            "    ret |= (mode & 0o111)",
            "    return ret",
            "",
            "",
            "class Index(object):",
            "    \"\"\"A Git Index file.\"\"\"",
            "",
            "    def __init__(self, filename):",
            "        \"\"\"Open an index file.",
            "",
            "        :param filename: Path to the index file",
            "        \"\"\"",
            "        self._filename = filename",
            "        self.clear()",
            "        self.read()",
            "",
            "    def __repr__(self):",
            "        return \"%s(%r)\" % (self.__class__.__name__, self._filename)",
            "",
            "    def write(self):",
            "        \"\"\"Write current contents of index to disk.\"\"\"",
            "        f = GitFile(self._filename, 'wb')",
            "        try:",
            "            f = SHA1Writer(f)",
            "            write_index_dict(f, self._byname)",
            "        finally:",
            "            f.close()",
            "",
            "    def read(self):",
            "        \"\"\"Read current contents of index from disk.\"\"\"",
            "        if not os.path.exists(self._filename):",
            "            return",
            "        f = GitFile(self._filename, 'rb')",
            "        try:",
            "            f = SHA1Reader(f)",
            "            for x in read_index(f):",
            "                self[x[0]] = IndexEntry(*x[1:])",
            "            # FIXME: Additional data?",
            "            f.read(os.path.getsize(self._filename)-f.tell()-20)",
            "            f.check_sha()",
            "        finally:",
            "            f.close()",
            "",
            "    def __len__(self):",
            "        \"\"\"Number of entries in this index file.\"\"\"",
            "        return len(self._byname)",
            "",
            "    def __getitem__(self, name):",
            "        \"\"\"Retrieve entry by relative path.",
            "",
            "        :return: tuple with (ctime, mtime, dev, ino, mode, uid, gid, size, sha, flags)",
            "        \"\"\"",
            "        return self._byname[name]",
            "",
            "    def __iter__(self):",
            "        \"\"\"Iterate over the paths in this index.\"\"\"",
            "        return iter(self._byname)",
            "",
            "    def get_sha1(self, path):",
            "        \"\"\"Return the (git object) SHA1 for the object at a path.\"\"\"",
            "        return self[path].sha",
            "",
            "    def get_mode(self, path):",
            "        \"\"\"Return the POSIX file mode for the object at a path.\"\"\"",
            "        return self[path].mode",
            "",
            "    def iterblobs(self):",
            "        \"\"\"Iterate over path, sha, mode tuples for use with commit_tree.\"\"\"",
            "        for path in self:",
            "            entry = self[path]",
            "            yield path, entry.sha, cleanup_mode(entry.mode)",
            "",
            "    def clear(self):",
            "        \"\"\"Remove all contents from this index.\"\"\"",
            "        self._byname = {}",
            "",
            "    def __setitem__(self, name, x):",
            "        assert isinstance(name, str)",
            "        assert len(x) == 10",
            "        # Remove the old entry if any",
            "        self._byname[name] = x",
            "",
            "    def __delitem__(self, name):",
            "        assert isinstance(name, str)",
            "        del self._byname[name]",
            "",
            "    def iteritems(self):",
            "        return self._byname.iteritems()",
            "",
            "    def update(self, entries):",
            "        for name, value in entries.iteritems():",
            "            self[name] = value",
            "",
            "    def changes_from_tree(self, object_store, tree, want_unchanged=False):",
            "        \"\"\"Find the differences between the contents of this index and a tree.",
            "",
            "        :param object_store: Object store to use for retrieving tree contents",
            "        :param tree: SHA1 of the root tree",
            "        :param want_unchanged: Whether unchanged files should be reported",
            "        :return: Iterator over tuples with (oldpath, newpath), (oldmode, newmode), (oldsha, newsha)",
            "        \"\"\"",
            "        def lookup_entry(path):",
            "            entry = self[path]",
            "            return entry.sha, entry.mode",
            "        for (name, mode, sha) in changes_from_tree(self._byname.keys(),",
            "                lookup_entry, object_store, tree,",
            "                want_unchanged=want_unchanged):",
            "            yield (name, mode, sha)",
            "",
            "    def commit(self, object_store):",
            "        \"\"\"Create a new tree from an index.",
            "",
            "        :param object_store: Object store to save the tree in",
            "        :return: Root tree SHA",
            "        \"\"\"",
            "        return commit_tree(object_store, self.iterblobs())",
            "",
            "",
            "def commit_tree(object_store, blobs):",
            "    \"\"\"Commit a new tree.",
            "",
            "    :param object_store: Object store to add trees to",
            "    :param blobs: Iterable over blob path, sha, mode entries",
            "    :return: SHA1 of the created tree.",
            "    \"\"\"",
            "",
            "    trees = {\"\": {}}",
            "",
            "    def add_tree(path):",
            "        if path in trees:",
            "            return trees[path]",
            "        dirname, basename = pathsplit(path)",
            "        t = add_tree(dirname)",
            "        assert isinstance(basename, str)",
            "        newtree = {}",
            "        t[basename] = newtree",
            "        trees[path] = newtree",
            "        return newtree",
            "",
            "    for path, sha, mode in blobs:",
            "        tree_path, basename = pathsplit(path)",
            "        tree = add_tree(tree_path)",
            "        tree[basename] = (mode, sha)",
            "",
            "    def build_tree(path):",
            "        tree = Tree()",
            "        for basename, entry in trees[path].iteritems():",
            "            if isinstance(entry, dict):",
            "                mode = stat.S_IFDIR",
            "                sha = build_tree(pathjoin(path, basename))",
            "            else:",
            "                (mode, sha) = entry",
            "            tree.add(basename, mode, sha)",
            "        object_store.add_object(tree)",
            "        return tree.id",
            "    return build_tree(\"\")",
            "",
            "",
            "def commit_index(object_store, index):",
            "    \"\"\"Create a new tree from an index.",
            "",
            "    :param object_store: Object store to save the tree in",
            "    :param index: Index file",
            "    :note: This function is deprecated, use index.commit() instead.",
            "    :return: Root tree sha.",
            "    \"\"\"",
            "    return commit_tree(object_store, index.iterblobs())",
            "",
            "",
            "def changes_from_tree(names, lookup_entry, object_store, tree,",
            "        want_unchanged=False):",
            "    \"\"\"Find the differences between the contents of a tree and",
            "    a working copy.",
            "",
            "    :param names: Iterable of names in the working copy",
            "    :param lookup_entry: Function to lookup an entry in the working copy",
            "    :param object_store: Object store to use for retrieving tree contents",
            "    :param tree: SHA1 of the root tree, or None for an empty tree",
            "    :param want_unchanged: Whether unchanged files should be reported",
            "    :return: Iterator over tuples with (oldpath, newpath), (oldmode, newmode),",
            "        (oldsha, newsha)",
            "    \"\"\"",
            "    other_names = set(names)",
            "",
            "    if tree is not None:",
            "        for (name, mode, sha) in object_store.iter_tree_contents(tree):",
            "            try:",
            "                (other_sha, other_mode) = lookup_entry(name)",
            "            except KeyError:",
            "                # Was removed",
            "                yield ((name, None), (mode, None), (sha, None))",
            "            else:",
            "                other_names.remove(name)",
            "                if (want_unchanged or other_sha != sha or other_mode != mode):",
            "                    yield ((name, name), (mode, other_mode), (sha, other_sha))",
            "",
            "    # Mention added files",
            "    for name in other_names:",
            "        (other_sha, other_mode) = lookup_entry(name)",
            "        yield ((None, name), (None, other_mode), (None, other_sha))",
            "",
            "",
            "def index_entry_from_stat(stat_val, hex_sha, flags, mode=None):",
            "    \"\"\"Create a new index entry from a stat value.",
            "",
            "    :param stat_val: POSIX stat_result instance",
            "    :param hex_sha: Hex sha of the object",
            "    :param flags: Index flags",
            "    \"\"\"",
            "    if mode is None:",
            "        mode = cleanup_mode(stat_val.st_mode)",
            "    return (stat_val.st_ctime, stat_val.st_mtime, stat_val.st_dev,",
            "            stat_val.st_ino, mode, stat_val.st_uid,",
            "            stat_val.st_gid, stat_val.st_size, hex_sha, flags)",
            "",
            "",
            "def build_file_from_blob(blob, mode, target_path, honor_filemode=True):",
            "    \"\"\"Build a file or symlink on disk based on a Git object.",
            "",
            "    :param obj: The git object",
            "    :param mode: File mode",
            "    :param target_path: Path to write to",
            "    :param honor_filemode: An optional flag to honor core.filemode setting in",
            "        config file, default is core.filemode=True, change executable bit",
            "    \"\"\"",
            "    if stat.S_ISLNK(mode):",
            "        # FIXME: This will fail on Windows. What should we do instead?",
            "        src_path = blob.as_raw_string()",
            "        try:",
            "            os.symlink(src_path, target_path)",
            "        except OSError as e:",
            "            if e.errno == errno.EEXIST:",
            "                os.unlink(target_path)",
            "                os.symlink(src_path, target_path)",
            "            else:",
            "                raise",
            "    else:",
            "        with open(target_path, 'wb') as f:",
            "            # Write out file",
            "            f.write(blob.as_raw_string())",
            "",
            "        if honor_filemode:",
            "            os.chmod(target_path, mode)",
            "",
            "",
            "def build_index_from_tree(prefix, index_path, object_store, tree_id,",
            "                          honor_filemode=True):",
            "    \"\"\"Generate and materialize index from a tree",
            "",
            "    :param tree_id: Tree to materialize",
            "    :param prefix: Target dir for materialized index files",
            "    :param index_path: Target path for generated index",
            "    :param object_store: Non-empty object store holding tree contents",
            "    :param honor_filemode: An optional flag to honor core.filemode setting in",
            "        config file, default is core.filemode=True, change executable bit",
            "",
            "    :note:: existing index is wiped and contents are not merged",
            "        in a working dir. Suiteable only for fresh clones.",
            "    \"\"\"",
            "",
            "    index = Index(index_path)",
            "",
            "    for entry in object_store.iter_tree_contents(tree_id):",
            "        full_path = os.path.join(prefix, entry.path)",
            "",
            "        if not os.path.exists(os.path.dirname(full_path)):",
            "            os.makedirs(os.path.dirname(full_path))",
            "",
            "        # FIXME: Merge new index into working tree",
            "        obj = object_store[entry.sha]",
            "        build_file_from_blob(obj, entry.mode, full_path,",
            "            honor_filemode=honor_filemode)",
            "        # Add file to index",
            "        st = os.lstat(full_path)",
            "        index[entry.path] = index_entry_from_stat(st, entry.sha, 0)",
            "",
            "    index.write()",
            "",
            "",
            "def blob_from_path_and_stat(path, st):",
            "    \"\"\"Create a blob from a path and a stat object.",
            "",
            "    :param path: Full path to file",
            "    :param st: A stat object",
            "    :return: A `Blob` object",
            "    \"\"\"",
            "    blob = Blob()",
            "    if not stat.S_ISLNK(st.st_mode):",
            "        with open(path, 'rb') as f:",
            "            blob.data = f.read()",
            "    else:",
            "        blob.data = os.readlink(path)",
            "    return blob",
            "",
            "",
            "def get_unstaged_changes(index, path):",
            "    \"\"\"Walk through an index and check for differences against working tree.",
            "",
            "    :param index: index to check",
            "    :param path: path in which to find files",
            "    :return: iterator over paths with unstaged changes",
            "    \"\"\"",
            "    # For each entry in the index check the sha1 & ensure not staged",
            "    for name, entry in index.iteritems():",
            "        fp = os.path.join(path, name)",
            "        blob = blob_from_path_and_stat(fp, os.lstat(fp))",
            "        if blob.id != entry.sha:",
            "            yield name"
        ],
        "afterPatchFile": [
            "# index.py -- File parser/writer for the git index file",
            "# Copyright (C) 2008-2013 Jelmer Vernooij <jelmer@samba.org>",
            "#",
            "# This program is free software; you can redistribute it and/or",
            "# modify it under the terms of the GNU General Public License",
            "# as published by the Free Software Foundation; version 2",
            "# of the License or (at your opinion) any later version of the license.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program; if not, write to the Free Software",
            "# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,",
            "# MA  02110-1301, USA.",
            "",
            "\"\"\"Parser for the git index file format.\"\"\"",
            "",
            "import collections",
            "import errno",
            "import os",
            "import stat",
            "import struct",
            "",
            "from dulwich.file import GitFile",
            "from dulwich.objects import (",
            "    Blob,",
            "    S_IFGITLINK,",
            "    S_ISGITLINK,",
            "    Tree,",
            "    hex_to_sha,",
            "    sha_to_hex,",
            "    )",
            "from dulwich.pack import (",
            "    SHA1Reader,",
            "    SHA1Writer,",
            "    )",
            "",
            "",
            "IndexEntry = collections.namedtuple(",
            "    'IndexEntry', [",
            "        'ctime', 'mtime', 'dev', 'ino', 'mode', 'uid', 'gid', 'size', 'sha',",
            "        'flags'])",
            "",
            "",
            "def pathsplit(path):",
            "    \"\"\"Split a /-delimited path into a directory part and a basename.",
            "",
            "    :param path: The path to split.",
            "    :return: Tuple with directory name and basename",
            "    \"\"\"",
            "    try:",
            "        (dirname, basename) = path.rsplit(\"/\", 1)",
            "    except ValueError:",
            "        return (\"\", path)",
            "    else:",
            "        return (dirname, basename)",
            "",
            "",
            "def pathjoin(*args):",
            "    \"\"\"Join a /-delimited path.",
            "",
            "    \"\"\"",
            "    return \"/\".join([p for p in args if p])",
            "",
            "",
            "def read_cache_time(f):",
            "    \"\"\"Read a cache time.",
            "",
            "    :param f: File-like object to read from",
            "    :return: Tuple with seconds and nanoseconds",
            "    \"\"\"",
            "    return struct.unpack(\">LL\", f.read(8))",
            "",
            "",
            "def write_cache_time(f, t):",
            "    \"\"\"Write a cache time.",
            "",
            "    :param f: File-like object to write to",
            "    :param t: Time to write (as int, float or tuple with secs and nsecs)",
            "    \"\"\"",
            "    if isinstance(t, int):",
            "        t = (t, 0)",
            "    elif isinstance(t, float):",
            "        (secs, nsecs) = divmod(t, 1.0)",
            "        t = (int(secs), int(nsecs * 1000000000))",
            "    elif not isinstance(t, tuple):",
            "        raise TypeError(t)",
            "    f.write(struct.pack(\">LL\", *t))",
            "",
            "",
            "def read_cache_entry(f):",
            "    \"\"\"Read an entry from a cache file.",
            "",
            "    :param f: File-like object to read from",
            "    :return: tuple with: device, inode, mode, uid, gid, size, sha, flags",
            "    \"\"\"",
            "    beginoffset = f.tell()",
            "    ctime = read_cache_time(f)",
            "    mtime = read_cache_time(f)",
            "    (dev, ino, mode, uid, gid, size, sha, flags, ) = \\",
            "        struct.unpack(\">LLLLLL20sH\", f.read(20 + 4 * 6 + 2))",
            "    name = f.read((flags & 0x0fff))",
            "    # Padding:",
            "    real_size = ((f.tell() - beginoffset + 8) & ~7)",
            "    f.read((beginoffset + real_size) - f.tell())",
            "    return (name, ctime, mtime, dev, ino, mode, uid, gid, size,",
            "            sha_to_hex(sha), flags & ~0x0fff)",
            "",
            "",
            "def write_cache_entry(f, entry):",
            "    \"\"\"Write an index entry to a file.",
            "",
            "    :param f: File object",
            "    :param entry: Entry to write, tuple with:",
            "        (name, ctime, mtime, dev, ino, mode, uid, gid, size, sha, flags)",
            "    \"\"\"",
            "    beginoffset = f.tell()",
            "    (name, ctime, mtime, dev, ino, mode, uid, gid, size, sha, flags) = entry",
            "    write_cache_time(f, ctime)",
            "    write_cache_time(f, mtime)",
            "    flags = len(name) | (flags &~ 0x0fff)",
            "    f.write(struct.pack(\">LLLLLL20sH\", dev & 0xFFFFFFFF, ino & 0xFFFFFFFF, mode, uid, gid, size, hex_to_sha(sha), flags))",
            "    f.write(name)",
            "    real_size = ((f.tell() - beginoffset + 8) & ~7)",
            "    f.write(\"\\0\" * ((beginoffset + real_size) - f.tell()))",
            "",
            "",
            "def read_index(f):",
            "    \"\"\"Read an index file, yielding the individual entries.\"\"\"",
            "    header = f.read(4)",
            "    if header != \"DIRC\":",
            "        raise AssertionError(\"Invalid index file header: %r\" % header)",
            "    (version, num_entries) = struct.unpack(\">LL\", f.read(4 * 2))",
            "    assert version in (1, 2)",
            "    for i in range(num_entries):",
            "        yield read_cache_entry(f)",
            "",
            "",
            "def read_index_dict(f):",
            "    \"\"\"Read an index file and return it as a dictionary.",
            "",
            "    :param f: File object to read from",
            "    \"\"\"",
            "    ret = {}",
            "    for x in read_index(f):",
            "        ret[x[0]] = IndexEntry(*x[1:])",
            "    return ret",
            "",
            "",
            "def write_index(f, entries):",
            "    \"\"\"Write an index file.",
            "",
            "    :param f: File-like object to write to",
            "    :param entries: Iterable over the entries to write",
            "    \"\"\"",
            "    f.write(\"DIRC\")",
            "    f.write(struct.pack(\">LL\", 2, len(entries)))",
            "    for x in entries:",
            "        write_cache_entry(f, x)",
            "",
            "",
            "def write_index_dict(f, entries):",
            "    \"\"\"Write an index file based on the contents of a dictionary.",
            "",
            "    \"\"\"",
            "    entries_list = []",
            "    for name in sorted(entries):",
            "        entries_list.append((name,) + tuple(entries[name]))",
            "    write_index(f, entries_list)",
            "",
            "",
            "def cleanup_mode(mode):",
            "    \"\"\"Cleanup a mode value.",
            "",
            "    This will return a mode that can be stored in a tree object.",
            "",
            "    :param mode: Mode to clean up.",
            "    \"\"\"",
            "    if stat.S_ISLNK(mode):",
            "        return stat.S_IFLNK",
            "    elif stat.S_ISDIR(mode):",
            "        return stat.S_IFDIR",
            "    elif S_ISGITLINK(mode):",
            "        return S_IFGITLINK",
            "    ret = stat.S_IFREG | 0o644",
            "    ret |= (mode & 0o111)",
            "    return ret",
            "",
            "",
            "class Index(object):",
            "    \"\"\"A Git Index file.\"\"\"",
            "",
            "    def __init__(self, filename):",
            "        \"\"\"Open an index file.",
            "",
            "        :param filename: Path to the index file",
            "        \"\"\"",
            "        self._filename = filename",
            "        self.clear()",
            "        self.read()",
            "",
            "    def __repr__(self):",
            "        return \"%s(%r)\" % (self.__class__.__name__, self._filename)",
            "",
            "    def write(self):",
            "        \"\"\"Write current contents of index to disk.\"\"\"",
            "        f = GitFile(self._filename, 'wb')",
            "        try:",
            "            f = SHA1Writer(f)",
            "            write_index_dict(f, self._byname)",
            "        finally:",
            "            f.close()",
            "",
            "    def read(self):",
            "        \"\"\"Read current contents of index from disk.\"\"\"",
            "        if not os.path.exists(self._filename):",
            "            return",
            "        f = GitFile(self._filename, 'rb')",
            "        try:",
            "            f = SHA1Reader(f)",
            "            for x in read_index(f):",
            "                self[x[0]] = IndexEntry(*x[1:])",
            "            # FIXME: Additional data?",
            "            f.read(os.path.getsize(self._filename)-f.tell()-20)",
            "            f.check_sha()",
            "        finally:",
            "            f.close()",
            "",
            "    def __len__(self):",
            "        \"\"\"Number of entries in this index file.\"\"\"",
            "        return len(self._byname)",
            "",
            "    def __getitem__(self, name):",
            "        \"\"\"Retrieve entry by relative path.",
            "",
            "        :return: tuple with (ctime, mtime, dev, ino, mode, uid, gid, size, sha, flags)",
            "        \"\"\"",
            "        return self._byname[name]",
            "",
            "    def __iter__(self):",
            "        \"\"\"Iterate over the paths in this index.\"\"\"",
            "        return iter(self._byname)",
            "",
            "    def get_sha1(self, path):",
            "        \"\"\"Return the (git object) SHA1 for the object at a path.\"\"\"",
            "        return self[path].sha",
            "",
            "    def get_mode(self, path):",
            "        \"\"\"Return the POSIX file mode for the object at a path.\"\"\"",
            "        return self[path].mode",
            "",
            "    def iterblobs(self):",
            "        \"\"\"Iterate over path, sha, mode tuples for use with commit_tree.\"\"\"",
            "        for path in self:",
            "            entry = self[path]",
            "            yield path, entry.sha, cleanup_mode(entry.mode)",
            "",
            "    def clear(self):",
            "        \"\"\"Remove all contents from this index.\"\"\"",
            "        self._byname = {}",
            "",
            "    def __setitem__(self, name, x):",
            "        assert isinstance(name, str)",
            "        assert len(x) == 10",
            "        # Remove the old entry if any",
            "        self._byname[name] = x",
            "",
            "    def __delitem__(self, name):",
            "        assert isinstance(name, str)",
            "        del self._byname[name]",
            "",
            "    def iteritems(self):",
            "        return self._byname.iteritems()",
            "",
            "    def update(self, entries):",
            "        for name, value in entries.iteritems():",
            "            self[name] = value",
            "",
            "    def changes_from_tree(self, object_store, tree, want_unchanged=False):",
            "        \"\"\"Find the differences between the contents of this index and a tree.",
            "",
            "        :param object_store: Object store to use for retrieving tree contents",
            "        :param tree: SHA1 of the root tree",
            "        :param want_unchanged: Whether unchanged files should be reported",
            "        :return: Iterator over tuples with (oldpath, newpath), (oldmode, newmode), (oldsha, newsha)",
            "        \"\"\"",
            "        def lookup_entry(path):",
            "            entry = self[path]",
            "            return entry.sha, entry.mode",
            "        for (name, mode, sha) in changes_from_tree(self._byname.keys(),",
            "                lookup_entry, object_store, tree,",
            "                want_unchanged=want_unchanged):",
            "            yield (name, mode, sha)",
            "",
            "    def commit(self, object_store):",
            "        \"\"\"Create a new tree from an index.",
            "",
            "        :param object_store: Object store to save the tree in",
            "        :return: Root tree SHA",
            "        \"\"\"",
            "        return commit_tree(object_store, self.iterblobs())",
            "",
            "",
            "def commit_tree(object_store, blobs):",
            "    \"\"\"Commit a new tree.",
            "",
            "    :param object_store: Object store to add trees to",
            "    :param blobs: Iterable over blob path, sha, mode entries",
            "    :return: SHA1 of the created tree.",
            "    \"\"\"",
            "",
            "    trees = {\"\": {}}",
            "",
            "    def add_tree(path):",
            "        if path in trees:",
            "            return trees[path]",
            "        dirname, basename = pathsplit(path)",
            "        t = add_tree(dirname)",
            "        assert isinstance(basename, str)",
            "        newtree = {}",
            "        t[basename] = newtree",
            "        trees[path] = newtree",
            "        return newtree",
            "",
            "    for path, sha, mode in blobs:",
            "        tree_path, basename = pathsplit(path)",
            "        tree = add_tree(tree_path)",
            "        tree[basename] = (mode, sha)",
            "",
            "    def build_tree(path):",
            "        tree = Tree()",
            "        for basename, entry in trees[path].iteritems():",
            "            if isinstance(entry, dict):",
            "                mode = stat.S_IFDIR",
            "                sha = build_tree(pathjoin(path, basename))",
            "            else:",
            "                (mode, sha) = entry",
            "            tree.add(basename, mode, sha)",
            "        object_store.add_object(tree)",
            "        return tree.id",
            "    return build_tree(\"\")",
            "",
            "",
            "def commit_index(object_store, index):",
            "    \"\"\"Create a new tree from an index.",
            "",
            "    :param object_store: Object store to save the tree in",
            "    :param index: Index file",
            "    :note: This function is deprecated, use index.commit() instead.",
            "    :return: Root tree sha.",
            "    \"\"\"",
            "    return commit_tree(object_store, index.iterblobs())",
            "",
            "",
            "def changes_from_tree(names, lookup_entry, object_store, tree,",
            "        want_unchanged=False):",
            "    \"\"\"Find the differences between the contents of a tree and",
            "    a working copy.",
            "",
            "    :param names: Iterable of names in the working copy",
            "    :param lookup_entry: Function to lookup an entry in the working copy",
            "    :param object_store: Object store to use for retrieving tree contents",
            "    :param tree: SHA1 of the root tree, or None for an empty tree",
            "    :param want_unchanged: Whether unchanged files should be reported",
            "    :return: Iterator over tuples with (oldpath, newpath), (oldmode, newmode),",
            "        (oldsha, newsha)",
            "    \"\"\"",
            "    other_names = set(names)",
            "",
            "    if tree is not None:",
            "        for (name, mode, sha) in object_store.iter_tree_contents(tree):",
            "            try:",
            "                (other_sha, other_mode) = lookup_entry(name)",
            "            except KeyError:",
            "                # Was removed",
            "                yield ((name, None), (mode, None), (sha, None))",
            "            else:",
            "                other_names.remove(name)",
            "                if (want_unchanged or other_sha != sha or other_mode != mode):",
            "                    yield ((name, name), (mode, other_mode), (sha, other_sha))",
            "",
            "    # Mention added files",
            "    for name in other_names:",
            "        (other_sha, other_mode) = lookup_entry(name)",
            "        yield ((None, name), (None, other_mode), (None, other_sha))",
            "",
            "",
            "def index_entry_from_stat(stat_val, hex_sha, flags, mode=None):",
            "    \"\"\"Create a new index entry from a stat value.",
            "",
            "    :param stat_val: POSIX stat_result instance",
            "    :param hex_sha: Hex sha of the object",
            "    :param flags: Index flags",
            "    \"\"\"",
            "    if mode is None:",
            "        mode = cleanup_mode(stat_val.st_mode)",
            "    return (stat_val.st_ctime, stat_val.st_mtime, stat_val.st_dev,",
            "            stat_val.st_ino, mode, stat_val.st_uid,",
            "            stat_val.st_gid, stat_val.st_size, hex_sha, flags)",
            "",
            "",
            "def build_file_from_blob(blob, mode, target_path, honor_filemode=True):",
            "    \"\"\"Build a file or symlink on disk based on a Git object.",
            "",
            "    :param obj: The git object",
            "    :param mode: File mode",
            "    :param target_path: Path to write to",
            "    :param honor_filemode: An optional flag to honor core.filemode setting in",
            "        config file, default is core.filemode=True, change executable bit",
            "    \"\"\"",
            "    if stat.S_ISLNK(mode):",
            "        # FIXME: This will fail on Windows. What should we do instead?",
            "        src_path = blob.as_raw_string()",
            "        try:",
            "            os.symlink(src_path, target_path)",
            "        except OSError as e:",
            "            if e.errno == errno.EEXIST:",
            "                os.unlink(target_path)",
            "                os.symlink(src_path, target_path)",
            "            else:",
            "                raise",
            "    else:",
            "        with open(target_path, 'wb') as f:",
            "            # Write out file",
            "            f.write(blob.as_raw_string())",
            "",
            "        if honor_filemode:",
            "            os.chmod(target_path, mode)",
            "",
            "",
            "def validate_path_default(path):",
            "    \"\"\"Default path validator that just checks for .git/.\"\"\"",
            "    return not path.startswith(\".git/\")",
            "",
            "",
            "def build_index_from_tree(prefix, index_path, object_store, tree_id,",
            "                          honor_filemode=True,",
            "                          validate_path=validate_path_default):",
            "    \"\"\"Generate and materialize index from a tree",
            "",
            "    :param tree_id: Tree to materialize",
            "    :param prefix: Target dir for materialized index files",
            "    :param index_path: Target path for generated index",
            "    :param object_store: Non-empty object store holding tree contents",
            "    :param honor_filemode: An optional flag to honor core.filemode setting in",
            "        config file, default is core.filemode=True, change executable bit",
            "    :param validate_path: Function to validate paths to check out;",
            "        default just refuses filenames starting with .git/.",
            "",
            "    :note:: existing index is wiped and contents are not merged",
            "        in a working dir. Suiteable only for fresh clones.",
            "    \"\"\"",
            "",
            "    index = Index(index_path)",
            "",
            "    for entry in object_store.iter_tree_contents(tree_id):",
            "        if not validate_path(entry.path):",
            "            continue",
            "        full_path = os.path.join(prefix, entry.path)",
            "",
            "        if not os.path.exists(os.path.dirname(full_path)):",
            "            os.makedirs(os.path.dirname(full_path))",
            "",
            "        # FIXME: Merge new index into working tree",
            "        obj = object_store[entry.sha]",
            "        build_file_from_blob(obj, entry.mode, full_path,",
            "            honor_filemode=honor_filemode)",
            "        # Add file to index",
            "        st = os.lstat(full_path)",
            "        index[entry.path] = index_entry_from_stat(st, entry.sha, 0)",
            "",
            "    index.write()",
            "",
            "",
            "def blob_from_path_and_stat(path, st):",
            "    \"\"\"Create a blob from a path and a stat object.",
            "",
            "    :param path: Full path to file",
            "    :param st: A stat object",
            "    :return: A `Blob` object",
            "    \"\"\"",
            "    blob = Blob()",
            "    if not stat.S_ISLNK(st.st_mode):",
            "        with open(path, 'rb') as f:",
            "            blob.data = f.read()",
            "    else:",
            "        blob.data = os.readlink(path)",
            "    return blob",
            "",
            "",
            "def get_unstaged_changes(index, path):",
            "    \"\"\"Walk through an index and check for differences against working tree.",
            "",
            "    :param index: index to check",
            "    :param path: path in which to find files",
            "    :return: iterator over paths with unstaged changes",
            "    \"\"\"",
            "    # For each entry in the index check the sha1 & ensure not staged",
            "    for name, entry in index.iteritems():",
            "        fp = os.path.join(path, name)",
            "        blob = blob_from_path_and_stat(fp, os.lstat(fp))",
            "        if blob.id != entry.sha:",
            "            yield name"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "435": [
                "build_index_from_tree"
            ]
        },
        "addLocation": [
            "src.octoprint.filemanager.storage.LocalFileStorage._copy_metadata_entry",
            "dulwich.index.build_index_from_tree"
        ]
    },
    "dulwich/tests/test_index.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 50,
                "afterPatchRowNumber": 50,
                "PatchRowcode": " from dulwich.tests import TestCase"
            },
            "1": {
                "beforePatchRowNumber": 51,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " from dulwich.tests.utils import skipIfPY3"
            },
            "2": {
                "beforePatchRowNumber": 52,
                "afterPatchRowNumber": 52,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 53,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "4": {
                "beforePatchRowNumber": 54,
                "afterPatchRowNumber": 53,
                "PatchRowcode": " @skipIfPY3"
            },
            "5": {
                "beforePatchRowNumber": 55,
                "afterPatchRowNumber": 54,
                "PatchRowcode": " class IndexTestCase(TestCase):"
            },
            "6": {
                "beforePatchRowNumber": 56,
                "afterPatchRowNumber": 55,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": 280,
                "PatchRowcode": "         # Verify no files"
            },
            "8": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 281,
                "PatchRowcode": "         self.assertEqual(['.git'], os.listdir(repo.path))"
            },
            "9": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": 282,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 283,
                "PatchRowcode": "+    def test_git_dir(self):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 284,
                "PatchRowcode": "+        if os.name != 'posix':"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 285,
                "PatchRowcode": "+            self.skipTest(\"test depends on POSIX shell\")"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 286,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 287,
                "PatchRowcode": "+        repo_dir = tempfile.mkdtemp()"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 288,
                "PatchRowcode": "+        repo = Repo.init(repo_dir)"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 289,
                "PatchRowcode": "+        self.addCleanup(shutil.rmtree, repo_dir)"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 290,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 291,
                "PatchRowcode": "+        # Populate repo"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 292,
                "PatchRowcode": "+        filea = Blob.from_string('file a')"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 293,
                "PatchRowcode": "+        filee = Blob.from_string('d')"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 294,
                "PatchRowcode": "+"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 295,
                "PatchRowcode": "+        tree = Tree()"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 296,
                "PatchRowcode": "+        tree['.git/a'] = (stat.S_IFREG | 0o644, filea.id)"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 297,
                "PatchRowcode": "+        tree['c/e'] = (stat.S_IFREG | 0o644, filee.id)"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 298,
                "PatchRowcode": "+"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 299,
                "PatchRowcode": "+        repo.object_store.add_objects([(o, None)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 300,
                "PatchRowcode": "+            for o in [filea, filee, tree]])"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 301,
                "PatchRowcode": "+"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 302,
                "PatchRowcode": "+        build_index_from_tree(repo.path, repo.index_path(),"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 303,
                "PatchRowcode": "+                repo.object_store, tree.id)"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 305,
                "PatchRowcode": "+        # Verify index entries"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 306,
                "PatchRowcode": "+        index = repo.open_index()"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 307,
                "PatchRowcode": "+        self.assertEqual(len(index), 1)"
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 308,
                "PatchRowcode": "+"
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 309,
                "PatchRowcode": "+        # filea"
            },
            "37": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 310,
                "PatchRowcode": "+        apath = os.path.join(repo.path, '.git', 'a')"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 311,
                "PatchRowcode": "+        self.assertFalse(os.path.exists(apath))"
            },
            "39": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 312,
                "PatchRowcode": "+"
            },
            "40": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 313,
                "PatchRowcode": "+        # filee"
            },
            "41": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 314,
                "PatchRowcode": "+        epath = os.path.join(repo.path, 'c', 'e')"
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+        self.assertTrue(os.path.exists(epath))"
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 316,
                "PatchRowcode": "+        self.assertReasonableIndexEntry(index['c/e'],"
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 317,
                "PatchRowcode": "+            stat.S_IFREG | 0o644, 1, filee.id)"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 318,
                "PatchRowcode": "+        self.assertFileContents(epath, 'd')"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 319,
                "PatchRowcode": "+"
            },
            "47": {
                "beforePatchRowNumber": 284,
                "afterPatchRowNumber": 320,
                "PatchRowcode": "     def test_nonempty(self):"
            },
            "48": {
                "beforePatchRowNumber": 285,
                "afterPatchRowNumber": 321,
                "PatchRowcode": "         if os.name != 'posix':"
            },
            "49": {
                "beforePatchRowNumber": 286,
                "afterPatchRowNumber": 322,
                "PatchRowcode": "             self.skipTest(\"test depends on POSIX shell\")"
            }
        },
        "frontPatchFile": [
            "# test_index.py -- Tests for the git index",
            "# Copyright (C) 2008-2009 Jelmer Vernooij <jelmer@samba.org>",
            "#",
            "# This program is free software; you can redistribute it and/or",
            "# modify it under the terms of the GNU General Public License",
            "# as published by the Free Software Foundation; version 2",
            "# or (at your option) any later version of the License.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program; if not, write to the Free Software",
            "# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,",
            "# MA  02110-1301, USA.",
            "",
            "\"\"\"Tests for the index.\"\"\"",
            "",
            "",
            "from io import BytesIO",
            "import os",
            "import shutil",
            "import stat",
            "import struct",
            "import tempfile",
            "",
            "from dulwich.index import (",
            "    Index,",
            "    build_index_from_tree,",
            "    cleanup_mode,",
            "    commit_tree,",
            "    get_unstaged_changes,",
            "    index_entry_from_stat,",
            "    read_index,",
            "    read_index_dict,",
            "    write_cache_time,",
            "    write_index,",
            "    write_index_dict,",
            "    )",
            "from dulwich.object_store import (",
            "    MemoryObjectStore,",
            "    )",
            "from dulwich.objects import (",
            "    Blob,",
            "    Tree,",
            "    )",
            "from dulwich.repo import Repo",
            "from dulwich.tests import TestCase",
            "from dulwich.tests.utils import skipIfPY3",
            "",
            "",
            "@skipIfPY3",
            "class IndexTestCase(TestCase):",
            "",
            "    datadir = os.path.join(os.path.dirname(__file__), 'data/indexes')",
            "",
            "    def get_simple_index(self, name):",
            "        return Index(os.path.join(self.datadir, name))",
            "",
            "",
            "@skipIfPY3",
            "class SimpleIndexTestCase(IndexTestCase):",
            "",
            "    def test_len(self):",
            "        self.assertEqual(1, len(self.get_simple_index(\"index\")))",
            "",
            "    def test_iter(self):",
            "        self.assertEqual(['bla'], list(self.get_simple_index(\"index\")))",
            "",
            "    def test_getitem(self):",
            "        self.assertEqual(((1230680220, 0), (1230680220, 0), 2050, 3761020,",
            "                           33188, 1000, 1000, 0,",
            "                           'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', 0),",
            "                          self.get_simple_index(\"index\")[\"bla\"])",
            "",
            "    def test_empty(self):",
            "        i = self.get_simple_index(\"notanindex\")",
            "        self.assertEqual(0, len(i))",
            "        self.assertFalse(os.path.exists(i._filename))",
            "",
            "    def test_against_empty_tree(self):",
            "        i = self.get_simple_index(\"index\")",
            "        changes = list(i.changes_from_tree(MemoryObjectStore(), None))",
            "        self.assertEqual(1, len(changes))",
            "        (oldname, newname), (oldmode, newmode), (oldsha, newsha) = changes[0]",
            "        self.assertEqual('bla', newname)",
            "        self.assertEqual('e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', newsha)",
            "",
            "",
            "@skipIfPY3",
            "class SimpleIndexWriterTestCase(IndexTestCase):",
            "",
            "    def setUp(self):",
            "        IndexTestCase.setUp(self)",
            "        self.tempdir = tempfile.mkdtemp()",
            "",
            "    def tearDown(self):",
            "        IndexTestCase.tearDown(self)",
            "        shutil.rmtree(self.tempdir)",
            "",
            "    def test_simple_write(self):",
            "        entries = [('barbla', (1230680220, 0), (1230680220, 0), 2050, 3761020,",
            "                    33188, 1000, 1000, 0,",
            "                    'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', 0)]",
            "        filename = os.path.join(self.tempdir, 'test-simple-write-index')",
            "        with open(filename, 'w+') as x:",
            "            write_index(x, entries)",
            "",
            "        with open(filename, 'r') as x:",
            "            self.assertEqual(entries, list(read_index(x)))",
            "",
            "",
            "@skipIfPY3",
            "class ReadIndexDictTests(IndexTestCase):",
            "",
            "    def setUp(self):",
            "        IndexTestCase.setUp(self)",
            "        self.tempdir = tempfile.mkdtemp()",
            "",
            "    def tearDown(self):",
            "        IndexTestCase.tearDown(self)",
            "        shutil.rmtree(self.tempdir)",
            "",
            "    def test_simple_write(self):",
            "        entries = {'barbla': ((1230680220, 0), (1230680220, 0), 2050, 3761020,",
            "                    33188, 1000, 1000, 0,",
            "                    'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', 0)}",
            "        filename = os.path.join(self.tempdir, 'test-simple-write-index')",
            "        with open(filename, 'w+') as x:",
            "            write_index_dict(x, entries)",
            "",
            "        with open(filename, 'r') as x:",
            "            self.assertEqual(entries, read_index_dict(x))",
            "",
            "",
            "@skipIfPY3",
            "class CommitTreeTests(TestCase):",
            "",
            "    def setUp(self):",
            "        super(CommitTreeTests, self).setUp()",
            "        self.store = MemoryObjectStore()",
            "",
            "    def test_single_blob(self):",
            "        blob = Blob()",
            "        blob.data = \"foo\"",
            "        self.store.add_object(blob)",
            "        blobs = [(\"bla\", blob.id, stat.S_IFREG)]",
            "        rootid = commit_tree(self.store, blobs)",
            "        self.assertEqual(rootid, \"1a1e80437220f9312e855c37ac4398b68e5c1d50\")",
            "        self.assertEqual((stat.S_IFREG, blob.id), self.store[rootid][\"bla\"])",
            "        self.assertEqual(set([rootid, blob.id]), set(self.store._data.keys()))",
            "",
            "    def test_nested(self):",
            "        blob = Blob()",
            "        blob.data = \"foo\"",
            "        self.store.add_object(blob)",
            "        blobs = [(\"bla/bar\", blob.id, stat.S_IFREG)]",
            "        rootid = commit_tree(self.store, blobs)",
            "        self.assertEqual(rootid, \"d92b959b216ad0d044671981196781b3258fa537\")",
            "        dirid = self.store[rootid][\"bla\"][1]",
            "        self.assertEqual(dirid, \"c1a1deb9788150829579a8b4efa6311e7b638650\")",
            "        self.assertEqual((stat.S_IFDIR, dirid), self.store[rootid][\"bla\"])",
            "        self.assertEqual((stat.S_IFREG, blob.id), self.store[dirid][\"bar\"])",
            "        self.assertEqual(set([rootid, dirid, blob.id]),",
            "                          set(self.store._data.keys()))",
            "",
            "",
            "@skipIfPY3",
            "class CleanupModeTests(TestCase):",
            "",
            "    def test_file(self):",
            "        self.assertEqual(0o100644, cleanup_mode(0o100000))",
            "",
            "    def test_executable(self):",
            "        self.assertEqual(0o100755, cleanup_mode(0o100711))",
            "",
            "    def test_symlink(self):",
            "        self.assertEqual(0o120000, cleanup_mode(0o120711))",
            "",
            "    def test_dir(self):",
            "        self.assertEqual(0o040000, cleanup_mode(0o40531))",
            "",
            "    def test_submodule(self):",
            "        self.assertEqual(0o160000, cleanup_mode(0o160744))",
            "",
            "",
            "@skipIfPY3",
            "class WriteCacheTimeTests(TestCase):",
            "",
            "    def test_write_string(self):",
            "        f = BytesIO()",
            "        self.assertRaises(TypeError, write_cache_time, f, \"foo\")",
            "",
            "    def test_write_int(self):",
            "        f = BytesIO()",
            "        write_cache_time(f, 434343)",
            "        self.assertEqual(struct.pack(\">LL\", 434343, 0), f.getvalue())",
            "",
            "    def test_write_tuple(self):",
            "        f = BytesIO()",
            "        write_cache_time(f, (434343, 21))",
            "        self.assertEqual(struct.pack(\">LL\", 434343, 21), f.getvalue())",
            "",
            "    def test_write_float(self):",
            "        f = BytesIO()",
            "        write_cache_time(f, 434343.000000021)",
            "        self.assertEqual(struct.pack(\">LL\", 434343, 21), f.getvalue())",
            "",
            "",
            "@skipIfPY3",
            "class IndexEntryFromStatTests(TestCase):",
            "",
            "    def test_simple(self):",
            "        st = os.stat_result((16877, 131078, 64769,",
            "                154, 1000, 1000, 12288,",
            "                1323629595, 1324180496, 1324180496))",
            "        entry = index_entry_from_stat(st, \"22\" * 20, 0)",
            "        self.assertEqual(entry, (",
            "            1324180496,",
            "            1324180496,",
            "            64769,",
            "            131078,",
            "            16384,",
            "            1000,",
            "            1000,",
            "            12288,",
            "            '2222222222222222222222222222222222222222',",
            "            0))",
            "",
            "    def test_override_mode(self):",
            "        st = os.stat_result((stat.S_IFREG + 0o644, 131078, 64769,",
            "                154, 1000, 1000, 12288,",
            "                1323629595, 1324180496, 1324180496))",
            "        entry = index_entry_from_stat(st, \"22\" * 20, 0,",
            "                mode=stat.S_IFREG + 0o755)",
            "        self.assertEqual(entry, (",
            "            1324180496,",
            "            1324180496,",
            "            64769,",
            "            131078,",
            "            33261,",
            "            1000,",
            "            1000,",
            "            12288,",
            "            '2222222222222222222222222222222222222222',",
            "            0))",
            "",
            "",
            "@skipIfPY3",
            "class BuildIndexTests(TestCase):",
            "",
            "    def assertReasonableIndexEntry(self, index_entry, mode, filesize, sha):",
            "        self.assertEqual(index_entry[4], mode)  # mode",
            "        self.assertEqual(index_entry[7], filesize)  # filesize",
            "        self.assertEqual(index_entry[8], sha)  # sha",
            "",
            "    def assertFileContents(self, path, contents, symlink=False):",
            "        if symlink:",
            "            self.assertEqual(os.readlink(path), contents)",
            "        else:",
            "            with open(path, 'rb') as f:",
            "                self.assertEqual(f.read(), contents)",
            "",
            "    def test_empty(self):",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        tree = Tree()",
            "        repo.object_store.add_object(tree)",
            "",
            "        build_index_from_tree(repo.path, repo.index_path(),",
            "                repo.object_store, tree.id)",
            "",
            "        # Verify index entries",
            "        index = repo.open_index()",
            "        self.assertEqual(len(index), 0)",
            "",
            "        # Verify no files",
            "        self.assertEqual(['.git'], os.listdir(repo.path))",
            "",
            "    def test_nonempty(self):",
            "        if os.name != 'posix':",
            "            self.skipTest(\"test depends on POSIX shell\")",
            "",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        # Populate repo",
            "        filea = Blob.from_string('file a')",
            "        fileb = Blob.from_string('file b')",
            "        filed = Blob.from_string('file d')",
            "        filee = Blob.from_string('d')",
            "",
            "        tree = Tree()",
            "        tree['a'] = (stat.S_IFREG | 0o644, filea.id)",
            "        tree['b'] = (stat.S_IFREG | 0o644, fileb.id)",
            "        tree['c/d'] = (stat.S_IFREG | 0o644, filed.id)",
            "        tree['c/e'] = (stat.S_IFLNK, filee.id)  # symlink",
            "",
            "        repo.object_store.add_objects([(o, None)",
            "            for o in [filea, fileb, filed, filee, tree]])",
            "",
            "        build_index_from_tree(repo.path, repo.index_path(),",
            "                repo.object_store, tree.id)",
            "",
            "        # Verify index entries",
            "        index = repo.open_index()",
            "        self.assertEqual(len(index), 4)",
            "",
            "        # filea",
            "        apath = os.path.join(repo.path, 'a')",
            "        self.assertTrue(os.path.exists(apath))",
            "        self.assertReasonableIndexEntry(index['a'],",
            "            stat.S_IFREG | 0o644, 6, filea.id)",
            "        self.assertFileContents(apath, 'file a')",
            "",
            "        # fileb",
            "        bpath = os.path.join(repo.path, 'b')",
            "        self.assertTrue(os.path.exists(bpath))",
            "        self.assertReasonableIndexEntry(index['b'],",
            "            stat.S_IFREG | 0o644, 6, fileb.id)",
            "        self.assertFileContents(bpath, 'file b')",
            "",
            "        # filed",
            "        dpath = os.path.join(repo.path, 'c', 'd')",
            "        self.assertTrue(os.path.exists(dpath))",
            "        self.assertReasonableIndexEntry(index['c/d'],",
            "            stat.S_IFREG | 0o644, 6, filed.id)",
            "        self.assertFileContents(dpath, 'file d')",
            "",
            "        # symlink to d",
            "        epath = os.path.join(repo.path, 'c', 'e')",
            "        self.assertTrue(os.path.exists(epath))",
            "        self.assertReasonableIndexEntry(index['c/e'],",
            "            stat.S_IFLNK, 1, filee.id)",
            "        self.assertFileContents(epath, 'd', symlink=True)",
            "",
            "        # Verify no extra files",
            "        self.assertEqual(['.git', 'a', 'b', 'c'],",
            "            sorted(os.listdir(repo.path)))",
            "        self.assertEqual(['d', 'e'],",
            "            sorted(os.listdir(os.path.join(repo.path, 'c'))))",
            "",
            "",
            "@skipIfPY3",
            "class GetUnstagedChangesTests(TestCase):",
            "",
            "    def test_get_unstaged_changes(self):",
            "        \"\"\"Unit test for get_unstaged_changes.\"\"\"",
            "",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        # Commit a dummy file then modify it",
            "        foo1_fullpath = os.path.join(repo_dir, 'foo1')",
            "        with open(foo1_fullpath, 'w') as f:",
            "            f.write('origstuff')",
            "",
            "        foo2_fullpath = os.path.join(repo_dir, 'foo2')",
            "        with open(foo2_fullpath, 'w') as f:",
            "            f.write('origstuff')",
            "",
            "        repo.stage(['foo1', 'foo2'])",
            "        repo.do_commit('test status', author='', committer='')",
            "",
            "        with open(foo1_fullpath, 'w') as f:",
            "            f.write('newstuff')",
            "",
            "        # modify access and modify time of path",
            "        os.utime(foo1_fullpath, (0, 0))",
            "",
            "        changes = get_unstaged_changes(repo.open_index(), repo_dir)",
            "",
            "        self.assertEqual(list(changes), ['foo1'])"
        ],
        "afterPatchFile": [
            "# test_index.py -- Tests for the git index",
            "# Copyright (C) 2008-2009 Jelmer Vernooij <jelmer@samba.org>",
            "#",
            "# This program is free software; you can redistribute it and/or",
            "# modify it under the terms of the GNU General Public License",
            "# as published by the Free Software Foundation; version 2",
            "# or (at your option) any later version of the License.",
            "#",
            "# This program is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with this program; if not, write to the Free Software",
            "# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,",
            "# MA  02110-1301, USA.",
            "",
            "\"\"\"Tests for the index.\"\"\"",
            "",
            "",
            "from io import BytesIO",
            "import os",
            "import shutil",
            "import stat",
            "import struct",
            "import tempfile",
            "",
            "from dulwich.index import (",
            "    Index,",
            "    build_index_from_tree,",
            "    cleanup_mode,",
            "    commit_tree,",
            "    get_unstaged_changes,",
            "    index_entry_from_stat,",
            "    read_index,",
            "    read_index_dict,",
            "    write_cache_time,",
            "    write_index,",
            "    write_index_dict,",
            "    )",
            "from dulwich.object_store import (",
            "    MemoryObjectStore,",
            "    )",
            "from dulwich.objects import (",
            "    Blob,",
            "    Tree,",
            "    )",
            "from dulwich.repo import Repo",
            "from dulwich.tests import TestCase",
            "from dulwich.tests.utils import skipIfPY3",
            "",
            "@skipIfPY3",
            "class IndexTestCase(TestCase):",
            "",
            "    datadir = os.path.join(os.path.dirname(__file__), 'data/indexes')",
            "",
            "    def get_simple_index(self, name):",
            "        return Index(os.path.join(self.datadir, name))",
            "",
            "",
            "@skipIfPY3",
            "class SimpleIndexTestCase(IndexTestCase):",
            "",
            "    def test_len(self):",
            "        self.assertEqual(1, len(self.get_simple_index(\"index\")))",
            "",
            "    def test_iter(self):",
            "        self.assertEqual(['bla'], list(self.get_simple_index(\"index\")))",
            "",
            "    def test_getitem(self):",
            "        self.assertEqual(((1230680220, 0), (1230680220, 0), 2050, 3761020,",
            "                           33188, 1000, 1000, 0,",
            "                           'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', 0),",
            "                          self.get_simple_index(\"index\")[\"bla\"])",
            "",
            "    def test_empty(self):",
            "        i = self.get_simple_index(\"notanindex\")",
            "        self.assertEqual(0, len(i))",
            "        self.assertFalse(os.path.exists(i._filename))",
            "",
            "    def test_against_empty_tree(self):",
            "        i = self.get_simple_index(\"index\")",
            "        changes = list(i.changes_from_tree(MemoryObjectStore(), None))",
            "        self.assertEqual(1, len(changes))",
            "        (oldname, newname), (oldmode, newmode), (oldsha, newsha) = changes[0]",
            "        self.assertEqual('bla', newname)",
            "        self.assertEqual('e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', newsha)",
            "",
            "",
            "@skipIfPY3",
            "class SimpleIndexWriterTestCase(IndexTestCase):",
            "",
            "    def setUp(self):",
            "        IndexTestCase.setUp(self)",
            "        self.tempdir = tempfile.mkdtemp()",
            "",
            "    def tearDown(self):",
            "        IndexTestCase.tearDown(self)",
            "        shutil.rmtree(self.tempdir)",
            "",
            "    def test_simple_write(self):",
            "        entries = [('barbla', (1230680220, 0), (1230680220, 0), 2050, 3761020,",
            "                    33188, 1000, 1000, 0,",
            "                    'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', 0)]",
            "        filename = os.path.join(self.tempdir, 'test-simple-write-index')",
            "        with open(filename, 'w+') as x:",
            "            write_index(x, entries)",
            "",
            "        with open(filename, 'r') as x:",
            "            self.assertEqual(entries, list(read_index(x)))",
            "",
            "",
            "@skipIfPY3",
            "class ReadIndexDictTests(IndexTestCase):",
            "",
            "    def setUp(self):",
            "        IndexTestCase.setUp(self)",
            "        self.tempdir = tempfile.mkdtemp()",
            "",
            "    def tearDown(self):",
            "        IndexTestCase.tearDown(self)",
            "        shutil.rmtree(self.tempdir)",
            "",
            "    def test_simple_write(self):",
            "        entries = {'barbla': ((1230680220, 0), (1230680220, 0), 2050, 3761020,",
            "                    33188, 1000, 1000, 0,",
            "                    'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391', 0)}",
            "        filename = os.path.join(self.tempdir, 'test-simple-write-index')",
            "        with open(filename, 'w+') as x:",
            "            write_index_dict(x, entries)",
            "",
            "        with open(filename, 'r') as x:",
            "            self.assertEqual(entries, read_index_dict(x))",
            "",
            "",
            "@skipIfPY3",
            "class CommitTreeTests(TestCase):",
            "",
            "    def setUp(self):",
            "        super(CommitTreeTests, self).setUp()",
            "        self.store = MemoryObjectStore()",
            "",
            "    def test_single_blob(self):",
            "        blob = Blob()",
            "        blob.data = \"foo\"",
            "        self.store.add_object(blob)",
            "        blobs = [(\"bla\", blob.id, stat.S_IFREG)]",
            "        rootid = commit_tree(self.store, blobs)",
            "        self.assertEqual(rootid, \"1a1e80437220f9312e855c37ac4398b68e5c1d50\")",
            "        self.assertEqual((stat.S_IFREG, blob.id), self.store[rootid][\"bla\"])",
            "        self.assertEqual(set([rootid, blob.id]), set(self.store._data.keys()))",
            "",
            "    def test_nested(self):",
            "        blob = Blob()",
            "        blob.data = \"foo\"",
            "        self.store.add_object(blob)",
            "        blobs = [(\"bla/bar\", blob.id, stat.S_IFREG)]",
            "        rootid = commit_tree(self.store, blobs)",
            "        self.assertEqual(rootid, \"d92b959b216ad0d044671981196781b3258fa537\")",
            "        dirid = self.store[rootid][\"bla\"][1]",
            "        self.assertEqual(dirid, \"c1a1deb9788150829579a8b4efa6311e7b638650\")",
            "        self.assertEqual((stat.S_IFDIR, dirid), self.store[rootid][\"bla\"])",
            "        self.assertEqual((stat.S_IFREG, blob.id), self.store[dirid][\"bar\"])",
            "        self.assertEqual(set([rootid, dirid, blob.id]),",
            "                          set(self.store._data.keys()))",
            "",
            "",
            "@skipIfPY3",
            "class CleanupModeTests(TestCase):",
            "",
            "    def test_file(self):",
            "        self.assertEqual(0o100644, cleanup_mode(0o100000))",
            "",
            "    def test_executable(self):",
            "        self.assertEqual(0o100755, cleanup_mode(0o100711))",
            "",
            "    def test_symlink(self):",
            "        self.assertEqual(0o120000, cleanup_mode(0o120711))",
            "",
            "    def test_dir(self):",
            "        self.assertEqual(0o040000, cleanup_mode(0o40531))",
            "",
            "    def test_submodule(self):",
            "        self.assertEqual(0o160000, cleanup_mode(0o160744))",
            "",
            "",
            "@skipIfPY3",
            "class WriteCacheTimeTests(TestCase):",
            "",
            "    def test_write_string(self):",
            "        f = BytesIO()",
            "        self.assertRaises(TypeError, write_cache_time, f, \"foo\")",
            "",
            "    def test_write_int(self):",
            "        f = BytesIO()",
            "        write_cache_time(f, 434343)",
            "        self.assertEqual(struct.pack(\">LL\", 434343, 0), f.getvalue())",
            "",
            "    def test_write_tuple(self):",
            "        f = BytesIO()",
            "        write_cache_time(f, (434343, 21))",
            "        self.assertEqual(struct.pack(\">LL\", 434343, 21), f.getvalue())",
            "",
            "    def test_write_float(self):",
            "        f = BytesIO()",
            "        write_cache_time(f, 434343.000000021)",
            "        self.assertEqual(struct.pack(\">LL\", 434343, 21), f.getvalue())",
            "",
            "",
            "@skipIfPY3",
            "class IndexEntryFromStatTests(TestCase):",
            "",
            "    def test_simple(self):",
            "        st = os.stat_result((16877, 131078, 64769,",
            "                154, 1000, 1000, 12288,",
            "                1323629595, 1324180496, 1324180496))",
            "        entry = index_entry_from_stat(st, \"22\" * 20, 0)",
            "        self.assertEqual(entry, (",
            "            1324180496,",
            "            1324180496,",
            "            64769,",
            "            131078,",
            "            16384,",
            "            1000,",
            "            1000,",
            "            12288,",
            "            '2222222222222222222222222222222222222222',",
            "            0))",
            "",
            "    def test_override_mode(self):",
            "        st = os.stat_result((stat.S_IFREG + 0o644, 131078, 64769,",
            "                154, 1000, 1000, 12288,",
            "                1323629595, 1324180496, 1324180496))",
            "        entry = index_entry_from_stat(st, \"22\" * 20, 0,",
            "                mode=stat.S_IFREG + 0o755)",
            "        self.assertEqual(entry, (",
            "            1324180496,",
            "            1324180496,",
            "            64769,",
            "            131078,",
            "            33261,",
            "            1000,",
            "            1000,",
            "            12288,",
            "            '2222222222222222222222222222222222222222',",
            "            0))",
            "",
            "",
            "@skipIfPY3",
            "class BuildIndexTests(TestCase):",
            "",
            "    def assertReasonableIndexEntry(self, index_entry, mode, filesize, sha):",
            "        self.assertEqual(index_entry[4], mode)  # mode",
            "        self.assertEqual(index_entry[7], filesize)  # filesize",
            "        self.assertEqual(index_entry[8], sha)  # sha",
            "",
            "    def assertFileContents(self, path, contents, symlink=False):",
            "        if symlink:",
            "            self.assertEqual(os.readlink(path), contents)",
            "        else:",
            "            with open(path, 'rb') as f:",
            "                self.assertEqual(f.read(), contents)",
            "",
            "    def test_empty(self):",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        tree = Tree()",
            "        repo.object_store.add_object(tree)",
            "",
            "        build_index_from_tree(repo.path, repo.index_path(),",
            "                repo.object_store, tree.id)",
            "",
            "        # Verify index entries",
            "        index = repo.open_index()",
            "        self.assertEqual(len(index), 0)",
            "",
            "        # Verify no files",
            "        self.assertEqual(['.git'], os.listdir(repo.path))",
            "",
            "    def test_git_dir(self):",
            "        if os.name != 'posix':",
            "            self.skipTest(\"test depends on POSIX shell\")",
            "",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        # Populate repo",
            "        filea = Blob.from_string('file a')",
            "        filee = Blob.from_string('d')",
            "",
            "        tree = Tree()",
            "        tree['.git/a'] = (stat.S_IFREG | 0o644, filea.id)",
            "        tree['c/e'] = (stat.S_IFREG | 0o644, filee.id)",
            "",
            "        repo.object_store.add_objects([(o, None)",
            "            for o in [filea, filee, tree]])",
            "",
            "        build_index_from_tree(repo.path, repo.index_path(),",
            "                repo.object_store, tree.id)",
            "",
            "        # Verify index entries",
            "        index = repo.open_index()",
            "        self.assertEqual(len(index), 1)",
            "",
            "        # filea",
            "        apath = os.path.join(repo.path, '.git', 'a')",
            "        self.assertFalse(os.path.exists(apath))",
            "",
            "        # filee",
            "        epath = os.path.join(repo.path, 'c', 'e')",
            "        self.assertTrue(os.path.exists(epath))",
            "        self.assertReasonableIndexEntry(index['c/e'],",
            "            stat.S_IFREG | 0o644, 1, filee.id)",
            "        self.assertFileContents(epath, 'd')",
            "",
            "    def test_nonempty(self):",
            "        if os.name != 'posix':",
            "            self.skipTest(\"test depends on POSIX shell\")",
            "",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        # Populate repo",
            "        filea = Blob.from_string('file a')",
            "        fileb = Blob.from_string('file b')",
            "        filed = Blob.from_string('file d')",
            "        filee = Blob.from_string('d')",
            "",
            "        tree = Tree()",
            "        tree['a'] = (stat.S_IFREG | 0o644, filea.id)",
            "        tree['b'] = (stat.S_IFREG | 0o644, fileb.id)",
            "        tree['c/d'] = (stat.S_IFREG | 0o644, filed.id)",
            "        tree['c/e'] = (stat.S_IFLNK, filee.id)  # symlink",
            "",
            "        repo.object_store.add_objects([(o, None)",
            "            for o in [filea, fileb, filed, filee, tree]])",
            "",
            "        build_index_from_tree(repo.path, repo.index_path(),",
            "                repo.object_store, tree.id)",
            "",
            "        # Verify index entries",
            "        index = repo.open_index()",
            "        self.assertEqual(len(index), 4)",
            "",
            "        # filea",
            "        apath = os.path.join(repo.path, 'a')",
            "        self.assertTrue(os.path.exists(apath))",
            "        self.assertReasonableIndexEntry(index['a'],",
            "            stat.S_IFREG | 0o644, 6, filea.id)",
            "        self.assertFileContents(apath, 'file a')",
            "",
            "        # fileb",
            "        bpath = os.path.join(repo.path, 'b')",
            "        self.assertTrue(os.path.exists(bpath))",
            "        self.assertReasonableIndexEntry(index['b'],",
            "            stat.S_IFREG | 0o644, 6, fileb.id)",
            "        self.assertFileContents(bpath, 'file b')",
            "",
            "        # filed",
            "        dpath = os.path.join(repo.path, 'c', 'd')",
            "        self.assertTrue(os.path.exists(dpath))",
            "        self.assertReasonableIndexEntry(index['c/d'],",
            "            stat.S_IFREG | 0o644, 6, filed.id)",
            "        self.assertFileContents(dpath, 'file d')",
            "",
            "        # symlink to d",
            "        epath = os.path.join(repo.path, 'c', 'e')",
            "        self.assertTrue(os.path.exists(epath))",
            "        self.assertReasonableIndexEntry(index['c/e'],",
            "            stat.S_IFLNK, 1, filee.id)",
            "        self.assertFileContents(epath, 'd', symlink=True)",
            "",
            "        # Verify no extra files",
            "        self.assertEqual(['.git', 'a', 'b', 'c'],",
            "            sorted(os.listdir(repo.path)))",
            "        self.assertEqual(['d', 'e'],",
            "            sorted(os.listdir(os.path.join(repo.path, 'c'))))",
            "",
            "",
            "@skipIfPY3",
            "class GetUnstagedChangesTests(TestCase):",
            "",
            "    def test_get_unstaged_changes(self):",
            "        \"\"\"Unit test for get_unstaged_changes.\"\"\"",
            "",
            "        repo_dir = tempfile.mkdtemp()",
            "        repo = Repo.init(repo_dir)",
            "        self.addCleanup(shutil.rmtree, repo_dir)",
            "",
            "        # Commit a dummy file then modify it",
            "        foo1_fullpath = os.path.join(repo_dir, 'foo1')",
            "        with open(foo1_fullpath, 'w') as f:",
            "            f.write('origstuff')",
            "",
            "        foo2_fullpath = os.path.join(repo_dir, 'foo2')",
            "        with open(foo2_fullpath, 'w') as f:",
            "            f.write('origstuff')",
            "",
            "        repo.stage(['foo1', 'foo2'])",
            "        repo.do_commit('test status', author='', committer='')",
            "",
            "        with open(foo1_fullpath, 'w') as f:",
            "            f.write('newstuff')",
            "",
            "        # modify access and modify time of path",
            "        os.utime(foo1_fullpath, (0, 0))",
            "",
            "        changes = get_unstaged_changes(repo.open_index(), repo_dir)",
            "",
            "        self.assertEqual(list(changes), ['foo1'])"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "53": []
        },
        "addLocation": []
    }
}