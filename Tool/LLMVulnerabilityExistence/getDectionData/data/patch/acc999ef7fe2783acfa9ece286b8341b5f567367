{
    "src/werkzeug/middleware/shared_data.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 22,
                "PatchRowcode": " from ..filesystem import get_filesystem_encoding"
            },
            "1": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " from ..http import http_date"
            },
            "2": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " from ..http import is_resource_modified"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+from ..security import safe_join"
            },
            "4": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " from ..wsgi import get_path_info"
            },
            "5": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": 27,
                "PatchRowcode": " from ..wsgi import wrap_file"
            },
            "6": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": 28,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "             if path is None:"
            },
            "8": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "                 return None, None"
            },
            "9": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 152,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            path = posixpath.join(package_path, path)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 153,
                "PatchRowcode": "+            path = safe_join(package_path, path)"
            },
            "12": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 154,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 155,
                "PatchRowcode": "             if not provider.has_resource(path):"
            },
            "14": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "                 return None, None"
            },
            "15": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "     def get_directory_loader(self, directory):"
            },
            "16": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 172,
                "PatchRowcode": "         def loader(path):"
            },
            "17": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "             if path is not None:"
            },
            "18": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                path = os.path.join(directory, path)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 174,
                "PatchRowcode": "+                path = safe_join(directory, path)"
            },
            "20": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 175,
                "PatchRowcode": "             else:"
            },
            "21": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 176,
                "PatchRowcode": "                 path = directory"
            },
            "22": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 177,
                "PatchRowcode": " "
            },
            "23": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 193,
                "PatchRowcode": "         )"
            },
            "24": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": 194,
                "PatchRowcode": " "
            },
            "25": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "     def __call__(self, environ, start_response):"
            },
            "26": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cleaned_path = get_path_info(environ)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 196,
                "PatchRowcode": "+        path = get_path_info(environ)"
            },
            "28": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 197,
                "PatchRowcode": " "
            },
            "29": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "         if PY2:"
            },
            "30": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            cleaned_path = cleaned_path.encode(get_filesystem_encoding())"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 199,
                "PatchRowcode": "+            path = path.encode(get_filesystem_encoding())"
            },
            "32": {
                "beforePatchRowNumber": 199,
                "afterPatchRowNumber": 200,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 200,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # sanitize the path for non unix systems"
            },
            "34": {
                "beforePatchRowNumber": 201,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        cleaned_path = cleaned_path.strip(\"/\")"
            },
            "35": {
                "beforePatchRowNumber": 202,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "36": {
                "beforePatchRowNumber": 203,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for sep in os.sep, os.altsep:"
            },
            "37": {
                "beforePatchRowNumber": 204,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if sep and sep != \"/\":"
            },
            "38": {
                "beforePatchRowNumber": 205,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                cleaned_path = cleaned_path.replace(sep, \"/\")"
            },
            "39": {
                "beforePatchRowNumber": 206,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "40": {
                "beforePatchRowNumber": 207,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path = \"/\" + \"/\".join(x for x in cleaned_path.split(\"/\") if x and x != \"..\")"
            },
            "41": {
                "beforePatchRowNumber": 208,
                "afterPatchRowNumber": 201,
                "PatchRowcode": "         file_loader = None"
            },
            "42": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 202,
                "PatchRowcode": " "
            },
            "43": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 203,
                "PatchRowcode": "         for search_path, loader in self.exports:"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Serve Shared Static Files",
            "=========================",
            "",
            ".. autoclass:: SharedDataMiddleware",
            "    :members: is_allowed",
            "",
            ":copyright: 2007 Pallets",
            ":license: BSD-3-Clause",
            "\"\"\"",
            "import mimetypes",
            "import os",
            "import posixpath",
            "from datetime import datetime",
            "from io import BytesIO",
            "from time import mktime",
            "from time import time",
            "from zlib import adler32",
            "",
            "from .._compat import PY2",
            "from .._compat import string_types",
            "from ..filesystem import get_filesystem_encoding",
            "from ..http import http_date",
            "from ..http import is_resource_modified",
            "from ..wsgi import get_path_info",
            "from ..wsgi import wrap_file",
            "",
            "",
            "class SharedDataMiddleware(object):",
            "",
            "    \"\"\"A WSGI middleware that provides static content for development",
            "    environments or simple server setups. Usage is quite simple::",
            "",
            "        import os",
            "        from werkzeug.wsgi import SharedDataMiddleware",
            "",
            "        app = SharedDataMiddleware(app, {",
            "            '/static': os.path.join(os.path.dirname(__file__), 'static')",
            "        })",
            "",
            "    The contents of the folder ``./shared`` will now be available on",
            "    ``http://example.com/shared/``.  This is pretty useful during development",
            "    because a standalone media server is not required.  One can also mount",
            "    files on the root folder and still continue to use the application because",
            "    the shared data middleware forwards all unhandled requests to the",
            "    application, even if the requests are below one of the shared folders.",
            "",
            "    If `pkg_resources` is available you can also tell the middleware to serve",
            "    files from package data::",
            "",
            "        app = SharedDataMiddleware(app, {",
            "            '/static': ('myapplication', 'static')",
            "        })",
            "",
            "    This will then serve the ``static`` folder in the `myapplication`",
            "    Python package.",
            "",
            "    The optional `disallow` parameter can be a list of :func:`~fnmatch.fnmatch`",
            "    rules for files that are not accessible from the web.  If `cache` is set to",
            "    `False` no caching headers are sent.",
            "",
            "    Currently the middleware does not support non ASCII filenames.  If the",
            "    encoding on the file system happens to be the encoding of the URI it may",
            "    work but this could also be by accident.  We strongly suggest using ASCII",
            "    only file names for static files.",
            "",
            "    The middleware will guess the mimetype using the Python `mimetype`",
            "    module.  If it's unable to figure out the charset it will fall back",
            "    to `fallback_mimetype`.",
            "",
            "    .. versionchanged:: 0.5",
            "       The cache timeout is configurable now.",
            "",
            "    .. versionadded:: 0.6",
            "       The `fallback_mimetype` parameter was added.",
            "",
            "    :param app: the application to wrap.  If you don't want to wrap an",
            "                application you can pass it :exc:`NotFound`.",
            "    :param exports: a list or dict of exported files and folders.",
            "    :param disallow: a list of :func:`~fnmatch.fnmatch` rules.",
            "    :param fallback_mimetype: the fallback mimetype for unknown files.",
            "    :param cache: enable or disable caching headers.",
            "    :param cache_timeout: the cache timeout in seconds for the headers.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        app,",
            "        exports,",
            "        disallow=None,",
            "        cache=True,",
            "        cache_timeout=60 * 60 * 12,",
            "        fallback_mimetype=\"text/plain\",",
            "    ):",
            "        self.app = app",
            "        self.exports = []",
            "        self.cache = cache",
            "        self.cache_timeout = cache_timeout",
            "",
            "        if hasattr(exports, \"items\"):",
            "            exports = exports.items()",
            "",
            "        for key, value in exports:",
            "            if isinstance(value, tuple):",
            "                loader = self.get_package_loader(*value)",
            "            elif isinstance(value, string_types):",
            "                if os.path.isfile(value):",
            "                    loader = self.get_file_loader(value)",
            "                else:",
            "                    loader = self.get_directory_loader(value)",
            "            else:",
            "                raise TypeError(\"unknown def %r\" % value)",
            "",
            "            self.exports.append((key, loader))",
            "",
            "        if disallow is not None:",
            "            from fnmatch import fnmatch",
            "",
            "            self.is_allowed = lambda x: not fnmatch(x, disallow)",
            "",
            "        self.fallback_mimetype = fallback_mimetype",
            "",
            "    def is_allowed(self, filename):",
            "        \"\"\"Subclasses can override this method to disallow the access to",
            "        certain files.  However by providing `disallow` in the constructor",
            "        this method is overwritten.",
            "        \"\"\"",
            "        return True",
            "",
            "    def _opener(self, filename):",
            "        return lambda: (",
            "            open(filename, \"rb\"),",
            "            datetime.utcfromtimestamp(os.path.getmtime(filename)),",
            "            int(os.path.getsize(filename)),",
            "        )",
            "",
            "    def get_file_loader(self, filename):",
            "        return lambda x: (os.path.basename(filename), self._opener(filename))",
            "",
            "    def get_package_loader(self, package, package_path):",
            "        from pkg_resources import DefaultProvider, ResourceManager, get_provider",
            "",
            "        loadtime = datetime.utcnow()",
            "        provider = get_provider(package)",
            "        manager = ResourceManager()",
            "        filesystem_bound = isinstance(provider, DefaultProvider)",
            "",
            "        def loader(path):",
            "            if path is None:",
            "                return None, None",
            "",
            "            path = posixpath.join(package_path, path)",
            "",
            "            if not provider.has_resource(path):",
            "                return None, None",
            "",
            "            basename = posixpath.basename(path)",
            "",
            "            if filesystem_bound:",
            "                return (",
            "                    basename,",
            "                    self._opener(provider.get_resource_filename(manager, path)),",
            "                )",
            "",
            "            s = provider.get_resource_string(manager, path)",
            "            return basename, lambda: (BytesIO(s), loadtime, len(s))",
            "",
            "        return loader",
            "",
            "    def get_directory_loader(self, directory):",
            "        def loader(path):",
            "            if path is not None:",
            "                path = os.path.join(directory, path)",
            "            else:",
            "                path = directory",
            "",
            "            if os.path.isfile(path):",
            "                return os.path.basename(path), self._opener(path)",
            "",
            "            return None, None",
            "",
            "        return loader",
            "",
            "    def generate_etag(self, mtime, file_size, real_filename):",
            "        if not isinstance(real_filename, bytes):",
            "            real_filename = real_filename.encode(get_filesystem_encoding())",
            "",
            "        return \"wzsdm-%d-%s-%s\" % (",
            "            mktime(mtime.timetuple()),",
            "            file_size,",
            "            adler32(real_filename) & 0xFFFFFFFF,",
            "        )",
            "",
            "    def __call__(self, environ, start_response):",
            "        cleaned_path = get_path_info(environ)",
            "",
            "        if PY2:",
            "            cleaned_path = cleaned_path.encode(get_filesystem_encoding())",
            "",
            "        # sanitize the path for non unix systems",
            "        cleaned_path = cleaned_path.strip(\"/\")",
            "",
            "        for sep in os.sep, os.altsep:",
            "            if sep and sep != \"/\":",
            "                cleaned_path = cleaned_path.replace(sep, \"/\")",
            "",
            "        path = \"/\" + \"/\".join(x for x in cleaned_path.split(\"/\") if x and x != \"..\")",
            "        file_loader = None",
            "",
            "        for search_path, loader in self.exports:",
            "            if search_path == path:",
            "                real_filename, file_loader = loader(None)",
            "",
            "                if file_loader is not None:",
            "                    break",
            "",
            "            if not search_path.endswith(\"/\"):",
            "                search_path += \"/\"",
            "",
            "            if path.startswith(search_path):",
            "                real_filename, file_loader = loader(path[len(search_path) :])",
            "",
            "                if file_loader is not None:",
            "                    break",
            "",
            "        if file_loader is None or not self.is_allowed(real_filename):",
            "            return self.app(environ, start_response)",
            "",
            "        guessed_type = mimetypes.guess_type(real_filename)",
            "        mime_type = guessed_type[0] or self.fallback_mimetype",
            "        f, mtime, file_size = file_loader()",
            "",
            "        headers = [(\"Date\", http_date())]",
            "",
            "        if self.cache:",
            "            timeout = self.cache_timeout",
            "            etag = self.generate_etag(mtime, file_size, real_filename)",
            "            headers += [",
            "                (\"Etag\", '\"%s\"' % etag),",
            "                (\"Cache-Control\", \"max-age=%d, public\" % timeout),",
            "            ]",
            "",
            "            if not is_resource_modified(environ, etag, last_modified=mtime):",
            "                f.close()",
            "                start_response(\"304 Not Modified\", headers)",
            "                return []",
            "",
            "            headers.append((\"Expires\", http_date(time() + timeout)))",
            "        else:",
            "            headers.append((\"Cache-Control\", \"public\"))",
            "",
            "        headers.extend(",
            "            (",
            "                (\"Content-Type\", mime_type),",
            "                (\"Content-Length\", str(file_size)),",
            "                (\"Last-Modified\", http_date(mtime)),",
            "            )",
            "        )",
            "        start_response(\"200 OK\", headers)",
            "        return wrap_file(environ, f)"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Serve Shared Static Files",
            "=========================",
            "",
            ".. autoclass:: SharedDataMiddleware",
            "    :members: is_allowed",
            "",
            ":copyright: 2007 Pallets",
            ":license: BSD-3-Clause",
            "\"\"\"",
            "import mimetypes",
            "import os",
            "import posixpath",
            "from datetime import datetime",
            "from io import BytesIO",
            "from time import mktime",
            "from time import time",
            "from zlib import adler32",
            "",
            "from .._compat import PY2",
            "from .._compat import string_types",
            "from ..filesystem import get_filesystem_encoding",
            "from ..http import http_date",
            "from ..http import is_resource_modified",
            "from ..security import safe_join",
            "from ..wsgi import get_path_info",
            "from ..wsgi import wrap_file",
            "",
            "",
            "class SharedDataMiddleware(object):",
            "",
            "    \"\"\"A WSGI middleware that provides static content for development",
            "    environments or simple server setups. Usage is quite simple::",
            "",
            "        import os",
            "        from werkzeug.wsgi import SharedDataMiddleware",
            "",
            "        app = SharedDataMiddleware(app, {",
            "            '/static': os.path.join(os.path.dirname(__file__), 'static')",
            "        })",
            "",
            "    The contents of the folder ``./shared`` will now be available on",
            "    ``http://example.com/shared/``.  This is pretty useful during development",
            "    because a standalone media server is not required.  One can also mount",
            "    files on the root folder and still continue to use the application because",
            "    the shared data middleware forwards all unhandled requests to the",
            "    application, even if the requests are below one of the shared folders.",
            "",
            "    If `pkg_resources` is available you can also tell the middleware to serve",
            "    files from package data::",
            "",
            "        app = SharedDataMiddleware(app, {",
            "            '/static': ('myapplication', 'static')",
            "        })",
            "",
            "    This will then serve the ``static`` folder in the `myapplication`",
            "    Python package.",
            "",
            "    The optional `disallow` parameter can be a list of :func:`~fnmatch.fnmatch`",
            "    rules for files that are not accessible from the web.  If `cache` is set to",
            "    `False` no caching headers are sent.",
            "",
            "    Currently the middleware does not support non ASCII filenames.  If the",
            "    encoding on the file system happens to be the encoding of the URI it may",
            "    work but this could also be by accident.  We strongly suggest using ASCII",
            "    only file names for static files.",
            "",
            "    The middleware will guess the mimetype using the Python `mimetype`",
            "    module.  If it's unable to figure out the charset it will fall back",
            "    to `fallback_mimetype`.",
            "",
            "    .. versionchanged:: 0.5",
            "       The cache timeout is configurable now.",
            "",
            "    .. versionadded:: 0.6",
            "       The `fallback_mimetype` parameter was added.",
            "",
            "    :param app: the application to wrap.  If you don't want to wrap an",
            "                application you can pass it :exc:`NotFound`.",
            "    :param exports: a list or dict of exported files and folders.",
            "    :param disallow: a list of :func:`~fnmatch.fnmatch` rules.",
            "    :param fallback_mimetype: the fallback mimetype for unknown files.",
            "    :param cache: enable or disable caching headers.",
            "    :param cache_timeout: the cache timeout in seconds for the headers.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        app,",
            "        exports,",
            "        disallow=None,",
            "        cache=True,",
            "        cache_timeout=60 * 60 * 12,",
            "        fallback_mimetype=\"text/plain\",",
            "    ):",
            "        self.app = app",
            "        self.exports = []",
            "        self.cache = cache",
            "        self.cache_timeout = cache_timeout",
            "",
            "        if hasattr(exports, \"items\"):",
            "            exports = exports.items()",
            "",
            "        for key, value in exports:",
            "            if isinstance(value, tuple):",
            "                loader = self.get_package_loader(*value)",
            "            elif isinstance(value, string_types):",
            "                if os.path.isfile(value):",
            "                    loader = self.get_file_loader(value)",
            "                else:",
            "                    loader = self.get_directory_loader(value)",
            "            else:",
            "                raise TypeError(\"unknown def %r\" % value)",
            "",
            "            self.exports.append((key, loader))",
            "",
            "        if disallow is not None:",
            "            from fnmatch import fnmatch",
            "",
            "            self.is_allowed = lambda x: not fnmatch(x, disallow)",
            "",
            "        self.fallback_mimetype = fallback_mimetype",
            "",
            "    def is_allowed(self, filename):",
            "        \"\"\"Subclasses can override this method to disallow the access to",
            "        certain files.  However by providing `disallow` in the constructor",
            "        this method is overwritten.",
            "        \"\"\"",
            "        return True",
            "",
            "    def _opener(self, filename):",
            "        return lambda: (",
            "            open(filename, \"rb\"),",
            "            datetime.utcfromtimestamp(os.path.getmtime(filename)),",
            "            int(os.path.getsize(filename)),",
            "        )",
            "",
            "    def get_file_loader(self, filename):",
            "        return lambda x: (os.path.basename(filename), self._opener(filename))",
            "",
            "    def get_package_loader(self, package, package_path):",
            "        from pkg_resources import DefaultProvider, ResourceManager, get_provider",
            "",
            "        loadtime = datetime.utcnow()",
            "        provider = get_provider(package)",
            "        manager = ResourceManager()",
            "        filesystem_bound = isinstance(provider, DefaultProvider)",
            "",
            "        def loader(path):",
            "            if path is None:",
            "                return None, None",
            "",
            "            path = safe_join(package_path, path)",
            "",
            "            if not provider.has_resource(path):",
            "                return None, None",
            "",
            "            basename = posixpath.basename(path)",
            "",
            "            if filesystem_bound:",
            "                return (",
            "                    basename,",
            "                    self._opener(provider.get_resource_filename(manager, path)),",
            "                )",
            "",
            "            s = provider.get_resource_string(manager, path)",
            "            return basename, lambda: (BytesIO(s), loadtime, len(s))",
            "",
            "        return loader",
            "",
            "    def get_directory_loader(self, directory):",
            "        def loader(path):",
            "            if path is not None:",
            "                path = safe_join(directory, path)",
            "            else:",
            "                path = directory",
            "",
            "            if os.path.isfile(path):",
            "                return os.path.basename(path), self._opener(path)",
            "",
            "            return None, None",
            "",
            "        return loader",
            "",
            "    def generate_etag(self, mtime, file_size, real_filename):",
            "        if not isinstance(real_filename, bytes):",
            "            real_filename = real_filename.encode(get_filesystem_encoding())",
            "",
            "        return \"wzsdm-%d-%s-%s\" % (",
            "            mktime(mtime.timetuple()),",
            "            file_size,",
            "            adler32(real_filename) & 0xFFFFFFFF,",
            "        )",
            "",
            "    def __call__(self, environ, start_response):",
            "        path = get_path_info(environ)",
            "",
            "        if PY2:",
            "            path = path.encode(get_filesystem_encoding())",
            "",
            "        file_loader = None",
            "",
            "        for search_path, loader in self.exports:",
            "            if search_path == path:",
            "                real_filename, file_loader = loader(None)",
            "",
            "                if file_loader is not None:",
            "                    break",
            "",
            "            if not search_path.endswith(\"/\"):",
            "                search_path += \"/\"",
            "",
            "            if path.startswith(search_path):",
            "                real_filename, file_loader = loader(path[len(search_path) :])",
            "",
            "                if file_loader is not None:",
            "                    break",
            "",
            "        if file_loader is None or not self.is_allowed(real_filename):",
            "            return self.app(environ, start_response)",
            "",
            "        guessed_type = mimetypes.guess_type(real_filename)",
            "        mime_type = guessed_type[0] or self.fallback_mimetype",
            "        f, mtime, file_size = file_loader()",
            "",
            "        headers = [(\"Date\", http_date())]",
            "",
            "        if self.cache:",
            "            timeout = self.cache_timeout",
            "            etag = self.generate_etag(mtime, file_size, real_filename)",
            "            headers += [",
            "                (\"Etag\", '\"%s\"' % etag),",
            "                (\"Cache-Control\", \"max-age=%d, public\" % timeout),",
            "            ]",
            "",
            "            if not is_resource_modified(environ, etag, last_modified=mtime):",
            "                f.close()",
            "                start_response(\"304 Not Modified\", headers)",
            "                return []",
            "",
            "            headers.append((\"Expires\", http_date(time() + timeout)))",
            "        else:",
            "            headers.append((\"Cache-Control\", \"public\"))",
            "",
            "        headers.extend(",
            "            (",
            "                (\"Content-Type\", mime_type),",
            "                (\"Content-Length\", str(file_size)),",
            "                (\"Last-Modified\", http_date(mtime)),",
            "            )",
            "        )",
            "        start_response(\"200 OK\", headers)",
            "        return wrap_file(environ, f)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "152": [
                "SharedDataMiddleware",
                "get_package_loader",
                "loader"
            ],
            "173": [
                "SharedDataMiddleware",
                "get_directory_loader",
                "loader"
            ],
            "195": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "198": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "200": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "201": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "202": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "203": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "204": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "205": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "206": [
                "SharedDataMiddleware",
                "__call__"
            ],
            "207": [
                "SharedDataMiddleware",
                "__call__"
            ]
        },
        "addLocation": []
    },
    "src/werkzeug/security.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 222,
                "afterPatchRowNumber": 222,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 223,
                "afterPatchRowNumber": 223,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 224,
                "afterPatchRowNumber": 224,
                "PatchRowcode": " def safe_join(directory, *pathnames):"
            },
            "3": {
                "beforePatchRowNumber": 225,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    \"\"\"Safely join `directory` and one or more untrusted `pathnames`.  If this"
            },
            "4": {
                "beforePatchRowNumber": 226,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    cannot be done, this function returns ``None``."
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 225,
                "PatchRowcode": "+    \"\"\"Safely join zero or more untrusted path components to a base"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 226,
                "PatchRowcode": "+    directory to avoid escaping the base directory."
            },
            "7": {
                "beforePatchRowNumber": 227,
                "afterPatchRowNumber": 227,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    :param directory: the base directory."
            },
            "9": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    :param pathnames: the untrusted pathnames relative to that directory."
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 228,
                "PatchRowcode": "+    :param directory: The trusted base directory."
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 229,
                "PatchRowcode": "+    :param pathnames: The untrusted path components relative to the"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 230,
                "PatchRowcode": "+        base directory."
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 231,
                "PatchRowcode": "+    :return: A safe path, otherwise ``None``."
            },
            "14": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 232,
                "PatchRowcode": "     \"\"\""
            },
            "15": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": 233,
                "PatchRowcode": "     parts = [directory]"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 234,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 235,
                "PatchRowcode": "     for filename in pathnames:"
            },
            "18": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         if filename != \"\":"
            },
            "19": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "             filename = posixpath.normpath(filename)"
            },
            "20": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        for sep in _os_alt_seps:"
            },
            "21": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if sep in filename:"
            },
            "22": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                return None"
            },
            "23": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        if os.path.isabs(filename) or filename == \"..\" or filename.startswith(\"../\"):"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 238,
                "PatchRowcode": "+"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+        if ("
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 240,
                "PatchRowcode": "+            any(sep in filename for sep in _os_alt_seps)"
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 241,
                "PatchRowcode": "+            or os.path.isabs(filename)"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 242,
                "PatchRowcode": "+            or filename == \"..\""
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 243,
                "PatchRowcode": "+            or filename.startswith(\"../\")"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 244,
                "PatchRowcode": "+        ):"
            },
            "31": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 245,
                "PatchRowcode": "             return None"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 246,
                "PatchRowcode": "+"
            },
            "33": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 247,
                "PatchRowcode": "         parts.append(filename)"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 248,
                "PatchRowcode": "+"
            },
            "35": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 249,
                "PatchRowcode": "     return posixpath.join(*parts)"
            }
        },
        "frontPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    werkzeug.security",
            "    ~~~~~~~~~~~~~~~~~",
            "",
            "    Security related helpers such as secure password hashing tools.",
            "",
            "    :copyright: 2007 Pallets",
            "    :license: BSD-3-Clause",
            "\"\"\"",
            "import codecs",
            "import hashlib",
            "import hmac",
            "import os",
            "import posixpath",
            "from random import SystemRandom",
            "from struct import Struct",
            "",
            "from ._compat import izip",
            "from ._compat import PY2",
            "from ._compat import range_type",
            "from ._compat import text_type",
            "from ._compat import to_bytes",
            "from ._compat import to_native",
            "",
            "SALT_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"",
            "DEFAULT_PBKDF2_ITERATIONS = 150000",
            "",
            "_pack_int = Struct(\">I\").pack",
            "_builtin_safe_str_cmp = getattr(hmac, \"compare_digest\", None)",
            "_sys_rng = SystemRandom()",
            "_os_alt_seps = list(",
            "    sep for sep in [os.path.sep, os.path.altsep] if sep not in (None, \"/\")",
            ")",
            "",
            "",
            "def pbkdf2_hex(",
            "    data, salt, iterations=DEFAULT_PBKDF2_ITERATIONS, keylen=None, hashfunc=None",
            "):",
            "    \"\"\"Like :func:`pbkdf2_bin`, but returns a hex-encoded string.",
            "",
            "    .. versionadded:: 0.9",
            "",
            "    :param data: the data to derive.",
            "    :param salt: the salt for the derivation.",
            "    :param iterations: the number of iterations.",
            "    :param keylen: the length of the resulting key.  If not provided,",
            "                   the digest size will be used.",
            "    :param hashfunc: the hash function to use.  This can either be the",
            "                     string name of a known hash function, or a function",
            "                     from the hashlib module.  Defaults to sha256.",
            "    \"\"\"",
            "    rv = pbkdf2_bin(data, salt, iterations, keylen, hashfunc)",
            "    return to_native(codecs.encode(rv, \"hex_codec\"))",
            "",
            "",
            "def pbkdf2_bin(",
            "    data, salt, iterations=DEFAULT_PBKDF2_ITERATIONS, keylen=None, hashfunc=None",
            "):",
            "    \"\"\"Returns a binary digest for the PBKDF2 hash algorithm of `data`",
            "    with the given `salt`. It iterates `iterations` times and produces a",
            "    key of `keylen` bytes. By default, SHA-256 is used as hash function;",
            "    a different hashlib `hashfunc` can be provided.",
            "",
            "    .. versionadded:: 0.9",
            "",
            "    :param data: the data to derive.",
            "    :param salt: the salt for the derivation.",
            "    :param iterations: the number of iterations.",
            "    :param keylen: the length of the resulting key.  If not provided",
            "                   the digest size will be used.",
            "    :param hashfunc: the hash function to use.  This can either be the",
            "                     string name of a known hash function or a function",
            "                     from the hashlib module.  Defaults to sha256.",
            "    \"\"\"",
            "    if not hashfunc:",
            "        hashfunc = \"sha256\"",
            "",
            "    data = to_bytes(data)",
            "    salt = to_bytes(salt)",
            "",
            "    if callable(hashfunc):",
            "        _test_hash = hashfunc()",
            "        hash_name = getattr(_test_hash, \"name\", None)",
            "    else:",
            "        hash_name = hashfunc",
            "    return hashlib.pbkdf2_hmac(hash_name, data, salt, iterations, keylen)",
            "",
            "",
            "def safe_str_cmp(a, b):",
            "    \"\"\"This function compares strings in somewhat constant time.  This",
            "    requires that the length of at least one string is known in advance.",
            "",
            "    Returns `True` if the two strings are equal, or `False` if they are not.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "    if isinstance(a, text_type):",
            "        a = a.encode(\"utf-8\")",
            "    if isinstance(b, text_type):",
            "        b = b.encode(\"utf-8\")",
            "",
            "    if _builtin_safe_str_cmp is not None:",
            "        return _builtin_safe_str_cmp(a, b)",
            "",
            "    if len(a) != len(b):",
            "        return False",
            "",
            "    rv = 0",
            "    if PY2:",
            "        for x, y in izip(a, b):",
            "            rv |= ord(x) ^ ord(y)",
            "    else:",
            "        for x, y in izip(a, b):",
            "            rv |= x ^ y",
            "",
            "    return rv == 0",
            "",
            "",
            "def gen_salt(length):",
            "    \"\"\"Generate a random string of SALT_CHARS with specified ``length``.\"\"\"",
            "    if length <= 0:",
            "        raise ValueError(\"Salt length must be positive\")",
            "    return \"\".join(_sys_rng.choice(SALT_CHARS) for _ in range_type(length))",
            "",
            "",
            "def _hash_internal(method, salt, password):",
            "    \"\"\"Internal password hash helper.  Supports plaintext without salt,",
            "    unsalted and salted passwords.  In case salted passwords are used",
            "    hmac is used.",
            "    \"\"\"",
            "    if method == \"plain\":",
            "        return password, method",
            "",
            "    if isinstance(password, text_type):",
            "        password = password.encode(\"utf-8\")",
            "",
            "    if method.startswith(\"pbkdf2:\"):",
            "        args = method[7:].split(\":\")",
            "        if len(args) not in (1, 2):",
            "            raise ValueError(\"Invalid number of arguments for PBKDF2\")",
            "        method = args.pop(0)",
            "        iterations = args and int(args[0] or 0) or DEFAULT_PBKDF2_ITERATIONS",
            "        is_pbkdf2 = True",
            "        actual_method = \"pbkdf2:%s:%d\" % (method, iterations)",
            "    else:",
            "        is_pbkdf2 = False",
            "        actual_method = method",
            "",
            "    if is_pbkdf2:",
            "        if not salt:",
            "            raise ValueError(\"Salt is required for PBKDF2\")",
            "        rv = pbkdf2_hex(password, salt, iterations, hashfunc=method)",
            "    elif salt:",
            "        if isinstance(salt, text_type):",
            "            salt = salt.encode(\"utf-8\")",
            "        mac = _create_mac(salt, password, method)",
            "        rv = mac.hexdigest()",
            "    else:",
            "        rv = hashlib.new(method, password).hexdigest()",
            "    return rv, actual_method",
            "",
            "",
            "def _create_mac(key, msg, method):",
            "    if callable(method):",
            "        return hmac.HMAC(key, msg, method)",
            "",
            "    def hashfunc(d=b\"\"):",
            "        return hashlib.new(method, d)",
            "",
            "    # Python 2.7 used ``hasattr(digestmod, '__call__')``",
            "    # to detect if hashfunc is callable",
            "    hashfunc.__call__ = hashfunc",
            "    return hmac.HMAC(key, msg, hashfunc)",
            "",
            "",
            "def generate_password_hash(password, method=\"pbkdf2:sha256\", salt_length=8):",
            "    \"\"\"Hash a password with the given method and salt with a string of",
            "    the given length. The format of the string returned includes the method",
            "    that was used so that :func:`check_password_hash` can check the hash.",
            "",
            "    The format for the hashed string looks like this::",
            "",
            "        method$salt$hash",
            "",
            "    This method can **not** generate unsalted passwords but it is possible",
            "    to set param method='plain' in order to enforce plaintext passwords.",
            "    If a salt is used, hmac is used internally to salt the password.",
            "",
            "    If PBKDF2 is wanted it can be enabled by setting the method to",
            "    ``pbkdf2:method:iterations`` where iterations is optional::",
            "",
            "        pbkdf2:sha256:80000$salt$hash",
            "        pbkdf2:sha256$salt$hash",
            "",
            "    :param password: the password to hash.",
            "    :param method: the hash method to use (one that hashlib supports). Can",
            "                   optionally be in the format ``pbkdf2:<method>[:iterations]``",
            "                   to enable PBKDF2.",
            "    :param salt_length: the length of the salt in letters.",
            "    \"\"\"",
            "    salt = gen_salt(salt_length) if method != \"plain\" else \"\"",
            "    h, actual_method = _hash_internal(method, salt, password)",
            "    return \"%s$%s$%s\" % (actual_method, salt, h)",
            "",
            "",
            "def check_password_hash(pwhash, password):",
            "    \"\"\"check a password against a given salted and hashed password value.",
            "    In order to support unsalted legacy passwords this method supports",
            "    plain text passwords, md5 and sha1 hashes (both salted and unsalted).",
            "",
            "    Returns `True` if the password matched, `False` otherwise.",
            "",
            "    :param pwhash: a hashed string like returned by",
            "                   :func:`generate_password_hash`.",
            "    :param password: the plaintext password to compare against the hash.",
            "    \"\"\"",
            "    if pwhash.count(\"$\") < 2:",
            "        return False",
            "    method, salt, hashval = pwhash.split(\"$\", 2)",
            "    return safe_str_cmp(_hash_internal(method, salt, password)[0], hashval)",
            "",
            "",
            "def safe_join(directory, *pathnames):",
            "    \"\"\"Safely join `directory` and one or more untrusted `pathnames`.  If this",
            "    cannot be done, this function returns ``None``.",
            "",
            "    :param directory: the base directory.",
            "    :param pathnames: the untrusted pathnames relative to that directory.",
            "    \"\"\"",
            "    parts = [directory]",
            "    for filename in pathnames:",
            "        if filename != \"\":",
            "            filename = posixpath.normpath(filename)",
            "        for sep in _os_alt_seps:",
            "            if sep in filename:",
            "                return None",
            "        if os.path.isabs(filename) or filename == \"..\" or filename.startswith(\"../\"):",
            "            return None",
            "        parts.append(filename)",
            "    return posixpath.join(*parts)"
        ],
        "afterPatchFile": [
            "# -*- coding: utf-8 -*-",
            "\"\"\"",
            "    werkzeug.security",
            "    ~~~~~~~~~~~~~~~~~",
            "",
            "    Security related helpers such as secure password hashing tools.",
            "",
            "    :copyright: 2007 Pallets",
            "    :license: BSD-3-Clause",
            "\"\"\"",
            "import codecs",
            "import hashlib",
            "import hmac",
            "import os",
            "import posixpath",
            "from random import SystemRandom",
            "from struct import Struct",
            "",
            "from ._compat import izip",
            "from ._compat import PY2",
            "from ._compat import range_type",
            "from ._compat import text_type",
            "from ._compat import to_bytes",
            "from ._compat import to_native",
            "",
            "SALT_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"",
            "DEFAULT_PBKDF2_ITERATIONS = 150000",
            "",
            "_pack_int = Struct(\">I\").pack",
            "_builtin_safe_str_cmp = getattr(hmac, \"compare_digest\", None)",
            "_sys_rng = SystemRandom()",
            "_os_alt_seps = list(",
            "    sep for sep in [os.path.sep, os.path.altsep] if sep not in (None, \"/\")",
            ")",
            "",
            "",
            "def pbkdf2_hex(",
            "    data, salt, iterations=DEFAULT_PBKDF2_ITERATIONS, keylen=None, hashfunc=None",
            "):",
            "    \"\"\"Like :func:`pbkdf2_bin`, but returns a hex-encoded string.",
            "",
            "    .. versionadded:: 0.9",
            "",
            "    :param data: the data to derive.",
            "    :param salt: the salt for the derivation.",
            "    :param iterations: the number of iterations.",
            "    :param keylen: the length of the resulting key.  If not provided,",
            "                   the digest size will be used.",
            "    :param hashfunc: the hash function to use.  This can either be the",
            "                     string name of a known hash function, or a function",
            "                     from the hashlib module.  Defaults to sha256.",
            "    \"\"\"",
            "    rv = pbkdf2_bin(data, salt, iterations, keylen, hashfunc)",
            "    return to_native(codecs.encode(rv, \"hex_codec\"))",
            "",
            "",
            "def pbkdf2_bin(",
            "    data, salt, iterations=DEFAULT_PBKDF2_ITERATIONS, keylen=None, hashfunc=None",
            "):",
            "    \"\"\"Returns a binary digest for the PBKDF2 hash algorithm of `data`",
            "    with the given `salt`. It iterates `iterations` times and produces a",
            "    key of `keylen` bytes. By default, SHA-256 is used as hash function;",
            "    a different hashlib `hashfunc` can be provided.",
            "",
            "    .. versionadded:: 0.9",
            "",
            "    :param data: the data to derive.",
            "    :param salt: the salt for the derivation.",
            "    :param iterations: the number of iterations.",
            "    :param keylen: the length of the resulting key.  If not provided",
            "                   the digest size will be used.",
            "    :param hashfunc: the hash function to use.  This can either be the",
            "                     string name of a known hash function or a function",
            "                     from the hashlib module.  Defaults to sha256.",
            "    \"\"\"",
            "    if not hashfunc:",
            "        hashfunc = \"sha256\"",
            "",
            "    data = to_bytes(data)",
            "    salt = to_bytes(salt)",
            "",
            "    if callable(hashfunc):",
            "        _test_hash = hashfunc()",
            "        hash_name = getattr(_test_hash, \"name\", None)",
            "    else:",
            "        hash_name = hashfunc",
            "    return hashlib.pbkdf2_hmac(hash_name, data, salt, iterations, keylen)",
            "",
            "",
            "def safe_str_cmp(a, b):",
            "    \"\"\"This function compares strings in somewhat constant time.  This",
            "    requires that the length of at least one string is known in advance.",
            "",
            "    Returns `True` if the two strings are equal, or `False` if they are not.",
            "",
            "    .. versionadded:: 0.7",
            "    \"\"\"",
            "    if isinstance(a, text_type):",
            "        a = a.encode(\"utf-8\")",
            "    if isinstance(b, text_type):",
            "        b = b.encode(\"utf-8\")",
            "",
            "    if _builtin_safe_str_cmp is not None:",
            "        return _builtin_safe_str_cmp(a, b)",
            "",
            "    if len(a) != len(b):",
            "        return False",
            "",
            "    rv = 0",
            "    if PY2:",
            "        for x, y in izip(a, b):",
            "            rv |= ord(x) ^ ord(y)",
            "    else:",
            "        for x, y in izip(a, b):",
            "            rv |= x ^ y",
            "",
            "    return rv == 0",
            "",
            "",
            "def gen_salt(length):",
            "    \"\"\"Generate a random string of SALT_CHARS with specified ``length``.\"\"\"",
            "    if length <= 0:",
            "        raise ValueError(\"Salt length must be positive\")",
            "    return \"\".join(_sys_rng.choice(SALT_CHARS) for _ in range_type(length))",
            "",
            "",
            "def _hash_internal(method, salt, password):",
            "    \"\"\"Internal password hash helper.  Supports plaintext without salt,",
            "    unsalted and salted passwords.  In case salted passwords are used",
            "    hmac is used.",
            "    \"\"\"",
            "    if method == \"plain\":",
            "        return password, method",
            "",
            "    if isinstance(password, text_type):",
            "        password = password.encode(\"utf-8\")",
            "",
            "    if method.startswith(\"pbkdf2:\"):",
            "        args = method[7:].split(\":\")",
            "        if len(args) not in (1, 2):",
            "            raise ValueError(\"Invalid number of arguments for PBKDF2\")",
            "        method = args.pop(0)",
            "        iterations = args and int(args[0] or 0) or DEFAULT_PBKDF2_ITERATIONS",
            "        is_pbkdf2 = True",
            "        actual_method = \"pbkdf2:%s:%d\" % (method, iterations)",
            "    else:",
            "        is_pbkdf2 = False",
            "        actual_method = method",
            "",
            "    if is_pbkdf2:",
            "        if not salt:",
            "            raise ValueError(\"Salt is required for PBKDF2\")",
            "        rv = pbkdf2_hex(password, salt, iterations, hashfunc=method)",
            "    elif salt:",
            "        if isinstance(salt, text_type):",
            "            salt = salt.encode(\"utf-8\")",
            "        mac = _create_mac(salt, password, method)",
            "        rv = mac.hexdigest()",
            "    else:",
            "        rv = hashlib.new(method, password).hexdigest()",
            "    return rv, actual_method",
            "",
            "",
            "def _create_mac(key, msg, method):",
            "    if callable(method):",
            "        return hmac.HMAC(key, msg, method)",
            "",
            "    def hashfunc(d=b\"\"):",
            "        return hashlib.new(method, d)",
            "",
            "    # Python 2.7 used ``hasattr(digestmod, '__call__')``",
            "    # to detect if hashfunc is callable",
            "    hashfunc.__call__ = hashfunc",
            "    return hmac.HMAC(key, msg, hashfunc)",
            "",
            "",
            "def generate_password_hash(password, method=\"pbkdf2:sha256\", salt_length=8):",
            "    \"\"\"Hash a password with the given method and salt with a string of",
            "    the given length. The format of the string returned includes the method",
            "    that was used so that :func:`check_password_hash` can check the hash.",
            "",
            "    The format for the hashed string looks like this::",
            "",
            "        method$salt$hash",
            "",
            "    This method can **not** generate unsalted passwords but it is possible",
            "    to set param method='plain' in order to enforce plaintext passwords.",
            "    If a salt is used, hmac is used internally to salt the password.",
            "",
            "    If PBKDF2 is wanted it can be enabled by setting the method to",
            "    ``pbkdf2:method:iterations`` where iterations is optional::",
            "",
            "        pbkdf2:sha256:80000$salt$hash",
            "        pbkdf2:sha256$salt$hash",
            "",
            "    :param password: the password to hash.",
            "    :param method: the hash method to use (one that hashlib supports). Can",
            "                   optionally be in the format ``pbkdf2:<method>[:iterations]``",
            "                   to enable PBKDF2.",
            "    :param salt_length: the length of the salt in letters.",
            "    \"\"\"",
            "    salt = gen_salt(salt_length) if method != \"plain\" else \"\"",
            "    h, actual_method = _hash_internal(method, salt, password)",
            "    return \"%s$%s$%s\" % (actual_method, salt, h)",
            "",
            "",
            "def check_password_hash(pwhash, password):",
            "    \"\"\"check a password against a given salted and hashed password value.",
            "    In order to support unsalted legacy passwords this method supports",
            "    plain text passwords, md5 and sha1 hashes (both salted and unsalted).",
            "",
            "    Returns `True` if the password matched, `False` otherwise.",
            "",
            "    :param pwhash: a hashed string like returned by",
            "                   :func:`generate_password_hash`.",
            "    :param password: the plaintext password to compare against the hash.",
            "    \"\"\"",
            "    if pwhash.count(\"$\") < 2:",
            "        return False",
            "    method, salt, hashval = pwhash.split(\"$\", 2)",
            "    return safe_str_cmp(_hash_internal(method, salt, password)[0], hashval)",
            "",
            "",
            "def safe_join(directory, *pathnames):",
            "    \"\"\"Safely join zero or more untrusted path components to a base",
            "    directory to avoid escaping the base directory.",
            "",
            "    :param directory: The trusted base directory.",
            "    :param pathnames: The untrusted path components relative to the",
            "        base directory.",
            "    :return: A safe path, otherwise ``None``.",
            "    \"\"\"",
            "    parts = [directory]",
            "",
            "    for filename in pathnames:",
            "        if filename != \"\":",
            "            filename = posixpath.normpath(filename)",
            "",
            "        if (",
            "            any(sep in filename for sep in _os_alt_seps)",
            "            or os.path.isabs(filename)",
            "            or filename == \"..\"",
            "            or filename.startswith(\"../\")",
            "        ):",
            "            return None",
            "",
            "        parts.append(filename)",
            "",
            "    return posixpath.join(*parts)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "0",
            "2",
            "0"
        ],
        "dele_reviseLocation": {
            "225": [
                "safe_join"
            ],
            "226": [
                "safe_join"
            ],
            "228": [
                "safe_join"
            ],
            "229": [
                "safe_join"
            ],
            "235": [
                "safe_join"
            ],
            "236": [
                "safe_join"
            ],
            "237": [
                "safe_join"
            ],
            "238": [
                "safe_join"
            ]
        },
        "addLocation": []
    }
}