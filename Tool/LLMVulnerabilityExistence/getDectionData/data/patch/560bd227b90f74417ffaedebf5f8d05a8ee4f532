{
    "urllib3/poolmanager.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 312,
                "afterPatchRowNumber": 312,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 313,
                "afterPatchRowNumber": 313,
                "PatchRowcode": "         kw['assert_same_host'] = False"
            },
            "2": {
                "beforePatchRowNumber": 314,
                "afterPatchRowNumber": 314,
                "PatchRowcode": "         kw['redirect'] = False"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 315,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": 315,
                "afterPatchRowNumber": 316,
                "PatchRowcode": "         if 'headers' not in kw:"
            },
            "5": {
                "beforePatchRowNumber": 316,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            kw['headers'] = self.headers"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 317,
                "PatchRowcode": "+            kw['headers'] = self.headers.copy()"
            },
            "7": {
                "beforePatchRowNumber": 317,
                "afterPatchRowNumber": 318,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 318,
                "afterPatchRowNumber": 319,
                "PatchRowcode": "         if self.proxy is not None and u.scheme == \"http\":"
            },
            "9": {
                "beforePatchRowNumber": 319,
                "afterPatchRowNumber": 320,
                "PatchRowcode": "             response = conn.urlopen(method, url, **kw)"
            },
            "10": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": 336,
                "PatchRowcode": "         if not isinstance(retries, Retry):"
            },
            "11": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 337,
                "PatchRowcode": "             retries = Retry.from_int(retries, redirect=redirect)"
            },
            "12": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 338,
                "PatchRowcode": " "
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+        # Strip headers marked as unsafe to forward to the redirected location."
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 340,
                "PatchRowcode": "+        # Check remove_headers_on_redirect to avoid a potential network call within"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 341,
                "PatchRowcode": "+        # conn.is_same_host() which may use socket.gethostbyname() in the future."
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+        if (retries.remove_headers_on_redirect"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 343,
                "PatchRowcode": "+                and not conn.is_same_host(redirect_location)):"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 344,
                "PatchRowcode": "+            for header in retries.remove_headers_on_redirect:"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+                kw['headers'].pop(header, None)"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 346,
                "PatchRowcode": "+"
            },
            "21": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": 347,
                "PatchRowcode": "         try:"
            },
            "22": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 348,
                "PatchRowcode": "             retries = retries.increment(method, url, response=response, _pool=conn)"
            },
            "23": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": 349,
                "PatchRowcode": "         except MaxRetryError:"
            }
        },
        "frontPatchFile": [
            "from __future__ import absolute_import",
            "import collections",
            "import functools",
            "import logging",
            "",
            "from ._collections import RecentlyUsedContainer",
            "from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool",
            "from .connectionpool import port_by_scheme",
            "from .exceptions import LocationValueError, MaxRetryError, ProxySchemeUnknown",
            "from .packages.six.moves.urllib.parse import urljoin",
            "from .request import RequestMethods",
            "from .util.url import parse_url",
            "from .util.retry import Retry",
            "",
            "",
            "__all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "SSL_KEYWORDS = ('key_file', 'cert_file', 'cert_reqs', 'ca_certs',",
            "                'ssl_version', 'ca_cert_dir', 'ssl_context')",
            "",
            "# All known keyword arguments that could be provided to the pool manager, its",
            "# pools, or the underlying connections. This is used to construct a pool key.",
            "_key_fields = (",
            "    'key_scheme',  # str",
            "    'key_host',  # str",
            "    'key_port',  # int",
            "    'key_timeout',  # int or float or Timeout",
            "    'key_retries',  # int or Retry",
            "    'key_strict',  # bool",
            "    'key_block',  # bool",
            "    'key_source_address',  # str",
            "    'key_key_file',  # str",
            "    'key_cert_file',  # str",
            "    'key_cert_reqs',  # str",
            "    'key_ca_certs',  # str",
            "    'key_ssl_version',  # str",
            "    'key_ca_cert_dir',  # str",
            "    'key_ssl_context',  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext",
            "    'key_maxsize',  # int",
            "    'key_headers',  # dict",
            "    'key__proxy',  # parsed proxy url",
            "    'key__proxy_headers',  # dict",
            "    'key_socket_options',  # list of (level (int), optname (int), value (int or str)) tuples",
            "    'key__socks_options',  # dict",
            "    'key_assert_hostname',  # bool or string",
            "    'key_assert_fingerprint',  # str",
            ")",
            "",
            "#: The namedtuple class used to construct keys for the connection pool.",
            "#: All custom key schemes should include the fields in this key at a minimum.",
            "PoolKey = collections.namedtuple('PoolKey', _key_fields)",
            "",
            "",
            "def _default_key_normalizer(key_class, request_context):",
            "    \"\"\"",
            "    Create a pool key out of a request context dictionary.",
            "",
            "    According to RFC 3986, both the scheme and host are case-insensitive.",
            "    Therefore, this function normalizes both before constructing the pool",
            "    key for an HTTPS request. If you wish to change this behaviour, provide",
            "    alternate callables to ``key_fn_by_scheme``.",
            "",
            "    :param key_class:",
            "        The class to use when constructing the key. This should be a namedtuple",
            "        with the ``scheme`` and ``host`` keys at a minimum.",
            "    :type  key_class: namedtuple",
            "    :param request_context:",
            "        A dictionary-like object that contain the context for a request.",
            "    :type  request_context: dict",
            "",
            "    :return: A namedtuple that can be used as a connection pool key.",
            "    :rtype:  PoolKey",
            "    \"\"\"",
            "    # Since we mutate the dictionary, make a copy first",
            "    context = request_context.copy()",
            "    context['scheme'] = context['scheme'].lower()",
            "    context['host'] = context['host'].lower()",
            "",
            "    # These are both dictionaries and need to be transformed into frozensets",
            "    for key in ('headers', '_proxy_headers', '_socks_options'):",
            "        if key in context and context[key] is not None:",
            "            context[key] = frozenset(context[key].items())",
            "",
            "    # The socket_options key may be a list and needs to be transformed into a",
            "    # tuple.",
            "    socket_opts = context.get('socket_options')",
            "    if socket_opts is not None:",
            "        context['socket_options'] = tuple(socket_opts)",
            "",
            "    # Map the kwargs to the names in the namedtuple - this is necessary since",
            "    # namedtuples can't have fields starting with '_'.",
            "    for key in list(context.keys()):",
            "        context['key_' + key] = context.pop(key)",
            "",
            "    # Default to ``None`` for keys missing from the context",
            "    for field in key_class._fields:",
            "        if field not in context:",
            "            context[field] = None",
            "",
            "    return key_class(**context)",
            "",
            "",
            "#: A dictionary that maps a scheme to a callable that creates a pool key.",
            "#: This can be used to alter the way pool keys are constructed, if desired.",
            "#: Each PoolManager makes a copy of this dictionary so they can be configured",
            "#: globally here, or individually on the instance.",
            "key_fn_by_scheme = {",
            "    'http': functools.partial(_default_key_normalizer, PoolKey),",
            "    'https': functools.partial(_default_key_normalizer, PoolKey),",
            "}",
            "",
            "pool_classes_by_scheme = {",
            "    'http': HTTPConnectionPool,",
            "    'https': HTTPSConnectionPool,",
            "}",
            "",
            "",
            "class PoolManager(RequestMethods):",
            "    \"\"\"",
            "    Allows for arbitrary requests while transparently keeping track of",
            "    necessary connection pools for you.",
            "",
            "    :param num_pools:",
            "        Number of connection pools to cache before discarding the least",
            "        recently used pool.",
            "",
            "    :param headers:",
            "        Headers to include with all requests, unless other headers are given",
            "        explicitly.",
            "",
            "    :param \\\\**connection_pool_kw:",
            "        Additional parameters are used to create fresh",
            "        :class:`urllib3.connectionpool.ConnectionPool` instances.",
            "",
            "    Example::",
            "",
            "        >>> manager = PoolManager(num_pools=2)",
            "        >>> r = manager.request('GET', 'http://google.com/')",
            "        >>> r = manager.request('GET', 'http://google.com/mail')",
            "        >>> r = manager.request('GET', 'http://yahoo.com/')",
            "        >>> len(manager.pools)",
            "        2",
            "",
            "    \"\"\"",
            "",
            "    proxy = None",
            "",
            "    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):",
            "        RequestMethods.__init__(self, headers)",
            "        self.connection_pool_kw = connection_pool_kw",
            "        self.pools = RecentlyUsedContainer(num_pools,",
            "                                           dispose_func=lambda p: p.close())",
            "",
            "        # Locally set the pool classes and keys so other PoolManagers can",
            "        # override them.",
            "        self.pool_classes_by_scheme = pool_classes_by_scheme",
            "        self.key_fn_by_scheme = key_fn_by_scheme.copy()",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, exc_type, exc_val, exc_tb):",
            "        self.clear()",
            "        # Return False to re-raise any potential exceptions",
            "        return False",
            "",
            "    def _new_pool(self, scheme, host, port, request_context=None):",
            "        \"\"\"",
            "        Create a new :class:`ConnectionPool` based on host, port, scheme, and",
            "        any additional pool keyword arguments.",
            "",
            "        If ``request_context`` is provided, it is provided as keyword arguments",
            "        to the pool class used. This method is used to actually create the",
            "        connection pools handed out by :meth:`connection_from_url` and",
            "        companion methods. It is intended to be overridden for customization.",
            "        \"\"\"",
            "        pool_cls = self.pool_classes_by_scheme[scheme]",
            "        if request_context is None:",
            "            request_context = self.connection_pool_kw.copy()",
            "",
            "        # Although the context has everything necessary to create the pool,",
            "        # this function has historically only used the scheme, host, and port",
            "        # in the positional args. When an API change is acceptable these can",
            "        # be removed.",
            "        for key in ('scheme', 'host', 'port'):",
            "            request_context.pop(key, None)",
            "",
            "        if scheme == 'http':",
            "            for kw in SSL_KEYWORDS:",
            "                request_context.pop(kw, None)",
            "",
            "        return pool_cls(host, port, **request_context)",
            "",
            "    def clear(self):",
            "        \"\"\"",
            "        Empty our store of pools and direct them all to close.",
            "",
            "        This will not affect in-flight connections, but they will not be",
            "        re-used after completion.",
            "        \"\"\"",
            "        self.pools.clear()",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the host, port, and scheme.",
            "",
            "        If ``port`` isn't given, it will be derived from the ``scheme`` using",
            "        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is",
            "        provided, it is merged with the instance's ``connection_pool_kw``",
            "        variable and used to create the new connection pool, if one is",
            "        needed.",
            "        \"\"\"",
            "",
            "        if not host:",
            "            raise LocationValueError(\"No host specified.\")",
            "",
            "        request_context = self._merge_pool_kwargs(pool_kwargs)",
            "        request_context['scheme'] = scheme or 'http'",
            "        if not port:",
            "            port = port_by_scheme.get(request_context['scheme'].lower(), 80)",
            "        request_context['port'] = port",
            "        request_context['host'] = host",
            "",
            "        return self.connection_from_context(request_context)",
            "",
            "    def connection_from_context(self, request_context):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the request context.",
            "",
            "        ``request_context`` must at least contain the ``scheme`` key and its",
            "        value must be a key in ``key_fn_by_scheme`` instance variable.",
            "        \"\"\"",
            "        scheme = request_context['scheme'].lower()",
            "        pool_key_constructor = self.key_fn_by_scheme[scheme]",
            "        pool_key = pool_key_constructor(request_context)",
            "",
            "        return self.connection_from_pool_key(pool_key, request_context=request_context)",
            "",
            "    def connection_from_pool_key(self, pool_key, request_context=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the provided pool key.",
            "",
            "        ``pool_key`` should be a namedtuple that only contains immutable",
            "        objects. At a minimum it must have the ``scheme``, ``host``, and",
            "        ``port`` fields.",
            "        \"\"\"",
            "        with self.pools.lock:",
            "            # If the scheme, host, or port doesn't match existing open",
            "            # connections, open a new ConnectionPool.",
            "            pool = self.pools.get(pool_key)",
            "            if pool:",
            "                return pool",
            "",
            "            # Make a fresh ConnectionPool of the desired type",
            "            scheme = request_context['scheme']",
            "            host = request_context['host']",
            "            port = request_context['port']",
            "            pool = self._new_pool(scheme, host, port, request_context=request_context)",
            "            self.pools[pool_key] = pool",
            "",
            "        return pool",
            "",
            "    def connection_from_url(self, url, pool_kwargs=None):",
            "        \"\"\"",
            "        Similar to :func:`urllib3.connectionpool.connection_from_url`.",
            "",
            "        If ``pool_kwargs`` is not provided and a new pool needs to be",
            "        constructed, ``self.connection_pool_kw`` is used to initialize",
            "        the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``",
            "        is provided, it is used instead. Note that if a new pool does not",
            "        need to be created for the request, the provided ``pool_kwargs`` are",
            "        not used.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        return self.connection_from_host(u.host, port=u.port, scheme=u.scheme,",
            "                                         pool_kwargs=pool_kwargs)",
            "",
            "    def _merge_pool_kwargs(self, override):",
            "        \"\"\"",
            "        Merge a dictionary of override values for self.connection_pool_kw.",
            "",
            "        This does not modify self.connection_pool_kw and returns a new dict.",
            "        Any keys in the override dictionary with a value of ``None`` are",
            "        removed from the merged dictionary.",
            "        \"\"\"",
            "        base_pool_kwargs = self.connection_pool_kw.copy()",
            "        if override:",
            "            for key, value in override.items():",
            "                if value is None:",
            "                    try:",
            "                        del base_pool_kwargs[key]",
            "                    except KeyError:",
            "                        pass",
            "                else:",
            "                    base_pool_kwargs[key] = value",
            "        return base_pool_kwargs",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"\"\"",
            "        Same as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`",
            "        with custom cross-host redirect logic and only sends the request-uri",
            "        portion of the ``url``.",
            "",
            "        The given ``url`` parameter must be absolute, such that an appropriate",
            "        :class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)",
            "",
            "        kw['assert_same_host'] = False",
            "        kw['redirect'] = False",
            "        if 'headers' not in kw:",
            "            kw['headers'] = self.headers",
            "",
            "        if self.proxy is not None and u.scheme == \"http\":",
            "            response = conn.urlopen(method, url, **kw)",
            "        else:",
            "            response = conn.urlopen(method, u.request_uri, **kw)",
            "",
            "        redirect_location = redirect and response.get_redirect_location()",
            "        if not redirect_location:",
            "            return response",
            "",
            "        # Support relative URLs for redirecting.",
            "        redirect_location = urljoin(url, redirect_location)",
            "",
            "        # RFC 7231, Section 6.4.4",
            "        if response.status == 303:",
            "            method = 'GET'",
            "",
            "        retries = kw.get('retries')",
            "        if not isinstance(retries, Retry):",
            "            retries = Retry.from_int(retries, redirect=redirect)",
            "",
            "        try:",
            "            retries = retries.increment(method, url, response=response, _pool=conn)",
            "        except MaxRetryError:",
            "            if retries.raise_on_redirect:",
            "                raise",
            "            return response",
            "",
            "        kw['retries'] = retries",
            "        kw['redirect'] = redirect",
            "",
            "        log.info(\"Redirecting %s -> %s\", url, redirect_location)",
            "        return self.urlopen(method, redirect_location, **kw)",
            "",
            "",
            "class ProxyManager(PoolManager):",
            "    \"\"\"",
            "    Behaves just like :class:`PoolManager`, but sends all requests through",
            "    the defined proxy, using the CONNECT method for HTTPS URLs.",
            "",
            "    :param proxy_url:",
            "        The URL of the proxy to be used.",
            "",
            "    :param proxy_headers:",
            "        A dictionary containing headers that will be sent to the proxy. In case",
            "        of HTTP they are being sent with each request, while in the",
            "        HTTPS/CONNECT case they are sent only once. Could be used for proxy",
            "        authentication.",
            "",
            "    Example:",
            "        >>> proxy = urllib3.ProxyManager('http://localhost:3128/')",
            "        >>> r1 = proxy.request('GET', 'http://google.com/')",
            "        >>> r2 = proxy.request('GET', 'http://httpbin.org/')",
            "        >>> len(proxy.pools)",
            "        1",
            "        >>> r3 = proxy.request('GET', 'https://httpbin.org/')",
            "        >>> r4 = proxy.request('GET', 'https://twitter.com/')",
            "        >>> len(proxy.pools)",
            "        3",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, proxy_url, num_pools=10, headers=None,",
            "                 proxy_headers=None, **connection_pool_kw):",
            "",
            "        if isinstance(proxy_url, HTTPConnectionPool):",
            "            proxy_url = '%s://%s:%i' % (proxy_url.scheme, proxy_url.host,",
            "                                        proxy_url.port)",
            "        proxy = parse_url(proxy_url)",
            "        if not proxy.port:",
            "            port = port_by_scheme.get(proxy.scheme, 80)",
            "            proxy = proxy._replace(port=port)",
            "",
            "        if proxy.scheme not in (\"http\", \"https\"):",
            "            raise ProxySchemeUnknown(proxy.scheme)",
            "",
            "        self.proxy = proxy",
            "        self.proxy_headers = proxy_headers or {}",
            "",
            "        connection_pool_kw['_proxy'] = self.proxy",
            "        connection_pool_kw['_proxy_headers'] = self.proxy_headers",
            "",
            "        super(ProxyManager, self).__init__(",
            "            num_pools, headers, **connection_pool_kw)",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        if scheme == \"https\":",
            "            return super(ProxyManager, self).connection_from_host(",
            "                host, port, scheme, pool_kwargs=pool_kwargs)",
            "",
            "        return super(ProxyManager, self).connection_from_host(",
            "            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs)",
            "",
            "    def _set_proxy_headers(self, url, headers=None):",
            "        \"\"\"",
            "        Sets headers needed by proxies: specifically, the Accept and Host",
            "        headers. Only sets headers not provided by the user.",
            "        \"\"\"",
            "        headers_ = {'Accept': '*/*'}",
            "",
            "        netloc = parse_url(url).netloc",
            "        if netloc:",
            "            headers_['Host'] = netloc",
            "",
            "        if headers:",
            "            headers_.update(headers)",
            "        return headers_",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"",
            "        u = parse_url(url)",
            "",
            "        if u.scheme == \"http\":",
            "            # For proxied HTTPS requests, httplib sets the necessary headers",
            "            # on the CONNECT to the proxy. For HTTP, we'll definitely",
            "            # need to set 'Host' at the very least.",
            "            headers = kw.get('headers', self.headers)",
            "            kw['headers'] = self._set_proxy_headers(url, headers)",
            "",
            "        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)",
            "",
            "",
            "def proxy_from_url(url, **kw):",
            "    return ProxyManager(proxy_url=url, **kw)"
        ],
        "afterPatchFile": [
            "from __future__ import absolute_import",
            "import collections",
            "import functools",
            "import logging",
            "",
            "from ._collections import RecentlyUsedContainer",
            "from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool",
            "from .connectionpool import port_by_scheme",
            "from .exceptions import LocationValueError, MaxRetryError, ProxySchemeUnknown",
            "from .packages.six.moves.urllib.parse import urljoin",
            "from .request import RequestMethods",
            "from .util.url import parse_url",
            "from .util.retry import Retry",
            "",
            "",
            "__all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "SSL_KEYWORDS = ('key_file', 'cert_file', 'cert_reqs', 'ca_certs',",
            "                'ssl_version', 'ca_cert_dir', 'ssl_context')",
            "",
            "# All known keyword arguments that could be provided to the pool manager, its",
            "# pools, or the underlying connections. This is used to construct a pool key.",
            "_key_fields = (",
            "    'key_scheme',  # str",
            "    'key_host',  # str",
            "    'key_port',  # int",
            "    'key_timeout',  # int or float or Timeout",
            "    'key_retries',  # int or Retry",
            "    'key_strict',  # bool",
            "    'key_block',  # bool",
            "    'key_source_address',  # str",
            "    'key_key_file',  # str",
            "    'key_cert_file',  # str",
            "    'key_cert_reqs',  # str",
            "    'key_ca_certs',  # str",
            "    'key_ssl_version',  # str",
            "    'key_ca_cert_dir',  # str",
            "    'key_ssl_context',  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext",
            "    'key_maxsize',  # int",
            "    'key_headers',  # dict",
            "    'key__proxy',  # parsed proxy url",
            "    'key__proxy_headers',  # dict",
            "    'key_socket_options',  # list of (level (int), optname (int), value (int or str)) tuples",
            "    'key__socks_options',  # dict",
            "    'key_assert_hostname',  # bool or string",
            "    'key_assert_fingerprint',  # str",
            ")",
            "",
            "#: The namedtuple class used to construct keys for the connection pool.",
            "#: All custom key schemes should include the fields in this key at a minimum.",
            "PoolKey = collections.namedtuple('PoolKey', _key_fields)",
            "",
            "",
            "def _default_key_normalizer(key_class, request_context):",
            "    \"\"\"",
            "    Create a pool key out of a request context dictionary.",
            "",
            "    According to RFC 3986, both the scheme and host are case-insensitive.",
            "    Therefore, this function normalizes both before constructing the pool",
            "    key for an HTTPS request. If you wish to change this behaviour, provide",
            "    alternate callables to ``key_fn_by_scheme``.",
            "",
            "    :param key_class:",
            "        The class to use when constructing the key. This should be a namedtuple",
            "        with the ``scheme`` and ``host`` keys at a minimum.",
            "    :type  key_class: namedtuple",
            "    :param request_context:",
            "        A dictionary-like object that contain the context for a request.",
            "    :type  request_context: dict",
            "",
            "    :return: A namedtuple that can be used as a connection pool key.",
            "    :rtype:  PoolKey",
            "    \"\"\"",
            "    # Since we mutate the dictionary, make a copy first",
            "    context = request_context.copy()",
            "    context['scheme'] = context['scheme'].lower()",
            "    context['host'] = context['host'].lower()",
            "",
            "    # These are both dictionaries and need to be transformed into frozensets",
            "    for key in ('headers', '_proxy_headers', '_socks_options'):",
            "        if key in context and context[key] is not None:",
            "            context[key] = frozenset(context[key].items())",
            "",
            "    # The socket_options key may be a list and needs to be transformed into a",
            "    # tuple.",
            "    socket_opts = context.get('socket_options')",
            "    if socket_opts is not None:",
            "        context['socket_options'] = tuple(socket_opts)",
            "",
            "    # Map the kwargs to the names in the namedtuple - this is necessary since",
            "    # namedtuples can't have fields starting with '_'.",
            "    for key in list(context.keys()):",
            "        context['key_' + key] = context.pop(key)",
            "",
            "    # Default to ``None`` for keys missing from the context",
            "    for field in key_class._fields:",
            "        if field not in context:",
            "            context[field] = None",
            "",
            "    return key_class(**context)",
            "",
            "",
            "#: A dictionary that maps a scheme to a callable that creates a pool key.",
            "#: This can be used to alter the way pool keys are constructed, if desired.",
            "#: Each PoolManager makes a copy of this dictionary so they can be configured",
            "#: globally here, or individually on the instance.",
            "key_fn_by_scheme = {",
            "    'http': functools.partial(_default_key_normalizer, PoolKey),",
            "    'https': functools.partial(_default_key_normalizer, PoolKey),",
            "}",
            "",
            "pool_classes_by_scheme = {",
            "    'http': HTTPConnectionPool,",
            "    'https': HTTPSConnectionPool,",
            "}",
            "",
            "",
            "class PoolManager(RequestMethods):",
            "    \"\"\"",
            "    Allows for arbitrary requests while transparently keeping track of",
            "    necessary connection pools for you.",
            "",
            "    :param num_pools:",
            "        Number of connection pools to cache before discarding the least",
            "        recently used pool.",
            "",
            "    :param headers:",
            "        Headers to include with all requests, unless other headers are given",
            "        explicitly.",
            "",
            "    :param \\\\**connection_pool_kw:",
            "        Additional parameters are used to create fresh",
            "        :class:`urllib3.connectionpool.ConnectionPool` instances.",
            "",
            "    Example::",
            "",
            "        >>> manager = PoolManager(num_pools=2)",
            "        >>> r = manager.request('GET', 'http://google.com/')",
            "        >>> r = manager.request('GET', 'http://google.com/mail')",
            "        >>> r = manager.request('GET', 'http://yahoo.com/')",
            "        >>> len(manager.pools)",
            "        2",
            "",
            "    \"\"\"",
            "",
            "    proxy = None",
            "",
            "    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):",
            "        RequestMethods.__init__(self, headers)",
            "        self.connection_pool_kw = connection_pool_kw",
            "        self.pools = RecentlyUsedContainer(num_pools,",
            "                                           dispose_func=lambda p: p.close())",
            "",
            "        # Locally set the pool classes and keys so other PoolManagers can",
            "        # override them.",
            "        self.pool_classes_by_scheme = pool_classes_by_scheme",
            "        self.key_fn_by_scheme = key_fn_by_scheme.copy()",
            "",
            "    def __enter__(self):",
            "        return self",
            "",
            "    def __exit__(self, exc_type, exc_val, exc_tb):",
            "        self.clear()",
            "        # Return False to re-raise any potential exceptions",
            "        return False",
            "",
            "    def _new_pool(self, scheme, host, port, request_context=None):",
            "        \"\"\"",
            "        Create a new :class:`ConnectionPool` based on host, port, scheme, and",
            "        any additional pool keyword arguments.",
            "",
            "        If ``request_context`` is provided, it is provided as keyword arguments",
            "        to the pool class used. This method is used to actually create the",
            "        connection pools handed out by :meth:`connection_from_url` and",
            "        companion methods. It is intended to be overridden for customization.",
            "        \"\"\"",
            "        pool_cls = self.pool_classes_by_scheme[scheme]",
            "        if request_context is None:",
            "            request_context = self.connection_pool_kw.copy()",
            "",
            "        # Although the context has everything necessary to create the pool,",
            "        # this function has historically only used the scheme, host, and port",
            "        # in the positional args. When an API change is acceptable these can",
            "        # be removed.",
            "        for key in ('scheme', 'host', 'port'):",
            "            request_context.pop(key, None)",
            "",
            "        if scheme == 'http':",
            "            for kw in SSL_KEYWORDS:",
            "                request_context.pop(kw, None)",
            "",
            "        return pool_cls(host, port, **request_context)",
            "",
            "    def clear(self):",
            "        \"\"\"",
            "        Empty our store of pools and direct them all to close.",
            "",
            "        This will not affect in-flight connections, but they will not be",
            "        re-used after completion.",
            "        \"\"\"",
            "        self.pools.clear()",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the host, port, and scheme.",
            "",
            "        If ``port`` isn't given, it will be derived from the ``scheme`` using",
            "        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is",
            "        provided, it is merged with the instance's ``connection_pool_kw``",
            "        variable and used to create the new connection pool, if one is",
            "        needed.",
            "        \"\"\"",
            "",
            "        if not host:",
            "            raise LocationValueError(\"No host specified.\")",
            "",
            "        request_context = self._merge_pool_kwargs(pool_kwargs)",
            "        request_context['scheme'] = scheme or 'http'",
            "        if not port:",
            "            port = port_by_scheme.get(request_context['scheme'].lower(), 80)",
            "        request_context['port'] = port",
            "        request_context['host'] = host",
            "",
            "        return self.connection_from_context(request_context)",
            "",
            "    def connection_from_context(self, request_context):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the request context.",
            "",
            "        ``request_context`` must at least contain the ``scheme`` key and its",
            "        value must be a key in ``key_fn_by_scheme`` instance variable.",
            "        \"\"\"",
            "        scheme = request_context['scheme'].lower()",
            "        pool_key_constructor = self.key_fn_by_scheme[scheme]",
            "        pool_key = pool_key_constructor(request_context)",
            "",
            "        return self.connection_from_pool_key(pool_key, request_context=request_context)",
            "",
            "    def connection_from_pool_key(self, pool_key, request_context=None):",
            "        \"\"\"",
            "        Get a :class:`ConnectionPool` based on the provided pool key.",
            "",
            "        ``pool_key`` should be a namedtuple that only contains immutable",
            "        objects. At a minimum it must have the ``scheme``, ``host``, and",
            "        ``port`` fields.",
            "        \"\"\"",
            "        with self.pools.lock:",
            "            # If the scheme, host, or port doesn't match existing open",
            "            # connections, open a new ConnectionPool.",
            "            pool = self.pools.get(pool_key)",
            "            if pool:",
            "                return pool",
            "",
            "            # Make a fresh ConnectionPool of the desired type",
            "            scheme = request_context['scheme']",
            "            host = request_context['host']",
            "            port = request_context['port']",
            "            pool = self._new_pool(scheme, host, port, request_context=request_context)",
            "            self.pools[pool_key] = pool",
            "",
            "        return pool",
            "",
            "    def connection_from_url(self, url, pool_kwargs=None):",
            "        \"\"\"",
            "        Similar to :func:`urllib3.connectionpool.connection_from_url`.",
            "",
            "        If ``pool_kwargs`` is not provided and a new pool needs to be",
            "        constructed, ``self.connection_pool_kw`` is used to initialize",
            "        the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``",
            "        is provided, it is used instead. Note that if a new pool does not",
            "        need to be created for the request, the provided ``pool_kwargs`` are",
            "        not used.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        return self.connection_from_host(u.host, port=u.port, scheme=u.scheme,",
            "                                         pool_kwargs=pool_kwargs)",
            "",
            "    def _merge_pool_kwargs(self, override):",
            "        \"\"\"",
            "        Merge a dictionary of override values for self.connection_pool_kw.",
            "",
            "        This does not modify self.connection_pool_kw and returns a new dict.",
            "        Any keys in the override dictionary with a value of ``None`` are",
            "        removed from the merged dictionary.",
            "        \"\"\"",
            "        base_pool_kwargs = self.connection_pool_kw.copy()",
            "        if override:",
            "            for key, value in override.items():",
            "                if value is None:",
            "                    try:",
            "                        del base_pool_kwargs[key]",
            "                    except KeyError:",
            "                        pass",
            "                else:",
            "                    base_pool_kwargs[key] = value",
            "        return base_pool_kwargs",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"\"\"",
            "        Same as :meth:`urllib3.connectionpool.HTTPConnectionPool.urlopen`",
            "        with custom cross-host redirect logic and only sends the request-uri",
            "        portion of the ``url``.",
            "",
            "        The given ``url`` parameter must be absolute, such that an appropriate",
            "        :class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.",
            "        \"\"\"",
            "        u = parse_url(url)",
            "        conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)",
            "",
            "        kw['assert_same_host'] = False",
            "        kw['redirect'] = False",
            "",
            "        if 'headers' not in kw:",
            "            kw['headers'] = self.headers.copy()",
            "",
            "        if self.proxy is not None and u.scheme == \"http\":",
            "            response = conn.urlopen(method, url, **kw)",
            "        else:",
            "            response = conn.urlopen(method, u.request_uri, **kw)",
            "",
            "        redirect_location = redirect and response.get_redirect_location()",
            "        if not redirect_location:",
            "            return response",
            "",
            "        # Support relative URLs for redirecting.",
            "        redirect_location = urljoin(url, redirect_location)",
            "",
            "        # RFC 7231, Section 6.4.4",
            "        if response.status == 303:",
            "            method = 'GET'",
            "",
            "        retries = kw.get('retries')",
            "        if not isinstance(retries, Retry):",
            "            retries = Retry.from_int(retries, redirect=redirect)",
            "",
            "        # Strip headers marked as unsafe to forward to the redirected location.",
            "        # Check remove_headers_on_redirect to avoid a potential network call within",
            "        # conn.is_same_host() which may use socket.gethostbyname() in the future.",
            "        if (retries.remove_headers_on_redirect",
            "                and not conn.is_same_host(redirect_location)):",
            "            for header in retries.remove_headers_on_redirect:",
            "                kw['headers'].pop(header, None)",
            "",
            "        try:",
            "            retries = retries.increment(method, url, response=response, _pool=conn)",
            "        except MaxRetryError:",
            "            if retries.raise_on_redirect:",
            "                raise",
            "            return response",
            "",
            "        kw['retries'] = retries",
            "        kw['redirect'] = redirect",
            "",
            "        log.info(\"Redirecting %s -> %s\", url, redirect_location)",
            "        return self.urlopen(method, redirect_location, **kw)",
            "",
            "",
            "class ProxyManager(PoolManager):",
            "    \"\"\"",
            "    Behaves just like :class:`PoolManager`, but sends all requests through",
            "    the defined proxy, using the CONNECT method for HTTPS URLs.",
            "",
            "    :param proxy_url:",
            "        The URL of the proxy to be used.",
            "",
            "    :param proxy_headers:",
            "        A dictionary containing headers that will be sent to the proxy. In case",
            "        of HTTP they are being sent with each request, while in the",
            "        HTTPS/CONNECT case they are sent only once. Could be used for proxy",
            "        authentication.",
            "",
            "    Example:",
            "        >>> proxy = urllib3.ProxyManager('http://localhost:3128/')",
            "        >>> r1 = proxy.request('GET', 'http://google.com/')",
            "        >>> r2 = proxy.request('GET', 'http://httpbin.org/')",
            "        >>> len(proxy.pools)",
            "        1",
            "        >>> r3 = proxy.request('GET', 'https://httpbin.org/')",
            "        >>> r4 = proxy.request('GET', 'https://twitter.com/')",
            "        >>> len(proxy.pools)",
            "        3",
            "",
            "    \"\"\"",
            "",
            "    def __init__(self, proxy_url, num_pools=10, headers=None,",
            "                 proxy_headers=None, **connection_pool_kw):",
            "",
            "        if isinstance(proxy_url, HTTPConnectionPool):",
            "            proxy_url = '%s://%s:%i' % (proxy_url.scheme, proxy_url.host,",
            "                                        proxy_url.port)",
            "        proxy = parse_url(proxy_url)",
            "        if not proxy.port:",
            "            port = port_by_scheme.get(proxy.scheme, 80)",
            "            proxy = proxy._replace(port=port)",
            "",
            "        if proxy.scheme not in (\"http\", \"https\"):",
            "            raise ProxySchemeUnknown(proxy.scheme)",
            "",
            "        self.proxy = proxy",
            "        self.proxy_headers = proxy_headers or {}",
            "",
            "        connection_pool_kw['_proxy'] = self.proxy",
            "        connection_pool_kw['_proxy_headers'] = self.proxy_headers",
            "",
            "        super(ProxyManager, self).__init__(",
            "            num_pools, headers, **connection_pool_kw)",
            "",
            "    def connection_from_host(self, host, port=None, scheme='http', pool_kwargs=None):",
            "        if scheme == \"https\":",
            "            return super(ProxyManager, self).connection_from_host(",
            "                host, port, scheme, pool_kwargs=pool_kwargs)",
            "",
            "        return super(ProxyManager, self).connection_from_host(",
            "            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs)",
            "",
            "    def _set_proxy_headers(self, url, headers=None):",
            "        \"\"\"",
            "        Sets headers needed by proxies: specifically, the Accept and Host",
            "        headers. Only sets headers not provided by the user.",
            "        \"\"\"",
            "        headers_ = {'Accept': '*/*'}",
            "",
            "        netloc = parse_url(url).netloc",
            "        if netloc:",
            "            headers_['Host'] = netloc",
            "",
            "        if headers:",
            "            headers_.update(headers)",
            "        return headers_",
            "",
            "    def urlopen(self, method, url, redirect=True, **kw):",
            "        \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"",
            "        u = parse_url(url)",
            "",
            "        if u.scheme == \"http\":",
            "            # For proxied HTTPS requests, httplib sets the necessary headers",
            "            # on the CONNECT to the proxy. For HTTP, we'll definitely",
            "            # need to set 'Host' at the very least.",
            "            headers = kw.get('headers', self.headers)",
            "            kw['headers'] = self._set_proxy_headers(url, headers)",
            "",
            "        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)",
            "",
            "",
            "def proxy_from_url(url, **kw):",
            "    return ProxyManager(proxy_url=url, **kw)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "316": [
                "PoolManager",
                "urlopen"
            ]
        },
        "addLocation": []
    },
    "urllib3/util/retry.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 19,
                "afterPatchRowNumber": 19,
                "PatchRowcode": " "
            },
            "1": {
                "beforePatchRowNumber": 20,
                "afterPatchRowNumber": 20,
                "PatchRowcode": " log = logging.getLogger(__name__)"
            },
            "2": {
                "beforePatchRowNumber": 21,
                "afterPatchRowNumber": 21,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": 22,
                "afterPatchRowNumber": 23,
                "PatchRowcode": " # Data structure for representing the metadata of requests that result in a retry."
            },
            "5": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " RequestHistory = namedtuple('RequestHistory', [\"method\", \"url\", \"error\","
            },
            "6": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 25,
                "PatchRowcode": "                                                \"status\", \"redirect_location\"])"
            },
            "7": {
                "beforePatchRowNumber": 139,
                "afterPatchRowNumber": 140,
                "PatchRowcode": "         Whether to respect Retry-After header on status codes defined as"
            },
            "8": {
                "beforePatchRowNumber": 140,
                "afterPatchRowNumber": 141,
                "PatchRowcode": "         :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not."
            },
            "9": {
                "beforePatchRowNumber": 141,
                "afterPatchRowNumber": 142,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 143,
                "PatchRowcode": "+    :param iterable remove_headers_on_redirect:"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 144,
                "PatchRowcode": "+        Sequence of headers to remove from the request when a response"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 145,
                "PatchRowcode": "+        indicating a redirect is returned before firing off the redirected"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 146,
                "PatchRowcode": "+        request."
            },
            "14": {
                "beforePatchRowNumber": 142,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "     \"\"\""
            },
            "15": {
                "beforePatchRowNumber": 143,
                "afterPatchRowNumber": 148,
                "PatchRowcode": " "
            },
            "16": {
                "beforePatchRowNumber": 144,
                "afterPatchRowNumber": 149,
                "PatchRowcode": "     DEFAULT_METHOD_WHITELIST = frozenset(["
            },
            "17": {
                "beforePatchRowNumber": 145,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "         'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE'])"
            },
            "18": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 151,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "     RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])"
            },
            "20": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 153,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 154,
                "PatchRowcode": "+    DEFAULT_REDIRECT_HEADERS_BLACKLIST = frozenset(['Authorization'])"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 155,
                "PatchRowcode": "+"
            },
            "23": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": 156,
                "PatchRowcode": "     #: Maximum backoff time."
            },
            "24": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 157,
                "PatchRowcode": "     BACKOFF_MAX = 120"
            },
            "25": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 158,
                "PatchRowcode": " "
            },
            "26": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 159,
                "PatchRowcode": "     def __init__(self, total=10, connect=None, read=None, redirect=None, status=None,"
            },
            "27": {
                "beforePatchRowNumber": 153,
                "afterPatchRowNumber": 160,
                "PatchRowcode": "                  method_whitelist=DEFAULT_METHOD_WHITELIST, status_forcelist=None,"
            },
            "28": {
                "beforePatchRowNumber": 154,
                "afterPatchRowNumber": 161,
                "PatchRowcode": "                  backoff_factor=0, raise_on_redirect=True, raise_on_status=True,"
            },
            "29": {
                "beforePatchRowNumber": 155,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                 history=None, respect_retry_after_header=True):"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 162,
                "PatchRowcode": "+                 history=None, respect_retry_after_header=True,"
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 163,
                "PatchRowcode": "+                 remove_headers_on_redirect=DEFAULT_REDIRECT_HEADERS_BLACKLIST):"
            },
            "32": {
                "beforePatchRowNumber": 156,
                "afterPatchRowNumber": 164,
                "PatchRowcode": " "
            },
            "33": {
                "beforePatchRowNumber": 157,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "         self.total = total"
            },
            "34": {
                "beforePatchRowNumber": 158,
                "afterPatchRowNumber": 166,
                "PatchRowcode": "         self.connect = connect"
            },
            "35": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 179,
                "PatchRowcode": "         self.raise_on_status = raise_on_status"
            },
            "36": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": 180,
                "PatchRowcode": "         self.history = history or tuple()"
            },
            "37": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 181,
                "PatchRowcode": "         self.respect_retry_after_header = respect_retry_after_header"
            },
            "38": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 182,
                "PatchRowcode": "+        self.remove_headers_on_redirect = remove_headers_on_redirect"
            },
            "39": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 183,
                "PatchRowcode": " "
            },
            "40": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 184,
                "PatchRowcode": "     def new(self, **kw):"
            },
            "41": {
                "beforePatchRowNumber": 176,
                "afterPatchRowNumber": 185,
                "PatchRowcode": "         params = dict("
            },
            "42": {
                "beforePatchRowNumber": 182,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "             raise_on_redirect=self.raise_on_redirect,"
            },
            "43": {
                "beforePatchRowNumber": 183,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "             raise_on_status=self.raise_on_status,"
            },
            "44": {
                "beforePatchRowNumber": 184,
                "afterPatchRowNumber": 193,
                "PatchRowcode": "             history=self.history,"
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+            remove_headers_on_redirect=self.remove_headers_on_redirect"
            },
            "46": {
                "beforePatchRowNumber": 185,
                "afterPatchRowNumber": 195,
                "PatchRowcode": "         )"
            },
            "47": {
                "beforePatchRowNumber": 186,
                "afterPatchRowNumber": 196,
                "PatchRowcode": "         params.update(kw)"
            },
            "48": {
                "beforePatchRowNumber": 187,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "         return type(self)(**params)"
            }
        },
        "frontPatchFile": [
            "from __future__ import absolute_import",
            "import time",
            "import logging",
            "from collections import namedtuple",
            "from itertools import takewhile",
            "import email",
            "import re",
            "",
            "from ..exceptions import (",
            "    ConnectTimeoutError,",
            "    MaxRetryError,",
            "    ProtocolError,",
            "    ReadTimeoutError,",
            "    ResponseError,",
            "    InvalidHeader,",
            ")",
            "from ..packages import six",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "# Data structure for representing the metadata of requests that result in a retry.",
            "RequestHistory = namedtuple('RequestHistory', [\"method\", \"url\", \"error\",",
            "                                               \"status\", \"redirect_location\"])",
            "",
            "",
            "class Retry(object):",
            "    \"\"\" Retry configuration.",
            "",
            "    Each retry attempt will create a new Retry object with updated values, so",
            "    they can be safely reused.",
            "",
            "    Retries can be defined as a default for a pool::",
            "",
            "        retries = Retry(connect=5, read=2, redirect=5)",
            "        http = PoolManager(retries=retries)",
            "        response = http.request('GET', 'http://example.com/')",
            "",
            "    Or per-request (which overrides the default for the pool)::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=Retry(10))",
            "",
            "    Retries can be disabled by passing ``False``::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=False)",
            "",
            "    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless",
            "    retries are disabled, in which case the causing exception will be raised.",
            "",
            "    :param int total:",
            "        Total number of retries to allow. Takes precedence over other counts.",
            "",
            "        Set to ``None`` to remove this constraint and fall back on other",
            "        counts. It's a good idea to set this to some sensibly-high value to",
            "        account for unexpected edge cases and avoid infinite retry loops.",
            "",
            "        Set to ``0`` to fail on the first retry.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int connect:",
            "        How many connection-related errors to retry on.",
            "",
            "        These are errors raised before the request is sent to the remote server,",
            "        which we assume has not triggered the server to process the request.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int read:",
            "        How many times to retry on read errors.",
            "",
            "        These errors are raised after the request was sent to the server, so the",
            "        request may have side-effects.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int redirect:",
            "        How many redirects to perform. Limit this to avoid infinite redirect",
            "        loops.",
            "",
            "        A redirect is a HTTP response with a status code 301, 302, 303, 307 or",
            "        308.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int status:",
            "        How many times to retry on bad status codes.",
            "",
            "        These are retries made on responses, where status code matches",
            "        ``status_forcelist``.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param iterable method_whitelist:",
            "        Set of uppercased HTTP method verbs that we should retry on.",
            "",
            "        By default, we only retry on methods which are considered to be",
            "        idempotent (multiple requests with the same parameters end with the",
            "        same state). See :attr:`Retry.DEFAULT_METHOD_WHITELIST`.",
            "",
            "        Set to a ``False`` value to retry on any verb.",
            "",
            "    :param iterable status_forcelist:",
            "        A set of integer HTTP status codes that we should force a retry on.",
            "        A retry is initiated if the request method is in ``method_whitelist``",
            "        and the response status code is in ``status_forcelist``.",
            "",
            "        By default, this is disabled with ``None``.",
            "",
            "    :param float backoff_factor:",
            "        A backoff factor to apply between attempts after the second try",
            "        (most errors are resolved immediately by a second try without a",
            "        delay). urllib3 will sleep for::",
            "",
            "            {backoff factor} * (2 ^ ({number of total retries} - 1))",
            "",
            "        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep",
            "        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer",
            "        than :attr:`Retry.BACKOFF_MAX`.",
            "",
            "        By default, backoff is disabled (set to 0).",
            "",
            "    :param bool raise_on_redirect: Whether, if the number of redirects is",
            "        exhausted, to raise a MaxRetryError, or to return a response with a",
            "        response code in the 3xx range.",
            "",
            "    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:",
            "        whether we should raise an exception, or return a response,",
            "        if status falls in ``status_forcelist`` range and retries have",
            "        been exhausted.",
            "",
            "    :param tuple history: The history of the request encountered during",
            "        each call to :meth:`~Retry.increment`. The list is in the order",
            "        the requests occurred. Each list item is of class :class:`RequestHistory`.",
            "",
            "    :param bool respect_retry_after_header:",
            "        Whether to respect Retry-After header on status codes defined as",
            "        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.",
            "",
            "    \"\"\"",
            "",
            "    DEFAULT_METHOD_WHITELIST = frozenset([",
            "        'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE'])",
            "",
            "    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])",
            "",
            "    #: Maximum backoff time.",
            "    BACKOFF_MAX = 120",
            "",
            "    def __init__(self, total=10, connect=None, read=None, redirect=None, status=None,",
            "                 method_whitelist=DEFAULT_METHOD_WHITELIST, status_forcelist=None,",
            "                 backoff_factor=0, raise_on_redirect=True, raise_on_status=True,",
            "                 history=None, respect_retry_after_header=True):",
            "",
            "        self.total = total",
            "        self.connect = connect",
            "        self.read = read",
            "        self.status = status",
            "",
            "        if redirect is False or total is False:",
            "            redirect = 0",
            "            raise_on_redirect = False",
            "",
            "        self.redirect = redirect",
            "        self.status_forcelist = status_forcelist or set()",
            "        self.method_whitelist = method_whitelist",
            "        self.backoff_factor = backoff_factor",
            "        self.raise_on_redirect = raise_on_redirect",
            "        self.raise_on_status = raise_on_status",
            "        self.history = history or tuple()",
            "        self.respect_retry_after_header = respect_retry_after_header",
            "",
            "    def new(self, **kw):",
            "        params = dict(",
            "            total=self.total,",
            "            connect=self.connect, read=self.read, redirect=self.redirect, status=self.status,",
            "            method_whitelist=self.method_whitelist,",
            "            status_forcelist=self.status_forcelist,",
            "            backoff_factor=self.backoff_factor,",
            "            raise_on_redirect=self.raise_on_redirect,",
            "            raise_on_status=self.raise_on_status,",
            "            history=self.history,",
            "        )",
            "        params.update(kw)",
            "        return type(self)(**params)",
            "",
            "    @classmethod",
            "    def from_int(cls, retries, redirect=True, default=None):",
            "        \"\"\" Backwards-compatibility for the old retries format.\"\"\"",
            "        if retries is None:",
            "            retries = default if default is not None else cls.DEFAULT",
            "",
            "        if isinstance(retries, Retry):",
            "            return retries",
            "",
            "        redirect = bool(redirect) and None",
            "        new_retries = cls(retries, redirect=redirect)",
            "        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)",
            "        return new_retries",
            "",
            "    def get_backoff_time(self):",
            "        \"\"\" Formula for computing the current backoff",
            "",
            "        :rtype: float",
            "        \"\"\"",
            "        # We want to consider only the last consecutive errors sequence (Ignore redirects).",
            "        consecutive_errors_len = len(list(takewhile(lambda x: x.redirect_location is None,",
            "                                                    reversed(self.history))))",
            "        if consecutive_errors_len <= 1:",
            "            return 0",
            "",
            "        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))",
            "        return min(self.BACKOFF_MAX, backoff_value)",
            "",
            "    def parse_retry_after(self, retry_after):",
            "        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4",
            "        if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):",
            "            seconds = int(retry_after)",
            "        else:",
            "            retry_date_tuple = email.utils.parsedate(retry_after)",
            "            if retry_date_tuple is None:",
            "                raise InvalidHeader(\"Invalid Retry-After header: %s\" % retry_after)",
            "            retry_date = time.mktime(retry_date_tuple)",
            "            seconds = retry_date - time.time()",
            "",
            "        if seconds < 0:",
            "            seconds = 0",
            "",
            "        return seconds",
            "",
            "    def get_retry_after(self, response):",
            "        \"\"\" Get the value of Retry-After in seconds. \"\"\"",
            "",
            "        retry_after = response.getheader(\"Retry-After\")",
            "",
            "        if retry_after is None:",
            "            return None",
            "",
            "        return self.parse_retry_after(retry_after)",
            "",
            "    def sleep_for_retry(self, response=None):",
            "        retry_after = self.get_retry_after(response)",
            "        if retry_after:",
            "            time.sleep(retry_after)",
            "            return True",
            "",
            "        return False",
            "",
            "    def _sleep_backoff(self):",
            "        backoff = self.get_backoff_time()",
            "        if backoff <= 0:",
            "            return",
            "        time.sleep(backoff)",
            "",
            "    def sleep(self, response=None):",
            "        \"\"\" Sleep between retry attempts.",
            "",
            "        This method will respect a server's ``Retry-After`` response header",
            "        and sleep the duration of the time requested. If that is not present, it",
            "        will use an exponential backoff. By default, the backoff factor is 0 and",
            "        this method will return immediately.",
            "        \"\"\"",
            "",
            "        if response:",
            "            slept = self.sleep_for_retry(response)",
            "            if slept:",
            "                return",
            "",
            "        self._sleep_backoff()",
            "",
            "    def _is_connection_error(self, err):",
            "        \"\"\" Errors when we're fairly sure that the server did not receive the",
            "        request, so it should be safe to retry.",
            "        \"\"\"",
            "        return isinstance(err, ConnectTimeoutError)",
            "",
            "    def _is_read_error(self, err):",
            "        \"\"\" Errors that occur after the request has been started, so we should",
            "        assume that the server began processing it.",
            "        \"\"\"",
            "        return isinstance(err, (ReadTimeoutError, ProtocolError))",
            "",
            "    def _is_method_retryable(self, method):",
            "        \"\"\" Checks if a given HTTP method should be retried upon, depending if",
            "        it is included on the method whitelist.",
            "        \"\"\"",
            "        if self.method_whitelist and method.upper() not in self.method_whitelist:",
            "            return False",
            "",
            "        return True",
            "",
            "    def is_retry(self, method, status_code, has_retry_after=False):",
            "        \"\"\" Is this method/status code retryable? (Based on whitelists and control",
            "        variables such as the number of total retries to allow, whether to",
            "        respect the Retry-After header, whether this header is present, and",
            "        whether the returned status code is on the list of status codes to",
            "        be retried upon on the presence of the aforementioned header)",
            "        \"\"\"",
            "        if not self._is_method_retryable(method):",
            "            return False",
            "",
            "        if self.status_forcelist and status_code in self.status_forcelist:",
            "            return True",
            "",
            "        return (self.total and self.respect_retry_after_header and",
            "                has_retry_after and (status_code in self.RETRY_AFTER_STATUS_CODES))",
            "",
            "    def is_exhausted(self):",
            "        \"\"\" Are we out of retries? \"\"\"",
            "        retry_counts = (self.total, self.connect, self.read, self.redirect, self.status)",
            "        retry_counts = list(filter(None, retry_counts))",
            "        if not retry_counts:",
            "            return False",
            "",
            "        return min(retry_counts) < 0",
            "",
            "    def increment(self, method=None, url=None, response=None, error=None,",
            "                  _pool=None, _stacktrace=None):",
            "        \"\"\" Return a new Retry object with incremented retry counters.",
            "",
            "        :param response: A response object, or None, if the server did not",
            "            return a response.",
            "        :type response: :class:`~urllib3.response.HTTPResponse`",
            "        :param Exception error: An error encountered during the request, or",
            "            None if the response was received successfully.",
            "",
            "        :return: A new ``Retry`` object.",
            "        \"\"\"",
            "        if self.total is False and error:",
            "            # Disabled, indicate to re-raise the error.",
            "            raise six.reraise(type(error), error, _stacktrace)",
            "",
            "        total = self.total",
            "        if total is not None:",
            "            total -= 1",
            "",
            "        connect = self.connect",
            "        read = self.read",
            "        redirect = self.redirect",
            "        status_count = self.status",
            "        cause = 'unknown'",
            "        status = None",
            "        redirect_location = None",
            "",
            "        if error and self._is_connection_error(error):",
            "            # Connect retry?",
            "            if connect is False:",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif connect is not None:",
            "                connect -= 1",
            "",
            "        elif error and self._is_read_error(error):",
            "            # Read retry?",
            "            if read is False or not self._is_method_retryable(method):",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif read is not None:",
            "                read -= 1",
            "",
            "        elif response and response.get_redirect_location():",
            "            # Redirect retry?",
            "            if redirect is not None:",
            "                redirect -= 1",
            "            cause = 'too many redirects'",
            "            redirect_location = response.get_redirect_location()",
            "            status = response.status",
            "",
            "        else:",
            "            # Incrementing because of a server error like a 500 in",
            "            # status_forcelist and a the given method is in the whitelist",
            "            cause = ResponseError.GENERIC_ERROR",
            "            if response and response.status:",
            "                if status_count is not None:",
            "                    status_count -= 1",
            "                cause = ResponseError.SPECIFIC_ERROR.format(",
            "                    status_code=response.status)",
            "                status = response.status",
            "",
            "        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)",
            "",
            "        new_retry = self.new(",
            "            total=total,",
            "            connect=connect, read=read, redirect=redirect, status=status_count,",
            "            history=history)",
            "",
            "        if new_retry.is_exhausted():",
            "            raise MaxRetryError(_pool, url, error or ResponseError(cause))",
            "",
            "        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)",
            "",
            "        return new_retry",
            "",
            "    def __repr__(self):",
            "        return ('{cls.__name__}(total={self.total}, connect={self.connect}, '",
            "                'read={self.read}, redirect={self.redirect}, status={self.status})').format(",
            "                    cls=type(self), self=self)",
            "",
            "",
            "# For backwards compatibility (equivalent to pre-v1.9):",
            "Retry.DEFAULT = Retry(3)"
        ],
        "afterPatchFile": [
            "from __future__ import absolute_import",
            "import time",
            "import logging",
            "from collections import namedtuple",
            "from itertools import takewhile",
            "import email",
            "import re",
            "",
            "from ..exceptions import (",
            "    ConnectTimeoutError,",
            "    MaxRetryError,",
            "    ProtocolError,",
            "    ReadTimeoutError,",
            "    ResponseError,",
            "    InvalidHeader,",
            ")",
            "from ..packages import six",
            "",
            "",
            "log = logging.getLogger(__name__)",
            "",
            "",
            "# Data structure for representing the metadata of requests that result in a retry.",
            "RequestHistory = namedtuple('RequestHistory', [\"method\", \"url\", \"error\",",
            "                                               \"status\", \"redirect_location\"])",
            "",
            "",
            "class Retry(object):",
            "    \"\"\" Retry configuration.",
            "",
            "    Each retry attempt will create a new Retry object with updated values, so",
            "    they can be safely reused.",
            "",
            "    Retries can be defined as a default for a pool::",
            "",
            "        retries = Retry(connect=5, read=2, redirect=5)",
            "        http = PoolManager(retries=retries)",
            "        response = http.request('GET', 'http://example.com/')",
            "",
            "    Or per-request (which overrides the default for the pool)::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=Retry(10))",
            "",
            "    Retries can be disabled by passing ``False``::",
            "",
            "        response = http.request('GET', 'http://example.com/', retries=False)",
            "",
            "    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless",
            "    retries are disabled, in which case the causing exception will be raised.",
            "",
            "    :param int total:",
            "        Total number of retries to allow. Takes precedence over other counts.",
            "",
            "        Set to ``None`` to remove this constraint and fall back on other",
            "        counts. It's a good idea to set this to some sensibly-high value to",
            "        account for unexpected edge cases and avoid infinite retry loops.",
            "",
            "        Set to ``0`` to fail on the first retry.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int connect:",
            "        How many connection-related errors to retry on.",
            "",
            "        These are errors raised before the request is sent to the remote server,",
            "        which we assume has not triggered the server to process the request.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int read:",
            "        How many times to retry on read errors.",
            "",
            "        These errors are raised after the request was sent to the server, so the",
            "        request may have side-effects.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param int redirect:",
            "        How many redirects to perform. Limit this to avoid infinite redirect",
            "        loops.",
            "",
            "        A redirect is a HTTP response with a status code 301, 302, 303, 307 or",
            "        308.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "        Set to ``False`` to disable and imply ``raise_on_redirect=False``.",
            "",
            "    :param int status:",
            "        How many times to retry on bad status codes.",
            "",
            "        These are retries made on responses, where status code matches",
            "        ``status_forcelist``.",
            "",
            "        Set to ``0`` to fail on the first retry of this type.",
            "",
            "    :param iterable method_whitelist:",
            "        Set of uppercased HTTP method verbs that we should retry on.",
            "",
            "        By default, we only retry on methods which are considered to be",
            "        idempotent (multiple requests with the same parameters end with the",
            "        same state). See :attr:`Retry.DEFAULT_METHOD_WHITELIST`.",
            "",
            "        Set to a ``False`` value to retry on any verb.",
            "",
            "    :param iterable status_forcelist:",
            "        A set of integer HTTP status codes that we should force a retry on.",
            "        A retry is initiated if the request method is in ``method_whitelist``",
            "        and the response status code is in ``status_forcelist``.",
            "",
            "        By default, this is disabled with ``None``.",
            "",
            "    :param float backoff_factor:",
            "        A backoff factor to apply between attempts after the second try",
            "        (most errors are resolved immediately by a second try without a",
            "        delay). urllib3 will sleep for::",
            "",
            "            {backoff factor} * (2 ^ ({number of total retries} - 1))",
            "",
            "        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep",
            "        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer",
            "        than :attr:`Retry.BACKOFF_MAX`.",
            "",
            "        By default, backoff is disabled (set to 0).",
            "",
            "    :param bool raise_on_redirect: Whether, if the number of redirects is",
            "        exhausted, to raise a MaxRetryError, or to return a response with a",
            "        response code in the 3xx range.",
            "",
            "    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:",
            "        whether we should raise an exception, or return a response,",
            "        if status falls in ``status_forcelist`` range and retries have",
            "        been exhausted.",
            "",
            "    :param tuple history: The history of the request encountered during",
            "        each call to :meth:`~Retry.increment`. The list is in the order",
            "        the requests occurred. Each list item is of class :class:`RequestHistory`.",
            "",
            "    :param bool respect_retry_after_header:",
            "        Whether to respect Retry-After header on status codes defined as",
            "        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.",
            "",
            "    :param iterable remove_headers_on_redirect:",
            "        Sequence of headers to remove from the request when a response",
            "        indicating a redirect is returned before firing off the redirected",
            "        request.",
            "    \"\"\"",
            "",
            "    DEFAULT_METHOD_WHITELIST = frozenset([",
            "        'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE'])",
            "",
            "    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])",
            "",
            "    DEFAULT_REDIRECT_HEADERS_BLACKLIST = frozenset(['Authorization'])",
            "",
            "    #: Maximum backoff time.",
            "    BACKOFF_MAX = 120",
            "",
            "    def __init__(self, total=10, connect=None, read=None, redirect=None, status=None,",
            "                 method_whitelist=DEFAULT_METHOD_WHITELIST, status_forcelist=None,",
            "                 backoff_factor=0, raise_on_redirect=True, raise_on_status=True,",
            "                 history=None, respect_retry_after_header=True,",
            "                 remove_headers_on_redirect=DEFAULT_REDIRECT_HEADERS_BLACKLIST):",
            "",
            "        self.total = total",
            "        self.connect = connect",
            "        self.read = read",
            "        self.status = status",
            "",
            "        if redirect is False or total is False:",
            "            redirect = 0",
            "            raise_on_redirect = False",
            "",
            "        self.redirect = redirect",
            "        self.status_forcelist = status_forcelist or set()",
            "        self.method_whitelist = method_whitelist",
            "        self.backoff_factor = backoff_factor",
            "        self.raise_on_redirect = raise_on_redirect",
            "        self.raise_on_status = raise_on_status",
            "        self.history = history or tuple()",
            "        self.respect_retry_after_header = respect_retry_after_header",
            "        self.remove_headers_on_redirect = remove_headers_on_redirect",
            "",
            "    def new(self, **kw):",
            "        params = dict(",
            "            total=self.total,",
            "            connect=self.connect, read=self.read, redirect=self.redirect, status=self.status,",
            "            method_whitelist=self.method_whitelist,",
            "            status_forcelist=self.status_forcelist,",
            "            backoff_factor=self.backoff_factor,",
            "            raise_on_redirect=self.raise_on_redirect,",
            "            raise_on_status=self.raise_on_status,",
            "            history=self.history,",
            "            remove_headers_on_redirect=self.remove_headers_on_redirect",
            "        )",
            "        params.update(kw)",
            "        return type(self)(**params)",
            "",
            "    @classmethod",
            "    def from_int(cls, retries, redirect=True, default=None):",
            "        \"\"\" Backwards-compatibility for the old retries format.\"\"\"",
            "        if retries is None:",
            "            retries = default if default is not None else cls.DEFAULT",
            "",
            "        if isinstance(retries, Retry):",
            "            return retries",
            "",
            "        redirect = bool(redirect) and None",
            "        new_retries = cls(retries, redirect=redirect)",
            "        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)",
            "        return new_retries",
            "",
            "    def get_backoff_time(self):",
            "        \"\"\" Formula for computing the current backoff",
            "",
            "        :rtype: float",
            "        \"\"\"",
            "        # We want to consider only the last consecutive errors sequence (Ignore redirects).",
            "        consecutive_errors_len = len(list(takewhile(lambda x: x.redirect_location is None,",
            "                                                    reversed(self.history))))",
            "        if consecutive_errors_len <= 1:",
            "            return 0",
            "",
            "        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))",
            "        return min(self.BACKOFF_MAX, backoff_value)",
            "",
            "    def parse_retry_after(self, retry_after):",
            "        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4",
            "        if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):",
            "            seconds = int(retry_after)",
            "        else:",
            "            retry_date_tuple = email.utils.parsedate(retry_after)",
            "            if retry_date_tuple is None:",
            "                raise InvalidHeader(\"Invalid Retry-After header: %s\" % retry_after)",
            "            retry_date = time.mktime(retry_date_tuple)",
            "            seconds = retry_date - time.time()",
            "",
            "        if seconds < 0:",
            "            seconds = 0",
            "",
            "        return seconds",
            "",
            "    def get_retry_after(self, response):",
            "        \"\"\" Get the value of Retry-After in seconds. \"\"\"",
            "",
            "        retry_after = response.getheader(\"Retry-After\")",
            "",
            "        if retry_after is None:",
            "            return None",
            "",
            "        return self.parse_retry_after(retry_after)",
            "",
            "    def sleep_for_retry(self, response=None):",
            "        retry_after = self.get_retry_after(response)",
            "        if retry_after:",
            "            time.sleep(retry_after)",
            "            return True",
            "",
            "        return False",
            "",
            "    def _sleep_backoff(self):",
            "        backoff = self.get_backoff_time()",
            "        if backoff <= 0:",
            "            return",
            "        time.sleep(backoff)",
            "",
            "    def sleep(self, response=None):",
            "        \"\"\" Sleep between retry attempts.",
            "",
            "        This method will respect a server's ``Retry-After`` response header",
            "        and sleep the duration of the time requested. If that is not present, it",
            "        will use an exponential backoff. By default, the backoff factor is 0 and",
            "        this method will return immediately.",
            "        \"\"\"",
            "",
            "        if response:",
            "            slept = self.sleep_for_retry(response)",
            "            if slept:",
            "                return",
            "",
            "        self._sleep_backoff()",
            "",
            "    def _is_connection_error(self, err):",
            "        \"\"\" Errors when we're fairly sure that the server did not receive the",
            "        request, so it should be safe to retry.",
            "        \"\"\"",
            "        return isinstance(err, ConnectTimeoutError)",
            "",
            "    def _is_read_error(self, err):",
            "        \"\"\" Errors that occur after the request has been started, so we should",
            "        assume that the server began processing it.",
            "        \"\"\"",
            "        return isinstance(err, (ReadTimeoutError, ProtocolError))",
            "",
            "    def _is_method_retryable(self, method):",
            "        \"\"\" Checks if a given HTTP method should be retried upon, depending if",
            "        it is included on the method whitelist.",
            "        \"\"\"",
            "        if self.method_whitelist and method.upper() not in self.method_whitelist:",
            "            return False",
            "",
            "        return True",
            "",
            "    def is_retry(self, method, status_code, has_retry_after=False):",
            "        \"\"\" Is this method/status code retryable? (Based on whitelists and control",
            "        variables such as the number of total retries to allow, whether to",
            "        respect the Retry-After header, whether this header is present, and",
            "        whether the returned status code is on the list of status codes to",
            "        be retried upon on the presence of the aforementioned header)",
            "        \"\"\"",
            "        if not self._is_method_retryable(method):",
            "            return False",
            "",
            "        if self.status_forcelist and status_code in self.status_forcelist:",
            "            return True",
            "",
            "        return (self.total and self.respect_retry_after_header and",
            "                has_retry_after and (status_code in self.RETRY_AFTER_STATUS_CODES))",
            "",
            "    def is_exhausted(self):",
            "        \"\"\" Are we out of retries? \"\"\"",
            "        retry_counts = (self.total, self.connect, self.read, self.redirect, self.status)",
            "        retry_counts = list(filter(None, retry_counts))",
            "        if not retry_counts:",
            "            return False",
            "",
            "        return min(retry_counts) < 0",
            "",
            "    def increment(self, method=None, url=None, response=None, error=None,",
            "                  _pool=None, _stacktrace=None):",
            "        \"\"\" Return a new Retry object with incremented retry counters.",
            "",
            "        :param response: A response object, or None, if the server did not",
            "            return a response.",
            "        :type response: :class:`~urllib3.response.HTTPResponse`",
            "        :param Exception error: An error encountered during the request, or",
            "            None if the response was received successfully.",
            "",
            "        :return: A new ``Retry`` object.",
            "        \"\"\"",
            "        if self.total is False and error:",
            "            # Disabled, indicate to re-raise the error.",
            "            raise six.reraise(type(error), error, _stacktrace)",
            "",
            "        total = self.total",
            "        if total is not None:",
            "            total -= 1",
            "",
            "        connect = self.connect",
            "        read = self.read",
            "        redirect = self.redirect",
            "        status_count = self.status",
            "        cause = 'unknown'",
            "        status = None",
            "        redirect_location = None",
            "",
            "        if error and self._is_connection_error(error):",
            "            # Connect retry?",
            "            if connect is False:",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif connect is not None:",
            "                connect -= 1",
            "",
            "        elif error and self._is_read_error(error):",
            "            # Read retry?",
            "            if read is False or not self._is_method_retryable(method):",
            "                raise six.reraise(type(error), error, _stacktrace)",
            "            elif read is not None:",
            "                read -= 1",
            "",
            "        elif response and response.get_redirect_location():",
            "            # Redirect retry?",
            "            if redirect is not None:",
            "                redirect -= 1",
            "            cause = 'too many redirects'",
            "            redirect_location = response.get_redirect_location()",
            "            status = response.status",
            "",
            "        else:",
            "            # Incrementing because of a server error like a 500 in",
            "            # status_forcelist and a the given method is in the whitelist",
            "            cause = ResponseError.GENERIC_ERROR",
            "            if response and response.status:",
            "                if status_count is not None:",
            "                    status_count -= 1",
            "                cause = ResponseError.SPECIFIC_ERROR.format(",
            "                    status_code=response.status)",
            "                status = response.status",
            "",
            "        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)",
            "",
            "        new_retry = self.new(",
            "            total=total,",
            "            connect=connect, read=read, redirect=redirect, status=status_count,",
            "            history=history)",
            "",
            "        if new_retry.is_exhausted():",
            "            raise MaxRetryError(_pool, url, error or ResponseError(cause))",
            "",
            "        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)",
            "",
            "        return new_retry",
            "",
            "    def __repr__(self):",
            "        return ('{cls.__name__}(total={self.total}, connect={self.connect}, '",
            "                'read={self.read}, redirect={self.redirect}, status={self.status})').format(",
            "                    cls=type(self), self=self)",
            "",
            "",
            "# For backwards compatibility (equivalent to pre-v1.9):",
            "Retry.DEFAULT = Retry(3)"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "155": [
                "Retry",
                "__init__"
            ]
        },
        "addLocation": []
    }
}