{
    "lib/ansible/module_utils/keycloak.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 57,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "         auth_keycloak_url=dict(type='str', aliases=['url'], required=True),"
            },
            "1": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         auth_client_id=dict(type='str', default='admin-cli'),"
            },
            "2": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "         auth_realm=dict(type='str', required=True),"
            },
            "3": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        auth_client_secret=dict(type='str', default=None),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+        auth_client_secret=dict(type='str', default=None, no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 61,
                "PatchRowcode": "         auth_username=dict(type='str', aliases=['username'], required=True),"
            },
            "6": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 62,
                "PatchRowcode": "         auth_password=dict(type='str', aliases=['password'], required=True, no_log=True),"
            },
            "7": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 63,
                "PatchRowcode": "         validate_certs=dict(type='bool', default=True)"
            }
        },
        "frontPatchFile": [
            "# Copyright (c) 2017, Eike Frost <ei@kefro.st>",
            "#",
            "# This code is part of Ansible, but is an independent component.",
            "# This particular file snippet, and this file snippet only, is BSD licensed.",
            "# Modules you write using this snippet, which is embedded dynamically by Ansible",
            "# still belong to the author of the module, and may assign their own license",
            "# to the complete work.",
            "#",
            "# Redistribution and use in source and binary forms, with or without modification,",
            "# are permitted provided that the following conditions are met:",
            "#",
            "#    * Redistributions of source code must retain the above copyright",
            "#      notice, this list of conditions and the following disclaimer.",
            "#    * Redistributions in binary form must reproduce the above copyright notice,",
            "#      this list of conditions and the following disclaimer in the documentation",
            "#      and/or other materials provided with the distribution.",
            "#",
            "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND",
            "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.",
            "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,",
            "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
            "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS",
            "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT",
            "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE",
            "# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "import json",
            "",
            "from ansible.module_utils.urls import open_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlencode",
            "from ansible.module_utils.six.moves.urllib.error import HTTPError",
            "",
            "URL_TOKEN = \"{url}/realms/{realm}/protocol/openid-connect/token\"",
            "URL_CLIENT = \"{url}/admin/realms/{realm}/clients/{id}\"",
            "URL_CLIENTS = \"{url}/admin/realms/{realm}/clients\"",
            "URL_CLIENT_ROLES = \"{url}/admin/realms/{realm}/clients/{id}/roles\"",
            "URL_REALM_ROLES = \"{url}/admin/realms/{realm}/roles\"",
            "",
            "URL_CLIENTTEMPLATE = \"{url}/admin/realms/{realm}/client-templates/{id}\"",
            "URL_CLIENTTEMPLATES = \"{url}/admin/realms/{realm}/client-templates\"",
            "URL_GROUPS = \"{url}/admin/realms/{realm}/groups\"",
            "URL_GROUP = \"{url}/admin/realms/{realm}/groups/{groupid}\"",
            "",
            "",
            "def keycloak_argument_spec():",
            "    \"\"\"",
            "    Returns argument_spec of options common to keycloak_*-modules",
            "",
            "    :return: argument_spec dict",
            "    \"\"\"",
            "    return dict(",
            "        auth_keycloak_url=dict(type='str', aliases=['url'], required=True),",
            "        auth_client_id=dict(type='str', default='admin-cli'),",
            "        auth_realm=dict(type='str', required=True),",
            "        auth_client_secret=dict(type='str', default=None),",
            "        auth_username=dict(type='str', aliases=['username'], required=True),",
            "        auth_password=dict(type='str', aliases=['password'], required=True, no_log=True),",
            "        validate_certs=dict(type='bool', default=True)",
            "    )",
            "",
            "",
            "def camel(words):",
            "    return words.split('_')[0] + ''.join(x.capitalize() or '_' for x in words.split('_')[1:])",
            "",
            "",
            "class KeycloakAPI(object):",
            "    \"\"\" Keycloak API access; Keycloak uses OAuth 2.0 to protect its API, an access token for which",
            "        is obtained through OpenID connect",
            "    \"\"\"",
            "    def __init__(self, module):",
            "        self.module = module",
            "        self.token = None",
            "        self._connect()",
            "",
            "    def _connect(self):",
            "        \"\"\" Obtains an access_token and saves it for use in API accesses",
            "        \"\"\"",
            "        self.baseurl = self.module.params.get('auth_keycloak_url')",
            "        self.validate_certs = self.module.params.get('validate_certs')",
            "",
            "        auth_url = URL_TOKEN.format(url=self.baseurl, realm=self.module.params.get('auth_realm'))",
            "",
            "        payload = {'grant_type': 'password',",
            "                   'client_id': self.module.params.get('auth_client_id'),",
            "                   'client_secret': self.module.params.get('auth_client_secret'),",
            "                   'username': self.module.params.get('auth_username'),",
            "                   'password': self.module.params.get('auth_password')}",
            "",
            "        # Remove empty items, for instance missing client_secret",
            "        payload = dict((k, v) for k, v in payload.items() if v is not None)",
            "",
            "        try:",
            "            r = json.load(open_url(auth_url, method='POST',",
            "                                   validate_certs=self.validate_certs, data=urlencode(payload)))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned invalid JSON when trying to obtain access token from %s: %s'",
            "                                      % (auth_url, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain access token from %s: %s'",
            "                                      % (auth_url, str(e)))",
            "",
            "        if 'access_token' in r:",
            "            self.token = r['access_token']",
            "            self.restheaders = {'Authorization': 'Bearer ' + self.token,",
            "                                'Content-Type': 'application/json'}",
            "",
            "        else:",
            "            self.module.fail_json(msg='Could not obtain access token from %s' % auth_url)",
            "",
            "    def get_clients(self, realm='master', filter=None):",
            "        \"\"\" Obtains client representations for clients in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :param filter: if defined, only the client with clientId specified in the filter is returned",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        clientlist_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "        if filter is not None:",
            "            clientlist_url += '?clientId=%s' % filter",
            "",
            "        try:",
            "            return json.load(open_url(clientlist_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_by_clientid(self, client_id, realm='master'):",
            "        \"\"\" Get client representation by clientId",
            "        :param client_id: The clientId to be queried",
            "        :param realm: realm from which to obtain the client representation",
            "        :return: dict with a client representation or None if none matching exist",
            "        \"\"\"",
            "        r = self.get_clients(realm=realm, filter=client_id)",
            "        if len(r) > 0:",
            "            return r[0]",
            "        else:",
            "            return None",
            "",
            "    def get_client_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client representation by id",
            "",
            "        :param id: id (not clientId) of client to be queried",
            "        :param realm: client from this realm",
            "        :return: dict of client representation or None if none matching exist",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return json.load(open_url(client_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                          % (id, realm, str(e)))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_id(self, client_id, realm='master'):",
            "        \"\"\" Obtain id of client by client_id",
            "",
            "        :param client_id: client_id of client to be queried",
            "        :param realm: client template from this realm",
            "        :return: id of client (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_by_clientid(client_id, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client(self, id, clientrep, realm=\"master\"):",
            "        \"\"\" Update an existing client",
            "        :param id: id (not clientId) of client to be updated in Keycloak",
            "        :param clientrep: corresponding (partial/full) client representation with updates",
            "        :param realm: realm the client is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client(self, clientrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clientrep: Client representation of client to be created. Must at least contain field clientId",
            "        :param realm: realm for client to be created",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(client_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client %s in realm %s: %s'",
            "                                      % (clientrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client from Keycloak",
            "",
            "        :param id: id (not clientId) of client to be deleted",
            "        :param realm: realm of client to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_templates(self, realm='master'):",
            "        \"\"\" Obtains client template representations for client templates in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_template_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client template representation by id",
            "",
            "        :param id: id (not name) of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, id=id, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client templates %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client template %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_template_by_name(self, name, realm='master'):",
            "        \"\"\" Obtain client template representation by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        result = self.get_client_templates(realm)",
            "        if isinstance(result, list):",
            "            result = [x for x in result if x['name'] == name]",
            "            if len(result) > 0:",
            "                return result[0]",
            "        return None",
            "",
            "    def get_client_template_id(self, name, realm='master'):",
            "        \"\"\" Obtain client template id by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: client template id (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_template_by_name(name, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client_template(self, id, clienttrep, realm=\"master\"):",
            "        \"\"\" Update an existing client template",
            "        :param id: id (not name) of client template to be updated in Keycloak",
            "        :param clienttrep: corresponding (partial/full) client template representation with updates",
            "        :param realm: realm the client template is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client_template(self, clienttrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clienttrep: Client template representation of client template to be created. Must at least contain field name",
            "        :param realm: realm for client template to be created in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client template %s in realm %s: %s'",
            "                                      % (clienttrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client_template(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client template from Keycloak",
            "",
            "        :param id: id (not name) of client to be deleted",
            "        :param realm: realm of client template to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_groups(self, realm=\"master\"):",
            "        \"\"\" Fetch the name and ID of all groups on the Keycloak server.",
            "",
            "        To fetch the full data of the group, make a subsequent call to",
            "        get_group_by_groupid, passing in the ID of the group you wish to return.",
            "",
            "        :param realm: Return the groups of this realm (default \"master\").",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch list of groups in realm %s: %s\"",
            "                                      % (realm, str(e)))",
            "",
            "    def get_group_by_groupid(self, gid, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group from the provided realm using the group's unique ID.",
            "",
            "        If the group does not exist, None is returned.",
            "",
            "        gid is a UUID provided by the Keycloak API",
            "        :param gid: UUID of the group to be returned",
            "        :param realm: Realm in which the group resides; default 'master'.",
            "        \"\"\"",
            "        groups_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=gid)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                          % (gid, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (gid, realm, str(e)))",
            "",
            "    def get_group_by_name(self, name, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group within a realm based on its name.",
            "",
            "        The Keycloak API does not allow filtering of the Groups resource by name.",
            "        As a result, this method first retrieves the entire list of groups - name and ID -",
            "        then performs a second query to fetch the group.",
            "",
            "        If the group does not exist, None is returned.",
            "        :param name: Name of the group to fetch.",
            "        :param realm: Realm in which the group resides; default 'master'",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            all_groups = self.get_groups(realm=realm)",
            "",
            "            for group in all_groups:",
            "                if group['name'] == name:",
            "                    return self.get_group_by_groupid(group['id'], realm=realm)",
            "",
            "            return None",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (name, realm, str(e)))",
            "",
            "    def create_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Create a Keycloak group.",
            "",
            "        :param grouprep: a GroupRepresentation of the group to be created. Must contain at minimum the field name.",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return open_url(groups_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not create group %s in realm %s: %s\"",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def update_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Update an existing group.",
            "",
            "        :param grouprep: A GroupRepresentation of the updated group.",
            "        :return HTTPResponse object on success",
            "        \"\"\"",
            "        group_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=grouprep['id'])",
            "",
            "        try:",
            "            return open_url(group_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update group %s in realm %s: %s'",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def delete_group(self, name=None, groupid=None, realm=\"master\"):",
            "        \"\"\" Delete a group. One of name or groupid must be provided.",
            "",
            "        Providing the group ID is preferred as it avoids a second lookup to",
            "        convert a group name to an ID.",
            "",
            "        :param name: The name of the group. A lookup will be performed to retrieve the group ID.",
            "        :param groupid: The ID of the group (preferred to name).",
            "        :param realm: The realm in which this group resides, default \"master\".",
            "        \"\"\"",
            "",
            "        if groupid is None and name is None:",
            "            # prefer an exception since this is almost certainly a programming error in the module itself.",
            "            raise Exception(\"Unable to delete group - one of group ID or name must be provided.\")",
            "",
            "        # only lookup the name if groupid isn't provided.",
            "        # in the case that both are provided, prefer the ID, since it's one",
            "        # less lookup.",
            "        if groupid is None and name is not None:",
            "            for group in self.get_groups(realm=realm):",
            "                if group['name'] == name:",
            "                    groupid = group['id']",
            "                    break",
            "",
            "        # if the group doesn't exist - no problem, nothing to delete.",
            "        if groupid is None:",
            "            return None",
            "",
            "        # should have a good groupid by here.",
            "        group_url = URL_GROUP.format(realm=realm, groupid=groupid, url=self.baseurl)",
            "        try:",
            "            return open_url(group_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Unable to delete group %s: %s\" % (groupid, str(e)))"
        ],
        "afterPatchFile": [
            "# Copyright (c) 2017, Eike Frost <ei@kefro.st>",
            "#",
            "# This code is part of Ansible, but is an independent component.",
            "# This particular file snippet, and this file snippet only, is BSD licensed.",
            "# Modules you write using this snippet, which is embedded dynamically by Ansible",
            "# still belong to the author of the module, and may assign their own license",
            "# to the complete work.",
            "#",
            "# Redistribution and use in source and binary forms, with or without modification,",
            "# are permitted provided that the following conditions are met:",
            "#",
            "#    * Redistributions of source code must retain the above copyright",
            "#      notice, this list of conditions and the following disclaimer.",
            "#    * Redistributions in binary form must reproduce the above copyright notice,",
            "#      this list of conditions and the following disclaimer in the documentation",
            "#      and/or other materials provided with the distribution.",
            "#",
            "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND",
            "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED",
            "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.",
            "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,",
            "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",
            "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS",
            "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT",
            "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE",
            "# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "import json",
            "",
            "from ansible.module_utils.urls import open_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlencode",
            "from ansible.module_utils.six.moves.urllib.error import HTTPError",
            "",
            "URL_TOKEN = \"{url}/realms/{realm}/protocol/openid-connect/token\"",
            "URL_CLIENT = \"{url}/admin/realms/{realm}/clients/{id}\"",
            "URL_CLIENTS = \"{url}/admin/realms/{realm}/clients\"",
            "URL_CLIENT_ROLES = \"{url}/admin/realms/{realm}/clients/{id}/roles\"",
            "URL_REALM_ROLES = \"{url}/admin/realms/{realm}/roles\"",
            "",
            "URL_CLIENTTEMPLATE = \"{url}/admin/realms/{realm}/client-templates/{id}\"",
            "URL_CLIENTTEMPLATES = \"{url}/admin/realms/{realm}/client-templates\"",
            "URL_GROUPS = \"{url}/admin/realms/{realm}/groups\"",
            "URL_GROUP = \"{url}/admin/realms/{realm}/groups/{groupid}\"",
            "",
            "",
            "def keycloak_argument_spec():",
            "    \"\"\"",
            "    Returns argument_spec of options common to keycloak_*-modules",
            "",
            "    :return: argument_spec dict",
            "    \"\"\"",
            "    return dict(",
            "        auth_keycloak_url=dict(type='str', aliases=['url'], required=True),",
            "        auth_client_id=dict(type='str', default='admin-cli'),",
            "        auth_realm=dict(type='str', required=True),",
            "        auth_client_secret=dict(type='str', default=None, no_log=True),",
            "        auth_username=dict(type='str', aliases=['username'], required=True),",
            "        auth_password=dict(type='str', aliases=['password'], required=True, no_log=True),",
            "        validate_certs=dict(type='bool', default=True)",
            "    )",
            "",
            "",
            "def camel(words):",
            "    return words.split('_')[0] + ''.join(x.capitalize() or '_' for x in words.split('_')[1:])",
            "",
            "",
            "class KeycloakAPI(object):",
            "    \"\"\" Keycloak API access; Keycloak uses OAuth 2.0 to protect its API, an access token for which",
            "        is obtained through OpenID connect",
            "    \"\"\"",
            "    def __init__(self, module):",
            "        self.module = module",
            "        self.token = None",
            "        self._connect()",
            "",
            "    def _connect(self):",
            "        \"\"\" Obtains an access_token and saves it for use in API accesses",
            "        \"\"\"",
            "        self.baseurl = self.module.params.get('auth_keycloak_url')",
            "        self.validate_certs = self.module.params.get('validate_certs')",
            "",
            "        auth_url = URL_TOKEN.format(url=self.baseurl, realm=self.module.params.get('auth_realm'))",
            "",
            "        payload = {'grant_type': 'password',",
            "                   'client_id': self.module.params.get('auth_client_id'),",
            "                   'client_secret': self.module.params.get('auth_client_secret'),",
            "                   'username': self.module.params.get('auth_username'),",
            "                   'password': self.module.params.get('auth_password')}",
            "",
            "        # Remove empty items, for instance missing client_secret",
            "        payload = dict((k, v) for k, v in payload.items() if v is not None)",
            "",
            "        try:",
            "            r = json.load(open_url(auth_url, method='POST',",
            "                                   validate_certs=self.validate_certs, data=urlencode(payload)))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned invalid JSON when trying to obtain access token from %s: %s'",
            "                                      % (auth_url, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain access token from %s: %s'",
            "                                      % (auth_url, str(e)))",
            "",
            "        if 'access_token' in r:",
            "            self.token = r['access_token']",
            "            self.restheaders = {'Authorization': 'Bearer ' + self.token,",
            "                                'Content-Type': 'application/json'}",
            "",
            "        else:",
            "            self.module.fail_json(msg='Could not obtain access token from %s' % auth_url)",
            "",
            "    def get_clients(self, realm='master', filter=None):",
            "        \"\"\" Obtains client representations for clients in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :param filter: if defined, only the client with clientId specified in the filter is returned",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        clientlist_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "        if filter is not None:",
            "            clientlist_url += '?clientId=%s' % filter",
            "",
            "        try:",
            "            return json.load(open_url(clientlist_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of clients for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_by_clientid(self, client_id, realm='master'):",
            "        \"\"\" Get client representation by clientId",
            "        :param client_id: The clientId to be queried",
            "        :param realm: realm from which to obtain the client representation",
            "        :return: dict with a client representation or None if none matching exist",
            "        \"\"\"",
            "        r = self.get_clients(realm=realm, filter=client_id)",
            "        if len(r) > 0:",
            "            return r[0]",
            "        else:",
            "            return None",
            "",
            "    def get_client_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client representation by id",
            "",
            "        :param id: id (not clientId) of client to be queried",
            "        :param realm: client from this realm",
            "        :return: dict of client representation or None if none matching exist",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return json.load(open_url(client_url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                          % (id, realm, str(e)))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_id(self, client_id, realm='master'):",
            "        \"\"\" Obtain id of client by client_id",
            "",
            "        :param client_id: client_id of client to be queried",
            "        :param realm: client template from this realm",
            "        :return: id of client (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_by_clientid(client_id, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client(self, id, clientrep, realm=\"master\"):",
            "        \"\"\" Update an existing client",
            "        :param id: id (not clientId) of client to be updated in Keycloak",
            "        :param clientrep: corresponding (partial/full) client representation with updates",
            "        :param realm: realm the client is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client(self, clientrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clientrep: Client representation of client to be created. Must at least contain field clientId",
            "        :param realm: realm for client to be created",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENTS.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(client_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clientrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client %s in realm %s: %s'",
            "                                      % (clientrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client from Keycloak",
            "",
            "        :param id: id (not clientId) of client to be deleted",
            "        :param realm: realm of client to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        client_url = URL_CLIENT.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(client_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_templates(self, realm='master'):",
            "        \"\"\" Obtains client template representations for client templates in a realm",
            "",
            "        :param realm: realm to be queried",
            "        :return: list of dicts of client representations",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain list of client templates for realm %s: %s'",
            "                                      % (realm, str(e)))",
            "",
            "    def get_client_template_by_id(self, id, realm='master'):",
            "        \"\"\" Obtain client template representation by id",
            "",
            "        :param id: id (not name) of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, id=id, realm=realm)",
            "",
            "        try:",
            "            return json.load(open_url(url, method='GET', headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except ValueError as e:",
            "            self.module.fail_json(msg='API returned incorrect JSON when trying to obtain client templates %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not obtain client template %s for realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_client_template_by_name(self, name, realm='master'):",
            "        \"\"\" Obtain client template representation by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: dict of client template representation or None if none matching exist",
            "        \"\"\"",
            "        result = self.get_client_templates(realm)",
            "        if isinstance(result, list):",
            "            result = [x for x in result if x['name'] == name]",
            "            if len(result) > 0:",
            "                return result[0]",
            "        return None",
            "",
            "    def get_client_template_id(self, name, realm='master'):",
            "        \"\"\" Obtain client template id by name",
            "",
            "        :param name: name of client template to be queried",
            "        :param realm: client template from this realm",
            "        :return: client template id (usually a UUID)",
            "        \"\"\"",
            "        result = self.get_client_template_by_name(name, realm)",
            "        if isinstance(result, dict) and 'id' in result:",
            "            return result['id']",
            "        else:",
            "            return None",
            "",
            "    def update_client_template(self, id, clienttrep, realm=\"master\"):",
            "        \"\"\" Update an existing client template",
            "        :param id: id (not name) of client template to be updated in Keycloak",
            "        :param clienttrep: corresponding (partial/full) client template representation with updates",
            "        :param realm: realm the client template is in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def create_client_template(self, clienttrep, realm=\"master\"):",
            "        \"\"\" Create a client in keycloak",
            "        :param clienttrep: Client template representation of client template to be created. Must at least contain field name",
            "        :param realm: realm for client template to be created in",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATES.format(url=self.baseurl, realm=realm)",
            "",
            "        try:",
            "            return open_url(url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(clienttrep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not create client template %s in realm %s: %s'",
            "                                      % (clienttrep['clientId'], realm, str(e)))",
            "",
            "    def delete_client_template(self, id, realm=\"master\"):",
            "        \"\"\" Delete a client template from Keycloak",
            "",
            "        :param id: id (not name) of client to be deleted",
            "        :param realm: realm of client template to be deleted",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        url = URL_CLIENTTEMPLATE.format(url=self.baseurl, realm=realm, id=id)",
            "",
            "        try:",
            "            return open_url(url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not delete client template %s in realm %s: %s'",
            "                                      % (id, realm, str(e)))",
            "",
            "    def get_groups(self, realm=\"master\"):",
            "        \"\"\" Fetch the name and ID of all groups on the Keycloak server.",
            "",
            "        To fetch the full data of the group, make a subsequent call to",
            "        get_group_by_groupid, passing in the ID of the group you wish to return.",
            "",
            "        :param realm: Return the groups of this realm (default \"master\").",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch list of groups in realm %s: %s\"",
            "                                      % (realm, str(e)))",
            "",
            "    def get_group_by_groupid(self, gid, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group from the provided realm using the group's unique ID.",
            "",
            "        If the group does not exist, None is returned.",
            "",
            "        gid is a UUID provided by the Keycloak API",
            "        :param gid: UUID of the group to be returned",
            "        :param realm: Realm in which the group resides; default 'master'.",
            "        \"\"\"",
            "        groups_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=gid)",
            "        try:",
            "            return json.load(open_url(groups_url, method=\"GET\", headers=self.restheaders,",
            "                                      validate_certs=self.validate_certs))",
            "",
            "        except HTTPError as e:",
            "            if e.code == 404:",
            "                return None",
            "            else:",
            "                self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                          % (gid, realm, str(e)))",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (gid, realm, str(e)))",
            "",
            "    def get_group_by_name(self, name, realm=\"master\"):",
            "        \"\"\" Fetch a keycloak group within a realm based on its name.",
            "",
            "        The Keycloak API does not allow filtering of the Groups resource by name.",
            "        As a result, this method first retrieves the entire list of groups - name and ID -",
            "        then performs a second query to fetch the group.",
            "",
            "        If the group does not exist, None is returned.",
            "        :param name: Name of the group to fetch.",
            "        :param realm: Realm in which the group resides; default 'master'",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            all_groups = self.get_groups(realm=realm)",
            "",
            "            for group in all_groups:",
            "                if group['name'] == name:",
            "                    return self.get_group_by_groupid(group['id'], realm=realm)",
            "",
            "            return None",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not fetch group %s in realm %s: %s\"",
            "                                      % (name, realm, str(e)))",
            "",
            "    def create_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Create a Keycloak group.",
            "",
            "        :param grouprep: a GroupRepresentation of the group to be created. Must contain at minimum the field name.",
            "        :return: HTTPResponse object on success",
            "        \"\"\"",
            "        groups_url = URL_GROUPS.format(url=self.baseurl, realm=realm)",
            "        try:",
            "            return open_url(groups_url, method='POST', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Could not create group %s in realm %s: %s\"",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def update_group(self, grouprep, realm=\"master\"):",
            "        \"\"\" Update an existing group.",
            "",
            "        :param grouprep: A GroupRepresentation of the updated group.",
            "        :return HTTPResponse object on success",
            "        \"\"\"",
            "        group_url = URL_GROUP.format(url=self.baseurl, realm=realm, groupid=grouprep['id'])",
            "",
            "        try:",
            "            return open_url(group_url, method='PUT', headers=self.restheaders,",
            "                            data=json.dumps(grouprep), validate_certs=self.validate_certs)",
            "        except Exception as e:",
            "            self.module.fail_json(msg='Could not update group %s in realm %s: %s'",
            "                                      % (grouprep['name'], realm, str(e)))",
            "",
            "    def delete_group(self, name=None, groupid=None, realm=\"master\"):",
            "        \"\"\" Delete a group. One of name or groupid must be provided.",
            "",
            "        Providing the group ID is preferred as it avoids a second lookup to",
            "        convert a group name to an ID.",
            "",
            "        :param name: The name of the group. A lookup will be performed to retrieve the group ID.",
            "        :param groupid: The ID of the group (preferred to name).",
            "        :param realm: The realm in which this group resides, default \"master\".",
            "        \"\"\"",
            "",
            "        if groupid is None and name is None:",
            "            # prefer an exception since this is almost certainly a programming error in the module itself.",
            "            raise Exception(\"Unable to delete group - one of group ID or name must be provided.\")",
            "",
            "        # only lookup the name if groupid isn't provided.",
            "        # in the case that both are provided, prefer the ID, since it's one",
            "        # less lookup.",
            "        if groupid is None and name is not None:",
            "            for group in self.get_groups(realm=realm):",
            "                if group['name'] == name:",
            "                    groupid = group['id']",
            "                    break",
            "",
            "        # if the group doesn't exist - no problem, nothing to delete.",
            "        if groupid is None:",
            "            return None",
            "",
            "        # should have a good groupid by here.",
            "        group_url = URL_GROUP.format(realm=realm, groupid=groupid, url=self.baseurl)",
            "        try:",
            "            return open_url(group_url, method='DELETE', headers=self.restheaders,",
            "                            validate_certs=self.validate_certs)",
            "",
            "        except Exception as e:",
            "            self.module.fail_json(msg=\"Unable to delete group %s: %s\" % (groupid, str(e)))"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "60": [
                "keycloak_argument_spec"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/docker/docker_swarm.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 620,
                "afterPatchRowNumber": 620,
                "PatchRowcode": "         name=dict(type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 621,
                "afterPatchRowNumber": 621,
                "PatchRowcode": "         labels=dict(type='dict'),"
            },
            "2": {
                "beforePatchRowNumber": 622,
                "afterPatchRowNumber": 622,
                "PatchRowcode": "         signing_ca_cert=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 623,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        signing_ca_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 623,
                "PatchRowcode": "+        signing_ca_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 624,
                "afterPatchRowNumber": 624,
                "PatchRowcode": "         ca_force_rotate=dict(type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 625,
                "afterPatchRowNumber": 625,
                "PatchRowcode": "         autolock_managers=dict(type='bool'),"
            },
            "7": {
                "beforePatchRowNumber": 626,
                "afterPatchRowNumber": 626,
                "PatchRowcode": "         node_id=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright 2016 Red Hat | Ansible",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: docker_swarm",
            "short_description: Manage Swarm cluster",
            "version_added: \"2.7\"",
            "description:",
            "  - Create a new Swarm cluster.",
            "  - Add/Remove nodes or managers to an existing cluster.",
            "options:",
            "  advertise_addr:",
            "    description:",
            "      - Externally reachable address advertised to other nodes.",
            "      - This can either be an address/port combination",
            "          in the form C(192.168.1.1:4567), or an interface followed by a",
            "          port number, like C(eth0:4567).",
            "      - If the port number is omitted,",
            "          the port number from the listen address is used.",
            "      - If I(advertise_addr) is not specified, it will be automatically",
            "          detected when possible.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "  default_addr_pool:",
            "    description:",
            "      - Default address pool in CIDR format.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: list",
            "    version_added: \"2.8\"",
            "  subnet_size:",
            "    description:",
            "      - Default address pool subnet mask length.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: int",
            "    version_added: \"2.8\"",
            "  listen_addr:",
            "    description:",
            "      - Listen address used for inter-manager communication.",
            "      - This can either be an address/port combination in the form",
            "          C(192.168.1.1:4567), or an interface followed by a port number,",
            "          like C(eth0:4567).",
            "      - If the port number is omitted, the default swarm listening port",
            "          is used.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "    default: 0.0.0.0:2377",
            "  force:",
            "    description:",
            "      - Use with state C(present) to force creating a new Swarm, even if already part of one.",
            "      - Use with state C(absent) to Leave the swarm even if this node is a manager.",
            "    type: bool",
            "    default: no",
            "  state:",
            "    description:",
            "      - Set to C(present), to create/update a new cluster.",
            "      - Set to C(join), to join an existing cluster.",
            "      - Set to C(absent), to leave an existing cluster.",
            "      - Set to C(remove), to remove an absent node from the cluster.",
            "        Note that removing requires Docker SDK for Python >= 2.4.0.",
            "      - Set to C(inspect) to display swarm informations.",
            "    type: str",
            "    required: yes",
            "    default: present",
            "    choices:",
            "      - present",
            "      - join",
            "      - absent",
            "      - remove",
            "      - inspect",
            "  node_id:",
            "    description:",
            "      - Swarm id of the node to remove.",
            "      - Used with I(state=remove).",
            "    type: str",
            "  join_token:",
            "    description:",
            "      - Swarm token used to join a swarm cluster.",
            "      - Used with I(state=join).",
            "    type: str",
            "  remote_addrs:",
            "    description:",
            "      - Remote address of one or more manager nodes of an existing Swarm to connect to.",
            "      - Used with I(state=join).",
            "    type: list",
            "  task_history_retention_limit:",
            "    description:",
            "      - Maximum number of tasks history stored.",
            "      - Docker default value is C(5).",
            "    type: int",
            "  snapshot_interval:",
            "    description:",
            "      - Number of logs entries between snapshot.",
            "      - Docker default value is C(10000).",
            "    type: int",
            "  keep_old_snapshots:",
            "    description:",
            "      - Number of snapshots to keep beyond the current snapshot.",
            "      - Docker default value is C(0).",
            "    type: int",
            "  log_entries_for_slow_followers:",
            "    description:",
            "      - Number of log entries to keep around to sync up slow followers after a snapshot is created.",
            "    type: int",
            "  heartbeat_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) between each heartbeat.",
            "      - Docker default value is C(1s).",
            "    type: int",
            "  election_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) needed without a leader to trigger a new election.",
            "      - Docker default value is C(10s).",
            "    type: int",
            "  dispatcher_heartbeat_period:",
            "    description:",
            "      - The delay for an agent to send a heartbeat to the dispatcher.",
            "      - Docker default value is C(5s).",
            "    type: int",
            "  node_cert_expiry:",
            "    description:",
            "      - Automatic expiry for nodes certificates.",
            "      - Docker default value is C(3months).",
            "    type: int",
            "  name:",
            "    description:",
            "      - The name of the swarm.",
            "    type: str",
            "  labels:",
            "    description:",
            "      - User-defined key/value metadata.",
            "      - Label operations in this module apply to the docker swarm cluster.",
            "        Use M(docker_node) module to add/modify/remove swarm node labels.",
            "      - Requires API version >= 1.32.",
            "    type: dict",
            "  signing_ca_cert:",
            "    description:",
            "      - The desired signing CA certificate for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a certificate, but the contents of the certificate.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  signing_ca_key:",
            "    description:",
            "      - The desired signing CA key for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a key, but the contents of the key.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  ca_force_rotate:",
            "    description:",
            "      - An integer whose purpose is to force swarm to generate a new signing CA certificate and key,",
            "          if none have been specified.",
            "      - Docker default value is C(0).",
            "      - Requires API version >= 1.30.",
            "    type: int",
            "  autolock_managers:",
            "    description:",
            "      - If set, generate a key and use it to lock data stored on the managers.",
            "      - Docker default value is C(no).",
            "      - M(docker_swarm_info) can be used to retrieve the unlock key.",
            "    type: bool",
            "  rotate_worker_token:",
            "    description: Rotate the worker join token.",
            "    type: bool",
            "    default: no",
            "  rotate_manager_token:",
            "    description: Rotate the manager join token.",
            "    type: bool",
            "    default: no",
            "extends_documentation_fragment:",
            "  - docker",
            "  - docker.docker_py_1_documentation",
            "requirements:",
            "  - \"L(Docker SDK for Python,https://docker-py.readthedocs.io/en/stable/) >= 1.10.0 (use L(docker-py,https://pypi.org/project/docker-py/) for Python 2.6)\"",
            "  - Docker API >= 1.25",
            "author:",
            "  - Thierry Bouvet (@tbouvet)",
            "  - Piotr Wojciechowski (@WojciechowskiPiotr)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "- name: Init a new swarm with default parameters",
            "  docker_swarm:",
            "    state: present",
            "",
            "- name: Update swarm configuration",
            "  docker_swarm:",
            "    state: present",
            "    election_tick: 5",
            "",
            "- name: Add nodes",
            "  docker_swarm:",
            "    state: join",
            "    advertise_addr: 192.168.1.2",
            "    join_token: SWMTKN-1--xxxxx",
            "    remote_addrs: [ '192.168.1.1:2377' ]",
            "",
            "- name: Leave swarm for a node",
            "  docker_swarm:",
            "    state: absent",
            "",
            "- name: Remove a swarm manager",
            "  docker_swarm:",
            "    state: absent",
            "    force: true",
            "",
            "- name: Remove node from swarm",
            "  docker_swarm:",
            "    state: remove",
            "    node_id: mynode",
            "",
            "- name: Inspect swarm",
            "  docker_swarm:",
            "    state: inspect",
            "  register: swarm_info",
            "'''",
            "",
            "RETURN = '''",
            "swarm_facts:",
            "  description: Informations about swarm.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "      JoinTokens:",
            "          description: Tokens to connect to the Swarm.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "              Worker:",
            "                  description: Token to create a new *worker* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "              Manager:",
            "                  description: Token to create a new *manager* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "      UnlockKey:",
            "          description: The swarm unlock-key if I(autolock_managers) is C(true).",
            "          returned: on success if I(autolock_managers) is C(true)",
            "            and swarm is initialised, or if I(autolock_managers) has changed.",
            "          type: str",
            "          example: SWMKEY-1-xxx",
            "",
            "actions:",
            "  description: Provides the actions done on the swarm.",
            "  returned: when action failed.",
            "  type: list",
            "  example: \"['This cluster is already a swarm cluster']\"",
            "",
            "'''",
            "",
            "import json",
            "import traceback",
            "",
            "try:",
            "    from docker.errors import DockerException, APIError",
            "except ImportError:",
            "    # missing Docker SDK for Python handled in ansible.module_utils.docker.common",
            "    pass",
            "",
            "from ansible.module_utils.docker.common import (",
            "    DockerBaseClass,",
            "    DifferenceTracker,",
            "    RequestException,",
            ")",
            "",
            "from ansible.module_utils.docker.swarm import AnsibleDockerSwarmClient",
            "",
            "from ansible.module_utils._text import to_native",
            "",
            "",
            "class TaskParameters(DockerBaseClass):",
            "    def __init__(self):",
            "        super(TaskParameters, self).__init__()",
            "",
            "        self.advertise_addr = None",
            "        self.listen_addr = None",
            "        self.remote_addrs = None",
            "        self.join_token = None",
            "",
            "        # Spec",
            "        self.snapshot_interval = None",
            "        self.task_history_retention_limit = None",
            "        self.keep_old_snapshots = None",
            "        self.log_entries_for_slow_followers = None",
            "        self.heartbeat_tick = None",
            "        self.election_tick = None",
            "        self.dispatcher_heartbeat_period = None",
            "        self.node_cert_expiry = None",
            "        self.name = None",
            "        self.labels = None",
            "        self.log_driver = None",
            "        self.signing_ca_cert = None",
            "        self.signing_ca_key = None",
            "        self.ca_force_rotate = None",
            "        self.autolock_managers = None",
            "        self.rotate_worker_token = None",
            "        self.rotate_manager_token = None",
            "        self.default_addr_pool = None",
            "        self.subnet_size = None",
            "",
            "    @staticmethod",
            "    def from_ansible_params(client):",
            "        result = TaskParameters()",
            "        for key, value in client.module.params.items():",
            "            if key in result.__dict__:",
            "                setattr(result, key, value)",
            "",
            "        result.update_parameters(client)",
            "        return result",
            "",
            "    def update_from_swarm_info(self, swarm_info):",
            "        spec = swarm_info['Spec']",
            "",
            "        ca_config = spec.get('CAConfig') or dict()",
            "        if self.node_cert_expiry is None:",
            "            self.node_cert_expiry = ca_config.get('NodeCertExpiry')",
            "        if self.ca_force_rotate is None:",
            "            self.ca_force_rotate = ca_config.get('ForceRotate')",
            "",
            "        dispatcher = spec.get('Dispatcher') or dict()",
            "        if self.dispatcher_heartbeat_period is None:",
            "            self.dispatcher_heartbeat_period = dispatcher.get('HeartbeatPeriod')",
            "",
            "        raft = spec.get('Raft') or dict()",
            "        if self.snapshot_interval is None:",
            "            self.snapshot_interval = raft.get('SnapshotInterval')",
            "        if self.keep_old_snapshots is None:",
            "            self.keep_old_snapshots = raft.get('KeepOldSnapshots')",
            "        if self.heartbeat_tick is None:",
            "            self.heartbeat_tick = raft.get('HeartbeatTick')",
            "        if self.log_entries_for_slow_followers is None:",
            "            self.log_entries_for_slow_followers = raft.get('LogEntriesForSlowFollowers')",
            "        if self.election_tick is None:",
            "            self.election_tick = raft.get('ElectionTick')",
            "",
            "        orchestration = spec.get('Orchestration') or dict()",
            "        if self.task_history_retention_limit is None:",
            "            self.task_history_retention_limit = orchestration.get('TaskHistoryRetentionLimit')",
            "",
            "        encryption_config = spec.get('EncryptionConfig') or dict()",
            "        if self.autolock_managers is None:",
            "            self.autolock_managers = encryption_config.get('AutoLockManagers')",
            "",
            "        if self.name is None:",
            "            self.name = spec['Name']",
            "",
            "        if self.labels is None:",
            "            self.labels = spec.get('Labels') or {}",
            "",
            "        if 'LogDriver' in spec['TaskDefaults']:",
            "            self.log_driver = spec['TaskDefaults']['LogDriver']",
            "",
            "    def update_parameters(self, client):",
            "        assign = dict(",
            "            snapshot_interval='snapshot_interval',",
            "            task_history_retention_limit='task_history_retention_limit',",
            "            keep_old_snapshots='keep_old_snapshots',",
            "            log_entries_for_slow_followers='log_entries_for_slow_followers',",
            "            heartbeat_tick='heartbeat_tick',",
            "            election_tick='election_tick',",
            "            dispatcher_heartbeat_period='dispatcher_heartbeat_period',",
            "            node_cert_expiry='node_cert_expiry',",
            "            name='name',",
            "            labels='labels',",
            "            signing_ca_cert='signing_ca_cert',",
            "            signing_ca_key='signing_ca_key',",
            "            ca_force_rotate='ca_force_rotate',",
            "            autolock_managers='autolock_managers',",
            "            log_driver='log_driver',",
            "        )",
            "        params = dict()",
            "        for dest, source in assign.items():",
            "            if not client.option_minimal_versions[source]['supported']:",
            "                continue",
            "            value = getattr(self, source)",
            "            if value is not None:",
            "                params[dest] = value",
            "        self.spec = client.create_swarm_spec(**params)",
            "",
            "    def compare_to_active(self, other, client, differences):",
            "        for k in self.__dict__:",
            "            if k in ('advertise_addr', 'listen_addr', 'remote_addrs', 'join_token',",
            "                     'rotate_worker_token', 'rotate_manager_token', 'spec',",
            "                     'default_addr_pool', 'subnet_size'):",
            "                continue",
            "            if not client.option_minimal_versions[k]['supported']:",
            "                continue",
            "            value = getattr(self, k)",
            "            if value is None:",
            "                continue",
            "            other_value = getattr(other, k)",
            "            if value != other_value:",
            "                differences.add(k, parameter=value, active=other_value)",
            "        if self.rotate_worker_token:",
            "            differences.add('rotate_worker_token', parameter=True, active=False)",
            "        if self.rotate_manager_token:",
            "            differences.add('rotate_manager_token', parameter=True, active=False)",
            "        return differences",
            "",
            "",
            "class SwarmManager(DockerBaseClass):",
            "",
            "    def __init__(self, client, results):",
            "",
            "        super(SwarmManager, self).__init__()",
            "",
            "        self.client = client",
            "        self.results = results",
            "        self.check_mode = self.client.check_mode",
            "        self.swarm_info = {}",
            "",
            "        self.state = client.module.params['state']",
            "        self.force = client.module.params['force']",
            "        self.node_id = client.module.params['node_id']",
            "",
            "        self.differences = DifferenceTracker()",
            "        self.parameters = TaskParameters.from_ansible_params(client)",
            "",
            "        self.created = False",
            "",
            "    def __call__(self):",
            "        choice_map = {",
            "            \"present\": self.init_swarm,",
            "            \"join\": self.join,",
            "            \"absent\": self.leave,",
            "            \"remove\": self.remove,",
            "            \"inspect\": self.inspect_swarm",
            "        }",
            "",
            "        if self.state == 'inspect':",
            "            self.client.module.deprecate(",
            "                \"The 'inspect' state is deprecated, please use 'docker_swarm_info' to inspect swarm cluster\",",
            "                version='2.12')",
            "",
            "        choice_map.get(self.state)()",
            "",
            "        if self.client.module._diff or self.parameters.debug:",
            "            diff = dict()",
            "            diff['before'], diff['after'] = self.differences.get_before_after()",
            "            self.results['diff'] = diff",
            "",
            "    def inspect_swarm(self):",
            "        try:",
            "            data = self.client.inspect_swarm()",
            "            json_str = json.dumps(data, ensure_ascii=False)",
            "            self.swarm_info = json.loads(json_str)",
            "",
            "            self.results['changed'] = False",
            "            self.results['swarm_facts'] = self.swarm_info",
            "",
            "            unlock_key = self.get_unlock_key()",
            "            self.swarm_info.update(unlock_key)",
            "        except APIError:",
            "            return",
            "",
            "    def get_unlock_key(self):",
            "        default = {'UnlockKey': None}",
            "        if not self.has_swarm_lock_changed():",
            "            return default",
            "        try:",
            "            return self.client.get_unlock_key() or default",
            "        except APIError:",
            "            return default",
            "",
            "    def has_swarm_lock_changed(self):",
            "        return self.parameters.autolock_managers and (",
            "            self.created or self.differences.has_difference_for('autolock_managers')",
            "        )",
            "",
            "    def init_swarm(self):",
            "        if not self.force and self.client.check_if_swarm_manager():",
            "            self.__update_swarm()",
            "            return",
            "",
            "        if not self.check_mode:",
            "            init_arguments = {",
            "                'advertise_addr': self.parameters.advertise_addr,",
            "                'listen_addr': self.parameters.listen_addr,",
            "                'force_new_cluster': self.force,",
            "                'swarm_spec': self.parameters.spec,",
            "            }",
            "            if self.parameters.default_addr_pool is not None:",
            "                init_arguments['default_addr_pool'] = self.parameters.default_addr_pool",
            "            if self.parameters.subnet_size is not None:",
            "                init_arguments['subnet_size'] = self.parameters.subnet_size",
            "            try:",
            "                self.client.init_swarm(**init_arguments)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not create a new Swarm Cluster: %s\" % to_native(exc))",
            "",
            "        if not self.client.check_if_swarm_manager():",
            "            if not self.check_mode:",
            "                self.client.fail(\"Swarm not created or other error!\")",
            "",
            "        self.created = True",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"New Swarm cluster created: %s\" % (self.swarm_info.get('ID')))",
            "        self.differences.add('state', parameter='present', active='absent')",
            "        self.results['changed'] = True",
            "        self.results['swarm_facts'] = {",
            "            'JoinTokens': self.swarm_info.get('JoinTokens'),",
            "            'UnlockKey': self.swarm_info.get('UnlockKey')",
            "        }",
            "",
            "    def __update_swarm(self):",
            "        try:",
            "            self.inspect_swarm()",
            "            version = self.swarm_info['Version']['Index']",
            "            self.parameters.update_from_swarm_info(self.swarm_info)",
            "            old_parameters = TaskParameters()",
            "            old_parameters.update_from_swarm_info(self.swarm_info)",
            "            self.parameters.compare_to_active(old_parameters, self.client, self.differences)",
            "            if self.differences.empty:",
            "                self.results['actions'].append(\"No modification\")",
            "                self.results['changed'] = False",
            "                return",
            "            update_parameters = TaskParameters.from_ansible_params(self.client)",
            "            update_parameters.update_parameters(self.client)",
            "            if not self.check_mode:",
            "                self.client.update_swarm(",
            "                    version=version, swarm_spec=update_parameters.spec,",
            "                    rotate_worker_token=self.parameters.rotate_worker_token,",
            "                    rotate_manager_token=self.parameters.rotate_manager_token)",
            "        except APIError as exc:",
            "            self.client.fail(\"Can not update a Swarm Cluster: %s\" % to_native(exc))",
            "            return",
            "",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"Swarm cluster updated\")",
            "        self.results['changed'] = True",
            "",
            "    def join(self):",
            "        if self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is already part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.join_swarm(",
            "                    remote_addrs=self.parameters.remote_addrs, join_token=self.parameters.join_token,",
            "                    listen_addr=self.parameters.listen_addr, advertise_addr=self.parameters.advertise_addr)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not join the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"New node is added to swarm cluster\")",
            "        self.differences.add('joined', parameter=True, active=False)",
            "        self.results['changed'] = True",
            "",
            "    def leave(self):",
            "        if not self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is not part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.leave_swarm(force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"This node can not leave the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node has left the swarm cluster\")",
            "        self.differences.add('joined', parameter='absent', active='present')",
            "        self.results['changed'] = True",
            "",
            "    def remove(self):",
            "        if not self.client.check_if_swarm_manager():",
            "            self.client.fail(\"This node is not a manager.\")",
            "",
            "        try:",
            "            status_down = self.client.check_if_swarm_node_is_down(node_id=self.node_id, repeat_check=5)",
            "        except APIError:",
            "            return",
            "",
            "        if not status_down:",
            "            self.client.fail(\"Can not remove the node. The status node is ready and not down.\")",
            "",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.remove_node(node_id=self.node_id, force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not remove the node from the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node is removed from swarm cluster.\")",
            "        self.differences.add('joined', parameter=False, active=True)",
            "        self.results['changed'] = True",
            "",
            "",
            "def _detect_remove_operation(client):",
            "    return client.module.params['state'] == 'remove'",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        advertise_addr=dict(type='str'),",
            "        state=dict(type='str', default='present', choices=['present', 'join', 'absent', 'remove', 'inspect']),",
            "        force=dict(type='bool', default=False),",
            "        listen_addr=dict(type='str', default='0.0.0.0:2377'),",
            "        remote_addrs=dict(type='list', elements='str'),",
            "        join_token=dict(type='str'),",
            "        snapshot_interval=dict(type='int'),",
            "        task_history_retention_limit=dict(type='int'),",
            "        keep_old_snapshots=dict(type='int'),",
            "        log_entries_for_slow_followers=dict(type='int'),",
            "        heartbeat_tick=dict(type='int'),",
            "        election_tick=dict(type='int'),",
            "        dispatcher_heartbeat_period=dict(type='int'),",
            "        node_cert_expiry=dict(type='int'),",
            "        name=dict(type='str'),",
            "        labels=dict(type='dict'),",
            "        signing_ca_cert=dict(type='str'),",
            "        signing_ca_key=dict(type='str'),",
            "        ca_force_rotate=dict(type='int'),",
            "        autolock_managers=dict(type='bool'),",
            "        node_id=dict(type='str'),",
            "        rotate_worker_token=dict(type='bool', default=False),",
            "        rotate_manager_token=dict(type='bool', default=False),",
            "        default_addr_pool=dict(type='list', elements='str'),",
            "        subnet_size=dict(type='int'),",
            "    )",
            "",
            "    required_if = [",
            "        ('state', 'join', ['advertise_addr', 'remote_addrs', 'join_token']),",
            "        ('state', 'remove', ['node_id'])",
            "    ]",
            "",
            "    option_minimal_versions = dict(",
            "        labels=dict(docker_py_version='2.6.0', docker_api_version='1.32'),",
            "        signing_ca_cert=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        signing_ca_key=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        ca_force_rotate=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        autolock_managers=dict(docker_py_version='2.6.0'),",
            "        log_driver=dict(docker_py_version='2.6.0'),",
            "        remove_operation=dict(",
            "            docker_py_version='2.4.0',",
            "            detect_usage=_detect_remove_operation,",
            "            usage_msg='remove swarm nodes'",
            "        ),",
            "        default_addr_pool=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "        subnet_size=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "    )",
            "",
            "    client = AnsibleDockerSwarmClient(",
            "        argument_spec=argument_spec,",
            "        supports_check_mode=True,",
            "        required_if=required_if,",
            "        min_docker_version='1.10.0',",
            "        min_docker_api_version='1.25',",
            "        option_minimal_versions=option_minimal_versions,",
            "    )",
            "",
            "    try:",
            "        results = dict(",
            "            changed=False,",
            "            result='',",
            "            actions=[]",
            "        )",
            "",
            "        SwarmManager(client, results)()",
            "        client.module.exit_json(**results)",
            "    except DockerException as e:",
            "        client.fail('An unexpected docker error occurred: {0}'.format(e), exception=traceback.format_exc())",
            "    except RequestException as e:",
            "        client.fail('An unexpected requests error occurred when docker-py tried to talk to the docker daemon: {0}'.format(e), exception=traceback.format_exc())",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright 2016 Red Hat | Ansible",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: docker_swarm",
            "short_description: Manage Swarm cluster",
            "version_added: \"2.7\"",
            "description:",
            "  - Create a new Swarm cluster.",
            "  - Add/Remove nodes or managers to an existing cluster.",
            "options:",
            "  advertise_addr:",
            "    description:",
            "      - Externally reachable address advertised to other nodes.",
            "      - This can either be an address/port combination",
            "          in the form C(192.168.1.1:4567), or an interface followed by a",
            "          port number, like C(eth0:4567).",
            "      - If the port number is omitted,",
            "          the port number from the listen address is used.",
            "      - If I(advertise_addr) is not specified, it will be automatically",
            "          detected when possible.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "  default_addr_pool:",
            "    description:",
            "      - Default address pool in CIDR format.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: list",
            "    version_added: \"2.8\"",
            "  subnet_size:",
            "    description:",
            "      - Default address pool subnet mask length.",
            "      - Only used when swarm is initialised. Because of this it's not considered",
            "        for idempotency checking.",
            "      - Requires API version >= 1.39.",
            "    type: int",
            "    version_added: \"2.8\"",
            "  listen_addr:",
            "    description:",
            "      - Listen address used for inter-manager communication.",
            "      - This can either be an address/port combination in the form",
            "          C(192.168.1.1:4567), or an interface followed by a port number,",
            "          like C(eth0:4567).",
            "      - If the port number is omitted, the default swarm listening port",
            "          is used.",
            "      - Only used when swarm is initialised or joined. Because of this it's not",
            "        considered for idempotency checking.",
            "    type: str",
            "    default: 0.0.0.0:2377",
            "  force:",
            "    description:",
            "      - Use with state C(present) to force creating a new Swarm, even if already part of one.",
            "      - Use with state C(absent) to Leave the swarm even if this node is a manager.",
            "    type: bool",
            "    default: no",
            "  state:",
            "    description:",
            "      - Set to C(present), to create/update a new cluster.",
            "      - Set to C(join), to join an existing cluster.",
            "      - Set to C(absent), to leave an existing cluster.",
            "      - Set to C(remove), to remove an absent node from the cluster.",
            "        Note that removing requires Docker SDK for Python >= 2.4.0.",
            "      - Set to C(inspect) to display swarm informations.",
            "    type: str",
            "    required: yes",
            "    default: present",
            "    choices:",
            "      - present",
            "      - join",
            "      - absent",
            "      - remove",
            "      - inspect",
            "  node_id:",
            "    description:",
            "      - Swarm id of the node to remove.",
            "      - Used with I(state=remove).",
            "    type: str",
            "  join_token:",
            "    description:",
            "      - Swarm token used to join a swarm cluster.",
            "      - Used with I(state=join).",
            "    type: str",
            "  remote_addrs:",
            "    description:",
            "      - Remote address of one or more manager nodes of an existing Swarm to connect to.",
            "      - Used with I(state=join).",
            "    type: list",
            "  task_history_retention_limit:",
            "    description:",
            "      - Maximum number of tasks history stored.",
            "      - Docker default value is C(5).",
            "    type: int",
            "  snapshot_interval:",
            "    description:",
            "      - Number of logs entries between snapshot.",
            "      - Docker default value is C(10000).",
            "    type: int",
            "  keep_old_snapshots:",
            "    description:",
            "      - Number of snapshots to keep beyond the current snapshot.",
            "      - Docker default value is C(0).",
            "    type: int",
            "  log_entries_for_slow_followers:",
            "    description:",
            "      - Number of log entries to keep around to sync up slow followers after a snapshot is created.",
            "    type: int",
            "  heartbeat_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) between each heartbeat.",
            "      - Docker default value is C(1s).",
            "    type: int",
            "  election_tick:",
            "    description:",
            "      - Amount of ticks (in seconds) needed without a leader to trigger a new election.",
            "      - Docker default value is C(10s).",
            "    type: int",
            "  dispatcher_heartbeat_period:",
            "    description:",
            "      - The delay for an agent to send a heartbeat to the dispatcher.",
            "      - Docker default value is C(5s).",
            "    type: int",
            "  node_cert_expiry:",
            "    description:",
            "      - Automatic expiry for nodes certificates.",
            "      - Docker default value is C(3months).",
            "    type: int",
            "  name:",
            "    description:",
            "      - The name of the swarm.",
            "    type: str",
            "  labels:",
            "    description:",
            "      - User-defined key/value metadata.",
            "      - Label operations in this module apply to the docker swarm cluster.",
            "        Use M(docker_node) module to add/modify/remove swarm node labels.",
            "      - Requires API version >= 1.32.",
            "    type: dict",
            "  signing_ca_cert:",
            "    description:",
            "      - The desired signing CA certificate for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a certificate, but the contents of the certificate.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  signing_ca_key:",
            "    description:",
            "      - The desired signing CA key for all swarm node TLS leaf certificates, in PEM format.",
            "      - This must not be a path to a key, but the contents of the key.",
            "      - Requires API version >= 1.30.",
            "    type: str",
            "  ca_force_rotate:",
            "    description:",
            "      - An integer whose purpose is to force swarm to generate a new signing CA certificate and key,",
            "          if none have been specified.",
            "      - Docker default value is C(0).",
            "      - Requires API version >= 1.30.",
            "    type: int",
            "  autolock_managers:",
            "    description:",
            "      - If set, generate a key and use it to lock data stored on the managers.",
            "      - Docker default value is C(no).",
            "      - M(docker_swarm_info) can be used to retrieve the unlock key.",
            "    type: bool",
            "  rotate_worker_token:",
            "    description: Rotate the worker join token.",
            "    type: bool",
            "    default: no",
            "  rotate_manager_token:",
            "    description: Rotate the manager join token.",
            "    type: bool",
            "    default: no",
            "extends_documentation_fragment:",
            "  - docker",
            "  - docker.docker_py_1_documentation",
            "requirements:",
            "  - \"L(Docker SDK for Python,https://docker-py.readthedocs.io/en/stable/) >= 1.10.0 (use L(docker-py,https://pypi.org/project/docker-py/) for Python 2.6)\"",
            "  - Docker API >= 1.25",
            "author:",
            "  - Thierry Bouvet (@tbouvet)",
            "  - Piotr Wojciechowski (@WojciechowskiPiotr)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "- name: Init a new swarm with default parameters",
            "  docker_swarm:",
            "    state: present",
            "",
            "- name: Update swarm configuration",
            "  docker_swarm:",
            "    state: present",
            "    election_tick: 5",
            "",
            "- name: Add nodes",
            "  docker_swarm:",
            "    state: join",
            "    advertise_addr: 192.168.1.2",
            "    join_token: SWMTKN-1--xxxxx",
            "    remote_addrs: [ '192.168.1.1:2377' ]",
            "",
            "- name: Leave swarm for a node",
            "  docker_swarm:",
            "    state: absent",
            "",
            "- name: Remove a swarm manager",
            "  docker_swarm:",
            "    state: absent",
            "    force: true",
            "",
            "- name: Remove node from swarm",
            "  docker_swarm:",
            "    state: remove",
            "    node_id: mynode",
            "",
            "- name: Inspect swarm",
            "  docker_swarm:",
            "    state: inspect",
            "  register: swarm_info",
            "'''",
            "",
            "RETURN = '''",
            "swarm_facts:",
            "  description: Informations about swarm.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "      JoinTokens:",
            "          description: Tokens to connect to the Swarm.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "              Worker:",
            "                  description: Token to create a new *worker* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "              Manager:",
            "                  description: Token to create a new *manager* node",
            "                  returned: success",
            "                  type: str",
            "                  example: SWMTKN-1--xxxxx",
            "      UnlockKey:",
            "          description: The swarm unlock-key if I(autolock_managers) is C(true).",
            "          returned: on success if I(autolock_managers) is C(true)",
            "            and swarm is initialised, or if I(autolock_managers) has changed.",
            "          type: str",
            "          example: SWMKEY-1-xxx",
            "",
            "actions:",
            "  description: Provides the actions done on the swarm.",
            "  returned: when action failed.",
            "  type: list",
            "  example: \"['This cluster is already a swarm cluster']\"",
            "",
            "'''",
            "",
            "import json",
            "import traceback",
            "",
            "try:",
            "    from docker.errors import DockerException, APIError",
            "except ImportError:",
            "    # missing Docker SDK for Python handled in ansible.module_utils.docker.common",
            "    pass",
            "",
            "from ansible.module_utils.docker.common import (",
            "    DockerBaseClass,",
            "    DifferenceTracker,",
            "    RequestException,",
            ")",
            "",
            "from ansible.module_utils.docker.swarm import AnsibleDockerSwarmClient",
            "",
            "from ansible.module_utils._text import to_native",
            "",
            "",
            "class TaskParameters(DockerBaseClass):",
            "    def __init__(self):",
            "        super(TaskParameters, self).__init__()",
            "",
            "        self.advertise_addr = None",
            "        self.listen_addr = None",
            "        self.remote_addrs = None",
            "        self.join_token = None",
            "",
            "        # Spec",
            "        self.snapshot_interval = None",
            "        self.task_history_retention_limit = None",
            "        self.keep_old_snapshots = None",
            "        self.log_entries_for_slow_followers = None",
            "        self.heartbeat_tick = None",
            "        self.election_tick = None",
            "        self.dispatcher_heartbeat_period = None",
            "        self.node_cert_expiry = None",
            "        self.name = None",
            "        self.labels = None",
            "        self.log_driver = None",
            "        self.signing_ca_cert = None",
            "        self.signing_ca_key = None",
            "        self.ca_force_rotate = None",
            "        self.autolock_managers = None",
            "        self.rotate_worker_token = None",
            "        self.rotate_manager_token = None",
            "        self.default_addr_pool = None",
            "        self.subnet_size = None",
            "",
            "    @staticmethod",
            "    def from_ansible_params(client):",
            "        result = TaskParameters()",
            "        for key, value in client.module.params.items():",
            "            if key in result.__dict__:",
            "                setattr(result, key, value)",
            "",
            "        result.update_parameters(client)",
            "        return result",
            "",
            "    def update_from_swarm_info(self, swarm_info):",
            "        spec = swarm_info['Spec']",
            "",
            "        ca_config = spec.get('CAConfig') or dict()",
            "        if self.node_cert_expiry is None:",
            "            self.node_cert_expiry = ca_config.get('NodeCertExpiry')",
            "        if self.ca_force_rotate is None:",
            "            self.ca_force_rotate = ca_config.get('ForceRotate')",
            "",
            "        dispatcher = spec.get('Dispatcher') or dict()",
            "        if self.dispatcher_heartbeat_period is None:",
            "            self.dispatcher_heartbeat_period = dispatcher.get('HeartbeatPeriod')",
            "",
            "        raft = spec.get('Raft') or dict()",
            "        if self.snapshot_interval is None:",
            "            self.snapshot_interval = raft.get('SnapshotInterval')",
            "        if self.keep_old_snapshots is None:",
            "            self.keep_old_snapshots = raft.get('KeepOldSnapshots')",
            "        if self.heartbeat_tick is None:",
            "            self.heartbeat_tick = raft.get('HeartbeatTick')",
            "        if self.log_entries_for_slow_followers is None:",
            "            self.log_entries_for_slow_followers = raft.get('LogEntriesForSlowFollowers')",
            "        if self.election_tick is None:",
            "            self.election_tick = raft.get('ElectionTick')",
            "",
            "        orchestration = spec.get('Orchestration') or dict()",
            "        if self.task_history_retention_limit is None:",
            "            self.task_history_retention_limit = orchestration.get('TaskHistoryRetentionLimit')",
            "",
            "        encryption_config = spec.get('EncryptionConfig') or dict()",
            "        if self.autolock_managers is None:",
            "            self.autolock_managers = encryption_config.get('AutoLockManagers')",
            "",
            "        if self.name is None:",
            "            self.name = spec['Name']",
            "",
            "        if self.labels is None:",
            "            self.labels = spec.get('Labels') or {}",
            "",
            "        if 'LogDriver' in spec['TaskDefaults']:",
            "            self.log_driver = spec['TaskDefaults']['LogDriver']",
            "",
            "    def update_parameters(self, client):",
            "        assign = dict(",
            "            snapshot_interval='snapshot_interval',",
            "            task_history_retention_limit='task_history_retention_limit',",
            "            keep_old_snapshots='keep_old_snapshots',",
            "            log_entries_for_slow_followers='log_entries_for_slow_followers',",
            "            heartbeat_tick='heartbeat_tick',",
            "            election_tick='election_tick',",
            "            dispatcher_heartbeat_period='dispatcher_heartbeat_period',",
            "            node_cert_expiry='node_cert_expiry',",
            "            name='name',",
            "            labels='labels',",
            "            signing_ca_cert='signing_ca_cert',",
            "            signing_ca_key='signing_ca_key',",
            "            ca_force_rotate='ca_force_rotate',",
            "            autolock_managers='autolock_managers',",
            "            log_driver='log_driver',",
            "        )",
            "        params = dict()",
            "        for dest, source in assign.items():",
            "            if not client.option_minimal_versions[source]['supported']:",
            "                continue",
            "            value = getattr(self, source)",
            "            if value is not None:",
            "                params[dest] = value",
            "        self.spec = client.create_swarm_spec(**params)",
            "",
            "    def compare_to_active(self, other, client, differences):",
            "        for k in self.__dict__:",
            "            if k in ('advertise_addr', 'listen_addr', 'remote_addrs', 'join_token',",
            "                     'rotate_worker_token', 'rotate_manager_token', 'spec',",
            "                     'default_addr_pool', 'subnet_size'):",
            "                continue",
            "            if not client.option_minimal_versions[k]['supported']:",
            "                continue",
            "            value = getattr(self, k)",
            "            if value is None:",
            "                continue",
            "            other_value = getattr(other, k)",
            "            if value != other_value:",
            "                differences.add(k, parameter=value, active=other_value)",
            "        if self.rotate_worker_token:",
            "            differences.add('rotate_worker_token', parameter=True, active=False)",
            "        if self.rotate_manager_token:",
            "            differences.add('rotate_manager_token', parameter=True, active=False)",
            "        return differences",
            "",
            "",
            "class SwarmManager(DockerBaseClass):",
            "",
            "    def __init__(self, client, results):",
            "",
            "        super(SwarmManager, self).__init__()",
            "",
            "        self.client = client",
            "        self.results = results",
            "        self.check_mode = self.client.check_mode",
            "        self.swarm_info = {}",
            "",
            "        self.state = client.module.params['state']",
            "        self.force = client.module.params['force']",
            "        self.node_id = client.module.params['node_id']",
            "",
            "        self.differences = DifferenceTracker()",
            "        self.parameters = TaskParameters.from_ansible_params(client)",
            "",
            "        self.created = False",
            "",
            "    def __call__(self):",
            "        choice_map = {",
            "            \"present\": self.init_swarm,",
            "            \"join\": self.join,",
            "            \"absent\": self.leave,",
            "            \"remove\": self.remove,",
            "            \"inspect\": self.inspect_swarm",
            "        }",
            "",
            "        if self.state == 'inspect':",
            "            self.client.module.deprecate(",
            "                \"The 'inspect' state is deprecated, please use 'docker_swarm_info' to inspect swarm cluster\",",
            "                version='2.12')",
            "",
            "        choice_map.get(self.state)()",
            "",
            "        if self.client.module._diff or self.parameters.debug:",
            "            diff = dict()",
            "            diff['before'], diff['after'] = self.differences.get_before_after()",
            "            self.results['diff'] = diff",
            "",
            "    def inspect_swarm(self):",
            "        try:",
            "            data = self.client.inspect_swarm()",
            "            json_str = json.dumps(data, ensure_ascii=False)",
            "            self.swarm_info = json.loads(json_str)",
            "",
            "            self.results['changed'] = False",
            "            self.results['swarm_facts'] = self.swarm_info",
            "",
            "            unlock_key = self.get_unlock_key()",
            "            self.swarm_info.update(unlock_key)",
            "        except APIError:",
            "            return",
            "",
            "    def get_unlock_key(self):",
            "        default = {'UnlockKey': None}",
            "        if not self.has_swarm_lock_changed():",
            "            return default",
            "        try:",
            "            return self.client.get_unlock_key() or default",
            "        except APIError:",
            "            return default",
            "",
            "    def has_swarm_lock_changed(self):",
            "        return self.parameters.autolock_managers and (",
            "            self.created or self.differences.has_difference_for('autolock_managers')",
            "        )",
            "",
            "    def init_swarm(self):",
            "        if not self.force and self.client.check_if_swarm_manager():",
            "            self.__update_swarm()",
            "            return",
            "",
            "        if not self.check_mode:",
            "            init_arguments = {",
            "                'advertise_addr': self.parameters.advertise_addr,",
            "                'listen_addr': self.parameters.listen_addr,",
            "                'force_new_cluster': self.force,",
            "                'swarm_spec': self.parameters.spec,",
            "            }",
            "            if self.parameters.default_addr_pool is not None:",
            "                init_arguments['default_addr_pool'] = self.parameters.default_addr_pool",
            "            if self.parameters.subnet_size is not None:",
            "                init_arguments['subnet_size'] = self.parameters.subnet_size",
            "            try:",
            "                self.client.init_swarm(**init_arguments)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not create a new Swarm Cluster: %s\" % to_native(exc))",
            "",
            "        if not self.client.check_if_swarm_manager():",
            "            if not self.check_mode:",
            "                self.client.fail(\"Swarm not created or other error!\")",
            "",
            "        self.created = True",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"New Swarm cluster created: %s\" % (self.swarm_info.get('ID')))",
            "        self.differences.add('state', parameter='present', active='absent')",
            "        self.results['changed'] = True",
            "        self.results['swarm_facts'] = {",
            "            'JoinTokens': self.swarm_info.get('JoinTokens'),",
            "            'UnlockKey': self.swarm_info.get('UnlockKey')",
            "        }",
            "",
            "    def __update_swarm(self):",
            "        try:",
            "            self.inspect_swarm()",
            "            version = self.swarm_info['Version']['Index']",
            "            self.parameters.update_from_swarm_info(self.swarm_info)",
            "            old_parameters = TaskParameters()",
            "            old_parameters.update_from_swarm_info(self.swarm_info)",
            "            self.parameters.compare_to_active(old_parameters, self.client, self.differences)",
            "            if self.differences.empty:",
            "                self.results['actions'].append(\"No modification\")",
            "                self.results['changed'] = False",
            "                return",
            "            update_parameters = TaskParameters.from_ansible_params(self.client)",
            "            update_parameters.update_parameters(self.client)",
            "            if not self.check_mode:",
            "                self.client.update_swarm(",
            "                    version=version, swarm_spec=update_parameters.spec,",
            "                    rotate_worker_token=self.parameters.rotate_worker_token,",
            "                    rotate_manager_token=self.parameters.rotate_manager_token)",
            "        except APIError as exc:",
            "            self.client.fail(\"Can not update a Swarm Cluster: %s\" % to_native(exc))",
            "            return",
            "",
            "        self.inspect_swarm()",
            "        self.results['actions'].append(\"Swarm cluster updated\")",
            "        self.results['changed'] = True",
            "",
            "    def join(self):",
            "        if self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is already part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.join_swarm(",
            "                    remote_addrs=self.parameters.remote_addrs, join_token=self.parameters.join_token,",
            "                    listen_addr=self.parameters.listen_addr, advertise_addr=self.parameters.advertise_addr)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not join the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"New node is added to swarm cluster\")",
            "        self.differences.add('joined', parameter=True, active=False)",
            "        self.results['changed'] = True",
            "",
            "    def leave(self):",
            "        if not self.client.check_if_swarm_node():",
            "            self.results['actions'].append(\"This node is not part of a swarm.\")",
            "            return",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.leave_swarm(force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"This node can not leave the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node has left the swarm cluster\")",
            "        self.differences.add('joined', parameter='absent', active='present')",
            "        self.results['changed'] = True",
            "",
            "    def remove(self):",
            "        if not self.client.check_if_swarm_manager():",
            "            self.client.fail(\"This node is not a manager.\")",
            "",
            "        try:",
            "            status_down = self.client.check_if_swarm_node_is_down(node_id=self.node_id, repeat_check=5)",
            "        except APIError:",
            "            return",
            "",
            "        if not status_down:",
            "            self.client.fail(\"Can not remove the node. The status node is ready and not down.\")",
            "",
            "        if not self.check_mode:",
            "            try:",
            "                self.client.remove_node(node_id=self.node_id, force=self.force)",
            "            except APIError as exc:",
            "                self.client.fail(\"Can not remove the node from the Swarm Cluster: %s\" % to_native(exc))",
            "        self.results['actions'].append(\"Node is removed from swarm cluster.\")",
            "        self.differences.add('joined', parameter=False, active=True)",
            "        self.results['changed'] = True",
            "",
            "",
            "def _detect_remove_operation(client):",
            "    return client.module.params['state'] == 'remove'",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        advertise_addr=dict(type='str'),",
            "        state=dict(type='str', default='present', choices=['present', 'join', 'absent', 'remove', 'inspect']),",
            "        force=dict(type='bool', default=False),",
            "        listen_addr=dict(type='str', default='0.0.0.0:2377'),",
            "        remote_addrs=dict(type='list', elements='str'),",
            "        join_token=dict(type='str'),",
            "        snapshot_interval=dict(type='int'),",
            "        task_history_retention_limit=dict(type='int'),",
            "        keep_old_snapshots=dict(type='int'),",
            "        log_entries_for_slow_followers=dict(type='int'),",
            "        heartbeat_tick=dict(type='int'),",
            "        election_tick=dict(type='int'),",
            "        dispatcher_heartbeat_period=dict(type='int'),",
            "        node_cert_expiry=dict(type='int'),",
            "        name=dict(type='str'),",
            "        labels=dict(type='dict'),",
            "        signing_ca_cert=dict(type='str'),",
            "        signing_ca_key=dict(type='str', no_log=True),",
            "        ca_force_rotate=dict(type='int'),",
            "        autolock_managers=dict(type='bool'),",
            "        node_id=dict(type='str'),",
            "        rotate_worker_token=dict(type='bool', default=False),",
            "        rotate_manager_token=dict(type='bool', default=False),",
            "        default_addr_pool=dict(type='list', elements='str'),",
            "        subnet_size=dict(type='int'),",
            "    )",
            "",
            "    required_if = [",
            "        ('state', 'join', ['advertise_addr', 'remote_addrs', 'join_token']),",
            "        ('state', 'remove', ['node_id'])",
            "    ]",
            "",
            "    option_minimal_versions = dict(",
            "        labels=dict(docker_py_version='2.6.0', docker_api_version='1.32'),",
            "        signing_ca_cert=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        signing_ca_key=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        ca_force_rotate=dict(docker_py_version='2.6.0', docker_api_version='1.30'),",
            "        autolock_managers=dict(docker_py_version='2.6.0'),",
            "        log_driver=dict(docker_py_version='2.6.0'),",
            "        remove_operation=dict(",
            "            docker_py_version='2.4.0',",
            "            detect_usage=_detect_remove_operation,",
            "            usage_msg='remove swarm nodes'",
            "        ),",
            "        default_addr_pool=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "        subnet_size=dict(docker_py_version='4.0.0', docker_api_version='1.39'),",
            "    )",
            "",
            "    client = AnsibleDockerSwarmClient(",
            "        argument_spec=argument_spec,",
            "        supports_check_mode=True,",
            "        required_if=required_if,",
            "        min_docker_version='1.10.0',",
            "        min_docker_api_version='1.25',",
            "        option_minimal_versions=option_minimal_versions,",
            "    )",
            "",
            "    try:",
            "        results = dict(",
            "            changed=False,",
            "            result='',",
            "            actions=[]",
            "        )",
            "",
            "        SwarmManager(client, results)()",
            "        client.module.exit_json(**results)",
            "    except DockerException as e:",
            "        client.fail('An unexpected docker error occurred: {0}'.format(e), exception=traceback.format_exc())",
            "    except RequestException as e:",
            "        client.fail('An unexpected requests error occurred when docker-py tried to talk to the docker daemon: {0}'.format(e), exception=traceback.format_exc())",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "623": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_backend_service.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 686,
                "afterPatchRowNumber": 686,
                "PatchRowcode": "             health_checks=dict(required=True, type='list', elements='str'),"
            },
            "1": {
                "beforePatchRowNumber": 687,
                "afterPatchRowNumber": 687,
                "PatchRowcode": "             iap=dict("
            },
            "2": {
                "beforePatchRowNumber": 688,
                "afterPatchRowNumber": 688,
                "PatchRowcode": "                 type='dict',"
            },
            "3": {
                "beforePatchRowNumber": 689,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                options=dict(enabled=dict(type='bool'), oauth2_client_id=dict(required=True, type='str'), oauth2_client_secret=dict(required=True, type='str')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 689,
                "PatchRowcode": "+                options=dict("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 690,
                "PatchRowcode": "+                    enabled=dict(type='bool'),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 691,
                "PatchRowcode": "+                    oauth2_client_id=dict(required=True, type='str'),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 692,
                "PatchRowcode": "+                    oauth2_client_secret=dict(required=True, type='str', no_log=True),"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 693,
                "PatchRowcode": "+                ),"
            },
            "9": {
                "beforePatchRowNumber": 690,
                "afterPatchRowNumber": 694,
                "PatchRowcode": "             ),"
            },
            "10": {
                "beforePatchRowNumber": 691,
                "afterPatchRowNumber": 695,
                "PatchRowcode": "             load_balancing_scheme=dict(default='EXTERNAL', type='str', choices=['INTERNAL', 'EXTERNAL']),"
            },
            "11": {
                "beforePatchRowNumber": 692,
                "afterPatchRowNumber": 696,
                "PatchRowcode": "             name=dict(required=True, type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_backend_service",
            "description:",
            "- Creates a BackendService resource in the specified project using the data included",
            "  in the request.",
            "short_description: Creates a GCP BackendService",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  affinity_cookie_ttl_sec:",
            "    description:",
            "    - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "      to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "      session (or equivalent). The maximum allowed value for TTL is one day.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "  backends:",
            "    description:",
            "    - The list of backends that serve this BackendService.",
            "    required: false",
            "    suboptions:",
            "      balancing_mode:",
            "        description:",
            "        - Specifies the balancing mode for this backend.",
            "        - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "          Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "        default: UTILIZATION",
            "        choices:",
            "        - UTILIZATION",
            "        - RATE",
            "        - CONNECTION",
            "      capacity_scaler:",
            "        description:",
            "        - A multiplier applied to the group's maximum servicing capacity (based on",
            "          UTILIZATION, RATE or CONNECTION).",
            "        - Default value is 1, which means the group will serve up to 100% of its configured",
            "          capacity (depending on balancingMode). A setting of 0 means the group is",
            "          completely drained, offering 0% of its available Capacity. Valid range is",
            "          [0.0,1.0].",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "        default: '1.0'",
            "      description:",
            "        description:",
            "        - An optional description of this resource.",
            "        - Provide this property when you create the resource.",
            "        required: false",
            "      group:",
            "        description:",
            "        - This instance group defines the list of instances that serve traffic. Member",
            "          virtual machine instances from each instance group must live in the same",
            "          zone as the instance group itself.",
            "        - No two backends in a backend service are allowed to use same Instance Group",
            "          resource.",
            "        - When the BackendService has load balancing scheme INTERNAL, the instance",
            "          group must be in a zone within the same region as the BackendService.",
            "        - 'This field represents a link to a InstanceGroup resource in GCP. It can",
            "          be specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "          and value of your resource''s selfLink Alternatively, you can add `register:",
            "          name-of-resource` to a gcp_compute_instance_group task and then set this",
            "          group field to \"{{ name-of-resource }}\"'",
            "        required: false",
            "      max_connections:",
            "        description:",
            "        - The max number of simultaneous connections for the group. Can be used with",
            "          either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance",
            "          must be set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_connections_per_instance:",
            "        description:",
            "        - The max number of simultaneous connections that a single backend instance",
            "          can handle. This is used to calculate the capacity of the group. Can be",
            "          used in either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance",
            "          must be set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_rate:",
            "        description:",
            "        - The max requests per second (RPS) of the group.",
            "        - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "          if RATE mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "          set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_rate_per_instance:",
            "        description:",
            "        - The max requests per second (RPS) that a single backend instance can handle.",
            "          This is used to calculate the capacity of the group. Can be used in either",
            "          balancing mode. For RATE mode, either maxRate or maxRatePerInstance must",
            "          be set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_utilization:",
            "        description:",
            "        - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "          target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "        default: '0.8'",
            "  cdn_policy:",
            "    description:",
            "    - Cloud CDN configuration for this BackendService.",
            "    required: false",
            "    suboptions:",
            "      cache_key_policy:",
            "        description:",
            "        - The CacheKeyPolicy for this CdnPolicy.",
            "        required: false",
            "        suboptions:",
            "          include_host:",
            "            description:",
            "            - If true requests to different hosts will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_protocol:",
            "            description:",
            "            - If true, http and https requests will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_query_string:",
            "            description:",
            "            - If true, include query string parameters in the cache key according",
            "              to query_string_whitelist and query_string_blacklist. If neither is",
            "              set, the entire query string will be included.",
            "            - If false, the query string will be excluded from the cache key entirely.",
            "            required: false",
            "            type: bool",
            "          query_string_blacklist:",
            "            description:",
            "            - Names of query string parameters to exclude in cache keys.",
            "            - All other parameters will be included. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "          query_string_whitelist:",
            "            description:",
            "            - Names of query string parameters to include in cache keys.",
            "            - All other parameters will be excluded. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "      signed_url_cache_max_age_sec:",
            "        description:",
            "        - Maximum number of seconds the response to a signed URL request will be considered",
            "          fresh, defaults to 1hr (3600s). After this time period, the response will",
            "          be revalidated before being served.",
            "        - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "          behave as though all responses from this backend had a \"Cache-Control: public,",
            "          max-age=[TTL]\" header, regardless of any existing Cache-Control header.",
            "          The actual headers served in responses will not be altered.'",
            "        required: false",
            "        default: '3600'",
            "        version_added: 2.8",
            "  connection_draining:",
            "    description:",
            "    - Settings for connection draining .",
            "    required: false",
            "    suboptions:",
            "      draining_timeout_sec:",
            "        description:",
            "        - Time for which instance will be drained (not accept new connections, but",
            "          still work to finish started).",
            "        required: false",
            "        default: '300'",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "  enable_cdn:",
            "    description:",
            "    - If true, enable Cloud CDN for this BackendService.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "    type: bool",
            "  health_checks:",
            "    description:",
            "    - The list of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "      checking this BackendService. Currently at most one health check can be specified,",
            "      and a health check is required.",
            "    - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "      instead.",
            "    required: true",
            "  iap:",
            "    description:",
            "    - Settings for enabling Cloud Identity Aware Proxy.",
            "    required: false",
            "    version_added: 2.7",
            "    suboptions:",
            "      enabled:",
            "        description:",
            "        - Enables IAP.",
            "        required: false",
            "        type: bool",
            "      oauth2_client_id:",
            "        description:",
            "        - OAuth2 Client ID for IAP .",
            "        required: true",
            "      oauth2_client_secret:",
            "        description:",
            "        - OAuth2 Client Secret for IAP .",
            "        required: true",
            "  load_balancing_scheme:",
            "    description:",
            "    - Indicates whether the backend service will be used with internal or external",
            "      load balancing. A backend service created for one type of load balancing cannot",
            "      be used with the other. One of `INTERNAL` or `EXTERNAL`. Defaults to `EXTERNAL`.",
            "    required: false",
            "    default: EXTERNAL",
            "    version_added: 2.7",
            "    choices:",
            "    - INTERNAL",
            "    - EXTERNAL",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  port_name:",
            "    description:",
            "    - Name of backend port. The same name should appear in the instance groups referenced",
            "      by this service. Required when the load balancing scheme is EXTERNAL.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "  protocol:",
            "    description:",
            "    - The protocol this BackendService uses to communicate with backends.",
            "    - Possible values are HTTP, HTTPS, TCP, and SSL. The default is HTTP.",
            "    - For internal load balancing, the possible values are TCP and UDP, and the default",
            "      is TCP.",
            "    required: false",
            "    choices:",
            "    - HTTP",
            "    - HTTPS",
            "    - TCP",
            "    - SSL",
            "  security_policy:",
            "    description:",
            "    - The security policy associated with this backend service.",
            "    required: false",
            "    version_added: 2.8",
            "  session_affinity:",
            "    description:",
            "    - Type of session affinity to use. The default is NONE.",
            "    - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "    - When the load balancing scheme is INTERNAL, can be NONE, CLIENT_IP, CLIENT_IP_PROTO,",
            "      or CLIENT_IP_PORT_PROTO.",
            "    - When the protocol is UDP, this field is not used.",
            "    required: false",
            "    choices:",
            "    - NONE",
            "    - CLIENT_IP",
            "    - GENERATED_COOKIE",
            "    - CLIENT_IP_PROTO",
            "    - CLIENT_IP_PORT_PROTO",
            "  timeout_sec:",
            "    description:",
            "    - How many seconds to wait for the backend before considering it a failed request.",
            "      Default is 30 seconds. Valid range is [1, 86400].",
            "    required: false",
            "    aliases:",
            "    - timeout_seconds",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance group",
            "  gcp_compute_instance_group:",
            "    name: instancegroup-backendservice",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: instancegroup",
            "",
            "- name: create a http health check",
            "  gcp_compute_http_health_check:",
            "    name: httphealthcheck-backendservice",
            "    healthy_threshold: 10",
            "    port: 8080",
            "    timeout_sec: 2",
            "    unhealthy_threshold: 5",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: healthcheck",
            "",
            "- name: create a backend service",
            "  gcp_compute_backend_service:",
            "    name: test_object",
            "    backends:",
            "    - group: \"{{ instancegroup }}\"",
            "    health_checks:",
            "    - \"{{ healthcheck.selfLink }}\"",
            "    enable_cdn: 'true'",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "affinityCookieTtlSec:",
            "  description:",
            "  - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "    to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "    session (or equivalent). The maximum allowed value for TTL is one day.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: int",
            "backends:",
            "  description:",
            "  - The list of backends that serve this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    balancingMode:",
            "      description:",
            "      - Specifies the balancing mode for this backend.",
            "      - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "        Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "    capacityScaler:",
            "      description:",
            "      - A multiplier applied to the group's maximum servicing capacity (based on UTILIZATION,",
            "        RATE or CONNECTION).",
            "      - Default value is 1, which means the group will serve up to 100% of its configured",
            "        capacity (depending on balancingMode). A setting of 0 means the group is completely",
            "        drained, offering 0% of its available Capacity. Valid range is [0.0,1.0].",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "    description:",
            "      description:",
            "      - An optional description of this resource.",
            "      - Provide this property when you create the resource.",
            "      returned: success",
            "      type: str",
            "    group:",
            "      description:",
            "      - This instance group defines the list of instances that serve traffic. Member",
            "        virtual machine instances from each instance group must live in the same zone",
            "        as the instance group itself.",
            "      - No two backends in a backend service are allowed to use same Instance Group",
            "        resource.",
            "      - When the BackendService has load balancing scheme INTERNAL, the instance group",
            "        must be in a zone within the same region as the BackendService.",
            "      returned: success",
            "      type: dict",
            "    maxConnections:",
            "      description:",
            "      - The max number of simultaneous connections for the group. Can be used with",
            "        either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance must",
            "        be set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: int",
            "    maxConnectionsPerInstance:",
            "      description:",
            "      - The max number of simultaneous connections that a single backend instance",
            "        can handle. This is used to calculate the capacity of the group. Can be used",
            "        in either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance must",
            "        be set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: int",
            "    maxRate:",
            "      description:",
            "      - The max requests per second (RPS) of the group.",
            "      - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "        if RATE mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "        set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: int",
            "    maxRatePerInstance:",
            "      description:",
            "      - The max requests per second (RPS) that a single backend instance can handle.",
            "        This is used to calculate the capacity of the group. Can be used in either",
            "        balancing mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "        set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "    maxUtilization:",
            "      description:",
            "      - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "        target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "cdnPolicy:",
            "  description:",
            "  - Cloud CDN configuration for this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    cacheKeyPolicy:",
            "      description:",
            "      - The CacheKeyPolicy for this CdnPolicy.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        includeHost:",
            "          description:",
            "          - If true requests to different hosts will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeProtocol:",
            "          description:",
            "          - If true, http and https requests will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeQueryString:",
            "          description:",
            "          - If true, include query string parameters in the cache key according to",
            "            query_string_whitelist and query_string_blacklist. If neither is set,",
            "            the entire query string will be included.",
            "          - If false, the query string will be excluded from the cache key entirely.",
            "          returned: success",
            "          type: bool",
            "        queryStringBlacklist:",
            "          description:",
            "          - Names of query string parameters to exclude in cache keys.",
            "          - All other parameters will be included. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "        queryStringWhitelist:",
            "          description:",
            "          - Names of query string parameters to include in cache keys.",
            "          - All other parameters will be excluded. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "    signedUrlCacheMaxAgeSec:",
            "      description:",
            "      - Maximum number of seconds the response to a signed URL request will be considered",
            "        fresh, defaults to 1hr (3600s). After this time period, the response will",
            "        be revalidated before being served.",
            "      - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "        behave as though all responses from this backend had a \"Cache-Control: public,",
            "        max-age=[TTL]\" header, regardless of any existing Cache-Control header. The",
            "        actual headers served in responses will not be altered.'",
            "      returned: success",
            "      type: int",
            "connectionDraining:",
            "  description:",
            "  - Settings for connection draining .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    drainingTimeoutSec:",
            "      description:",
            "      - Time for which instance will be drained (not accept new connections, but still",
            "        work to finish started).",
            "      returned: success",
            "      type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "fingerprint:",
            "  description:",
            "  - Fingerprint of this resource. A hash of the contents stored in this object. This",
            "    field is used in optimistic locking.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "enableCDN:",
            "  description:",
            "  - If true, enable Cloud CDN for this BackendService.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: bool",
            "healthChecks:",
            "  description:",
            "  - The list of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "    checking this BackendService. Currently at most one health check can be specified,",
            "    and a health check is required.",
            "  - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "    instead.",
            "  returned: success",
            "  type: list",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "iap:",
            "  description:",
            "  - Settings for enabling Cloud Identity Aware Proxy.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    enabled:",
            "      description:",
            "      - Enables IAP.",
            "      returned: success",
            "      type: bool",
            "    oauth2ClientId:",
            "      description:",
            "      - OAuth2 Client ID for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecret:",
            "      description:",
            "      - OAuth2 Client Secret for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecretSha256:",
            "      description:",
            "      - OAuth2 Client Secret SHA-256 for IAP .",
            "      returned: success",
            "      type: str",
            "loadBalancingScheme:",
            "  description:",
            "  - Indicates whether the backend service will be used with internal or external load",
            "    balancing. A backend service created for one type of load balancing cannot be",
            "    used with the other. One of `INTERNAL` or `EXTERNAL`. Defaults to `EXTERNAL`.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "portName:",
            "  description:",
            "  - Name of backend port. The same name should appear in the instance groups referenced",
            "    by this service. Required when the load balancing scheme is EXTERNAL.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: str",
            "protocol:",
            "  description:",
            "  - The protocol this BackendService uses to communicate with backends.",
            "  - Possible values are HTTP, HTTPS, TCP, and SSL. The default is HTTP.",
            "  - For internal load balancing, the possible values are TCP and UDP, and the default",
            "    is TCP.",
            "  returned: success",
            "  type: str",
            "securityPolicy:",
            "  description:",
            "  - The security policy associated with this backend service.",
            "  returned: success",
            "  type: str",
            "sessionAffinity:",
            "  description:",
            "  - Type of session affinity to use. The default is NONE.",
            "  - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "  - When the load balancing scheme is INTERNAL, can be NONE, CLIENT_IP, CLIENT_IP_PROTO,",
            "    or CLIENT_IP_PORT_PROTO.",
            "  - When the protocol is UDP, this field is not used.",
            "  returned: success",
            "  type: str",
            "timeoutSec:",
            "  description:",
            "  - How many seconds to wait for the backend before considering it a failed request.",
            "    Default is 30 seconds. Valid range is [1, 86400].",
            "  returned: success",
            "  type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            affinity_cookie_ttl_sec=dict(type='int'),",
            "            backends=dict(",
            "                type='list',",
            "                elements='dict',",
            "                options=dict(",
            "                    balancing_mode=dict(default='UTILIZATION', type='str', choices=['UTILIZATION', 'RATE', 'CONNECTION']),",
            "                    capacity_scaler=dict(default=1.0, type='str'),",
            "                    description=dict(type='str'),",
            "                    group=dict(type='dict'),",
            "                    max_connections=dict(type='int'),",
            "                    max_connections_per_instance=dict(type='int'),",
            "                    max_rate=dict(type='int'),",
            "                    max_rate_per_instance=dict(type='str'),",
            "                    max_utilization=dict(default=0.8, type='str'),",
            "                ),",
            "            ),",
            "            cdn_policy=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    cache_key_policy=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            include_host=dict(type='bool'),",
            "                            include_protocol=dict(type='bool'),",
            "                            include_query_string=dict(type='bool'),",
            "                            query_string_blacklist=dict(type='list', elements='str'),",
            "                            query_string_whitelist=dict(type='list', elements='str'),",
            "                        ),",
            "                    ),",
            "                    signed_url_cache_max_age_sec=dict(default=3600, type='int'),",
            "                ),",
            "            ),",
            "            connection_draining=dict(type='dict', options=dict(draining_timeout_sec=dict(default=300, type='int'))),",
            "            description=dict(type='str'),",
            "            enable_cdn=dict(type='bool'),",
            "            health_checks=dict(required=True, type='list', elements='str'),",
            "            iap=dict(",
            "                type='dict',",
            "                options=dict(enabled=dict(type='bool'), oauth2_client_id=dict(required=True, type='str'), oauth2_client_secret=dict(required=True, type='str')),",
            "            ),",
            "            load_balancing_scheme=dict(default='EXTERNAL', type='str', choices=['INTERNAL', 'EXTERNAL']),",
            "            name=dict(required=True, type='str'),",
            "            port_name=dict(type='str'),",
            "            protocol=dict(type='str', choices=['HTTP', 'HTTPS', 'TCP', 'SSL']),",
            "            security_policy=dict(type='str'),",
            "            session_affinity=dict(type='str', choices=['NONE', 'CLIENT_IP', 'GENERATED_COOKIE', 'CLIENT_IP_PROTO', 'CLIENT_IP_PORT_PROTO']),",
            "            timeout_sec=dict(type='int', aliases=['timeout_seconds']),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#backendService'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.put(link, resource_to_request(module)))",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('securityPolicy') != request.get('securityPolicy'):",
            "        security_policy_update(module, request, response)",
            "",
            "",
            "def security_policy_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/backendServices/{name}/setSecurityPolicy\"]).format(**module.params),",
            "        {u'securityPolicy': module.params.get('security_policy')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#backendService',",
            "        u'affinityCookieTtlSec': module.params.get('affinity_cookie_ttl_sec'),",
            "        u'backends': BackendServiceBackendsArray(module.params.get('backends', []), module).to_request(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(module.params.get('cdn_policy', {}), module).to_request(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(module.params.get('connection_draining', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'enableCDN': module.params.get('enable_cdn'),",
            "        u'healthChecks': module.params.get('health_checks'),",
            "        u'iap': BackendServiceIap(module.params.get('iap', {}), module).to_request(),",
            "        u'loadBalancingScheme': module.params.get('load_balancing_scheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': module.params.get('port_name'),",
            "        u'protocol': module.params.get('protocol'),",
            "        u'securityPolicy': module.params.get('security_policy'),",
            "        u'sessionAffinity': module.params.get('session_affinity'),",
            "        u'timeoutSec': module.params.get('timeout_sec'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'affinityCookieTtlSec': response.get(u'affinityCookieTtlSec'),",
            "        u'backends': BackendServiceBackendsArray(response.get(u'backends', []), module).from_response(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(response.get(u'cdnPolicy', {}), module).from_response(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(response.get(u'connectionDraining', {}), module).from_response(),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'fingerprint': response.get(u'fingerprint'),",
            "        u'description': response.get(u'description'),",
            "        u'enableCDN': response.get(u'enableCDN'),",
            "        u'healthChecks': response.get(u'healthChecks'),",
            "        u'id': response.get(u'id'),",
            "        u'iap': BackendServiceIap(response.get(u'iap', {}), module).from_response(),",
            "        u'loadBalancingScheme': response.get(u'loadBalancingScheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': response.get(u'portName'),",
            "        u'protocol': response.get(u'protocol'),",
            "        u'securityPolicy': response.get(u'securityPolicy'),",
            "        u'sessionAffinity': response.get(u'sessionAffinity'),",
            "        u'timeoutSec': response.get(u'timeoutSec'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#backendService')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class BackendServiceBackendsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get('balancing_mode'),",
            "                u'capacityScaler': item.get('capacity_scaler'),",
            "                u'description': item.get('description'),",
            "                u'group': replace_resource_dict(item.get(u'group', {}), 'selfLink'),",
            "                u'maxConnections': item.get('max_connections'),",
            "                u'maxConnectionsPerInstance': item.get('max_connections_per_instance'),",
            "                u'maxRate': item.get('max_rate'),",
            "                u'maxRatePerInstance': item.get('max_rate_per_instance'),",
            "                u'maxUtilization': item.get('max_utilization'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get(u'balancingMode'),",
            "                u'capacityScaler': item.get(u'capacityScaler'),",
            "                u'description': item.get(u'description'),",
            "                u'group': item.get(u'group'),",
            "                u'maxConnections': item.get(u'maxConnections'),",
            "                u'maxConnectionsPerInstance': item.get(u'maxConnectionsPerInstance'),",
            "                u'maxRate': item.get(u'maxRate'),",
            "                u'maxRatePerInstance': item.get(u'maxRatePerInstance'),",
            "                u'maxUtilization': item.get(u'maxUtilization'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCdnpolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get('cache_key_policy', {}), self.module).to_request(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get('signed_url_cache_max_age_sec'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get(u'cacheKeyPolicy', {}), self.module).from_response(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get(u'signedUrlCacheMaxAgeSec'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCachekeypolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get('include_host'),",
            "                u'includeProtocol': self.request.get('include_protocol'),",
            "                u'includeQueryString': self.request.get('include_query_string'),",
            "                u'queryStringBlacklist': self.request.get('query_string_blacklist'),",
            "                u'queryStringWhitelist': self.request.get('query_string_whitelist'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get(u'includeHost'),",
            "                u'includeProtocol': self.request.get(u'includeProtocol'),",
            "                u'includeQueryString': self.request.get(u'includeQueryString'),",
            "                u'queryStringBlacklist': self.request.get(u'queryStringBlacklist'),",
            "                u'queryStringWhitelist': self.request.get(u'queryStringWhitelist'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceConnectiondraining(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get('draining_timeout_sec')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get(u'drainingTimeoutSec')})",
            "",
            "",
            "class BackendServiceIap(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get('enabled'),",
            "                u'oauth2ClientId': self.request.get('oauth2_client_id'),",
            "                u'oauth2ClientSecret': self.request.get('oauth2_client_secret'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get(u'enabled'),",
            "                u'oauth2ClientId': self.request.get(u'oauth2ClientId'),",
            "                u'oauth2ClientSecret': self.request.get(u'oauth2ClientSecret'),",
            "            }",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_backend_service",
            "description:",
            "- Creates a BackendService resource in the specified project using the data included",
            "  in the request.",
            "short_description: Creates a GCP BackendService",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  affinity_cookie_ttl_sec:",
            "    description:",
            "    - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "      to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "      session (or equivalent). The maximum allowed value for TTL is one day.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "  backends:",
            "    description:",
            "    - The list of backends that serve this BackendService.",
            "    required: false",
            "    suboptions:",
            "      balancing_mode:",
            "        description:",
            "        - Specifies the balancing mode for this backend.",
            "        - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "          Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "        default: UTILIZATION",
            "        choices:",
            "        - UTILIZATION",
            "        - RATE",
            "        - CONNECTION",
            "      capacity_scaler:",
            "        description:",
            "        - A multiplier applied to the group's maximum servicing capacity (based on",
            "          UTILIZATION, RATE or CONNECTION).",
            "        - Default value is 1, which means the group will serve up to 100% of its configured",
            "          capacity (depending on balancingMode). A setting of 0 means the group is",
            "          completely drained, offering 0% of its available Capacity. Valid range is",
            "          [0.0,1.0].",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "        default: '1.0'",
            "      description:",
            "        description:",
            "        - An optional description of this resource.",
            "        - Provide this property when you create the resource.",
            "        required: false",
            "      group:",
            "        description:",
            "        - This instance group defines the list of instances that serve traffic. Member",
            "          virtual machine instances from each instance group must live in the same",
            "          zone as the instance group itself.",
            "        - No two backends in a backend service are allowed to use same Instance Group",
            "          resource.",
            "        - When the BackendService has load balancing scheme INTERNAL, the instance",
            "          group must be in a zone within the same region as the BackendService.",
            "        - 'This field represents a link to a InstanceGroup resource in GCP. It can",
            "          be specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "          and value of your resource''s selfLink Alternatively, you can add `register:",
            "          name-of-resource` to a gcp_compute_instance_group task and then set this",
            "          group field to \"{{ name-of-resource }}\"'",
            "        required: false",
            "      max_connections:",
            "        description:",
            "        - The max number of simultaneous connections for the group. Can be used with",
            "          either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance",
            "          must be set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_connections_per_instance:",
            "        description:",
            "        - The max number of simultaneous connections that a single backend instance",
            "          can handle. This is used to calculate the capacity of the group. Can be",
            "          used in either CONNECTION or UTILIZATION balancing modes.",
            "        - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance",
            "          must be set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_rate:",
            "        description:",
            "        - The max requests per second (RPS) of the group.",
            "        - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "          if RATE mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "          set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_rate_per_instance:",
            "        description:",
            "        - The max requests per second (RPS) that a single backend instance can handle.",
            "          This is used to calculate the capacity of the group. Can be used in either",
            "          balancing mode. For RATE mode, either maxRate or maxRatePerInstance must",
            "          be set.",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "      max_utilization:",
            "        description:",
            "        - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "          target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "        - This cannot be used for internal load balancing.",
            "        required: false",
            "        default: '0.8'",
            "  cdn_policy:",
            "    description:",
            "    - Cloud CDN configuration for this BackendService.",
            "    required: false",
            "    suboptions:",
            "      cache_key_policy:",
            "        description:",
            "        - The CacheKeyPolicy for this CdnPolicy.",
            "        required: false",
            "        suboptions:",
            "          include_host:",
            "            description:",
            "            - If true requests to different hosts will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_protocol:",
            "            description:",
            "            - If true, http and https requests will be cached separately.",
            "            required: false",
            "            type: bool",
            "          include_query_string:",
            "            description:",
            "            - If true, include query string parameters in the cache key according",
            "              to query_string_whitelist and query_string_blacklist. If neither is",
            "              set, the entire query string will be included.",
            "            - If false, the query string will be excluded from the cache key entirely.",
            "            required: false",
            "            type: bool",
            "          query_string_blacklist:",
            "            description:",
            "            - Names of query string parameters to exclude in cache keys.",
            "            - All other parameters will be included. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "          query_string_whitelist:",
            "            description:",
            "            - Names of query string parameters to include in cache keys.",
            "            - All other parameters will be excluded. Either specify query_string_whitelist",
            "              or query_string_blacklist, not both.",
            "            - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "            required: false",
            "      signed_url_cache_max_age_sec:",
            "        description:",
            "        - Maximum number of seconds the response to a signed URL request will be considered",
            "          fresh, defaults to 1hr (3600s). After this time period, the response will",
            "          be revalidated before being served.",
            "        - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "          behave as though all responses from this backend had a \"Cache-Control: public,",
            "          max-age=[TTL]\" header, regardless of any existing Cache-Control header.",
            "          The actual headers served in responses will not be altered.'",
            "        required: false",
            "        default: '3600'",
            "        version_added: 2.8",
            "  connection_draining:",
            "    description:",
            "    - Settings for connection draining .",
            "    required: false",
            "    suboptions:",
            "      draining_timeout_sec:",
            "        description:",
            "        - Time for which instance will be drained (not accept new connections, but",
            "          still work to finish started).",
            "        required: false",
            "        default: '300'",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "  enable_cdn:",
            "    description:",
            "    - If true, enable Cloud CDN for this BackendService.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "    type: bool",
            "  health_checks:",
            "    description:",
            "    - The list of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "      checking this BackendService. Currently at most one health check can be specified,",
            "      and a health check is required.",
            "    - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "      instead.",
            "    required: true",
            "  iap:",
            "    description:",
            "    - Settings for enabling Cloud Identity Aware Proxy.",
            "    required: false",
            "    version_added: 2.7",
            "    suboptions:",
            "      enabled:",
            "        description:",
            "        - Enables IAP.",
            "        required: false",
            "        type: bool",
            "      oauth2_client_id:",
            "        description:",
            "        - OAuth2 Client ID for IAP .",
            "        required: true",
            "      oauth2_client_secret:",
            "        description:",
            "        - OAuth2 Client Secret for IAP .",
            "        required: true",
            "  load_balancing_scheme:",
            "    description:",
            "    - Indicates whether the backend service will be used with internal or external",
            "      load balancing. A backend service created for one type of load balancing cannot",
            "      be used with the other. One of `INTERNAL` or `EXTERNAL`. Defaults to `EXTERNAL`.",
            "    required: false",
            "    default: EXTERNAL",
            "    version_added: 2.7",
            "    choices:",
            "    - INTERNAL",
            "    - EXTERNAL",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  port_name:",
            "    description:",
            "    - Name of backend port. The same name should appear in the instance groups referenced",
            "      by this service. Required when the load balancing scheme is EXTERNAL.",
            "    - When the load balancing scheme is INTERNAL, this field is not used.",
            "    required: false",
            "  protocol:",
            "    description:",
            "    - The protocol this BackendService uses to communicate with backends.",
            "    - Possible values are HTTP, HTTPS, TCP, and SSL. The default is HTTP.",
            "    - For internal load balancing, the possible values are TCP and UDP, and the default",
            "      is TCP.",
            "    required: false",
            "    choices:",
            "    - HTTP",
            "    - HTTPS",
            "    - TCP",
            "    - SSL",
            "  security_policy:",
            "    description:",
            "    - The security policy associated with this backend service.",
            "    required: false",
            "    version_added: 2.8",
            "  session_affinity:",
            "    description:",
            "    - Type of session affinity to use. The default is NONE.",
            "    - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "    - When the load balancing scheme is INTERNAL, can be NONE, CLIENT_IP, CLIENT_IP_PROTO,",
            "      or CLIENT_IP_PORT_PROTO.",
            "    - When the protocol is UDP, this field is not used.",
            "    required: false",
            "    choices:",
            "    - NONE",
            "    - CLIENT_IP",
            "    - GENERATED_COOKIE",
            "    - CLIENT_IP_PROTO",
            "    - CLIENT_IP_PORT_PROTO",
            "  timeout_sec:",
            "    description:",
            "    - How many seconds to wait for the backend before considering it a failed request.",
            "      Default is 30 seconds. Valid range is [1, 86400].",
            "    required: false",
            "    aliases:",
            "    - timeout_seconds",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance group",
            "  gcp_compute_instance_group:",
            "    name: instancegroup-backendservice",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: instancegroup",
            "",
            "- name: create a http health check",
            "  gcp_compute_http_health_check:",
            "    name: httphealthcheck-backendservice",
            "    healthy_threshold: 10",
            "    port: 8080",
            "    timeout_sec: 2",
            "    unhealthy_threshold: 5",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: healthcheck",
            "",
            "- name: create a backend service",
            "  gcp_compute_backend_service:",
            "    name: test_object",
            "    backends:",
            "    - group: \"{{ instancegroup }}\"",
            "    health_checks:",
            "    - \"{{ healthcheck.selfLink }}\"",
            "    enable_cdn: 'true'",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "affinityCookieTtlSec:",
            "  description:",
            "  - Lifetime of cookies in seconds if session_affinity is GENERATED_COOKIE. If set",
            "    to 0, the cookie is non-persistent and lasts only until the end of the browser",
            "    session (or equivalent). The maximum allowed value for TTL is one day.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: int",
            "backends:",
            "  description:",
            "  - The list of backends that serve this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    balancingMode:",
            "      description:",
            "      - Specifies the balancing mode for this backend.",
            "      - For global HTTP(S) or TCP/SSL load balancing, the default is UTILIZATION.",
            "        Valid values are UTILIZATION, RATE (for HTTP(S)) and CONNECTION (for TCP/SSL).",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "    capacityScaler:",
            "      description:",
            "      - A multiplier applied to the group's maximum servicing capacity (based on UTILIZATION,",
            "        RATE or CONNECTION).",
            "      - Default value is 1, which means the group will serve up to 100% of its configured",
            "        capacity (depending on balancingMode). A setting of 0 means the group is completely",
            "        drained, offering 0% of its available Capacity. Valid range is [0.0,1.0].",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "    description:",
            "      description:",
            "      - An optional description of this resource.",
            "      - Provide this property when you create the resource.",
            "      returned: success",
            "      type: str",
            "    group:",
            "      description:",
            "      - This instance group defines the list of instances that serve traffic. Member",
            "        virtual machine instances from each instance group must live in the same zone",
            "        as the instance group itself.",
            "      - No two backends in a backend service are allowed to use same Instance Group",
            "        resource.",
            "      - When the BackendService has load balancing scheme INTERNAL, the instance group",
            "        must be in a zone within the same region as the BackendService.",
            "      returned: success",
            "      type: dict",
            "    maxConnections:",
            "      description:",
            "      - The max number of simultaneous connections for the group. Can be used with",
            "        either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance must",
            "        be set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: int",
            "    maxConnectionsPerInstance:",
            "      description:",
            "      - The max number of simultaneous connections that a single backend instance",
            "        can handle. This is used to calculate the capacity of the group. Can be used",
            "        in either CONNECTION or UTILIZATION balancing modes.",
            "      - For CONNECTION mode, either maxConnections or maxConnectionsPerInstance must",
            "        be set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: int",
            "    maxRate:",
            "      description:",
            "      - The max requests per second (RPS) of the group.",
            "      - Can be used with either RATE or UTILIZATION balancing modes, but required",
            "        if RATE mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "        set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: int",
            "    maxRatePerInstance:",
            "      description:",
            "      - The max requests per second (RPS) that a single backend instance can handle.",
            "        This is used to calculate the capacity of the group. Can be used in either",
            "        balancing mode. For RATE mode, either maxRate or maxRatePerInstance must be",
            "        set.",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "    maxUtilization:",
            "      description:",
            "      - Used when balancingMode is UTILIZATION. This ratio defines the CPU utilization",
            "        target for the group. The default is 0.8. Valid range is [0.0, 1.0].",
            "      - This cannot be used for internal load balancing.",
            "      returned: success",
            "      type: str",
            "cdnPolicy:",
            "  description:",
            "  - Cloud CDN configuration for this BackendService.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    cacheKeyPolicy:",
            "      description:",
            "      - The CacheKeyPolicy for this CdnPolicy.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        includeHost:",
            "          description:",
            "          - If true requests to different hosts will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeProtocol:",
            "          description:",
            "          - If true, http and https requests will be cached separately.",
            "          returned: success",
            "          type: bool",
            "        includeQueryString:",
            "          description:",
            "          - If true, include query string parameters in the cache key according to",
            "            query_string_whitelist and query_string_blacklist. If neither is set,",
            "            the entire query string will be included.",
            "          - If false, the query string will be excluded from the cache key entirely.",
            "          returned: success",
            "          type: bool",
            "        queryStringBlacklist:",
            "          description:",
            "          - Names of query string parameters to exclude in cache keys.",
            "          - All other parameters will be included. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "        queryStringWhitelist:",
            "          description:",
            "          - Names of query string parameters to include in cache keys.",
            "          - All other parameters will be excluded. Either specify query_string_whitelist",
            "            or query_string_blacklist, not both.",
            "          - \"'&' and '=' will be percent encoded and not treated as delimiters.\"",
            "          returned: success",
            "          type: list",
            "    signedUrlCacheMaxAgeSec:",
            "      description:",
            "      - Maximum number of seconds the response to a signed URL request will be considered",
            "        fresh, defaults to 1hr (3600s). After this time period, the response will",
            "        be revalidated before being served.",
            "      - 'When serving responses to signed URL requests, Cloud CDN will internally",
            "        behave as though all responses from this backend had a \"Cache-Control: public,",
            "        max-age=[TTL]\" header, regardless of any existing Cache-Control header. The",
            "        actual headers served in responses will not be altered.'",
            "      returned: success",
            "      type: int",
            "connectionDraining:",
            "  description:",
            "  - Settings for connection draining .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    drainingTimeoutSec:",
            "      description:",
            "      - Time for which instance will be drained (not accept new connections, but still",
            "        work to finish started).",
            "      returned: success",
            "      type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "fingerprint:",
            "  description:",
            "  - Fingerprint of this resource. A hash of the contents stored in this object. This",
            "    field is used in optimistic locking.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "enableCDN:",
            "  description:",
            "  - If true, enable Cloud CDN for this BackendService.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: bool",
            "healthChecks:",
            "  description:",
            "  - The list of URLs to the HttpHealthCheck or HttpsHealthCheck resource for health",
            "    checking this BackendService. Currently at most one health check can be specified,",
            "    and a health check is required.",
            "  - For internal load balancing, a URL to a HealthCheck resource must be specified",
            "    instead.",
            "  returned: success",
            "  type: list",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "iap:",
            "  description:",
            "  - Settings for enabling Cloud Identity Aware Proxy.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    enabled:",
            "      description:",
            "      - Enables IAP.",
            "      returned: success",
            "      type: bool",
            "    oauth2ClientId:",
            "      description:",
            "      - OAuth2 Client ID for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecret:",
            "      description:",
            "      - OAuth2 Client Secret for IAP .",
            "      returned: success",
            "      type: str",
            "    oauth2ClientSecretSha256:",
            "      description:",
            "      - OAuth2 Client Secret SHA-256 for IAP .",
            "      returned: success",
            "      type: str",
            "loadBalancingScheme:",
            "  description:",
            "  - Indicates whether the backend service will be used with internal or external load",
            "    balancing. A backend service created for one type of load balancing cannot be",
            "    used with the other. One of `INTERNAL` or `EXTERNAL`. Defaults to `EXTERNAL`.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "portName:",
            "  description:",
            "  - Name of backend port. The same name should appear in the instance groups referenced",
            "    by this service. Required when the load balancing scheme is EXTERNAL.",
            "  - When the load balancing scheme is INTERNAL, this field is not used.",
            "  returned: success",
            "  type: str",
            "protocol:",
            "  description:",
            "  - The protocol this BackendService uses to communicate with backends.",
            "  - Possible values are HTTP, HTTPS, TCP, and SSL. The default is HTTP.",
            "  - For internal load balancing, the possible values are TCP and UDP, and the default",
            "    is TCP.",
            "  returned: success",
            "  type: str",
            "securityPolicy:",
            "  description:",
            "  - The security policy associated with this backend service.",
            "  returned: success",
            "  type: str",
            "sessionAffinity:",
            "  description:",
            "  - Type of session affinity to use. The default is NONE.",
            "  - When the load balancing scheme is EXTERNAL, can be NONE, CLIENT_IP, or GENERATED_COOKIE.",
            "  - When the load balancing scheme is INTERNAL, can be NONE, CLIENT_IP, CLIENT_IP_PROTO,",
            "    or CLIENT_IP_PORT_PROTO.",
            "  - When the protocol is UDP, this field is not used.",
            "  returned: success",
            "  type: str",
            "timeoutSec:",
            "  description:",
            "  - How many seconds to wait for the backend before considering it a failed request.",
            "    Default is 30 seconds. Valid range is [1, 86400].",
            "  returned: success",
            "  type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            affinity_cookie_ttl_sec=dict(type='int'),",
            "            backends=dict(",
            "                type='list',",
            "                elements='dict',",
            "                options=dict(",
            "                    balancing_mode=dict(default='UTILIZATION', type='str', choices=['UTILIZATION', 'RATE', 'CONNECTION']),",
            "                    capacity_scaler=dict(default=1.0, type='str'),",
            "                    description=dict(type='str'),",
            "                    group=dict(type='dict'),",
            "                    max_connections=dict(type='int'),",
            "                    max_connections_per_instance=dict(type='int'),",
            "                    max_rate=dict(type='int'),",
            "                    max_rate_per_instance=dict(type='str'),",
            "                    max_utilization=dict(default=0.8, type='str'),",
            "                ),",
            "            ),",
            "            cdn_policy=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    cache_key_policy=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            include_host=dict(type='bool'),",
            "                            include_protocol=dict(type='bool'),",
            "                            include_query_string=dict(type='bool'),",
            "                            query_string_blacklist=dict(type='list', elements='str'),",
            "                            query_string_whitelist=dict(type='list', elements='str'),",
            "                        ),",
            "                    ),",
            "                    signed_url_cache_max_age_sec=dict(default=3600, type='int'),",
            "                ),",
            "            ),",
            "            connection_draining=dict(type='dict', options=dict(draining_timeout_sec=dict(default=300, type='int'))),",
            "            description=dict(type='str'),",
            "            enable_cdn=dict(type='bool'),",
            "            health_checks=dict(required=True, type='list', elements='str'),",
            "            iap=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    enabled=dict(type='bool'),",
            "                    oauth2_client_id=dict(required=True, type='str'),",
            "                    oauth2_client_secret=dict(required=True, type='str', no_log=True),",
            "                ),",
            "            ),",
            "            load_balancing_scheme=dict(default='EXTERNAL', type='str', choices=['INTERNAL', 'EXTERNAL']),",
            "            name=dict(required=True, type='str'),",
            "            port_name=dict(type='str'),",
            "            protocol=dict(type='str', choices=['HTTP', 'HTTPS', 'TCP', 'SSL']),",
            "            security_policy=dict(type='str'),",
            "            session_affinity=dict(type='str', choices=['NONE', 'CLIENT_IP', 'GENERATED_COOKIE', 'CLIENT_IP_PROTO', 'CLIENT_IP_PORT_PROTO']),",
            "            timeout_sec=dict(type='int', aliases=['timeout_seconds']),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#backendService'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.put(link, resource_to_request(module)))",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('securityPolicy') != request.get('securityPolicy'):",
            "        security_policy_update(module, request, response)",
            "",
            "",
            "def security_policy_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/backendServices/{name}/setSecurityPolicy\"]).format(**module.params),",
            "        {u'securityPolicy': module.params.get('security_policy')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#backendService',",
            "        u'affinityCookieTtlSec': module.params.get('affinity_cookie_ttl_sec'),",
            "        u'backends': BackendServiceBackendsArray(module.params.get('backends', []), module).to_request(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(module.params.get('cdn_policy', {}), module).to_request(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(module.params.get('connection_draining', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'enableCDN': module.params.get('enable_cdn'),",
            "        u'healthChecks': module.params.get('health_checks'),",
            "        u'iap': BackendServiceIap(module.params.get('iap', {}), module).to_request(),",
            "        u'loadBalancingScheme': module.params.get('load_balancing_scheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': module.params.get('port_name'),",
            "        u'protocol': module.params.get('protocol'),",
            "        u'securityPolicy': module.params.get('security_policy'),",
            "        u'sessionAffinity': module.params.get('session_affinity'),",
            "        u'timeoutSec': module.params.get('timeout_sec'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/backendServices\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'affinityCookieTtlSec': response.get(u'affinityCookieTtlSec'),",
            "        u'backends': BackendServiceBackendsArray(response.get(u'backends', []), module).from_response(),",
            "        u'cdnPolicy': BackendServiceCdnpolicy(response.get(u'cdnPolicy', {}), module).from_response(),",
            "        u'connectionDraining': BackendServiceConnectiondraining(response.get(u'connectionDraining', {}), module).from_response(),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'fingerprint': response.get(u'fingerprint'),",
            "        u'description': response.get(u'description'),",
            "        u'enableCDN': response.get(u'enableCDN'),",
            "        u'healthChecks': response.get(u'healthChecks'),",
            "        u'id': response.get(u'id'),",
            "        u'iap': BackendServiceIap(response.get(u'iap', {}), module).from_response(),",
            "        u'loadBalancingScheme': response.get(u'loadBalancingScheme'),",
            "        u'name': module.params.get('name'),",
            "        u'portName': response.get(u'portName'),",
            "        u'protocol': response.get(u'protocol'),",
            "        u'securityPolicy': response.get(u'securityPolicy'),",
            "        u'sessionAffinity': response.get(u'sessionAffinity'),",
            "        u'timeoutSec': response.get(u'timeoutSec'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#backendService')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class BackendServiceBackendsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get('balancing_mode'),",
            "                u'capacityScaler': item.get('capacity_scaler'),",
            "                u'description': item.get('description'),",
            "                u'group': replace_resource_dict(item.get(u'group', {}), 'selfLink'),",
            "                u'maxConnections': item.get('max_connections'),",
            "                u'maxConnectionsPerInstance': item.get('max_connections_per_instance'),",
            "                u'maxRate': item.get('max_rate'),",
            "                u'maxRatePerInstance': item.get('max_rate_per_instance'),",
            "                u'maxUtilization': item.get('max_utilization'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'balancingMode': item.get(u'balancingMode'),",
            "                u'capacityScaler': item.get(u'capacityScaler'),",
            "                u'description': item.get(u'description'),",
            "                u'group': item.get(u'group'),",
            "                u'maxConnections': item.get(u'maxConnections'),",
            "                u'maxConnectionsPerInstance': item.get(u'maxConnectionsPerInstance'),",
            "                u'maxRate': item.get(u'maxRate'),",
            "                u'maxRatePerInstance': item.get(u'maxRatePerInstance'),",
            "                u'maxUtilization': item.get(u'maxUtilization'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCdnpolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get('cache_key_policy', {}), self.module).to_request(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get('signed_url_cache_max_age_sec'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'cacheKeyPolicy': BackendServiceCachekeypolicy(self.request.get(u'cacheKeyPolicy', {}), self.module).from_response(),",
            "                u'signedUrlCacheMaxAgeSec': self.request.get(u'signedUrlCacheMaxAgeSec'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceCachekeypolicy(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get('include_host'),",
            "                u'includeProtocol': self.request.get('include_protocol'),",
            "                u'includeQueryString': self.request.get('include_query_string'),",
            "                u'queryStringBlacklist': self.request.get('query_string_blacklist'),",
            "                u'queryStringWhitelist': self.request.get('query_string_whitelist'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'includeHost': self.request.get(u'includeHost'),",
            "                u'includeProtocol': self.request.get(u'includeProtocol'),",
            "                u'includeQueryString': self.request.get(u'includeQueryString'),",
            "                u'queryStringBlacklist': self.request.get(u'queryStringBlacklist'),",
            "                u'queryStringWhitelist': self.request.get(u'queryStringWhitelist'),",
            "            }",
            "        )",
            "",
            "",
            "class BackendServiceConnectiondraining(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get('draining_timeout_sec')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'drainingTimeoutSec': self.request.get(u'drainingTimeoutSec')})",
            "",
            "",
            "class BackendServiceIap(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get('enabled'),",
            "                u'oauth2ClientId': self.request.get('oauth2_client_id'),",
            "                u'oauth2ClientSecret': self.request.get('oauth2_client_secret'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'enabled': self.request.get(u'enabled'),",
            "                u'oauth2ClientId': self.request.get(u'oauth2ClientId'),",
            "                u'oauth2ClientSecret': self.request.get(u'oauth2ClientSecret'),",
            "            }",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "689": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_disk.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 440,
                "afterPatchRowNumber": 440,
                "PatchRowcode": "             type=dict(type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 441,
                "afterPatchRowNumber": 441,
                "PatchRowcode": "             source_image=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 442,
                "afterPatchRowNumber": 442,
                "PatchRowcode": "             zone=dict(required=True, type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 443,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": 444,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 443,
                "PatchRowcode": "+            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 444,
                "PatchRowcode": "+            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "7": {
                "beforePatchRowNumber": 445,
                "afterPatchRowNumber": 445,
                "PatchRowcode": "             source_snapshot=dict(type='dict'),"
            },
            "8": {
                "beforePatchRowNumber": 446,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 446,
                "PatchRowcode": "+            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),"
            },
            "10": {
                "beforePatchRowNumber": 447,
                "afterPatchRowNumber": 447,
                "PatchRowcode": "         )"
            },
            "11": {
                "beforePatchRowNumber": 448,
                "afterPatchRowNumber": 448,
                "PatchRowcode": "     )"
            },
            "12": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 449,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP Disk",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "    version_added: 2.7",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "    version_added: 2.8",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "    version_added: 2.7",
            "  source_image:",
            "    description:",
            "    - The source image used to create this disk. If the source image is deleted, this",
            "      field will not be set.",
            "    - 'To create a disk with one of the public operating system images, specify the",
            "      image by its family name. For example, specify family/debian-8 to use the latest",
            "      Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "      use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "      To create a disk with a private image that you created, specify the image name",
            "      in the following format: global/images/my-private-image You can also specify",
            "      a private image by its image family, which returns the latest version of the",
            "      image in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "      .'",
            "    required: false",
            "  zone:",
            "    description:",
            "    - A reference to the zone where the disk resides.",
            "    required: true",
            "  source_image_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source image. Required if the source",
            "      image is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/disks)'",
            "- 'Adding a persistent disk: U(https://cloud.google.com/compute/docs/disks/add-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: test_object",
            "    size_gb: 50",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    zone: us-central1-a",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last dettach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "sourceImage:",
            "  description:",
            "  - The source image used to create this disk. If the source image is deleted, this",
            "    field will not be set.",
            "  - 'To create a disk with one of the public operating system images, specify the",
            "    image by its family name. For example, specify family/debian-8 to use the latest",
            "    Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "    use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "    To create a disk with a private image that you created, specify the image name",
            "    in the following format: global/images/my-private-image You can also specify a",
            "    private image by its image family, which returns the latest version of the image",
            "    in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "    .'",
            "  returned: success",
            "  type: str",
            "zone:",
            "  description:",
            "  - A reference to the zone where the disk resides.",
            "  returned: success",
            "  type: str",
            "sourceImageEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source image. Required if the source",
            "    image is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceImageId:",
            "  description:",
            "  - The ID value of the image used to create this disk. This value identifies the",
            "    exact image that was used to create this persistent disk. For example, if you",
            "    created the persistent disk from an image that was later deleted and recreated",
            "    under the same name, the source image ID would identify the exact version of the",
            "    image that was used.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            type=dict(type='str'),",
            "            source_image=dict(type='str'),",
            "            zone=dict(required=True, type='str'),",
            "            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), kms_key_name=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'sourceImageEncryptionKey': DiskSourceimageencryptionkey(module.params.get('source_image_encryption_key', {}), module).to_request(),",
            "        u'diskEncryptionKey': DiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': DiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'type': disk_type_selflink(module.params.get('type'), module.params),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'type': response.get(u'type'),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/[a-z1-9\\-]*/diskTypes/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class DiskSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP Disk",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "    version_added: 2.7",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "    version_added: 2.8",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "    version_added: 2.7",
            "  source_image:",
            "    description:",
            "    - The source image used to create this disk. If the source image is deleted, this",
            "      field will not be set.",
            "    - 'To create a disk with one of the public operating system images, specify the",
            "      image by its family name. For example, specify family/debian-8 to use the latest",
            "      Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "      use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "      To create a disk with a private image that you created, specify the image name",
            "      in the following format: global/images/my-private-image You can also specify",
            "      a private image by its image family, which returns the latest version of the",
            "      image in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "      .'",
            "    required: false",
            "  zone:",
            "    description:",
            "    - A reference to the zone where the disk resides.",
            "    required: true",
            "  source_image_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source image. Required if the source",
            "      image is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "      kms_key_name:",
            "        description:",
            "        - The name of the encryption key that is stored in Google Cloud KMS.",
            "        required: false",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/disks)'",
            "- 'Adding a persistent disk: U(https://cloud.google.com/compute/docs/disks/add-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: test_object",
            "    size_gb: 50",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    zone: us-central1-a",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last dettach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "sourceImage:",
            "  description:",
            "  - The source image used to create this disk. If the source image is deleted, this",
            "    field will not be set.",
            "  - 'To create a disk with one of the public operating system images, specify the",
            "    image by its family name. For example, specify family/debian-8 to use the latest",
            "    Debian 8 image: projects/debian-cloud/global/images/family/debian-8 Alternatively,",
            "    use a specific version of a public operating system image: projects/debian-cloud/global/images/debian-8-jessie-vYYYYMMDD",
            "    To create a disk with a private image that you created, specify the image name",
            "    in the following format: global/images/my-private-image You can also specify a",
            "    private image by its image family, which returns the latest version of the image",
            "    in that family. Replace the image name with family/family-name: global/images/family/my-private-family",
            "    .'",
            "  returned: success",
            "  type: str",
            "zone:",
            "  description:",
            "  - A reference to the zone where the disk resides.",
            "  returned: success",
            "  type: str",
            "sourceImageEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source image. Required if the source",
            "    image is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceImageId:",
            "  description:",
            "  - The ID value of the image used to create this disk. This value identifies the",
            "    exact image that was used to create this persistent disk. For example, if you",
            "    created the persistent disk from an image that was later deleted and recreated",
            "    under the same name, the source image ID would identify the exact version of the",
            "    image that was used.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    kmsKeyName:",
            "      description:",
            "      - The name of the encryption key that is stored in Google Cloud KMS.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            type=dict(type='str'),",
            "            source_image=dict(type='str'),",
            "            zone=dict(required=True, type='str'),",
            "            source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True), kms_key_name=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/zones/{zone}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'sourceImageEncryptionKey': DiskSourceimageencryptionkey(module.params.get('source_image_encryption_key', {}), module).to_request(),",
            "        u'diskEncryptionKey': DiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': DiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'type': disk_type_selflink(module.params.get('type'), module.params),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'type': response.get(u'type'),",
            "        u'sourceImage': module.params.get('source_image'),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/[a-z1-9\\-]*/diskTypes/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class DiskSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "class DiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'kmsKeyName': self.request.get('kms_key_name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'kmsKeyName': self.request.get(u'kmsKeyName')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "443": [
                "main"
            ],
            "444": [
                "main"
            ],
            "446": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_image.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 444,
                "afterPatchRowNumber": 444,
                "PatchRowcode": "             disk_size_gb=dict(type='int'),"
            },
            "1": {
                "beforePatchRowNumber": 445,
                "afterPatchRowNumber": 445,
                "PatchRowcode": "             family=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 446,
                "afterPatchRowNumber": 446,
                "PatchRowcode": "             guest_os_features=dict(type='list', elements='dict', options=dict(type=dict(type='str', choices=['VIRTIO_SCSI_MULTIQUEUE']))),"
            },
            "3": {
                "beforePatchRowNumber": 447,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 447,
                "PatchRowcode": "+            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "5": {
                "beforePatchRowNumber": 448,
                "afterPatchRowNumber": 448,
                "PatchRowcode": "             labels=dict(type='dict'),"
            },
            "6": {
                "beforePatchRowNumber": 449,
                "afterPatchRowNumber": 449,
                "PatchRowcode": "             licenses=dict(type='list', elements='str'),"
            },
            "7": {
                "beforePatchRowNumber": 450,
                "afterPatchRowNumber": 450,
                "PatchRowcode": "             name=dict(required=True, type='str'),"
            },
            "8": {
                "beforePatchRowNumber": 453,
                "afterPatchRowNumber": 453,
                "PatchRowcode": "                 options=dict(container_type=dict(type='str', choices=['TAR']), sha1_checksum=dict(type='str'), source=dict(required=True, type='str')),"
            },
            "9": {
                "beforePatchRowNumber": 454,
                "afterPatchRowNumber": 454,
                "PatchRowcode": "             ),"
            },
            "10": {
                "beforePatchRowNumber": 455,
                "afterPatchRowNumber": 455,
                "PatchRowcode": "             source_disk=dict(type='dict'),"
            },
            "11": {
                "beforePatchRowNumber": 456,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 456,
                "PatchRowcode": "+            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "13": {
                "beforePatchRowNumber": 457,
                "afterPatchRowNumber": 457,
                "PatchRowcode": "             source_disk_id=dict(type='str'),"
            },
            "14": {
                "beforePatchRowNumber": 458,
                "afterPatchRowNumber": 458,
                "PatchRowcode": "             source_type=dict(type='str', choices=['RAW']),"
            },
            "15": {
                "beforePatchRowNumber": 459,
                "afterPatchRowNumber": 459,
                "PatchRowcode": "         )"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_image",
            "description:",
            "- Represents an Image resource.",
            "- Google Compute Engine uses operating system images to create the root persistent",
            "  disks for your instances. You specify an image when you create an instance. Images",
            "  contain a boot loader, an operating system, and a root file system. Linux operating",
            "  system images are also capable of running containers on Compute Engine.",
            "- Images can be either public or custom.",
            "- Public images are provided and maintained by Google, open-source communities, and",
            "  third-party vendors. By default, all projects have access to these images and can",
            "  use them to create instances. Custom images are available only to your project.",
            "  You can create a custom image from root persistent disks and other images. Then,",
            "  use the custom image to create an instance.",
            "short_description: Creates a GCP Image",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  disk_size_gb:",
            "    description:",
            "    - Size of the image when restored onto a persistent disk (in GB).",
            "    required: false",
            "  family:",
            "    description:",
            "    - The name of the image family to which this image belongs. You can create disks",
            "      by specifying an image family instead of a specific image name. The image family",
            "      always returns its latest image that is not deprecated. The name of the image",
            "      family must comply with RFC1035.",
            "    required: false",
            "  guest_os_features:",
            "    description:",
            "    - A list of features to enable on the guest OS. Applicable for bootable images",
            "      only. Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which",
            "      allows each virtual CPU to have its own queue. For Windows images, you can only",
            "      enable VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher.",
            "      Linux images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "    - For new Windows images, the server might also populate this field with the value",
            "      WINDOWS, to indicate that this is a Windows image.",
            "    - This value is purely informational and does not enable or disable any features.",
            "    required: false",
            "    suboptions:",
            "      type:",
            "        description:",
            "        - The type of supported feature. Currenty only VIRTIO_SCSI_MULTIQUEUE is supported.",
            "          For newer Windows images, the server might also populate this property with",
            "          the value WINDOWS to indicate that this is a Windows image. This value is",
            "          purely informational and does not enable or disable any features.",
            "        required: false",
            "        choices:",
            "        - VIRTIO_SCSI_MULTIQUEUE",
            "  image_encryption_key:",
            "    description:",
            "    - Encrypts the image using a customer-supplied encryption key.",
            "    - After you encrypt an image with a customer-supplied key, you must provide the",
            "      same key if you use the image later (e.g. to create a disk from the image) .",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "  labels:",
            "    description:",
            "    - Labels to apply to this Image.",
            "    required: false",
            "    version_added: 2.8",
            "  licenses:",
            "    description:",
            "    - Any applicable license URI.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource; provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  raw_disk:",
            "    description:",
            "    - The parameters of the raw disk image.",
            "    required: false",
            "    suboptions:",
            "      container_type:",
            "        description:",
            "        - The format used to encode and transmit the block device, which should be",
            "          TAR. This is just a container and transmission format and not a runtime",
            "          format. Provided by the client when the disk image is created.",
            "        required: false",
            "        choices:",
            "        - TAR",
            "      sha1_checksum:",
            "        description:",
            "        - An optional SHA1 checksum of the disk image before unpackaging.",
            "        - This is provided by the client when the disk image is created.",
            "        required: false",
            "      source:",
            "        description:",
            "        - The full Google Cloud Storage URL where disk storage is stored You must",
            "          provide either this property or the sourceDisk property but not both.",
            "        required: true",
            "  source_disk:",
            "    description:",
            "    - The source disk to create this image based on.",
            "    - You must provide either this property or the rawDisk.source property but not",
            "      both to create an image.",
            "    - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_disk task and then set this source_disk field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "  source_disk_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source disk. Required if the source",
            "      disk is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "  source_disk_id:",
            "    description:",
            "    - The ID value of the disk used to create this image. This value may be used to",
            "      determine whether the image was taken from the current or a previous instance",
            "      of a given disk name.",
            "    required: false",
            "  source_type:",
            "    description:",
            "    - The type of the image used to create this disk. The default and only value is",
            "      RAW .",
            "    required: false",
            "    choices:",
            "    - RAW",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/images)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/images)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: disk-image",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: disk",
            "",
            "- name: create a image",
            "  gcp_compute_image:",
            "    name: test_object",
            "    source_disk: \"{{ disk }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "archiveSizeBytes:",
            "  description:",
            "  - Size of the image tar.gz archive stored in Google Cloud Storage (in bytes).",
            "  returned: success",
            "  type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "deprecated:",
            "  description:",
            "  - The deprecation status associated with this image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    deleted:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DELETED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    deprecated:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DEPRECATED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    obsolete:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to OBSOLETE. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    replacement:",
            "      description:",
            "      - The URL of the suggested replacement for a deprecated resource.",
            "      - The suggested replacement resource must be the same kind of resource as the",
            "        deprecated resource.",
            "      returned: success",
            "      type: str",
            "    state:",
            "      description:",
            "      - The deprecation state of this resource. This can be DEPRECATED, OBSOLETE,",
            "        or DELETED. Operations which create a new resource using a DEPRECATED resource",
            "        will return successfully, but with a warning indicating the deprecated resource",
            "        and recommending its replacement. Operations which use OBSOLETE or DELETED",
            "        resources will be rejected and result in an error.",
            "      returned: success",
            "      type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "diskSizeGb:",
            "  description:",
            "  - Size of the image when restored onto a persistent disk (in GB).",
            "  returned: success",
            "  type: int",
            "family:",
            "  description:",
            "  - The name of the image family to which this image belongs. You can create disks",
            "    by specifying an image family instead of a specific image name. The image family",
            "    always returns its latest image that is not deprecated. The name of the image",
            "    family must comply with RFC1035.",
            "  returned: success",
            "  type: str",
            "guestOsFeatures:",
            "  description:",
            "  - A list of features to enable on the guest OS. Applicable for bootable images only.",
            "    Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which allows",
            "    each virtual CPU to have its own queue. For Windows images, you can only enable",
            "    VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher. Linux",
            "    images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "  - For new Windows images, the server might also populate this field with the value",
            "    WINDOWS, to indicate that this is a Windows image.",
            "  - This value is purely informational and does not enable or disable any features.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    type:",
            "      description:",
            "      - The type of supported feature. Currenty only VIRTIO_SCSI_MULTIQUEUE is supported.",
            "        For newer Windows images, the server might also populate this property with",
            "        the value WINDOWS to indicate that this is a Windows image. This value is",
            "        purely informational and does not enable or disable any features.",
            "      returned: success",
            "      type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "imageEncryptionKey:",
            "  description:",
            "  - Encrypts the image using a customer-supplied encryption key.",
            "  - After you encrypt an image with a customer-supplied key, you must provide the",
            "    same key if you use the image later (e.g. to create a disk from the image) .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this Image.",
            "  returned: success",
            "  type: dict",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "licenses:",
            "  description:",
            "  - Any applicable license URI.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource; provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "rawDisk:",
            "  description:",
            "  - The parameters of the raw disk image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    containerType:",
            "      description:",
            "      - The format used to encode and transmit the block device, which should be TAR.",
            "        This is just a container and transmission format and not a runtime format.",
            "        Provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    sha1Checksum:",
            "      description:",
            "      - An optional SHA1 checksum of the disk image before unpackaging.",
            "      - This is provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    source:",
            "      description:",
            "      - The full Google Cloud Storage URL where disk storage is stored You must provide",
            "        either this property or the sourceDisk property but not both.",
            "      returned: success",
            "      type: str",
            "sourceDisk:",
            "  description:",
            "  - The source disk to create this image based on.",
            "  - You must provide either this property or the rawDisk.source property but not both",
            "    to create an image.",
            "  returned: success",
            "  type: dict",
            "sourceDiskEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source disk. Required if the source",
            "    disk is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceDiskId:",
            "  description:",
            "  - The ID value of the disk used to create this image. This value may be used to",
            "    determine whether the image was taken from the current or a previous instance",
            "    of a given disk name.",
            "  returned: success",
            "  type: str",
            "sourceType:",
            "  description:",
            "  - The type of the image used to create this disk. The default and only value is",
            "    RAW .",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            disk_size_gb=dict(type='int'),",
            "            family=dict(type='str'),",
            "            guest_os_features=dict(type='list', elements='dict', options=dict(type=dict(type='str', choices=['VIRTIO_SCSI_MULTIQUEUE']))),",
            "            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            raw_disk=dict(",
            "                type='dict',",
            "                options=dict(container_type=dict(type='str', choices=['TAR']), sha1_checksum=dict(type='str'), source=dict(required=True, type='str')),",
            "            ),",
            "            source_disk=dict(type='dict'),",
            "            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "            source_disk_id=dict(type='str'),",
            "            source_type=dict(type='str', choices=['RAW']),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#image'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        labels_update(module, request, response)",
            "",
            "",
            "def labels_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/images/{name}/setLabels\"]).format(**module.params),",
            "        {u'labels': module.params.get('labels'), u'labelFingerprint': response.get('labelFingerprint')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#image',",
            "        u'description': module.params.get('description'),",
            "        u'diskSizeGb': module.params.get('disk_size_gb'),",
            "        u'family': module.params.get('family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(module.params.get('guest_os_features', []), module).to_request(),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(module.params.get('image_encryption_key', {}), module).to_request(),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'rawDisk': ImageRawdisk(module.params.get('raw_disk', {}), module).to_request(),",
            "        u'sourceDisk': replace_resource_dict(module.params.get(u'source_disk', {}), 'selfLink'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(module.params.get('source_disk_encryption_key', {}), module).to_request(),",
            "        u'sourceDiskId': module.params.get('source_disk_id'),",
            "        u'sourceType': module.params.get('source_type'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'archiveSizeBytes': response.get(u'archiveSizeBytes'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'deprecated': ImageDeprecated(response.get(u'deprecated', {}), module).from_response(),",
            "        u'description': response.get(u'description'),",
            "        u'diskSizeGb': response.get(u'diskSizeGb'),",
            "        u'family': response.get(u'family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(response.get(u'guestOsFeatures', []), module).from_response(),",
            "        u'id': response.get(u'id'),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(response.get(u'imageEncryptionKey', {}), module).from_response(),",
            "        u'labels': response.get(u'labels'),",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': response.get(u'name'),",
            "        u'rawDisk': ImageRawdisk(response.get(u'rawDisk', {}), module).from_response(),",
            "        u'sourceDisk': response.get(u'sourceDisk'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(response.get(u'sourceDiskEncryptionKey', {}), module).from_response(),",
            "        u'sourceDiskId': response.get(u'sourceDiskId'),",
            "        u'sourceType': response.get(u'sourceType'),",
            "    }",
            "",
            "",
            "def license_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1//projects/.*/global/licenses/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1//projects/{project}/global/licenses/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#image')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class ImageDeprecated(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get('deleted'),",
            "                u'deprecated': self.request.get('deprecated'),",
            "                u'obsolete': self.request.get('obsolete'),",
            "                u'replacement': self.request.get('replacement'),",
            "                u'state': self.request.get('state'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get(u'deleted'),",
            "                u'deprecated': self.request.get(u'deprecated'),",
            "                u'obsolete': self.request.get(u'obsolete'),",
            "                u'replacement': self.request.get(u'replacement'),",
            "                u'state': self.request.get(u'state'),",
            "            }",
            "        )",
            "",
            "",
            "class ImageGuestosfeaturesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get(u'type')})",
            "",
            "",
            "class ImageImageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class ImageRawdisk(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get('container_type'), u'sha1Checksum': self.request.get('sha1_checksum'), u'source': self.request.get('source')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get(u'containerType'), u'sha1Checksum': self.request.get(u'sha1Checksum'), u'source': self.request.get(u'source')}",
            "        )",
            "",
            "",
            "class ImageSourcediskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_image",
            "description:",
            "- Represents an Image resource.",
            "- Google Compute Engine uses operating system images to create the root persistent",
            "  disks for your instances. You specify an image when you create an instance. Images",
            "  contain a boot loader, an operating system, and a root file system. Linux operating",
            "  system images are also capable of running containers on Compute Engine.",
            "- Images can be either public or custom.",
            "- Public images are provided and maintained by Google, open-source communities, and",
            "  third-party vendors. By default, all projects have access to these images and can",
            "  use them to create instances. Custom images are available only to your project.",
            "  You can create a custom image from root persistent disks and other images. Then,",
            "  use the custom image to create an instance.",
            "short_description: Creates a GCP Image",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  disk_size_gb:",
            "    description:",
            "    - Size of the image when restored onto a persistent disk (in GB).",
            "    required: false",
            "  family:",
            "    description:",
            "    - The name of the image family to which this image belongs. You can create disks",
            "      by specifying an image family instead of a specific image name. The image family",
            "      always returns its latest image that is not deprecated. The name of the image",
            "      family must comply with RFC1035.",
            "    required: false",
            "  guest_os_features:",
            "    description:",
            "    - A list of features to enable on the guest OS. Applicable for bootable images",
            "      only. Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which",
            "      allows each virtual CPU to have its own queue. For Windows images, you can only",
            "      enable VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher.",
            "      Linux images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "    - For new Windows images, the server might also populate this field with the value",
            "      WINDOWS, to indicate that this is a Windows image.",
            "    - This value is purely informational and does not enable or disable any features.",
            "    required: false",
            "    suboptions:",
            "      type:",
            "        description:",
            "        - The type of supported feature. Currenty only VIRTIO_SCSI_MULTIQUEUE is supported.",
            "          For newer Windows images, the server might also populate this property with",
            "          the value WINDOWS to indicate that this is a Windows image. This value is",
            "          purely informational and does not enable or disable any features.",
            "        required: false",
            "        choices:",
            "        - VIRTIO_SCSI_MULTIQUEUE",
            "  image_encryption_key:",
            "    description:",
            "    - Encrypts the image using a customer-supplied encryption key.",
            "    - After you encrypt an image with a customer-supplied key, you must provide the",
            "      same key if you use the image later (e.g. to create a disk from the image) .",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "  labels:",
            "    description:",
            "    - Labels to apply to this Image.",
            "    required: false",
            "    version_added: 2.8",
            "  licenses:",
            "    description:",
            "    - Any applicable license URI.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource; provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  raw_disk:",
            "    description:",
            "    - The parameters of the raw disk image.",
            "    required: false",
            "    suboptions:",
            "      container_type:",
            "        description:",
            "        - The format used to encode and transmit the block device, which should be",
            "          TAR. This is just a container and transmission format and not a runtime",
            "          format. Provided by the client when the disk image is created.",
            "        required: false",
            "        choices:",
            "        - TAR",
            "      sha1_checksum:",
            "        description:",
            "        - An optional SHA1 checksum of the disk image before unpackaging.",
            "        - This is provided by the client when the disk image is created.",
            "        required: false",
            "      source:",
            "        description:",
            "        - The full Google Cloud Storage URL where disk storage is stored You must",
            "          provide either this property or the sourceDisk property but not both.",
            "        required: true",
            "  source_disk:",
            "    description:",
            "    - The source disk to create this image based on.",
            "    - You must provide either this property or the rawDisk.source property but not",
            "      both to create an image.",
            "    - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_disk task and then set this source_disk field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "  source_disk_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source disk. Required if the source",
            "      disk is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "  source_disk_id:",
            "    description:",
            "    - The ID value of the disk used to create this image. This value may be used to",
            "      determine whether the image was taken from the current or a previous instance",
            "      of a given disk name.",
            "    required: false",
            "  source_type:",
            "    description:",
            "    - The type of the image used to create this disk. The default and only value is",
            "      RAW .",
            "    required: false",
            "    choices:",
            "    - RAW",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/v1/images)'",
            "- 'Official Documentation: U(https://cloud.google.com/compute/docs/images)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a disk",
            "  gcp_compute_disk:",
            "    name: disk-image",
            "    zone: us-central1-a",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: disk",
            "",
            "- name: create a image",
            "  gcp_compute_image:",
            "    name: test_object",
            "    source_disk: \"{{ disk }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "archiveSizeBytes:",
            "  description:",
            "  - Size of the image tar.gz archive stored in Google Cloud Storage (in bytes).",
            "  returned: success",
            "  type: int",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "deprecated:",
            "  description:",
            "  - The deprecation status associated with this image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    deleted:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DELETED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    deprecated:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to DEPRECATED. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    obsolete:",
            "      description:",
            "      - An optional RFC3339 timestamp on or after which the state of this resource",
            "        is intended to change to OBSOLETE. This is only informational and the status",
            "        will not change unless the client explicitly changes it.",
            "      returned: success",
            "      type: str",
            "    replacement:",
            "      description:",
            "      - The URL of the suggested replacement for a deprecated resource.",
            "      - The suggested replacement resource must be the same kind of resource as the",
            "        deprecated resource.",
            "      returned: success",
            "      type: str",
            "    state:",
            "      description:",
            "      - The deprecation state of this resource. This can be DEPRECATED, OBSOLETE,",
            "        or DELETED. Operations which create a new resource using a DEPRECATED resource",
            "        will return successfully, but with a warning indicating the deprecated resource",
            "        and recommending its replacement. Operations which use OBSOLETE or DELETED",
            "        resources will be rejected and result in an error.",
            "      returned: success",
            "      type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "diskSizeGb:",
            "  description:",
            "  - Size of the image when restored onto a persistent disk (in GB).",
            "  returned: success",
            "  type: int",
            "family:",
            "  description:",
            "  - The name of the image family to which this image belongs. You can create disks",
            "    by specifying an image family instead of a specific image name. The image family",
            "    always returns its latest image that is not deprecated. The name of the image",
            "    family must comply with RFC1035.",
            "  returned: success",
            "  type: str",
            "guestOsFeatures:",
            "  description:",
            "  - A list of features to enable on the guest OS. Applicable for bootable images only.",
            "    Currently, only one feature can be enabled, VIRTIO_SCSI_MULTIQUEUE, which allows",
            "    each virtual CPU to have its own queue. For Windows images, you can only enable",
            "    VIRTIO_SCSI_MULTIQUEUE on images with driver version 1.2.0.1621 or higher. Linux",
            "    images with kernel versions 3.17 and higher will support VIRTIO_SCSI_MULTIQUEUE.",
            "  - For new Windows images, the server might also populate this field with the value",
            "    WINDOWS, to indicate that this is a Windows image.",
            "  - This value is purely informational and does not enable or disable any features.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    type:",
            "      description:",
            "      - The type of supported feature. Currenty only VIRTIO_SCSI_MULTIQUEUE is supported.",
            "        For newer Windows images, the server might also populate this property with",
            "        the value WINDOWS to indicate that this is a Windows image. This value is",
            "        purely informational and does not enable or disable any features.",
            "      returned: success",
            "      type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "imageEncryptionKey:",
            "  description:",
            "  - Encrypts the image using a customer-supplied encryption key.",
            "  - After you encrypt an image with a customer-supplied key, you must provide the",
            "    same key if you use the image later (e.g. to create a disk from the image) .",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this Image.",
            "  returned: success",
            "  type: dict",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "licenses:",
            "  description:",
            "  - Any applicable license URI.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource; provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "rawDisk:",
            "  description:",
            "  - The parameters of the raw disk image.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    containerType:",
            "      description:",
            "      - The format used to encode and transmit the block device, which should be TAR.",
            "        This is just a container and transmission format and not a runtime format.",
            "        Provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    sha1Checksum:",
            "      description:",
            "      - An optional SHA1 checksum of the disk image before unpackaging.",
            "      - This is provided by the client when the disk image is created.",
            "      returned: success",
            "      type: str",
            "    source:",
            "      description:",
            "      - The full Google Cloud Storage URL where disk storage is stored You must provide",
            "        either this property or the sourceDisk property but not both.",
            "      returned: success",
            "      type: str",
            "sourceDisk:",
            "  description:",
            "  - The source disk to create this image based on.",
            "  - You must provide either this property or the rawDisk.source property but not both",
            "    to create an image.",
            "  returned: success",
            "  type: dict",
            "sourceDiskEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source disk. Required if the source",
            "    disk is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceDiskId:",
            "  description:",
            "  - The ID value of the disk used to create this image. This value may be used to",
            "    determine whether the image was taken from the current or a previous instance",
            "    of a given disk name.",
            "  returned: success",
            "  type: str",
            "sourceType:",
            "  description:",
            "  - The type of the image used to create this disk. The default and only value is",
            "    RAW .",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            disk_size_gb=dict(type='int'),",
            "            family=dict(type='str'),",
            "            guest_os_features=dict(type='list', elements='dict', options=dict(type=dict(type='str', choices=['VIRTIO_SCSI_MULTIQUEUE']))),",
            "            image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            raw_disk=dict(",
            "                type='dict',",
            "                options=dict(container_type=dict(type='str', choices=['TAR']), sha1_checksum=dict(type='str'), source=dict(required=True, type='str')),",
            "            ),",
            "            source_disk=dict(type='dict'),",
            "            source_disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "            source_disk_id=dict(type='str'),",
            "            source_type=dict(type='str', choices=['RAW']),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#image'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        labels_update(module, request, response)",
            "",
            "",
            "def labels_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/global/images/{name}/setLabels\"]).format(**module.params),",
            "        {u'labels': module.params.get('labels'), u'labelFingerprint': response.get('labelFingerprint')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#image',",
            "        u'description': module.params.get('description'),",
            "        u'diskSizeGb': module.params.get('disk_size_gb'),",
            "        u'family': module.params.get('family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(module.params.get('guest_os_features', []), module).to_request(),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(module.params.get('image_encryption_key', {}), module).to_request(),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'rawDisk': ImageRawdisk(module.params.get('raw_disk', {}), module).to_request(),",
            "        u'sourceDisk': replace_resource_dict(module.params.get(u'source_disk', {}), 'selfLink'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(module.params.get('source_disk_encryption_key', {}), module).to_request(),",
            "        u'sourceDiskId': module.params.get('source_disk_id'),",
            "        u'sourceType': module.params.get('source_type'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/images\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'archiveSizeBytes': response.get(u'archiveSizeBytes'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'deprecated': ImageDeprecated(response.get(u'deprecated', {}), module).from_response(),",
            "        u'description': response.get(u'description'),",
            "        u'diskSizeGb': response.get(u'diskSizeGb'),",
            "        u'family': response.get(u'family'),",
            "        u'guestOsFeatures': ImageGuestosfeaturesArray(response.get(u'guestOsFeatures', []), module).from_response(),",
            "        u'id': response.get(u'id'),",
            "        u'imageEncryptionKey': ImageImageencryptionkey(response.get(u'imageEncryptionKey', {}), module).from_response(),",
            "        u'labels': response.get(u'labels'),",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': response.get(u'name'),",
            "        u'rawDisk': ImageRawdisk(response.get(u'rawDisk', {}), module).from_response(),",
            "        u'sourceDisk': response.get(u'sourceDisk'),",
            "        u'sourceDiskEncryptionKey': ImageSourcediskencryptionkey(response.get(u'sourceDiskEncryptionKey', {}), module).from_response(),",
            "        u'sourceDiskId': response.get(u'sourceDiskId'),",
            "        u'sourceType': response.get(u'sourceType'),",
            "    }",
            "",
            "",
            "def license_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1//projects/.*/global/licenses/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1//projects/{project}/global/licenses/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#image')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class ImageDeprecated(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get('deleted'),",
            "                u'deprecated': self.request.get('deprecated'),",
            "                u'obsolete': self.request.get('obsolete'),",
            "                u'replacement': self.request.get('replacement'),",
            "                u'state': self.request.get('state'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'deleted': self.request.get(u'deleted'),",
            "                u'deprecated': self.request.get(u'deprecated'),",
            "                u'obsolete': self.request.get(u'obsolete'),",
            "                u'replacement': self.request.get(u'replacement'),",
            "                u'state': self.request.get(u'state'),",
            "            }",
            "        )",
            "",
            "",
            "class ImageGuestosfeaturesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'type': item.get(u'type')})",
            "",
            "",
            "class ImageImageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class ImageRawdisk(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get('container_type'), u'sha1Checksum': self.request.get('sha1_checksum'), u'source': self.request.get('source')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'containerType': self.request.get(u'containerType'), u'sha1Checksum': self.request.get(u'sha1Checksum'), u'source': self.request.get(u'source')}",
            "        )",
            "",
            "",
            "class ImageSourcediskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "447": [
                "main"
            ],
            "456": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_instance_template.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 863,
                "afterPatchRowNumber": 863,
                "PatchRowcode": "                             auto_delete=dict(type='bool'),"
            },
            "1": {
                "beforePatchRowNumber": 864,
                "afterPatchRowNumber": 864,
                "PatchRowcode": "                             boot=dict(type='bool'),"
            },
            "2": {
                "beforePatchRowNumber": 865,
                "afterPatchRowNumber": 865,
                "PatchRowcode": "                             device_name=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 866,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), rsa_encrypted_key=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 866,
                "PatchRowcode": "+                            disk_encryption_key=dict("
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 867,
                "PatchRowcode": "+                                type='dict',"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 868,
                "PatchRowcode": "+                                options=dict("
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 869,
                "PatchRowcode": "+                                    raw_key=dict(type='str', no_log=True),"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 870,
                "PatchRowcode": "+                                    rsa_encrypted_key=dict(type='str', no_log=True),"
            },
            "9": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 871,
                "PatchRowcode": "+                                ),"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 872,
                "PatchRowcode": "+                            ),"
            },
            "11": {
                "beforePatchRowNumber": 867,
                "afterPatchRowNumber": 873,
                "PatchRowcode": "                             index=dict(type='int'),"
            },
            "12": {
                "beforePatchRowNumber": 868,
                "afterPatchRowNumber": 874,
                "PatchRowcode": "                             initialize_params=dict("
            },
            "13": {
                "beforePatchRowNumber": 869,
                "afterPatchRowNumber": 875,
                "PatchRowcode": "                                 type='dict',"
            },
            "14": {
                "beforePatchRowNumber": 872,
                "afterPatchRowNumber": 878,
                "PatchRowcode": "                                     disk_size_gb=dict(type='int'),"
            },
            "15": {
                "beforePatchRowNumber": 873,
                "afterPatchRowNumber": 879,
                "PatchRowcode": "                                     disk_type=dict(type='str'),"
            },
            "16": {
                "beforePatchRowNumber": 874,
                "afterPatchRowNumber": 880,
                "PatchRowcode": "                                     source_image=dict(type='str'),"
            },
            "17": {
                "beforePatchRowNumber": 875,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 881,
                "PatchRowcode": "+                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "19": {
                "beforePatchRowNumber": 876,
                "afterPatchRowNumber": 882,
                "PatchRowcode": "                                 ),"
            },
            "20": {
                "beforePatchRowNumber": 877,
                "afterPatchRowNumber": 883,
                "PatchRowcode": "                             ),"
            },
            "21": {
                "beforePatchRowNumber": 878,
                "afterPatchRowNumber": 884,
                "PatchRowcode": "                             interface=dict(type='str', choices=['SCSI', 'NVME']),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_instance_template",
            "description:",
            "- Defines an Instance Template resource that provides configuration settings for your",
            "  virtual machine instances. Instance templates are not tied to the lifetime of an",
            "  instance and can be used and reused as to deploy virtual machines. You can also",
            "  use different templates to create different virtual machine configurations. Instance",
            "  templates are required when you create a managed instance group.",
            "- 'Tip: Disks should be set to autoDelete=true so that leftover disks are not left",
            "  behind on machine deletion.'",
            "short_description: Creates a GCP InstanceTemplate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "    required: true",
            "  properties:",
            "    description:",
            "    - The instance properties for this instance template.",
            "    required: false",
            "    suboptions:",
            "      can_ip_forward:",
            "        description:",
            "        - Enables instances created based on this template to send packets with source",
            "          IP addresses other than their own and receive packets with destination IP",
            "          addresses other than their own. If these instances will be used as an IP",
            "          gateway or it will be set as the next-hop in a Route resource, specify true.",
            "          If unsure, leave this set to false.",
            "        required: false",
            "        type: bool",
            "      description:",
            "        description:",
            "        - An optional text description for the instances that are created from this",
            "          instance template.",
            "        required: false",
            "      disks:",
            "        description:",
            "        - An array of disks that are associated with the instances that are created",
            "          from this template.",
            "        required: false",
            "        suboptions:",
            "          auto_delete:",
            "            description:",
            "            - Specifies whether the disk will be auto-deleted when the instance is",
            "              deleted (but not when the disk is detached from the instance).",
            "            - 'Tip: Disks should be set to autoDelete=true so that leftover disks",
            "              are not left behind on machine deletion.'",
            "            required: false",
            "            type: bool",
            "          boot:",
            "            description:",
            "            - Indicates that this is a boot disk. The virtual machine will use the",
            "              first partition of the disk for its root filesystem.",
            "            required: false",
            "            type: bool",
            "          device_name:",
            "            description:",
            "            - Specifies a unique device name of your choice that is reflected into",
            "              the /dev/disk/by-id/google-* tree of a Linux operating system running",
            "              within the instance. This name can be used to reference the device for",
            "              mounting, resizing, and so on, from within the instance.",
            "            required: false",
            "          disk_encryption_key:",
            "            description:",
            "            - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "            required: false",
            "            suboptions:",
            "              raw_key:",
            "                description:",
            "                - Specifies a 256-bit customer-supplied encryption key, encoded in",
            "                  RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                required: false",
            "              rsa_encrypted_key:",
            "                description:",
            "                - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                  encryption key to either encrypt or decrypt this resource.",
            "                required: false",
            "          index:",
            "            description:",
            "            - Assigns a zero-based index to this disk, where 0 is reserved for the",
            "              boot disk. For example, if you have many disks attached to an instance,",
            "              each disk would have a unique index number. If not specified, the server",
            "              will choose an appropriate value.",
            "            required: false",
            "          initialize_params:",
            "            description:",
            "            - Specifies the parameters for a new disk that will be created alongside",
            "              the new instance. Use initialization parameters to create boot disks",
            "              or local SSDs attached to the new instance.",
            "            required: false",
            "            suboptions:",
            "              disk_name:",
            "                description:",
            "                - Specifies the disk name. If not specified, the default is to use",
            "                  the name of the instance.",
            "                required: false",
            "              disk_size_gb:",
            "                description:",
            "                - Specifies the size of the disk in base-2 GB.",
            "                required: false",
            "              disk_type:",
            "                description:",
            "                - Reference to a disk type.",
            "                - Specifies the disk type to use to create the instance.",
            "                - If not specified, the default is pd-standard.",
            "                required: false",
            "              source_image:",
            "                description:",
            "                - The source image to create this disk. When creating a new instance,",
            "                  one of initializeParams.sourceImage or disks.source is required.",
            "                  To create a disk with one of the public operating system images,",
            "                  specify the image by its family name.",
            "                required: false",
            "              source_image_encryption_key:",
            "                description:",
            "                - The customer-supplied encryption key of the source image. Required",
            "                  if the source image is protected by a customer-supplied encryption",
            "                  key.",
            "                - Instance templates do not store customer-supplied encryption keys,",
            "                  so you cannot create disks for instances in a managed instance group",
            "                  if the source images are encrypted with your own keys.",
            "                required: false",
            "                suboptions:",
            "                  raw_key:",
            "                    description:",
            "                    - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                      in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                    required: false",
            "          interface:",
            "            description:",
            "            - Specifies the disk interface to use for attaching this disk, which is",
            "              either SCSI or NVME. The default is SCSI.",
            "            - Persistent disks must always use SCSI and the request will fail if you",
            "              attempt to attach a persistent disk in any other format than SCSI.",
            "            required: false",
            "            choices:",
            "            - SCSI",
            "            - NVME",
            "          mode:",
            "            description:",
            "            - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "              If not specified, the default is to attach the disk in READ_WRITE mode.",
            "            required: false",
            "            choices:",
            "            - READ_WRITE",
            "            - READ_ONLY",
            "          source:",
            "            description:",
            "            - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "              or disks.source is required.",
            "            - If desired, you can also attach existing non-root persistent disks using",
            "              this property. This field is only applicable for persistent disks.",
            "            - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "              the disk.",
            "            - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "              in two ways. First, you can place a dictionary with key ''name'' and",
            "              value of your resource''s name Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_disk task and then set this source",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "          type:",
            "            description:",
            "            - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not",
            "              specified, the default is PERSISTENT.",
            "            required: false",
            "            choices:",
            "            - SCRATCH",
            "            - PERSISTENT",
            "      machine_type:",
            "        description:",
            "        - The machine type to use in the VM instance template.",
            "        required: true",
            "      min_cpu_platform:",
            "        description:",
            "        - Specifies a minimum CPU platform for the VM instance. Applicable values",
            "          are the friendly names of CPU platforms .",
            "        required: false",
            "      metadata:",
            "        description:",
            "        - The metadata key/value pairs to assign to instances that are created from",
            "          this template. These pairs can consist of custom metadata or predefined",
            "          keys.",
            "        required: false",
            "      guest_accelerators:",
            "        description:",
            "        - List of the type and count of accelerator cards attached to the instance",
            "          .",
            "        required: false",
            "        suboptions:",
            "          accelerator_count:",
            "            description:",
            "            - The number of the guest accelerator cards exposed to this instance.",
            "            required: false",
            "          accelerator_type:",
            "            description:",
            "            - Full or partial URL of the accelerator type resource to expose to this",
            "              instance.",
            "            required: false",
            "      network_interfaces:",
            "        description:",
            "        - An array of configurations for this interface. This specifies how this interface",
            "          is configured to interact with other network services, such as connecting",
            "          to the internet. Only one network interface is supported per instance.",
            "        required: false",
            "        suboptions:",
            "          access_configs:",
            "            description:",
            "            - An array of configurations for this interface. Currently, only one access",
            "              config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs",
            "              specified, then this instance will have no external internet access.",
            "            required: false",
            "            suboptions:",
            "              name:",
            "                description:",
            "                - The name of this access configuration. The default and recommended",
            "                  name is External NAT but you can use any arbitrary string you would",
            "                  like. For example, My external IP or Network Access.",
            "                required: true",
            "              nat_ip:",
            "                description:",
            "                - Reference to an address.",
            "                - An external IP address associated with this instance.",
            "                - Specify an unused static external IP address available to the project",
            "                  or leave this field undefined to use an IP from a shared ephemeral",
            "                  IP address pool. If you specify a static external IP address, it",
            "                  must live in the same region as the zone of the instance.",
            "                - 'This field represents a link to a Address resource in GCP. It can",
            "                  be specified in two ways. First, you can place a dictionary with",
            "                  key ''address'' and value of your resource''s address Alternatively,",
            "                  you can add `register: name-of-resource` to a gcp_compute_address",
            "                  task and then set this nat_ip field to \"{{ name-of-resource }}\"'",
            "                required: false",
            "              type:",
            "                description:",
            "                - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "                required: true",
            "                choices:",
            "                - ONE_TO_ONE_NAT",
            "          alias_ip_ranges:",
            "            description:",
            "            - An array of alias IP ranges for this network interface. Can only be",
            "              specified for network interfaces on subnet-mode networks.",
            "            required: false",
            "            suboptions:",
            "              ip_cidr_range:",
            "                description:",
            "                - The IP CIDR range represented by this alias IP range.",
            "                - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                  contain IP addresses reserved by system or used by other network",
            "                  interfaces. This range may be a single IP address (e.g. 10.2.3.4),",
            "                  a netmask (e.g. /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "                required: false",
            "              subnetwork_range_name:",
            "                description:",
            "                - Optional subnetwork secondary range name specifying the secondary",
            "                  range from which to allocate the IP CIDR range for this alias IP",
            "                  range. If left unspecified, the primary range of the subnetwork",
            "                  will be used.",
            "                required: false",
            "          network:",
            "            description:",
            "            - Specifies the title of an existing network. When creating an instance,",
            "              if neither the network nor the subnetwork is specified, the default",
            "              network global/networks/default is used; if the network is not specified",
            "              but the subnetwork is specified, the network is inferred.",
            "            - 'This field represents a link to a Network resource in GCP. It can be",
            "              specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "              and value of your resource''s selfLink Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_network task and then set this network",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "          network_ip:",
            "            description:",
            "            - An IPv4 internal network address to assign to the instance for this",
            "              network interface. If not specified by the user, an unused internal",
            "              IP is assigned by the system.",
            "            required: false",
            "          subnetwork:",
            "            description:",
            "            - Reference to a VPC network.",
            "            - If the network resource is in legacy mode, do not provide this property.",
            "              If the network is in auto subnet mode, providing the subnetwork is optional.",
            "              If the network is in custom subnet mode, then this field should be specified.",
            "            - 'This field represents a link to a Subnetwork resource in GCP. It can",
            "              be specified in two ways. First, you can place a dictionary with key",
            "              ''selfLink'' and value of your resource''s selfLink Alternatively, you",
            "              can add `register: name-of-resource` to a gcp_compute_subnetwork task",
            "              and then set this subnetwork field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "      scheduling:",
            "        description:",
            "        - Sets the scheduling options for this instance.",
            "        required: false",
            "        suboptions:",
            "          automatic_restart:",
            "            description:",
            "            - Specifies whether the instance should be automatically restarted if",
            "              it is terminated by Compute Engine (not terminated by a user).",
            "            - You can only set the automatic restart option for standard instances.",
            "              Preemptible instances cannot be automatically restarted.",
            "            required: false",
            "            type: bool",
            "          on_host_maintenance:",
            "            description:",
            "            - Defines the maintenance behavior for this instance. For standard instances,",
            "              the default behavior is MIGRATE. For preemptible instances, the default",
            "              and only possible behavior is TERMINATE.",
            "            - For more information, see Setting Instance Scheduling Options.",
            "            required: false",
            "          preemptible:",
            "            description:",
            "            - Defines whether the instance is preemptible. This can only be set during",
            "              instance creation, it cannot be set or changed after the instance has",
            "              been created.",
            "            required: false",
            "            type: bool",
            "      service_accounts:",
            "        description:",
            "        - A list of service accounts, with their specified scopes, authorized for",
            "          this instance. Only one service account per VM instance is supported.",
            "        required: false",
            "        suboptions:",
            "          email:",
            "            description:",
            "            - Email address of the service account.",
            "            required: false",
            "          scopes:",
            "            description:",
            "            - The list of scopes to be made available for this service account.",
            "            required: false",
            "      tags:",
            "        description:",
            "        - A list of tags to apply to this instance. Tags are used to identify valid",
            "          sources or targets for network firewalls and are specified by the client",
            "          during instance creation. The tags can be later modified by the setTags",
            "          method. Each tag within the list must comply with RFC1035.",
            "        required: false",
            "        suboptions:",
            "          fingerprint:",
            "            description:",
            "            - Specifies a fingerprint for this request, which is essentially a hash",
            "              of the metadata's contents and used for optimistic locking.",
            "            - The fingerprint is initially generated by Compute Engine and changes",
            "              after every request to modify or update metadata. You must always provide",
            "              an up-to-date fingerprint hash in order to update or change metadata.",
            "            required: false",
            "          items:",
            "            description:",
            "            - An array of tags. Each tag must be 1-63 characters long, and comply",
            "              with RFC1035.",
            "            required: false",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-instancetemplate",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a address",
            "  gcp_compute_address:",
            "    name: address-instancetemplate",
            "    region: us-west1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: address",
            "",
            "- name: create a instance template",
            "  gcp_compute_instance_template:",
            "    name: test_object",
            "    properties:",
            "      disks:",
            "      - auto_delete: 'true'",
            "        boot: 'true'",
            "        initialize_params:",
            "          source_image: projects/ubuntu-os-cloud/global/images/family/ubuntu-1604-lts",
            "      machine_type: n1-standard-1",
            "      network_interfaces:",
            "      - network: \"{{ network }}\"",
            "        access_configs:",
            "        - name: test-config",
            "          type: ONE_TO_ONE_NAT",
            "          nat_ip: \"{{ address }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "  returned: success",
            "  type: str",
            "properties:",
            "  description:",
            "  - The instance properties for this instance template.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    canIpForward:",
            "      description:",
            "      - Enables instances created based on this template to send packets with source",
            "        IP addresses other than their own and receive packets with destination IP",
            "        addresses other than their own. If these instances will be used as an IP gateway",
            "        or it will be set as the next-hop in a Route resource, specify true. If unsure,",
            "        leave this set to false.",
            "      returned: success",
            "      type: bool",
            "    description:",
            "      description:",
            "      - An optional text description for the instances that are created from this",
            "        instance template.",
            "      returned: success",
            "      type: str",
            "    disks:",
            "      description:",
            "      - An array of disks that are associated with the instances that are created",
            "        from this template.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        autoDelete:",
            "          description:",
            "          - Specifies whether the disk will be auto-deleted when the instance is deleted",
            "            (but not when the disk is detached from the instance).",
            "          - 'Tip: Disks should be set to autoDelete=true so that leftover disks are",
            "            not left behind on machine deletion.'",
            "          returned: success",
            "          type: bool",
            "        boot:",
            "          description:",
            "          - Indicates that this is a boot disk. The virtual machine will use the first",
            "            partition of the disk for its root filesystem.",
            "          returned: success",
            "          type: bool",
            "        deviceName:",
            "          description:",
            "          - Specifies a unique device name of your choice that is reflected into the",
            "            /dev/disk/by-id/google-* tree of a Linux operating system running within",
            "            the instance. This name can be used to reference the device for mounting,",
            "            resizing, and so on, from within the instance.",
            "          returned: success",
            "          type: str",
            "        diskEncryptionKey:",
            "          description:",
            "          - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            rawKey:",
            "              description:",
            "              - Specifies a 256-bit customer-supplied encryption key, encoded in RFC",
            "                4648 base64 to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            rsaEncryptedKey:",
            "              description:",
            "              - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                encryption key to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            sha256:",
            "              description:",
            "              - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                encryption key that protects this resource.",
            "              returned: success",
            "              type: str",
            "        index:",
            "          description:",
            "          - Assigns a zero-based index to this disk, where 0 is reserved for the boot",
            "            disk. For example, if you have many disks attached to an instance, each",
            "            disk would have a unique index number. If not specified, the server will",
            "            choose an appropriate value.",
            "          returned: success",
            "          type: int",
            "        initializeParams:",
            "          description:",
            "          - Specifies the parameters for a new disk that will be created alongside",
            "            the new instance. Use initialization parameters to create boot disks or",
            "            local SSDs attached to the new instance.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            diskName:",
            "              description:",
            "              - Specifies the disk name. If not specified, the default is to use the",
            "                name of the instance.",
            "              returned: success",
            "              type: str",
            "            diskSizeGb:",
            "              description:",
            "              - Specifies the size of the disk in base-2 GB.",
            "              returned: success",
            "              type: int",
            "            diskType:",
            "              description:",
            "              - Reference to a disk type.",
            "              - Specifies the disk type to use to create the instance.",
            "              - If not specified, the default is pd-standard.",
            "              returned: success",
            "              type: str",
            "            sourceImage:",
            "              description:",
            "              - The source image to create this disk. When creating a new instance,",
            "                one of initializeParams.sourceImage or disks.source is required. To",
            "                create a disk with one of the public operating system images, specify",
            "                the image by its family name.",
            "              returned: success",
            "              type: str",
            "            sourceImageEncryptionKey:",
            "              description:",
            "              - The customer-supplied encryption key of the source image. Required",
            "                if the source image is protected by a customer-supplied encryption",
            "                key.",
            "              - Instance templates do not store customer-supplied encryption keys,",
            "                so you cannot create disks for instances in a managed instance group",
            "                if the source images are encrypted with your own keys.",
            "              returned: success",
            "              type: complex",
            "              contains:",
            "                rawKey:",
            "                  description:",
            "                  - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                    in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                  returned: success",
            "                  type: str",
            "                sha256:",
            "                  description:",
            "                  - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                    encryption key that protects this resource.",
            "                  returned: success",
            "                  type: str",
            "        interface:",
            "          description:",
            "          - Specifies the disk interface to use for attaching this disk, which is",
            "            either SCSI or NVME. The default is SCSI.",
            "          - Persistent disks must always use SCSI and the request will fail if you",
            "            attempt to attach a persistent disk in any other format than SCSI.",
            "          returned: success",
            "          type: str",
            "        mode:",
            "          description:",
            "          - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "            If not specified, the default is to attach the disk in READ_WRITE mode.",
            "          returned: success",
            "          type: str",
            "        source:",
            "          description:",
            "          - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "            or disks.source is required.",
            "          - If desired, you can also attach existing non-root persistent disks using",
            "            this property. This field is only applicable for persistent disks.",
            "          - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "            the disk.",
            "          returned: success",
            "          type: dict",
            "        type:",
            "          description:",
            "          - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not specified,",
            "            the default is PERSISTENT.",
            "          returned: success",
            "          type: str",
            "    machineType:",
            "      description:",
            "      - The machine type to use in the VM instance template.",
            "      returned: success",
            "      type: str",
            "    minCpuPlatform:",
            "      description:",
            "      - Specifies a minimum CPU platform for the VM instance. Applicable values are",
            "        the friendly names of CPU platforms .",
            "      returned: success",
            "      type: str",
            "    metadata:",
            "      description:",
            "      - The metadata key/value pairs to assign to instances that are created from",
            "        this template. These pairs can consist of custom metadata or predefined keys.",
            "      returned: success",
            "      type: dict",
            "    guestAccelerators:",
            "      description:",
            "      - List of the type and count of accelerator cards attached to the instance .",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        acceleratorCount:",
            "          description:",
            "          - The number of the guest accelerator cards exposed to this instance.",
            "          returned: success",
            "          type: int",
            "        acceleratorType:",
            "          description:",
            "          - Full or partial URL of the accelerator type resource to expose to this",
            "            instance.",
            "          returned: success",
            "          type: str",
            "    networkInterfaces:",
            "      description:",
            "      - An array of configurations for this interface. This specifies how this interface",
            "        is configured to interact with other network services, such as connecting",
            "        to the internet. Only one network interface is supported per instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        accessConfigs:",
            "          description:",
            "          - An array of configurations for this interface. Currently, only one access",
            "            config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs specified,",
            "            then this instance will have no external internet access.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            name:",
            "              description:",
            "              - The name of this access configuration. The default and recommended",
            "                name is External NAT but you can use any arbitrary string you would",
            "                like. For example, My external IP or Network Access.",
            "              returned: success",
            "              type: str",
            "            natIP:",
            "              description:",
            "              - Reference to an address.",
            "              - An external IP address associated with this instance.",
            "              - Specify an unused static external IP address available to the project",
            "                or leave this field undefined to use an IP from a shared ephemeral",
            "                IP address pool. If you specify a static external IP address, it must",
            "                live in the same region as the zone of the instance.",
            "              returned: success",
            "              type: dict",
            "            type:",
            "              description:",
            "              - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "              returned: success",
            "              type: str",
            "        aliasIpRanges:",
            "          description:",
            "          - An array of alias IP ranges for this network interface. Can only be specified",
            "            for network interfaces on subnet-mode networks.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            ipCidrRange:",
            "              description:",
            "              - The IP CIDR range represented by this alias IP range.",
            "              - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                contain IP addresses reserved by system or used by other network interfaces.",
            "                This range may be a single IP address (e.g. 10.2.3.4), a netmask (e.g.",
            "                /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "              returned: success",
            "              type: str",
            "            subnetworkRangeName:",
            "              description:",
            "              - Optional subnetwork secondary range name specifying the secondary",
            "                range from which to allocate the IP CIDR range for this alias IP range.",
            "                If left unspecified, the primary range of the subnetwork will be used.",
            "              returned: success",
            "              type: str",
            "        name:",
            "          description:",
            "          - The name of the network interface, generated by the server. For network",
            "            devices, these are eth0, eth1, etc .",
            "          returned: success",
            "          type: str",
            "        network:",
            "          description:",
            "          - Specifies the title of an existing network. When creating an instance,",
            "            if neither the network nor the subnetwork is specified, the default network",
            "            global/networks/default is used; if the network is not specified but the",
            "            subnetwork is specified, the network is inferred.",
            "          returned: success",
            "          type: dict",
            "        networkIP:",
            "          description:",
            "          - An IPv4 internal network address to assign to the instance for this network",
            "            interface. If not specified by the user, an unused internal IP is assigned",
            "            by the system.",
            "          returned: success",
            "          type: str",
            "        subnetwork:",
            "          description:",
            "          - Reference to a VPC network.",
            "          - If the network resource is in legacy mode, do not provide this property.",
            "            If the network is in auto subnet mode, providing the subnetwork is optional.",
            "            If the network is in custom subnet mode, then this field should be specified.",
            "          returned: success",
            "          type: dict",
            "    scheduling:",
            "      description:",
            "      - Sets the scheduling options for this instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        automaticRestart:",
            "          description:",
            "          - Specifies whether the instance should be automatically restarted if it",
            "            is terminated by Compute Engine (not terminated by a user).",
            "          - You can only set the automatic restart option for standard instances.",
            "            Preemptible instances cannot be automatically restarted.",
            "          returned: success",
            "          type: bool",
            "        onHostMaintenance:",
            "          description:",
            "          - Defines the maintenance behavior for this instance. For standard instances,",
            "            the default behavior is MIGRATE. For preemptible instances, the default",
            "            and only possible behavior is TERMINATE.",
            "          - For more information, see Setting Instance Scheduling Options.",
            "          returned: success",
            "          type: str",
            "        preemptible:",
            "          description:",
            "          - Defines whether the instance is preemptible. This can only be set during",
            "            instance creation, it cannot be set or changed after the instance has",
            "            been created.",
            "          returned: success",
            "          type: bool",
            "    serviceAccounts:",
            "      description:",
            "      - A list of service accounts, with their specified scopes, authorized for this",
            "        instance. Only one service account per VM instance is supported.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        email:",
            "          description:",
            "          - Email address of the service account.",
            "          returned: success",
            "          type: str",
            "        scopes:",
            "          description:",
            "          - The list of scopes to be made available for this service account.",
            "          returned: success",
            "          type: list",
            "    tags:",
            "      description:",
            "      - A list of tags to apply to this instance. Tags are used to identify valid",
            "        sources or targets for network firewalls and are specified by the client during",
            "        instance creation. The tags can be later modified by the setTags method. Each",
            "        tag within the list must comply with RFC1035.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        fingerprint:",
            "          description:",
            "          - Specifies a fingerprint for this request, which is essentially a hash",
            "            of the metadata's contents and used for optimistic locking.",
            "          - The fingerprint is initially generated by Compute Engine and changes after",
            "            every request to modify or update metadata. You must always provide an",
            "            up-to-date fingerprint hash in order to update or change metadata.",
            "          returned: success",
            "          type: str",
            "        items:",
            "          description:",
            "          - An array of tags. Each tag must be 1-63 characters long, and comply with",
            "            RFC1035.",
            "          returned: success",
            "          type: list",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(required=True, type='str'),",
            "            properties=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    can_ip_forward=dict(type='bool'),",
            "                    description=dict(type='str'),",
            "                    disks=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            auto_delete=dict(type='bool'),",
            "                            boot=dict(type='bool'),",
            "                            device_name=dict(type='str'),",
            "                            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'), rsa_encrypted_key=dict(type='str'))),",
            "                            index=dict(type='int'),",
            "                            initialize_params=dict(",
            "                                type='dict',",
            "                                options=dict(",
            "                                    disk_name=dict(type='str'),",
            "                                    disk_size_gb=dict(type='int'),",
            "                                    disk_type=dict(type='str'),",
            "                                    source_image=dict(type='str'),",
            "                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "                                ),",
            "                            ),",
            "                            interface=dict(type='str', choices=['SCSI', 'NVME']),",
            "                            mode=dict(type='str', choices=['READ_WRITE', 'READ_ONLY']),",
            "                            source=dict(type='dict'),",
            "                            type=dict(type='str', choices=['SCRATCH', 'PERSISTENT']),",
            "                        ),",
            "                    ),",
            "                    machine_type=dict(required=True, type='str'),",
            "                    min_cpu_platform=dict(type='str'),",
            "                    metadata=dict(type='dict'),",
            "                    guest_accelerators=dict(type='list', elements='dict', options=dict(accelerator_count=dict(type='int'), accelerator_type=dict(type='str'))),",
            "                    network_interfaces=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            access_configs=dict(",
            "                                type='list',",
            "                                elements='dict',",
            "                                options=dict(",
            "                                    name=dict(required=True, type='str'),",
            "                                    nat_ip=dict(type='dict'),",
            "                                    type=dict(required=True, type='str', choices=['ONE_TO_ONE_NAT']),",
            "                                ),",
            "                            ),",
            "                            alias_ip_ranges=dict(",
            "                                type='list', elements='dict', options=dict(ip_cidr_range=dict(type='str'), subnetwork_range_name=dict(type='str'))",
            "                            ),",
            "                            network=dict(type='dict'),",
            "                            network_ip=dict(type='str'),",
            "                            subnetwork=dict(type='dict'),",
            "                        ),",
            "                    ),",
            "                    scheduling=dict(",
            "                        type='dict', options=dict(automatic_restart=dict(type='bool'), on_host_maintenance=dict(type='str'), preemptible=dict(type='bool'))",
            "                    ),",
            "                    service_accounts=dict(type='list', elements='dict', options=dict(email=dict(type='str'), scopes=dict(type='list', elements='str'))),",
            "                    tags=dict(type='dict', options=dict(fingerprint=dict(type='str'), items=dict(type='list', elements='str'))),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#instanceTemplate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    module.fail_json(msg=\"InstanceTemplate cannot be edited\")",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#instanceTemplate',",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'properties': InstanceTemplateProperties(module.params.get('properties', {}), module).to_request(),",
            "    }",
            "    request = encode_request(request, module)",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    result = decode_response(result, module)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "    request = decode_response(request, module)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'properties': InstanceTemplateProperties(response.get(u'properties', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/[a-z1-9\\-]*/diskTypes/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#instanceTemplate')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "def encode_request(request, module):",
            "    if 'metadata' in request and request['metadata'] is not None:",
            "        request['metadata'] = metadata_encoder(request['metadata'])",
            "    return request",
            "",
            "",
            "def decode_response(response, module):",
            "    if 'metadata' in response and response['metadata'] is not None:",
            "        response['metadata'] = metadata_decoder(response['metadata'])",
            "    return response",
            "",
            "",
            "# TODO(alexstephen): Implement updating metadata on existing resources.",
            "",
            "# Expose instance 'metadata' as a simple name/value pair hash. However the API",
            "# defines metadata as a NestedObject with the following layout:",
            "#",
            "# metadata {",
            "#   fingerprint: 'hash-of-last-metadata'",
            "#   items: [",
            "#     {",
            "#       key: 'metadata1-key'",
            "#       value: 'metadata1-value'",
            "#     },",
            "#     ...",
            "#   ]",
            "# }",
            "#",
            "def metadata_encoder(metadata):",
            "    metadata_new = []",
            "    for key in metadata:",
            "        value = metadata[key]",
            "        metadata_new.append({\"key\": key, \"value\": value})",
            "    return {'items': metadata_new}",
            "",
            "",
            "# Map metadata.items[]{key:,value:} => metadata[key]=value",
            "def metadata_decoder(metadata):",
            "    items = {}",
            "    if 'items' in metadata:",
            "        metadata_items = metadata['items']",
            "        for item in metadata_items:",
            "            items[item['key']] = item['value']",
            "    return items",
            "",
            "",
            "class InstanceTemplateProperties(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get('can_ip_forward'),",
            "                u'description': self.request.get('description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get('disks', []), self.module).to_request(),",
            "                u'machineType': self.request.get('machine_type'),",
            "                u'minCpuPlatform': self.request.get('min_cpu_platform'),",
            "                u'metadata': self.request.get('metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get('guest_accelerators', []), self.module).to_request(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get('network_interfaces', []), self.module).to_request(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get('scheduling', {}), self.module).to_request(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get('service_accounts', []), self.module).to_request(),",
            "                u'tags': InstanceTemplateTags(self.request.get('tags', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get(u'canIpForward'),",
            "                u'description': self.request.get(u'description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get(u'disks', []), self.module).from_response(),",
            "                u'machineType': self.request.get(u'machineType'),",
            "                u'minCpuPlatform': self.request.get(u'minCpuPlatform'),",
            "                u'metadata': self.request.get(u'metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get(u'guestAccelerators', []), self.module).from_response(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get(u'networkInterfaces', []), self.module).from_response(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get(u'scheduling', {}), self.module).from_response(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get(u'serviceAccounts', []), self.module).from_response(),",
            "                u'tags': InstanceTemplateTags(self.request.get(u'tags', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDisksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get('auto_delete'),",
            "                u'boot': item.get('boot'),",
            "                u'deviceName': item.get('device_name'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get('disk_encryption_key', {}), self.module).to_request(),",
            "                u'index': item.get('index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(item.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get('interface'),",
            "                u'mode': item.get('mode'),",
            "                u'source': replace_resource_dict(item.get(u'source', {}), 'name'),",
            "                u'type': item.get('type'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get(u'autoDelete'),",
            "                u'boot': item.get(u'boot'),",
            "                u'deviceName': item.get(u'deviceName'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get(u'diskEncryptionKey', {}), self.module).from_response(),",
            "                u'index': item.get(u'index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(self.module.params.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get(u'interface'),",
            "                u'mode': item.get(u'mode'),",
            "                u'source': item.get(u'source'),",
            "                u'type': item.get(u'type'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'rsaEncryptedKey': self.request.get('rsa_encrypted_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'rsaEncryptedKey': self.request.get(u'rsaEncryptedKey')})",
            "",
            "",
            "class InstanceTemplateInitializeparams(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get('disk_name'),",
            "                u'diskSizeGb': self.request.get('disk_size_gb'),",
            "                u'diskType': disk_type_selflink(self.request.get('disk_type'), self.module.params),",
            "                u'sourceImage': self.request.get('source_image'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get('source_image_encryption_key', {}), self.module",
            "                ).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get(u'diskName'),",
            "                u'diskSizeGb': self.request.get(u'diskSizeGb'),",
            "                u'diskType': self.request.get(u'diskType'),",
            "                u'sourceImage': self.request.get(u'sourceImage'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get(u'sourceImageEncryptionKey', {}), self.module",
            "                ).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class InstanceTemplateGuestacceleratorsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get('accelerator_count'), u'acceleratorType': item.get('accelerator_type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get(u'acceleratorCount'), u'acceleratorType': item.get(u'acceleratorType')})",
            "",
            "",
            "class InstanceTemplateNetworkinterfacesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get('access_configs', []), self.module).to_request(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get('alias_ip_ranges', []), self.module).to_request(),",
            "                u'network': replace_resource_dict(item.get(u'network', {}), 'selfLink'),",
            "                u'networkIP': item.get('network_ip'),",
            "                u'subnetwork': replace_resource_dict(item.get(u'subnetwork', {}), 'selfLink'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get(u'accessConfigs', []), self.module).from_response(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get(u'aliasIpRanges', []), self.module).from_response(),",
            "                u'network': item.get(u'network'),",
            "                u'networkIP': item.get(u'networkIP'),",
            "                u'subnetwork': item.get(u'subnetwork'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateAccessconfigsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {u'name': item.get('name'), u'natIP': replace_resource_dict(item.get(u'nat_ip', {}), 'address'), u'type': item.get('type')}",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get(u'name'), u'natIP': item.get(u'natIP'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceTemplateAliasiprangesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get('ip_cidr_range'), u'subnetworkRangeName': item.get('subnetwork_range_name')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get(u'ipCidrRange'), u'subnetworkRangeName': item.get(u'subnetworkRangeName')})",
            "",
            "",
            "class InstanceTemplateScheduling(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get('automatic_restart'),",
            "                u'onHostMaintenance': self.request.get('on_host_maintenance'),",
            "                u'preemptible': self.request.get('preemptible'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get(u'automaticRestart'),",
            "                u'onHostMaintenance': self.request.get(u'onHostMaintenance'),",
            "                u'preemptible': self.request.get(u'preemptible'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateServiceaccountsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get('email'), u'scopes': item.get('scopes')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get(u'email'), u'scopes': item.get(u'scopes')})",
            "",
            "",
            "class InstanceTemplateTags(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get('fingerprint'), u'items': self.request.get('items')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get(u'fingerprint'), u'items': self.request.get(u'items')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_instance_template",
            "description:",
            "- Defines an Instance Template resource that provides configuration settings for your",
            "  virtual machine instances. Instance templates are not tied to the lifetime of an",
            "  instance and can be used and reused as to deploy virtual machines. You can also",
            "  use different templates to create different virtual machine configurations. Instance",
            "  templates are required when you create a managed instance group.",
            "- 'Tip: Disks should be set to autoDelete=true so that leftover disks are not left",
            "  behind on machine deletion.'",
            "short_description: Creates a GCP InstanceTemplate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "    required: true",
            "  properties:",
            "    description:",
            "    - The instance properties for this instance template.",
            "    required: false",
            "    suboptions:",
            "      can_ip_forward:",
            "        description:",
            "        - Enables instances created based on this template to send packets with source",
            "          IP addresses other than their own and receive packets with destination IP",
            "          addresses other than their own. If these instances will be used as an IP",
            "          gateway or it will be set as the next-hop in a Route resource, specify true.",
            "          If unsure, leave this set to false.",
            "        required: false",
            "        type: bool",
            "      description:",
            "        description:",
            "        - An optional text description for the instances that are created from this",
            "          instance template.",
            "        required: false",
            "      disks:",
            "        description:",
            "        - An array of disks that are associated with the instances that are created",
            "          from this template.",
            "        required: false",
            "        suboptions:",
            "          auto_delete:",
            "            description:",
            "            - Specifies whether the disk will be auto-deleted when the instance is",
            "              deleted (but not when the disk is detached from the instance).",
            "            - 'Tip: Disks should be set to autoDelete=true so that leftover disks",
            "              are not left behind on machine deletion.'",
            "            required: false",
            "            type: bool",
            "          boot:",
            "            description:",
            "            - Indicates that this is a boot disk. The virtual machine will use the",
            "              first partition of the disk for its root filesystem.",
            "            required: false",
            "            type: bool",
            "          device_name:",
            "            description:",
            "            - Specifies a unique device name of your choice that is reflected into",
            "              the /dev/disk/by-id/google-* tree of a Linux operating system running",
            "              within the instance. This name can be used to reference the device for",
            "              mounting, resizing, and so on, from within the instance.",
            "            required: false",
            "          disk_encryption_key:",
            "            description:",
            "            - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "            required: false",
            "            suboptions:",
            "              raw_key:",
            "                description:",
            "                - Specifies a 256-bit customer-supplied encryption key, encoded in",
            "                  RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                required: false",
            "              rsa_encrypted_key:",
            "                description:",
            "                - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                  encryption key to either encrypt or decrypt this resource.",
            "                required: false",
            "          index:",
            "            description:",
            "            - Assigns a zero-based index to this disk, where 0 is reserved for the",
            "              boot disk. For example, if you have many disks attached to an instance,",
            "              each disk would have a unique index number. If not specified, the server",
            "              will choose an appropriate value.",
            "            required: false",
            "          initialize_params:",
            "            description:",
            "            - Specifies the parameters for a new disk that will be created alongside",
            "              the new instance. Use initialization parameters to create boot disks",
            "              or local SSDs attached to the new instance.",
            "            required: false",
            "            suboptions:",
            "              disk_name:",
            "                description:",
            "                - Specifies the disk name. If not specified, the default is to use",
            "                  the name of the instance.",
            "                required: false",
            "              disk_size_gb:",
            "                description:",
            "                - Specifies the size of the disk in base-2 GB.",
            "                required: false",
            "              disk_type:",
            "                description:",
            "                - Reference to a disk type.",
            "                - Specifies the disk type to use to create the instance.",
            "                - If not specified, the default is pd-standard.",
            "                required: false",
            "              source_image:",
            "                description:",
            "                - The source image to create this disk. When creating a new instance,",
            "                  one of initializeParams.sourceImage or disks.source is required.",
            "                  To create a disk with one of the public operating system images,",
            "                  specify the image by its family name.",
            "                required: false",
            "              source_image_encryption_key:",
            "                description:",
            "                - The customer-supplied encryption key of the source image. Required",
            "                  if the source image is protected by a customer-supplied encryption",
            "                  key.",
            "                - Instance templates do not store customer-supplied encryption keys,",
            "                  so you cannot create disks for instances in a managed instance group",
            "                  if the source images are encrypted with your own keys.",
            "                required: false",
            "                suboptions:",
            "                  raw_key:",
            "                    description:",
            "                    - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                      in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                    required: false",
            "          interface:",
            "            description:",
            "            - Specifies the disk interface to use for attaching this disk, which is",
            "              either SCSI or NVME. The default is SCSI.",
            "            - Persistent disks must always use SCSI and the request will fail if you",
            "              attempt to attach a persistent disk in any other format than SCSI.",
            "            required: false",
            "            choices:",
            "            - SCSI",
            "            - NVME",
            "          mode:",
            "            description:",
            "            - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "              If not specified, the default is to attach the disk in READ_WRITE mode.",
            "            required: false",
            "            choices:",
            "            - READ_WRITE",
            "            - READ_ONLY",
            "          source:",
            "            description:",
            "            - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "              or disks.source is required.",
            "            - If desired, you can also attach existing non-root persistent disks using",
            "              this property. This field is only applicable for persistent disks.",
            "            - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "              the disk.",
            "            - 'This field represents a link to a Disk resource in GCP. It can be specified",
            "              in two ways. First, you can place a dictionary with key ''name'' and",
            "              value of your resource''s name Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_disk task and then set this source",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "          type:",
            "            description:",
            "            - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not",
            "              specified, the default is PERSISTENT.",
            "            required: false",
            "            choices:",
            "            - SCRATCH",
            "            - PERSISTENT",
            "      machine_type:",
            "        description:",
            "        - The machine type to use in the VM instance template.",
            "        required: true",
            "      min_cpu_platform:",
            "        description:",
            "        - Specifies a minimum CPU platform for the VM instance. Applicable values",
            "          are the friendly names of CPU platforms .",
            "        required: false",
            "      metadata:",
            "        description:",
            "        - The metadata key/value pairs to assign to instances that are created from",
            "          this template. These pairs can consist of custom metadata or predefined",
            "          keys.",
            "        required: false",
            "      guest_accelerators:",
            "        description:",
            "        - List of the type and count of accelerator cards attached to the instance",
            "          .",
            "        required: false",
            "        suboptions:",
            "          accelerator_count:",
            "            description:",
            "            - The number of the guest accelerator cards exposed to this instance.",
            "            required: false",
            "          accelerator_type:",
            "            description:",
            "            - Full or partial URL of the accelerator type resource to expose to this",
            "              instance.",
            "            required: false",
            "      network_interfaces:",
            "        description:",
            "        - An array of configurations for this interface. This specifies how this interface",
            "          is configured to interact with other network services, such as connecting",
            "          to the internet. Only one network interface is supported per instance.",
            "        required: false",
            "        suboptions:",
            "          access_configs:",
            "            description:",
            "            - An array of configurations for this interface. Currently, only one access",
            "              config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs",
            "              specified, then this instance will have no external internet access.",
            "            required: false",
            "            suboptions:",
            "              name:",
            "                description:",
            "                - The name of this access configuration. The default and recommended",
            "                  name is External NAT but you can use any arbitrary string you would",
            "                  like. For example, My external IP or Network Access.",
            "                required: true",
            "              nat_ip:",
            "                description:",
            "                - Reference to an address.",
            "                - An external IP address associated with this instance.",
            "                - Specify an unused static external IP address available to the project",
            "                  or leave this field undefined to use an IP from a shared ephemeral",
            "                  IP address pool. If you specify a static external IP address, it",
            "                  must live in the same region as the zone of the instance.",
            "                - 'This field represents a link to a Address resource in GCP. It can",
            "                  be specified in two ways. First, you can place a dictionary with",
            "                  key ''address'' and value of your resource''s address Alternatively,",
            "                  you can add `register: name-of-resource` to a gcp_compute_address",
            "                  task and then set this nat_ip field to \"{{ name-of-resource }}\"'",
            "                required: false",
            "              type:",
            "                description:",
            "                - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "                required: true",
            "                choices:",
            "                - ONE_TO_ONE_NAT",
            "          alias_ip_ranges:",
            "            description:",
            "            - An array of alias IP ranges for this network interface. Can only be",
            "              specified for network interfaces on subnet-mode networks.",
            "            required: false",
            "            suboptions:",
            "              ip_cidr_range:",
            "                description:",
            "                - The IP CIDR range represented by this alias IP range.",
            "                - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                  contain IP addresses reserved by system or used by other network",
            "                  interfaces. This range may be a single IP address (e.g. 10.2.3.4),",
            "                  a netmask (e.g. /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "                required: false",
            "              subnetwork_range_name:",
            "                description:",
            "                - Optional subnetwork secondary range name specifying the secondary",
            "                  range from which to allocate the IP CIDR range for this alias IP",
            "                  range. If left unspecified, the primary range of the subnetwork",
            "                  will be used.",
            "                required: false",
            "          network:",
            "            description:",
            "            - Specifies the title of an existing network. When creating an instance,",
            "              if neither the network nor the subnetwork is specified, the default",
            "              network global/networks/default is used; if the network is not specified",
            "              but the subnetwork is specified, the network is inferred.",
            "            - 'This field represents a link to a Network resource in GCP. It can be",
            "              specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "              and value of your resource''s selfLink Alternatively, you can add `register:",
            "              name-of-resource` to a gcp_compute_network task and then set this network",
            "              field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "          network_ip:",
            "            description:",
            "            - An IPv4 internal network address to assign to the instance for this",
            "              network interface. If not specified by the user, an unused internal",
            "              IP is assigned by the system.",
            "            required: false",
            "          subnetwork:",
            "            description:",
            "            - Reference to a VPC network.",
            "            - If the network resource is in legacy mode, do not provide this property.",
            "              If the network is in auto subnet mode, providing the subnetwork is optional.",
            "              If the network is in custom subnet mode, then this field should be specified.",
            "            - 'This field represents a link to a Subnetwork resource in GCP. It can",
            "              be specified in two ways. First, you can place a dictionary with key",
            "              ''selfLink'' and value of your resource''s selfLink Alternatively, you",
            "              can add `register: name-of-resource` to a gcp_compute_subnetwork task",
            "              and then set this subnetwork field to \"{{ name-of-resource }}\"'",
            "            required: false",
            "      scheduling:",
            "        description:",
            "        - Sets the scheduling options for this instance.",
            "        required: false",
            "        suboptions:",
            "          automatic_restart:",
            "            description:",
            "            - Specifies whether the instance should be automatically restarted if",
            "              it is terminated by Compute Engine (not terminated by a user).",
            "            - You can only set the automatic restart option for standard instances.",
            "              Preemptible instances cannot be automatically restarted.",
            "            required: false",
            "            type: bool",
            "          on_host_maintenance:",
            "            description:",
            "            - Defines the maintenance behavior for this instance. For standard instances,",
            "              the default behavior is MIGRATE. For preemptible instances, the default",
            "              and only possible behavior is TERMINATE.",
            "            - For more information, see Setting Instance Scheduling Options.",
            "            required: false",
            "          preemptible:",
            "            description:",
            "            - Defines whether the instance is preemptible. This can only be set during",
            "              instance creation, it cannot be set or changed after the instance has",
            "              been created.",
            "            required: false",
            "            type: bool",
            "      service_accounts:",
            "        description:",
            "        - A list of service accounts, with their specified scopes, authorized for",
            "          this instance. Only one service account per VM instance is supported.",
            "        required: false",
            "        suboptions:",
            "          email:",
            "            description:",
            "            - Email address of the service account.",
            "            required: false",
            "          scopes:",
            "            description:",
            "            - The list of scopes to be made available for this service account.",
            "            required: false",
            "      tags:",
            "        description:",
            "        - A list of tags to apply to this instance. Tags are used to identify valid",
            "          sources or targets for network firewalls and are specified by the client",
            "          during instance creation. The tags can be later modified by the setTags",
            "          method. Each tag within the list must comply with RFC1035.",
            "        required: false",
            "        suboptions:",
            "          fingerprint:",
            "            description:",
            "            - Specifies a fingerprint for this request, which is essentially a hash",
            "              of the metadata's contents and used for optimistic locking.",
            "            - The fingerprint is initially generated by Compute Engine and changes",
            "              after every request to modify or update metadata. You must always provide",
            "              an up-to-date fingerprint hash in order to update or change metadata.",
            "            required: false",
            "          items:",
            "            description:",
            "            - An array of tags. Each tag must be 1-63 characters long, and comply",
            "              with RFC1035.",
            "            required: false",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-instancetemplate",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a address",
            "  gcp_compute_address:",
            "    name: address-instancetemplate",
            "    region: us-west1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: address",
            "",
            "- name: create a instance template",
            "  gcp_compute_instance_template:",
            "    name: test_object",
            "    properties:",
            "      disks:",
            "      - auto_delete: 'true'",
            "        boot: 'true'",
            "        initialize_params:",
            "          source_image: projects/ubuntu-os-cloud/global/images/family/ubuntu-1604-lts",
            "      machine_type: n1-standard-1",
            "      network_interfaces:",
            "      - network: \"{{ network }}\"",
            "        access_configs:",
            "        - name: test-config",
            "          type: ONE_TO_ONE_NAT",
            "          nat_ip: \"{{ address }}\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource. This identifier is defined by the server.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. The name is 1-63 characters long and complies with RFC1035.",
            "  returned: success",
            "  type: str",
            "properties:",
            "  description:",
            "  - The instance properties for this instance template.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    canIpForward:",
            "      description:",
            "      - Enables instances created based on this template to send packets with source",
            "        IP addresses other than their own and receive packets with destination IP",
            "        addresses other than their own. If these instances will be used as an IP gateway",
            "        or it will be set as the next-hop in a Route resource, specify true. If unsure,",
            "        leave this set to false.",
            "      returned: success",
            "      type: bool",
            "    description:",
            "      description:",
            "      - An optional text description for the instances that are created from this",
            "        instance template.",
            "      returned: success",
            "      type: str",
            "    disks:",
            "      description:",
            "      - An array of disks that are associated with the instances that are created",
            "        from this template.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        autoDelete:",
            "          description:",
            "          - Specifies whether the disk will be auto-deleted when the instance is deleted",
            "            (but not when the disk is detached from the instance).",
            "          - 'Tip: Disks should be set to autoDelete=true so that leftover disks are",
            "            not left behind on machine deletion.'",
            "          returned: success",
            "          type: bool",
            "        boot:",
            "          description:",
            "          - Indicates that this is a boot disk. The virtual machine will use the first",
            "            partition of the disk for its root filesystem.",
            "          returned: success",
            "          type: bool",
            "        deviceName:",
            "          description:",
            "          - Specifies a unique device name of your choice that is reflected into the",
            "            /dev/disk/by-id/google-* tree of a Linux operating system running within",
            "            the instance. This name can be used to reference the device for mounting,",
            "            resizing, and so on, from within the instance.",
            "          returned: success",
            "          type: str",
            "        diskEncryptionKey:",
            "          description:",
            "          - Encrypts or decrypts a disk using a customer-supplied encryption key.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            rawKey:",
            "              description:",
            "              - Specifies a 256-bit customer-supplied encryption key, encoded in RFC",
            "                4648 base64 to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            rsaEncryptedKey:",
            "              description:",
            "              - Specifies an RFC 4648 base64 encoded, RSA-wrapped 2048-bit customer-supplied",
            "                encryption key to either encrypt or decrypt this resource.",
            "              returned: success",
            "              type: str",
            "            sha256:",
            "              description:",
            "              - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                encryption key that protects this resource.",
            "              returned: success",
            "              type: str",
            "        index:",
            "          description:",
            "          - Assigns a zero-based index to this disk, where 0 is reserved for the boot",
            "            disk. For example, if you have many disks attached to an instance, each",
            "            disk would have a unique index number. If not specified, the server will",
            "            choose an appropriate value.",
            "          returned: success",
            "          type: int",
            "        initializeParams:",
            "          description:",
            "          - Specifies the parameters for a new disk that will be created alongside",
            "            the new instance. Use initialization parameters to create boot disks or",
            "            local SSDs attached to the new instance.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            diskName:",
            "              description:",
            "              - Specifies the disk name. If not specified, the default is to use the",
            "                name of the instance.",
            "              returned: success",
            "              type: str",
            "            diskSizeGb:",
            "              description:",
            "              - Specifies the size of the disk in base-2 GB.",
            "              returned: success",
            "              type: int",
            "            diskType:",
            "              description:",
            "              - Reference to a disk type.",
            "              - Specifies the disk type to use to create the instance.",
            "              - If not specified, the default is pd-standard.",
            "              returned: success",
            "              type: str",
            "            sourceImage:",
            "              description:",
            "              - The source image to create this disk. When creating a new instance,",
            "                one of initializeParams.sourceImage or disks.source is required. To",
            "                create a disk with one of the public operating system images, specify",
            "                the image by its family name.",
            "              returned: success",
            "              type: str",
            "            sourceImageEncryptionKey:",
            "              description:",
            "              - The customer-supplied encryption key of the source image. Required",
            "                if the source image is protected by a customer-supplied encryption",
            "                key.",
            "              - Instance templates do not store customer-supplied encryption keys,",
            "                so you cannot create disks for instances in a managed instance group",
            "                if the source images are encrypted with your own keys.",
            "              returned: success",
            "              type: complex",
            "              contains:",
            "                rawKey:",
            "                  description:",
            "                  - Specifies a 256-bit customer-supplied encryption key, encoded",
            "                    in RFC 4648 base64 to either encrypt or decrypt this resource.",
            "                  returned: success",
            "                  type: str",
            "                sha256:",
            "                  description:",
            "                  - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied",
            "                    encryption key that protects this resource.",
            "                  returned: success",
            "                  type: str",
            "        interface:",
            "          description:",
            "          - Specifies the disk interface to use for attaching this disk, which is",
            "            either SCSI or NVME. The default is SCSI.",
            "          - Persistent disks must always use SCSI and the request will fail if you",
            "            attempt to attach a persistent disk in any other format than SCSI.",
            "          returned: success",
            "          type: str",
            "        mode:",
            "          description:",
            "          - The mode in which to attach this disk, either READ_WRITE or READ_ONLY.",
            "            If not specified, the default is to attach the disk in READ_WRITE mode.",
            "          returned: success",
            "          type: str",
            "        source:",
            "          description:",
            "          - Reference to a disk. When creating a new instance, one of initializeParams.sourceImage",
            "            or disks.source is required.",
            "          - If desired, you can also attach existing non-root persistent disks using",
            "            this property. This field is only applicable for persistent disks.",
            "          - Note that for InstanceTemplate, specify the disk name, not the URL for",
            "            the disk.",
            "          returned: success",
            "          type: dict",
            "        type:",
            "          description:",
            "          - Specifies the type of the disk, either SCRATCH or PERSISTENT. If not specified,",
            "            the default is PERSISTENT.",
            "          returned: success",
            "          type: str",
            "    machineType:",
            "      description:",
            "      - The machine type to use in the VM instance template.",
            "      returned: success",
            "      type: str",
            "    minCpuPlatform:",
            "      description:",
            "      - Specifies a minimum CPU platform for the VM instance. Applicable values are",
            "        the friendly names of CPU platforms .",
            "      returned: success",
            "      type: str",
            "    metadata:",
            "      description:",
            "      - The metadata key/value pairs to assign to instances that are created from",
            "        this template. These pairs can consist of custom metadata or predefined keys.",
            "      returned: success",
            "      type: dict",
            "    guestAccelerators:",
            "      description:",
            "      - List of the type and count of accelerator cards attached to the instance .",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        acceleratorCount:",
            "          description:",
            "          - The number of the guest accelerator cards exposed to this instance.",
            "          returned: success",
            "          type: int",
            "        acceleratorType:",
            "          description:",
            "          - Full or partial URL of the accelerator type resource to expose to this",
            "            instance.",
            "          returned: success",
            "          type: str",
            "    networkInterfaces:",
            "      description:",
            "      - An array of configurations for this interface. This specifies how this interface",
            "        is configured to interact with other network services, such as connecting",
            "        to the internet. Only one network interface is supported per instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        accessConfigs:",
            "          description:",
            "          - An array of configurations for this interface. Currently, only one access",
            "            config, ONE_TO_ONE_NAT, is supported. If there are no accessConfigs specified,",
            "            then this instance will have no external internet access.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            name:",
            "              description:",
            "              - The name of this access configuration. The default and recommended",
            "                name is External NAT but you can use any arbitrary string you would",
            "                like. For example, My external IP or Network Access.",
            "              returned: success",
            "              type: str",
            "            natIP:",
            "              description:",
            "              - Reference to an address.",
            "              - An external IP address associated with this instance.",
            "              - Specify an unused static external IP address available to the project",
            "                or leave this field undefined to use an IP from a shared ephemeral",
            "                IP address pool. If you specify a static external IP address, it must",
            "                live in the same region as the zone of the instance.",
            "              returned: success",
            "              type: dict",
            "            type:",
            "              description:",
            "              - The type of configuration. The default and only option is ONE_TO_ONE_NAT.",
            "              returned: success",
            "              type: str",
            "        aliasIpRanges:",
            "          description:",
            "          - An array of alias IP ranges for this network interface. Can only be specified",
            "            for network interfaces on subnet-mode networks.",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            ipCidrRange:",
            "              description:",
            "              - The IP CIDR range represented by this alias IP range.",
            "              - This IP CIDR range must belong to the specified subnetwork and cannot",
            "                contain IP addresses reserved by system or used by other network interfaces.",
            "                This range may be a single IP address (e.g. 10.2.3.4), a netmask (e.g.",
            "                /24) or a CIDR format string (e.g. 10.1.2.0/24).",
            "              returned: success",
            "              type: str",
            "            subnetworkRangeName:",
            "              description:",
            "              - Optional subnetwork secondary range name specifying the secondary",
            "                range from which to allocate the IP CIDR range for this alias IP range.",
            "                If left unspecified, the primary range of the subnetwork will be used.",
            "              returned: success",
            "              type: str",
            "        name:",
            "          description:",
            "          - The name of the network interface, generated by the server. For network",
            "            devices, these are eth0, eth1, etc .",
            "          returned: success",
            "          type: str",
            "        network:",
            "          description:",
            "          - Specifies the title of an existing network. When creating an instance,",
            "            if neither the network nor the subnetwork is specified, the default network",
            "            global/networks/default is used; if the network is not specified but the",
            "            subnetwork is specified, the network is inferred.",
            "          returned: success",
            "          type: dict",
            "        networkIP:",
            "          description:",
            "          - An IPv4 internal network address to assign to the instance for this network",
            "            interface. If not specified by the user, an unused internal IP is assigned",
            "            by the system.",
            "          returned: success",
            "          type: str",
            "        subnetwork:",
            "          description:",
            "          - Reference to a VPC network.",
            "          - If the network resource is in legacy mode, do not provide this property.",
            "            If the network is in auto subnet mode, providing the subnetwork is optional.",
            "            If the network is in custom subnet mode, then this field should be specified.",
            "          returned: success",
            "          type: dict",
            "    scheduling:",
            "      description:",
            "      - Sets the scheduling options for this instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        automaticRestart:",
            "          description:",
            "          - Specifies whether the instance should be automatically restarted if it",
            "            is terminated by Compute Engine (not terminated by a user).",
            "          - You can only set the automatic restart option for standard instances.",
            "            Preemptible instances cannot be automatically restarted.",
            "          returned: success",
            "          type: bool",
            "        onHostMaintenance:",
            "          description:",
            "          - Defines the maintenance behavior for this instance. For standard instances,",
            "            the default behavior is MIGRATE. For preemptible instances, the default",
            "            and only possible behavior is TERMINATE.",
            "          - For more information, see Setting Instance Scheduling Options.",
            "          returned: success",
            "          type: str",
            "        preemptible:",
            "          description:",
            "          - Defines whether the instance is preemptible. This can only be set during",
            "            instance creation, it cannot be set or changed after the instance has",
            "            been created.",
            "          returned: success",
            "          type: bool",
            "    serviceAccounts:",
            "      description:",
            "      - A list of service accounts, with their specified scopes, authorized for this",
            "        instance. Only one service account per VM instance is supported.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        email:",
            "          description:",
            "          - Email address of the service account.",
            "          returned: success",
            "          type: str",
            "        scopes:",
            "          description:",
            "          - The list of scopes to be made available for this service account.",
            "          returned: success",
            "          type: list",
            "    tags:",
            "      description:",
            "      - A list of tags to apply to this instance. Tags are used to identify valid",
            "        sources or targets for network firewalls and are specified by the client during",
            "        instance creation. The tags can be later modified by the setTags method. Each",
            "        tag within the list must comply with RFC1035.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        fingerprint:",
            "          description:",
            "          - Specifies a fingerprint for this request, which is essentially a hash",
            "            of the metadata's contents and used for optimistic locking.",
            "          - The fingerprint is initially generated by Compute Engine and changes after",
            "            every request to modify or update metadata. You must always provide an",
            "            up-to-date fingerprint hash in order to update or change metadata.",
            "          returned: success",
            "          type: str",
            "        items:",
            "          description:",
            "          - An array of tags. Each tag must be 1-63 characters long, and comply with",
            "            RFC1035.",
            "          returned: success",
            "          type: list",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(required=True, type='str'),",
            "            properties=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    can_ip_forward=dict(type='bool'),",
            "                    description=dict(type='str'),",
            "                    disks=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            auto_delete=dict(type='bool'),",
            "                            boot=dict(type='bool'),",
            "                            device_name=dict(type='str'),",
            "                            disk_encryption_key=dict(",
            "                                type='dict',",
            "                                options=dict(",
            "                                    raw_key=dict(type='str', no_log=True),",
            "                                    rsa_encrypted_key=dict(type='str', no_log=True),",
            "                                ),",
            "                            ),",
            "                            index=dict(type='int'),",
            "                            initialize_params=dict(",
            "                                type='dict',",
            "                                options=dict(",
            "                                    disk_name=dict(type='str'),",
            "                                    disk_size_gb=dict(type='int'),",
            "                                    disk_type=dict(type='str'),",
            "                                    source_image=dict(type='str'),",
            "                                    source_image_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "                                ),",
            "                            ),",
            "                            interface=dict(type='str', choices=['SCSI', 'NVME']),",
            "                            mode=dict(type='str', choices=['READ_WRITE', 'READ_ONLY']),",
            "                            source=dict(type='dict'),",
            "                            type=dict(type='str', choices=['SCRATCH', 'PERSISTENT']),",
            "                        ),",
            "                    ),",
            "                    machine_type=dict(required=True, type='str'),",
            "                    min_cpu_platform=dict(type='str'),",
            "                    metadata=dict(type='dict'),",
            "                    guest_accelerators=dict(type='list', elements='dict', options=dict(accelerator_count=dict(type='int'), accelerator_type=dict(type='str'))),",
            "                    network_interfaces=dict(",
            "                        type='list',",
            "                        elements='dict',",
            "                        options=dict(",
            "                            access_configs=dict(",
            "                                type='list',",
            "                                elements='dict',",
            "                                options=dict(",
            "                                    name=dict(required=True, type='str'),",
            "                                    nat_ip=dict(type='dict'),",
            "                                    type=dict(required=True, type='str', choices=['ONE_TO_ONE_NAT']),",
            "                                ),",
            "                            ),",
            "                            alias_ip_ranges=dict(",
            "                                type='list', elements='dict', options=dict(ip_cidr_range=dict(type='str'), subnetwork_range_name=dict(type='str'))",
            "                            ),",
            "                            network=dict(type='dict'),",
            "                            network_ip=dict(type='str'),",
            "                            subnetwork=dict(type='dict'),",
            "                        ),",
            "                    ),",
            "                    scheduling=dict(",
            "                        type='dict', options=dict(automatic_restart=dict(type='bool'), on_host_maintenance=dict(type='str'), preemptible=dict(type='bool'))",
            "                    ),",
            "                    service_accounts=dict(type='list', elements='dict', options=dict(email=dict(type='str'), scopes=dict(type='list', elements='str'))),",
            "                    tags=dict(type='dict', options=dict(fingerprint=dict(type='str'), items=dict(type='list', elements='str'))),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#instanceTemplate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    module.fail_json(msg=\"InstanceTemplate cannot be edited\")",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#instanceTemplate',",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'properties': InstanceTemplateProperties(module.params.get('properties', {}), module).to_request(),",
            "    }",
            "    request = encode_request(request, module)",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/instanceTemplates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    result = decode_response(result, module)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "    request = decode_response(request, module)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'properties': InstanceTemplateProperties(response.get(u'properties', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/[a-z1-9\\-]*/diskTypes/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/{zone}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#instanceTemplate')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "def encode_request(request, module):",
            "    if 'metadata' in request and request['metadata'] is not None:",
            "        request['metadata'] = metadata_encoder(request['metadata'])",
            "    return request",
            "",
            "",
            "def decode_response(response, module):",
            "    if 'metadata' in response and response['metadata'] is not None:",
            "        response['metadata'] = metadata_decoder(response['metadata'])",
            "    return response",
            "",
            "",
            "# TODO(alexstephen): Implement updating metadata on existing resources.",
            "",
            "# Expose instance 'metadata' as a simple name/value pair hash. However the API",
            "# defines metadata as a NestedObject with the following layout:",
            "#",
            "# metadata {",
            "#   fingerprint: 'hash-of-last-metadata'",
            "#   items: [",
            "#     {",
            "#       key: 'metadata1-key'",
            "#       value: 'metadata1-value'",
            "#     },",
            "#     ...",
            "#   ]",
            "# }",
            "#",
            "def metadata_encoder(metadata):",
            "    metadata_new = []",
            "    for key in metadata:",
            "        value = metadata[key]",
            "        metadata_new.append({\"key\": key, \"value\": value})",
            "    return {'items': metadata_new}",
            "",
            "",
            "# Map metadata.items[]{key:,value:} => metadata[key]=value",
            "def metadata_decoder(metadata):",
            "    items = {}",
            "    if 'items' in metadata:",
            "        metadata_items = metadata['items']",
            "        for item in metadata_items:",
            "            items[item['key']] = item['value']",
            "    return items",
            "",
            "",
            "class InstanceTemplateProperties(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get('can_ip_forward'),",
            "                u'description': self.request.get('description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get('disks', []), self.module).to_request(),",
            "                u'machineType': self.request.get('machine_type'),",
            "                u'minCpuPlatform': self.request.get('min_cpu_platform'),",
            "                u'metadata': self.request.get('metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get('guest_accelerators', []), self.module).to_request(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get('network_interfaces', []), self.module).to_request(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get('scheduling', {}), self.module).to_request(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get('service_accounts', []), self.module).to_request(),",
            "                u'tags': InstanceTemplateTags(self.request.get('tags', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'canIpForward': self.request.get(u'canIpForward'),",
            "                u'description': self.request.get(u'description'),",
            "                u'disks': InstanceTemplateDisksArray(self.request.get(u'disks', []), self.module).from_response(),",
            "                u'machineType': self.request.get(u'machineType'),",
            "                u'minCpuPlatform': self.request.get(u'minCpuPlatform'),",
            "                u'metadata': self.request.get(u'metadata'),",
            "                u'guestAccelerators': InstanceTemplateGuestacceleratorsArray(self.request.get(u'guestAccelerators', []), self.module).from_response(),",
            "                u'networkInterfaces': InstanceTemplateNetworkinterfacesArray(self.request.get(u'networkInterfaces', []), self.module).from_response(),",
            "                u'scheduling': InstanceTemplateScheduling(self.request.get(u'scheduling', {}), self.module).from_response(),",
            "                u'serviceAccounts': InstanceTemplateServiceaccountsArray(self.request.get(u'serviceAccounts', []), self.module).from_response(),",
            "                u'tags': InstanceTemplateTags(self.request.get(u'tags', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDisksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get('auto_delete'),",
            "                u'boot': item.get('boot'),",
            "                u'deviceName': item.get('device_name'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get('disk_encryption_key', {}), self.module).to_request(),",
            "                u'index': item.get('index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(item.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get('interface'),",
            "                u'mode': item.get('mode'),",
            "                u'source': replace_resource_dict(item.get(u'source', {}), 'name'),",
            "                u'type': item.get('type'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'autoDelete': item.get(u'autoDelete'),",
            "                u'boot': item.get(u'boot'),",
            "                u'deviceName': item.get(u'deviceName'),",
            "                u'diskEncryptionKey': InstanceTemplateDiskencryptionkey(item.get(u'diskEncryptionKey', {}), self.module).from_response(),",
            "                u'index': item.get(u'index'),",
            "                u'initializeParams': InstanceTemplateInitializeparams(self.module.params.get('initialize_params', {}), self.module).to_request(),",
            "                u'interface': item.get(u'interface'),",
            "                u'mode': item.get(u'mode'),",
            "                u'source': item.get(u'source'),",
            "                u'type': item.get(u'type'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key'), u'rsaEncryptedKey': self.request.get('rsa_encrypted_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey'), u'rsaEncryptedKey': self.request.get(u'rsaEncryptedKey')})",
            "",
            "",
            "class InstanceTemplateInitializeparams(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get('disk_name'),",
            "                u'diskSizeGb': self.request.get('disk_size_gb'),",
            "                u'diskType': disk_type_selflink(self.request.get('disk_type'), self.module.params),",
            "                u'sourceImage': self.request.get('source_image'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get('source_image_encryption_key', {}), self.module",
            "                ).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'diskName': self.request.get(u'diskName'),",
            "                u'diskSizeGb': self.request.get(u'diskSizeGb'),",
            "                u'diskType': self.request.get(u'diskType'),",
            "                u'sourceImage': self.request.get(u'sourceImage'),",
            "                u'sourceImageEncryptionKey': InstanceTemplateSourceimageencryptionkey(",
            "                    self.request.get(u'sourceImageEncryptionKey', {}), self.module",
            "                ).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateSourceimageencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class InstanceTemplateGuestacceleratorsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get('accelerator_count'), u'acceleratorType': item.get('accelerator_type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'acceleratorCount': item.get(u'acceleratorCount'), u'acceleratorType': item.get(u'acceleratorType')})",
            "",
            "",
            "class InstanceTemplateNetworkinterfacesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get('access_configs', []), self.module).to_request(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get('alias_ip_ranges', []), self.module).to_request(),",
            "                u'network': replace_resource_dict(item.get(u'network', {}), 'selfLink'),",
            "                u'networkIP': item.get('network_ip'),",
            "                u'subnetwork': replace_resource_dict(item.get(u'subnetwork', {}), 'selfLink'),",
            "            }",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'accessConfigs': InstanceTemplateAccessconfigsArray(item.get(u'accessConfigs', []), self.module).from_response(),",
            "                u'aliasIpRanges': InstanceTemplateAliasiprangesArray(item.get(u'aliasIpRanges', []), self.module).from_response(),",
            "                u'network': item.get(u'network'),",
            "                u'networkIP': item.get(u'networkIP'),",
            "                u'subnetwork': item.get(u'subnetwork'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateAccessconfigsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict(",
            "            {u'name': item.get('name'), u'natIP': replace_resource_dict(item.get(u'nat_ip', {}), 'address'), u'type': item.get('type')}",
            "        )",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'name': item.get(u'name'), u'natIP': item.get(u'natIP'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceTemplateAliasiprangesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get('ip_cidr_range'), u'subnetworkRangeName': item.get('subnetwork_range_name')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipCidrRange': item.get(u'ipCidrRange'), u'subnetworkRangeName': item.get(u'subnetworkRangeName')})",
            "",
            "",
            "class InstanceTemplateScheduling(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get('automatic_restart'),",
            "                u'onHostMaintenance': self.request.get('on_host_maintenance'),",
            "                u'preemptible': self.request.get('preemptible'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'automaticRestart': self.request.get(u'automaticRestart'),",
            "                u'onHostMaintenance': self.request.get(u'onHostMaintenance'),",
            "                u'preemptible': self.request.get(u'preemptible'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceTemplateServiceaccountsArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get('email'), u'scopes': item.get('scopes')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'email': item.get(u'email'), u'scopes': item.get(u'scopes')})",
            "",
            "",
            "class InstanceTemplateTags(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get('fingerprint'), u'items': self.request.get('items')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'fingerprint': self.request.get(u'fingerprint'), u'items': self.request.get(u'items')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "866": [
                "main"
            ],
            "875": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_region_disk.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": 354,
                "PatchRowcode": "             replica_zones=dict(required=True, type='list', elements='str'),"
            },
            "1": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": 355,
                "PatchRowcode": "             type=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": 356,
                "PatchRowcode": "             region=dict(required=True, type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 357,
                "PatchRowcode": "+            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "5": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": 358,
                "PatchRowcode": "             source_snapshot=dict(type='dict'),"
            },
            "6": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 359,
                "PatchRowcode": "+            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),"
            },
            "8": {
                "beforePatchRowNumber": 360,
                "afterPatchRowNumber": 360,
                "PatchRowcode": "         )"
            },
            "9": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": 361,
                "PatchRowcode": "     )"
            },
            "10": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": 362,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_region_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP RegionDisk",
            "version_added: 2.8",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "  replica_zones:",
            "    description:",
            "    - URLs of the zones where the disk should be replicated to.",
            "    required: true",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "  region:",
            "    description:",
            "    - A reference to the region where the disk resides.",
            "    required: true",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/beta/regionDisks)'",
            "- 'Adding or Resizing Regional Persistent Disks: U(https://cloud.google.com/compute/docs/disks/regional-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a region disk",
            "  gcp_compute_region_disk:",
            "    name: test_object",
            "    size_gb: 50",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    region: us-central1",
            "    replica_zones:",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-a",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-b",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last dettach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "replicaZones:",
            "  description:",
            "  - URLs of the zones where the disk should be replicated to.",
            "  returned: success",
            "  type: list",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - A reference to the region where the disk resides.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            replica_zones=dict(required=True, type='list', elements='str'),",
            "            type=dict(type='str'),",
            "            region=dict(required=True, type='str'),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str'))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'diskEncryptionKey': RegionDiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': RegionDiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'replicaZones': module.params.get('replica_zones'),",
            "        u'type': region_disk_type_selflink(module.params.get('type'), module.params),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'replicaZones': response.get(u'replicaZones'),",
            "        u'type': response.get(u'type'),",
            "    }",
            "",
            "",
            "def zone_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def region_disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/regions/{region}/diskTypes/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class RegionDiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class RegionDiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_region_disk",
            "description:",
            "- Persistent disks are durable storage devices that function similarly to the physical",
            "  disks in a desktop or a server. Compute Engine manages the hardware behind these",
            "  devices to ensure data redundancy and optimize performance for you. Persistent disks",
            "  are available as either standard hard disk drives (HDD) or solid-state drives (SSD).",
            "- Persistent disks are located independently from your virtual machine instances,",
            "  so you can detach or move persistent disks to keep your data even after you delete",
            "  your instances. Persistent disk performance scales automatically with size, so you",
            "  can resize your existing persistent disks or add more persistent disks to an instance",
            "  to meet your performance and storage space requirements.",
            "- Add a persistent disk to your instance when you need reliable and affordable storage",
            "  with consistent performance characteristics.",
            "short_description: Creates a GCP RegionDisk",
            "version_added: 2.8",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  description:",
            "    description:",
            "    - An optional description of this resource. Provide this property when you create",
            "      the resource.",
            "    required: false",
            "  labels:",
            "    description:",
            "    - Labels to apply to this disk. A list of key->value pairs.",
            "    required: false",
            "  licenses:",
            "    description:",
            "    - Any applicable publicly visible licenses.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: true",
            "  size_gb:",
            "    description:",
            "    - Size of the persistent disk, specified in GB. You can specify this field when",
            "      creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "      or specify it alone to create an empty persistent disk.",
            "    - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "      of sizeGb must not be less than the size of the sourceImage or the size of the",
            "      snapshot.",
            "    required: false",
            "  physical_block_size_bytes:",
            "    description:",
            "    - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "      a default value is used. Currently supported sizes are 4096 and 16384, other",
            "      sizes may be added in the future.",
            "    - If an unsupported value is requested, the error message will list the supported",
            "      values for the caller's project.",
            "    required: false",
            "  replica_zones:",
            "    description:",
            "    - URLs of the zones where the disk should be replicated to.",
            "    required: true",
            "  type:",
            "    description:",
            "    - URL of the disk type resource describing which disk type to use to create the",
            "      disk. Provide this when creating the disk.",
            "    required: false",
            "  region:",
            "    description:",
            "    - A reference to the region where the disk resides.",
            "    required: true",
            "  disk_encryption_key:",
            "    description:",
            "    - Encrypts the disk using a customer-supplied encryption key.",
            "    - After you encrypt a disk with a customer-supplied key, you must provide the",
            "      same key if you use the disk later (e.g. to create a disk snapshot or an image,",
            "      or to attach the disk to a virtual machine).",
            "    - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "    - If you do not provide an encryption key when creating the disk, then the disk",
            "      will be encrypted using an automatically generated key and you do not need to",
            "      provide a key to use the disk later.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "  source_snapshot:",
            "    description:",
            "    - The source snapshot used to create this disk. You can provide this as a partial",
            "      or full URL to the resource.",
            "    - 'This field represents a link to a Snapshot resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_snapshot task and then set this source_snapshot field to \"{{",
            "      name-of-resource }}\"'",
            "    required: false",
            "  source_snapshot_encryption_key:",
            "    description:",
            "    - The customer-supplied encryption key of the source snapshot. Required if the",
            "      source snapshot is protected by a customer-supplied encryption key.",
            "    required: false",
            "    suboptions:",
            "      raw_key:",
            "        description:",
            "        - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "          base64 to either encrypt or decrypt this resource.",
            "        required: false",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/beta/regionDisks)'",
            "- 'Adding or Resizing Regional Persistent Disks: U(https://cloud.google.com/compute/docs/disks/regional-persistent-disk)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a region disk",
            "  gcp_compute_region_disk:",
            "    name: test_object",
            "    size_gb: 50",
            "    disk_encryption_key:",
            "      raw_key: SGVsbG8gZnJvbSBHb29nbGUgQ2xvdWQgUGxhdGZvcm0=",
            "    region: us-central1",
            "    replica_zones:",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-a",
            "    - https://www.googleapis.com/compute/v1/projects/google.com:graphite-playground/zones/us-central1-b",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "labelFingerprint:",
            "  description:",
            "  - The fingerprint used for optimistic locking of this resource. Used internally",
            "    during updates.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource. Provide this property when you create",
            "    the resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "lastAttachTimestamp:",
            "  description:",
            "  - Last attach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "lastDetachTimestamp:",
            "  description:",
            "  - Last dettach timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "labels:",
            "  description:",
            "  - Labels to apply to this disk. A list of key->value pairs.",
            "  returned: success",
            "  type: dict",
            "licenses:",
            "  description:",
            "  - Any applicable publicly visible licenses.",
            "  returned: success",
            "  type: list",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "sizeGb:",
            "  description:",
            "  - Size of the persistent disk, specified in GB. You can specify this field when",
            "    creating a persistent disk using the sourceImage or sourceSnapshot parameter,",
            "    or specify it alone to create an empty persistent disk.",
            "  - If you specify this field along with sourceImage or sourceSnapshot, the value",
            "    of sizeGb must not be less than the size of the sourceImage or the size of the",
            "    snapshot.",
            "  returned: success",
            "  type: int",
            "users:",
            "  description:",
            "  - 'Links to the users of the disk (attached instances) in form: project/zones/zone/instances/instance",
            "    .'",
            "  returned: success",
            "  type: list",
            "physicalBlockSizeBytes:",
            "  description:",
            "  - Physical block size of the persistent disk, in bytes. If not present in a request,",
            "    a default value is used. Currently supported sizes are 4096 and 16384, other sizes",
            "    may be added in the future.",
            "  - If an unsupported value is requested, the error message will list the supported",
            "    values for the caller's project.",
            "  returned: success",
            "  type: int",
            "replicaZones:",
            "  description:",
            "  - URLs of the zones where the disk should be replicated to.",
            "  returned: success",
            "  type: list",
            "type:",
            "  description:",
            "  - URL of the disk type resource describing which disk type to use to create the",
            "    disk. Provide this when creating the disk.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - A reference to the region where the disk resides.",
            "  returned: success",
            "  type: str",
            "diskEncryptionKey:",
            "  description:",
            "  - Encrypts the disk using a customer-supplied encryption key.",
            "  - After you encrypt a disk with a customer-supplied key, you must provide the same",
            "    key if you use the disk later (e.g. to create a disk snapshot or an image, or",
            "    to attach the disk to a virtual machine).",
            "  - Customer-supplied encryption keys do not protect access to metadata of the disk.",
            "  - If you do not provide an encryption key when creating the disk, then the disk",
            "    will be encrypted using an automatically generated key and you do not need to",
            "    provide a key to use the disk later.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshot:",
            "  description:",
            "  - The source snapshot used to create this disk. You can provide this as a partial",
            "    or full URL to the resource.",
            "  returned: success",
            "  type: dict",
            "sourceSnapshotEncryptionKey:",
            "  description:",
            "  - The customer-supplied encryption key of the source snapshot. Required if the source",
            "    snapshot is protected by a customer-supplied encryption key.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    rawKey:",
            "      description:",
            "      - Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648",
            "        base64 to either encrypt or decrypt this resource.",
            "      returned: success",
            "      type: str",
            "    sha256:",
            "      description:",
            "      - The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption",
            "        key that protects this resource.",
            "      returned: success",
            "      type: str",
            "sourceSnapshotId:",
            "  description:",
            "  - The unique ID of the snapshot used to create this disk. This value identifies",
            "    the exact snapshot that was used to create this persistent disk. For example,",
            "    if you created the persistent disk from a snapshot that was later deleted and",
            "    recreated under the same name, the source snapshot ID would identify the exact",
            "    version of the snapshot that was used.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import re",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            description=dict(type='str'),",
            "            labels=dict(type='dict'),",
            "            licenses=dict(type='list', elements='str'),",
            "            name=dict(required=True, type='str'),",
            "            size_gb=dict(type='int'),",
            "            physical_block_size_bytes=dict(type='int'),",
            "            replica_zones=dict(required=True, type='list', elements='str'),",
            "            type=dict(type='str'),",
            "            region=dict(required=True, type='str'),",
            "            disk_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "            source_snapshot=dict(type='dict'),",
            "            source_snapshot_encryption_key=dict(type='dict', options=dict(raw_key=dict(type='str', no_log=True))),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#disk'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    update_fields(module, resource_to_request(module), response_to_hash(module, fetch))",
            "    return fetch_resource(module, self_link(module), kind)",
            "",
            "",
            "def update_fields(module, request, response):",
            "    if response.get('labels') != request.get('labels'):",
            "        label_fingerprint_update(module, request, response)",
            "    if response.get('sizeGb') != request.get('sizeGb'):",
            "        size_gb_update(module, request, response)",
            "",
            "",
            "def label_fingerprint_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/setLabels\"]).format(**module.params),",
            "        {u'labelFingerprint': response.get('labelFingerprint'), u'labels': module.params.get('labels')},",
            "    )",
            "",
            "",
            "def size_gb_update(module, request, response):",
            "    auth = GcpSession(module, 'compute')",
            "    auth.post(",
            "        ''.join([\"https://www.googleapis.com/compute/v1/\", \"projects/{project}/regions/{region}/disks/{name}/resize\"]).format(**module.params),",
            "        {u'sizeGb': module.params.get('size_gb')},",
            "    )",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#disk',",
            "        u'diskEncryptionKey': RegionDiskDiskencryptionkey(module.params.get('disk_encryption_key', {}), module).to_request(),",
            "        u'sourceSnapshotEncryptionKey': RegionDiskSourcesnapshotencryptionkey(module.params.get('source_snapshot_encryption_key', {}), module).to_request(),",
            "        u'description': module.params.get('description'),",
            "        u'labels': module.params.get('labels'),",
            "        u'licenses': module.params.get('licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': module.params.get('size_gb'),",
            "        u'physicalBlockSizeBytes': module.params.get('physical_block_size_bytes'),",
            "        u'replicaZones': module.params.get('replica_zones'),",
            "        u'type': region_disk_type_selflink(module.params.get('type'), module.params),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/disks\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'labelFingerprint': response.get(u'labelFingerprint'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'lastAttachTimestamp': response.get(u'lastAttachTimestamp'),",
            "        u'lastDetachTimestamp': response.get(u'lastDetachTimestamp'),",
            "        u'labels': response.get(u'labels'),",
            "        u'licenses': response.get(u'licenses'),",
            "        u'name': module.params.get('name'),",
            "        u'sizeGb': response.get(u'sizeGb'),",
            "        u'users': response.get(u'users'),",
            "        u'physicalBlockSizeBytes': response.get(u'physicalBlockSizeBytes'),",
            "        u'replicaZones': response.get(u'replicaZones'),",
            "        u'type': response.get(u'type'),",
            "    }",
            "",
            "",
            "def zone_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/zones/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/zones/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def region_disk_type_selflink(name, params):",
            "    if name is None:",
            "        return",
            "    url = r\"https://www.googleapis.com/compute/v1/projects/.*/regions/{region}/diskTypes/[a-z1-9\\-]*\"",
            "    if not re.match(url, name):",
            "        name = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/diskTypes/%s\".format(**params) % name",
            "    return name",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#disk')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class RegionDiskDiskencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "class RegionDiskSourcesnapshotencryptionkey(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get('raw_key')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'rawKey': self.request.get(u'rawKey')})",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "357": [
                "main"
            ],
            "359": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_ssl_certificate.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 163,
                "afterPatchRowNumber": 163,
                "PatchRowcode": "             certificate=dict(required=True, type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 164,
                "afterPatchRowNumber": 164,
                "PatchRowcode": "             description=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 165,
                "afterPatchRowNumber": 165,
                "PatchRowcode": "             name=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 166,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            private_key=dict(required=True, type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 166,
                "PatchRowcode": "+            private_key=dict(required=True, type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 167,
                "afterPatchRowNumber": 167,
                "PatchRowcode": "         )"
            },
            "6": {
                "beforePatchRowNumber": 168,
                "afterPatchRowNumber": 168,
                "PatchRowcode": "     )"
            },
            "7": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 169,
                "PatchRowcode": " "
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_ssl_certificate",
            "description:",
            "- An SslCertificate resource, used for HTTPS load balancing. This resource provides",
            "  a mechanism to upload an SSL key and certificate to the load balancer to serve secure",
            "  connections from the user.",
            "short_description: Creates a GCP SslCertificate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  certificate:",
            "    description:",
            "    - The certificate in PEM format.",
            "    - The certificate chain must be no greater than 5 certs long.",
            "    - The chain must include at least one intermediate cert.",
            "    required: true",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: false",
            "  private_key:",
            "    description:",
            "    - The write-only private key in PEM format.",
            "    required: true",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/sslCertificates)'",
            "- 'Official Documentation: U(https://cloud.google.com/load-balancing/docs/ssl-certificates)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a ssl certificate",
            "  gcp_compute_ssl_certificate:",
            "    name: test_object",
            "    description: A certificate for testing. Do not use this certificate in production",
            "    certificate: \"-----BEGIN CERTIFICATE----- MIICqjCCAk+gAwIBAgIJAIuJ+0352Kq4MAoGCCqGSM49BAMCMIGwMQswCQYDVQQG",
            "      EwJVUzETMBEGA1UECAwKV2FzaGluZ3RvbjERMA8GA1UEBwwIS2lya2xhbmQxFTAT BgNVBAoMDEdvb2dsZSwgSW5jLjEeMBwGA1UECwwVR29vZ2xlIENsb3VkIFBsYXRm",
            "      b3JtMR8wHQYDVQQDDBZ3d3cubXktc2VjdXJlLXNpdGUuY29tMSEwHwYJKoZIhvcN AQkBFhJuZWxzb25hQGdvb2dsZS5jb20wHhcNMTcwNjI4MDQ1NjI2WhcNMjcwNjI2",
            "      MDQ1NjI2WjCBsDELMAkGA1UEBhMCVVMxEzARBgNVBAgMCldhc2hpbmd0b24xETAP BgNVBAcMCEtpcmtsYW5kMRUwEwYDVQQKDAxHb29nbGUsIEluYy4xHjAcBgNVBAsM",
            "      FUdvb2dsZSBDbG91ZCBQbGF0Zm9ybTEfMB0GA1UEAwwWd3d3Lm15LXNlY3VyZS1z aXRlLmNvbTEhMB8GCSqGSIb3DQEJARYSbmVsc29uYUBnb29nbGUuY29tMFkwEwYH",
            "      KoZIzj0CAQYIKoZIzj0DAQcDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ 4mzkzTv0dXyB750fOGN02HtkpBOZzzvUARTR10JQoSe2/5PIwaNQME4wHQYDVR0O",
            "      BBYEFKIQC3A2SDpxcdfn0YLKineDNq/BMB8GA1UdIwQYMBaAFKIQC3A2SDpxcdfn 0YLKineDNq/BMAwGA1UdEwQFMAMBAf8wCgYIKoZIzj0EAwIDSQAwRgIhALs4vy+O",
            "      M3jcqgA4fSW/oKw6UJxp+M6a+nGMX+UJR3YgAiEAvvl39QRVAiv84hdoCuyON0lJ zqGNhIPGq2ULqXKK8BY=",
            "      -----END CERTIFICATE-----\"",
            "    private_key: \"-----BEGIN EC PRIVATE KEY----- MHcCAQEEIObtRo8tkUqoMjeHhsOh2ouPpXCgBcP+EDxZCB/tws15oAoGCCqGSM49",
            "      AwEHoUQDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ4mzkzTv0dXyB750f OGN02HtkpBOZzzvUARTR10JQoSe2/5PIwQ==",
            "      -----END EC PRIVATE KEY-----\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "certificate:",
            "  description:",
            "  - The certificate in PEM format.",
            "  - The certificate chain must be no greater than 5 certs long.",
            "  - The chain must include at least one intermediate cert.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "privateKey:",
            "  description:",
            "  - The write-only private key in PEM format.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            certificate=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(type='str'),",
            "            private_key=dict(required=True, type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#sslCertificate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    module.fail_json(msg=\"SslCertificate cannot be edited\")",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#sslCertificate',",
            "        u'certificate': module.params.get('certificate'),",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'certificate': response.get(u'certificate'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#sslCertificate')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_ssl_certificate",
            "description:",
            "- An SslCertificate resource, used for HTTPS load balancing. This resource provides",
            "  a mechanism to upload an SSL key and certificate to the load balancer to serve secure",
            "  connections from the user.",
            "short_description: Creates a GCP SslCertificate",
            "version_added: 2.6",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  certificate:",
            "    description:",
            "    - The certificate in PEM format.",
            "    - The certificate chain must be no greater than 5 certs long.",
            "    - The chain must include at least one intermediate cert.",
            "    required: true",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the resource. Provided by the client when the resource is created. The",
            "      name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "      name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "      which means the first character must be a lowercase letter, and all following",
            "      characters must be a dash, lowercase letter, or digit, except the last character,",
            "      which cannot be a dash.",
            "    required: false",
            "  private_key:",
            "    description:",
            "    - The write-only private key in PEM format.",
            "    required: true",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/sslCertificates)'",
            "- 'Official Documentation: U(https://cloud.google.com/load-balancing/docs/ssl-certificates)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a ssl certificate",
            "  gcp_compute_ssl_certificate:",
            "    name: test_object",
            "    description: A certificate for testing. Do not use this certificate in production",
            "    certificate: \"-----BEGIN CERTIFICATE----- MIICqjCCAk+gAwIBAgIJAIuJ+0352Kq4MAoGCCqGSM49BAMCMIGwMQswCQYDVQQG",
            "      EwJVUzETMBEGA1UECAwKV2FzaGluZ3RvbjERMA8GA1UEBwwIS2lya2xhbmQxFTAT BgNVBAoMDEdvb2dsZSwgSW5jLjEeMBwGA1UECwwVR29vZ2xlIENsb3VkIFBsYXRm",
            "      b3JtMR8wHQYDVQQDDBZ3d3cubXktc2VjdXJlLXNpdGUuY29tMSEwHwYJKoZIhvcN AQkBFhJuZWxzb25hQGdvb2dsZS5jb20wHhcNMTcwNjI4MDQ1NjI2WhcNMjcwNjI2",
            "      MDQ1NjI2WjCBsDELMAkGA1UEBhMCVVMxEzARBgNVBAgMCldhc2hpbmd0b24xETAP BgNVBAcMCEtpcmtsYW5kMRUwEwYDVQQKDAxHb29nbGUsIEluYy4xHjAcBgNVBAsM",
            "      FUdvb2dsZSBDbG91ZCBQbGF0Zm9ybTEfMB0GA1UEAwwWd3d3Lm15LXNlY3VyZS1z aXRlLmNvbTEhMB8GCSqGSIb3DQEJARYSbmVsc29uYUBnb29nbGUuY29tMFkwEwYH",
            "      KoZIzj0CAQYIKoZIzj0DAQcDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ 4mzkzTv0dXyB750fOGN02HtkpBOZzzvUARTR10JQoSe2/5PIwaNQME4wHQYDVR0O",
            "      BBYEFKIQC3A2SDpxcdfn0YLKineDNq/BMB8GA1UdIwQYMBaAFKIQC3A2SDpxcdfn 0YLKineDNq/BMAwGA1UdEwQFMAMBAf8wCgYIKoZIzj0EAwIDSQAwRgIhALs4vy+O",
            "      M3jcqgA4fSW/oKw6UJxp+M6a+nGMX+UJR3YgAiEAvvl39QRVAiv84hdoCuyON0lJ zqGNhIPGq2ULqXKK8BY=",
            "      -----END CERTIFICATE-----\"",
            "    private_key: \"-----BEGIN EC PRIVATE KEY----- MHcCAQEEIObtRo8tkUqoMjeHhsOh2ouPpXCgBcP+EDxZCB/tws15oAoGCCqGSM49",
            "      AwEHoUQDQgAEHGzpcRJ4XzfBJCCPMQeXQpTXwlblimODQCuQ4mzkzTv0dXyB750f OGN02HtkpBOZzzvUARTR10JQoSe2/5PIwQ==",
            "      -----END EC PRIVATE KEY-----\"",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "certificate:",
            "  description:",
            "  - The certificate in PEM format.",
            "  - The certificate chain must be no greater than 5 certs long.",
            "  - The chain must include at least one intermediate cert.",
            "  returned: success",
            "  type: str",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "id:",
            "  description:",
            "  - The unique identifier for the resource.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the resource. Provided by the client when the resource is created. The",
            "    name must be 1-63 characters long, and comply with RFC1035. Specifically, the",
            "    name must be 1-63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`",
            "    which means the first character must be a lowercase letter, and all following",
            "    characters must be a dash, lowercase letter, or digit, except the last character,",
            "    which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "privateKey:",
            "  description:",
            "  - The write-only private key in PEM format.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            certificate=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            name=dict(type='str'),",
            "            private_key=dict(required=True, type='str', no_log=True),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#sslCertificate'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    module.fail_json(msg=\"SslCertificate cannot be edited\")",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#sslCertificate',",
            "        u'certificate': module.params.get('certificate'),",
            "        u'description': module.params.get('description'),",
            "        u'name': module.params.get('name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/global/sslCertificates\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'certificate': response.get(u'certificate'),",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'description': response.get(u'description'),",
            "        u'id': response.get(u'id'),",
            "        u'name': response.get(u'name'),",
            "        u'privateKey': module.params.get('private_key'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/global/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#sslCertificate')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "166": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_compute_vpn_tunnel.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 269,
                "afterPatchRowNumber": 269,
                "PatchRowcode": "             target_vpn_gateway=dict(required=True, type='dict'),"
            },
            "1": {
                "beforePatchRowNumber": 270,
                "afterPatchRowNumber": 270,
                "PatchRowcode": "             router=dict(type='dict'),"
            },
            "2": {
                "beforePatchRowNumber": 271,
                "afterPatchRowNumber": 271,
                "PatchRowcode": "             peer_ip=dict(required=True, type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 272,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            shared_secret=dict(required=True, type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 272,
                "PatchRowcode": "+            shared_secret=dict(required=True, type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 273,
                "afterPatchRowNumber": 273,
                "PatchRowcode": "             ike_version=dict(default=2, type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 274,
                "afterPatchRowNumber": 274,
                "PatchRowcode": "             local_traffic_selector=dict(type='list', elements='str'),"
            },
            "7": {
                "beforePatchRowNumber": 275,
                "afterPatchRowNumber": 275,
                "PatchRowcode": "             remote_traffic_selector=dict(type='list', elements='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_vpn_tunnel",
            "description:",
            "- VPN tunnel resource.",
            "short_description: Creates a GCP VpnTunnel",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  name:",
            "    description:",
            "    - Name of the resource. The name must be 1-63 characters long, and comply with",
            "      RFC1035. Specifically, the name must be 1-63 characters long and match the regular",
            "      expression `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must",
            "      be a lowercase letter, and all following characters must be a dash, lowercase",
            "      letter, or digit, except the last character, which cannot be a dash.",
            "    required: true",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "  target_vpn_gateway:",
            "    description:",
            "    - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "    - 'This field represents a link to a TargetVpnGateway resource in GCP. It can",
            "      be specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "      and value of your resource''s selfLink Alternatively, you can add `register:",
            "      name-of-resource` to a gcp_compute_target_vpn_gateway task and then set this",
            "      target_vpn_gateway field to \"{{ name-of-resource }}\"'",
            "    required: true",
            "  router:",
            "    description:",
            "    - URL of router resource to be used for dynamic routing.",
            "    - 'This field represents a link to a Router resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_router task and then set this router field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "  peer_ip:",
            "    description:",
            "    - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "    required: true",
            "  shared_secret:",
            "    description:",
            "    - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "      the peer VPN gateway.",
            "    required: true",
            "  ike_version:",
            "    description:",
            "    - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "    - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "    required: false",
            "    default: '2'",
            "  local_traffic_selector:",
            "    description:",
            "    - Local traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "  remote_traffic_selector:",
            "    description:",
            "    - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "  region:",
            "    description:",
            "    - The region where the tunnel is located.",
            "    required: true",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/vpnTunnels)'",
            "- 'Cloud VPN Overview: U(https://cloud.google.com/vpn/docs/concepts/overview)'",
            "- 'Networks and Tunnel Routing: U(https://cloud.google.com/vpn/docs/concepts/choosing-networks-routing)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-vpn-tunnel",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a router",
            "  gcp_compute_router:",
            "    name: router-vpn-tunnel",
            "    network: \"{{ network }}\"",
            "    bgp:",
            "      asn: 64514",
            "      advertise_mode: CUSTOM",
            "      advertised_groups:",
            "      - ALL_SUBNETS",
            "      advertised_ip_ranges:",
            "      - range: 1.2.3.4",
            "      - range: 6.7.0.0/16",
            "    region: us-central1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: router",
            "",
            "- name: create a target vpn gateway",
            "  gcp_compute_target_vpn_gateway:",
            "    name: gateway-vpn-tunnel",
            "    region: us-west1",
            "    network: \"{{ network }}\"",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: gateway",
            "",
            "- name: create a vpn tunnel",
            "  gcp_compute_vpn_tunnel:",
            "    name: test_object",
            "    region: us-west1",
            "    target_vpn_gateway: \"{{ gateway }}\"",
            "    router: \"{{ router }}\"",
            "    shared_secret: super secret",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. The name must be 1-63 characters long, and comply with RFC1035.",
            "    Specifically, the name must be 1-63 characters long and match the regular expression",
            "    `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must be a lowercase",
            "    letter, and all following characters must be a dash, lowercase letter, or digit,",
            "    except the last character, which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "targetVpnGateway:",
            "  description:",
            "  - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "  returned: success",
            "  type: dict",
            "router:",
            "  description:",
            "  - URL of router resource to be used for dynamic routing.",
            "  returned: success",
            "  type: dict",
            "peerIp:",
            "  description:",
            "  - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "  returned: success",
            "  type: str",
            "sharedSecret:",
            "  description:",
            "  - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "    the peer VPN gateway.",
            "  returned: success",
            "  type: str",
            "sharedSecretHash:",
            "  description:",
            "  - Hash of the shared secret.",
            "  returned: success",
            "  type: str",
            "ikeVersion:",
            "  description:",
            "  - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "  - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "  returned: success",
            "  type: int",
            "localTrafficSelector:",
            "  description:",
            "  - Local traffic selector to use when establishing the VPN tunnel with peer VPN gateway.",
            "    The value should be a CIDR formatted string, for example `192.168.0.0/16`. The",
            "    ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "remoteTrafficSelector:",
            "  description:",
            "  - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "    gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "    The ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "region:",
            "  description:",
            "  - The region where the tunnel is located.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            name=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            target_vpn_gateway=dict(required=True, type='dict'),",
            "            router=dict(type='dict'),",
            "            peer_ip=dict(required=True, type='str'),",
            "            shared_secret=dict(required=True, type='str'),",
            "            ike_version=dict(default=2, type='int'),",
            "            local_traffic_selector=dict(type='list', elements='str'),",
            "            remote_traffic_selector=dict(type='list', elements='str'),",
            "            region=dict(required=True, type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#vpnTunnel'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    module.fail_json(msg=\"VpnTunnel cannot be edited\")",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#vpnTunnel',",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': module.params.get('peer_ip'),",
            "        u'sharedSecret': module.params.get('shared_secret'),",
            "        u'ikeVersion': module.params.get('ike_version'),",
            "        u'localTrafficSelector': module.params.get('local_traffic_selector'),",
            "        u'remoteTrafficSelector': module.params.get('remote_traffic_selector'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'name': response.get(u'name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': response.get(u'peerIp'),",
            "        u'sharedSecret': response.get(u'sharedSecret'),",
            "        u'sharedSecretHash': response.get(u'sharedSecretHash'),",
            "        u'ikeVersion': response.get(u'ikeVersion'),",
            "        u'localTrafficSelector': response.get(u'localTrafficSelector'),",
            "        u'remoteTrafficSelector': response.get(u'remoteTrafficSelector'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#vpnTunnel')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_compute_vpn_tunnel",
            "description:",
            "- VPN tunnel resource.",
            "short_description: Creates a GCP VpnTunnel",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  name:",
            "    description:",
            "    - Name of the resource. The name must be 1-63 characters long, and comply with",
            "      RFC1035. Specifically, the name must be 1-63 characters long and match the regular",
            "      expression `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must",
            "      be a lowercase letter, and all following characters must be a dash, lowercase",
            "      letter, or digit, except the last character, which cannot be a dash.",
            "    required: true",
            "  description:",
            "    description:",
            "    - An optional description of this resource.",
            "    required: false",
            "  target_vpn_gateway:",
            "    description:",
            "    - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "    - 'This field represents a link to a TargetVpnGateway resource in GCP. It can",
            "      be specified in two ways. First, you can place a dictionary with key ''selfLink''",
            "      and value of your resource''s selfLink Alternatively, you can add `register:",
            "      name-of-resource` to a gcp_compute_target_vpn_gateway task and then set this",
            "      target_vpn_gateway field to \"{{ name-of-resource }}\"'",
            "    required: true",
            "  router:",
            "    description:",
            "    - URL of router resource to be used for dynamic routing.",
            "    - 'This field represents a link to a Router resource in GCP. It can be specified",
            "      in two ways. First, you can place a dictionary with key ''selfLink'' and value",
            "      of your resource''s selfLink Alternatively, you can add `register: name-of-resource`",
            "      to a gcp_compute_router task and then set this router field to \"{{ name-of-resource",
            "      }}\"'",
            "    required: false",
            "  peer_ip:",
            "    description:",
            "    - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "    required: true",
            "  shared_secret:",
            "    description:",
            "    - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "      the peer VPN gateway.",
            "    required: true",
            "  ike_version:",
            "    description:",
            "    - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "    - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "    required: false",
            "    default: '2'",
            "  local_traffic_selector:",
            "    description:",
            "    - Local traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "  remote_traffic_selector:",
            "    description:",
            "    - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "      gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "      The ranges should be disjoint.",
            "    - Only IPv4 is supported.",
            "    required: false",
            "  region:",
            "    description:",
            "    - The region where the tunnel is located.",
            "    required: true",
            "extends_documentation_fragment: gcp",
            "notes:",
            "- 'API Reference: U(https://cloud.google.com/compute/docs/reference/rest/v1/vpnTunnels)'",
            "- 'Cloud VPN Overview: U(https://cloud.google.com/vpn/docs/concepts/overview)'",
            "- 'Networks and Tunnel Routing: U(https://cloud.google.com/vpn/docs/concepts/choosing-networks-routing)'",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a network",
            "  gcp_compute_network:",
            "    name: network-vpn-tunnel",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: network",
            "",
            "- name: create a router",
            "  gcp_compute_router:",
            "    name: router-vpn-tunnel",
            "    network: \"{{ network }}\"",
            "    bgp:",
            "      asn: 64514",
            "      advertise_mode: CUSTOM",
            "      advertised_groups:",
            "      - ALL_SUBNETS",
            "      advertised_ip_ranges:",
            "      - range: 1.2.3.4",
            "      - range: 6.7.0.0/16",
            "    region: us-central1",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: router",
            "",
            "- name: create a target vpn gateway",
            "  gcp_compute_target_vpn_gateway:",
            "    name: gateway-vpn-tunnel",
            "    region: us-west1",
            "    network: \"{{ network }}\"",
            "    project: \"{{ gcp_project }}\"",
            "    auth_kind: \"{{ gcp_cred_kind }}\"",
            "    service_account_file: \"{{ gcp_cred_file }}\"",
            "    state: present",
            "  register: gateway",
            "",
            "- name: create a vpn tunnel",
            "  gcp_compute_vpn_tunnel:",
            "    name: test_object",
            "    region: us-west1",
            "    target_vpn_gateway: \"{{ gateway }}\"",
            "    router: \"{{ router }}\"",
            "    shared_secret: super secret",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "creationTimestamp:",
            "  description:",
            "  - Creation timestamp in RFC3339 text format.",
            "  returned: success",
            "  type: str",
            "name:",
            "  description:",
            "  - Name of the resource. The name must be 1-63 characters long, and comply with RFC1035.",
            "    Specifically, the name must be 1-63 characters long and match the regular expression",
            "    `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first character must be a lowercase",
            "    letter, and all following characters must be a dash, lowercase letter, or digit,",
            "    except the last character, which cannot be a dash.",
            "  returned: success",
            "  type: str",
            "description:",
            "  description:",
            "  - An optional description of this resource.",
            "  returned: success",
            "  type: str",
            "targetVpnGateway:",
            "  description:",
            "  - URL of the Target VPN gateway with which this VPN tunnel is associated.",
            "  returned: success",
            "  type: dict",
            "router:",
            "  description:",
            "  - URL of router resource to be used for dynamic routing.",
            "  returned: success",
            "  type: dict",
            "peerIp:",
            "  description:",
            "  - IP address of the peer VPN gateway. Only IPv4 is supported.",
            "  returned: success",
            "  type: str",
            "sharedSecret:",
            "  description:",
            "  - Shared secret used to set the secure session between the Cloud VPN gateway and",
            "    the peer VPN gateway.",
            "  returned: success",
            "  type: str",
            "sharedSecretHash:",
            "  description:",
            "  - Hash of the shared secret.",
            "  returned: success",
            "  type: str",
            "ikeVersion:",
            "  description:",
            "  - IKE protocol version to use when establishing the VPN tunnel with peer VPN gateway.",
            "  - Acceptable IKE versions are 1 or 2. Default version is 2.",
            "  returned: success",
            "  type: int",
            "localTrafficSelector:",
            "  description:",
            "  - Local traffic selector to use when establishing the VPN tunnel with peer VPN gateway.",
            "    The value should be a CIDR formatted string, for example `192.168.0.0/16`. The",
            "    ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "remoteTrafficSelector:",
            "  description:",
            "  - Remote traffic selector to use when establishing the VPN tunnel with peer VPN",
            "    gateway. The value should be a CIDR formatted string, for example `192.168.0.0/16`.",
            "    The ranges should be disjoint.",
            "  - Only IPv4 is supported.",
            "  returned: success",
            "  type: list",
            "region:",
            "  description:",
            "  - The region where the tunnel is located.",
            "  returned: success",
            "  type: str",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            name=dict(required=True, type='str'),",
            "            description=dict(type='str'),",
            "            target_vpn_gateway=dict(required=True, type='dict'),",
            "            router=dict(type='dict'),",
            "            peer_ip=dict(required=True, type='str'),",
            "            shared_secret=dict(required=True, type='str', no_log=True),",
            "            ike_version=dict(default=2, type='int'),",
            "            local_traffic_selector=dict(type='list', elements='str'),",
            "            remote_traffic_selector=dict(type='list', elements='str'),",
            "            region=dict(required=True, type='str'),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/compute']",
            "",
            "    state = module.params['state']",
            "    kind = 'compute#vpnTunnel'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind):",
            "    module.fail_json(msg=\"VpnTunnel cannot be edited\")",
            "",
            "",
            "def delete(module, link, kind):",
            "    auth = GcpSession(module, 'compute')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'compute#vpnTunnel',",
            "        u'name': module.params.get('name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': module.params.get('peer_ip'),",
            "        u'sharedSecret': module.params.get('shared_secret'),",
            "        u'ikeVersion': module.params.get('ike_version'),",
            "        u'localTrafficSelector': module.params.get('local_traffic_selector'),",
            "        u'remoteTrafficSelector': module.params.get('remote_traffic_selector'),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'compute')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/vpnTunnels\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    try:",
            "        module.raise_for_status(response)",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError):",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % response.text)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'creationTimestamp': response.get(u'creationTimestamp'),",
            "        u'name': response.get(u'name'),",
            "        u'description': module.params.get('description'),",
            "        u'targetVpnGateway': replace_resource_dict(module.params.get(u'target_vpn_gateway', {}), 'selfLink'),",
            "        u'router': replace_resource_dict(module.params.get(u'router', {}), 'selfLink'),",
            "        u'peerIp': response.get(u'peerIp'),",
            "        u'sharedSecret': response.get(u'sharedSecret'),",
            "        u'sharedSecretHash': response.get(u'sharedSecretHash'),",
            "        u'ikeVersion': response.get(u'ikeVersion'),",
            "        u'localTrafficSelector': response.get(u'localTrafficSelector'),",
            "        u'remoteTrafficSelector': response.get(u'remoteTrafficSelector'),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'compute#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'compute#vpnTunnel')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'compute#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "272": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/google/gcp_sql_instance.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 626,
                "afterPatchRowNumber": 626,
                "PatchRowcode": "                         options=dict("
            },
            "1": {
                "beforePatchRowNumber": 627,
                "afterPatchRowNumber": 627,
                "PatchRowcode": "                             ca_certificate=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 628,
                "afterPatchRowNumber": 628,
                "PatchRowcode": "                             client_certificate=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 629,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            client_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 629,
                "PatchRowcode": "+                            client_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 630,
                "afterPatchRowNumber": 630,
                "PatchRowcode": "                             connect_retry_interval=dict(type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 631,
                "afterPatchRowNumber": 631,
                "PatchRowcode": "                             dump_file_path=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 632,
                "afterPatchRowNumber": 632,
                "PatchRowcode": "                             master_heartbeat_period=dict(type='int'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_sql_instance",
            "description:",
            "- Represents a Cloud SQL instance. Cloud SQL instances are SQL databases hosted in",
            "  Google's cloud. The Instances resource provides methods for common configuration",
            "  and management tasks.",
            "short_description: Creates a GCP Instance",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  backend_type:",
            "    description:",
            "    - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "    - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "    - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "    required: false",
            "    choices:",
            "    - FIRST_GEN",
            "    - SECOND_GEN",
            "    - EXTERNAL",
            "  connection_name:",
            "    description:",
            "    - Connection name of the Cloud SQL instance used in connection strings.",
            "    required: false",
            "  database_version:",
            "    description:",
            "    - The database engine type and version. For First Generation instances, can be",
            "      MYSQL_5_5, or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or",
            "      MYSQL_5_7. Defaults to MYSQL_5_6.",
            "    - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be",
            "      changed after instance creation.'",
            "    required: false",
            "    choices:",
            "    - MYSQL_5_5",
            "    - MYSQL_5_6",
            "    - MYSQL_5_7",
            "    - POSTGRES_9_6",
            "  failover_replica:",
            "    description:",
            "    - The name and status of the failover replica. This property is applicable only",
            "      to Second Generation instances.",
            "    required: false",
            "    suboptions:",
            "      name:",
            "        description:",
            "        - The name of the failover replica. If specified at instance creation, a failover",
            "          replica is created for the instance. The name doesn't include the project",
            "          ID. This property is applicable only to Second Generation instances.",
            "        required: false",
            "  instance_type:",
            "    description:",
            "    - The instance type. This can be one of the following.",
            "    - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "    - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "    - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "    required: false",
            "    choices:",
            "    - CLOUD_SQL_INSTANCE",
            "    - ON_PREMISES_INSTANCE",
            "    - READ_REPLICA_INSTANCE",
            "  ipv6_address:",
            "    description:",
            "    - The IPv6 address assigned to the instance. This property is applicable only",
            "      to First Generation instances.",
            "    required: false",
            "  master_instance_name:",
            "    description:",
            "    - The name of the instance which will act as master in the replication setup.",
            "    required: false",
            "  max_disk_size:",
            "    description:",
            "    - The maximum disk size of the instance in bytes.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the Cloud SQL instance. This does not include the project ID.",
            "    required: true",
            "  region:",
            "    description:",
            "    - The geographical region. Defaults to us-central or us-central1 depending on",
            "      the instance type (First Generation or Second Generation/PostgreSQL).",
            "    required: false",
            "  replica_configuration:",
            "    description:",
            "    - Configuration specific to failover replicas and read replicas.",
            "    required: false",
            "    suboptions:",
            "      failover_target:",
            "        description:",
            "        - Specifies if the replica is the failover target. If the field is set to",
            "          true the replica will be designated as a failover replica.",
            "        - In case the master instance fails, the replica instance will be promoted",
            "          as the new master instance.",
            "        - Only one replica can be specified as failover target, and the replica has",
            "          to be in different zone with the master instance.",
            "        required: false",
            "        type: bool",
            "      mysql_replica_configuration:",
            "        description:",
            "        - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "          Replication configuration information such as the username, password, certificates,",
            "          and keys are not stored in the instance metadata. The configuration information",
            "          is used only to set up the replication connection and is stored by MySQL",
            "          in a file named master.info in the data directory.",
            "        required: false",
            "        suboptions:",
            "          ca_certificate:",
            "            description:",
            "            - PEM representation of the trusted CA's x509 certificate.",
            "            required: false",
            "          client_certificate:",
            "            description:",
            "            - PEM representation of the slave's x509 certificate .",
            "            required: false",
            "          client_key:",
            "            description:",
            "            - PEM representation of the slave's private key. The corresponding public",
            "              key is encoded in the client's certificate.",
            "            required: false",
            "          connect_retry_interval:",
            "            description:",
            "            - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "            required: false",
            "          dump_file_path:",
            "            description:",
            "            - Path to a SQL dump file in Google Cloud Storage from which the slave",
            "              instance is to be created. The URI is in the form gs://bucketName/fileName.",
            "              Compressed gzip files (.gz) are also supported. Dumps should have the",
            "              binlog co-ordinates from which replication should begin. This can be",
            "              accomplished by setting --master-data to 1 when using mysqldump.",
            "            required: false",
            "          master_heartbeat_period:",
            "            description:",
            "            - Interval in milliseconds between replication heartbeats.",
            "            required: false",
            "          password:",
            "            description:",
            "            - The password for the replication connection.",
            "            required: false",
            "          ssl_cipher:",
            "            description:",
            "            - A list of permissible ciphers to use for SSL encryption.",
            "            required: false",
            "          username:",
            "            description:",
            "            - The username for the replication connection.",
            "            required: false",
            "          verify_server_certificate:",
            "            description:",
            "            - Whether or not to check the master's Common Name value in the certificate",
            "              that it sends during the SSL handshake.",
            "            required: false",
            "            type: bool",
            "      replica_names:",
            "        description:",
            "        - The replicas of the instance.",
            "        required: false",
            "      service_account_email_address:",
            "        description:",
            "        - The service account email address assigned to the instance. This property",
            "          is applicable only to Second Generation instances.",
            "        required: false",
            "  settings:",
            "    description:",
            "    - The user settings.",
            "    required: false",
            "    suboptions:",
            "      ip_configuration:",
            "        description:",
            "        - The settings for IP Management. This allows to enable or disable the instance",
            "          IP and manage which external networks can connect to the instance. The IPv4",
            "          address cannot be disabled for Second Generation instances.",
            "        required: false",
            "        suboptions:",
            "          ipv4_enabled:",
            "            description:",
            "            - Whether the instance should be assigned an IP address or not.",
            "            required: false",
            "            type: bool",
            "          authorized_networks:",
            "            description:",
            "            - The list of external networks that are allowed to connect to the instance",
            "              using the IP. In CIDR notation, also known as 'slash' notation (e.g.",
            "              192.168.100.0/24).",
            "            required: false",
            "            suboptions:",
            "              expiration_time:",
            "                description:",
            "                - The time when this access control entry expires in RFC 3339 format,",
            "                  for example 2012-11-15T16:19:00.094Z.",
            "                required: false",
            "              name:",
            "                description:",
            "                - An optional label to identify this entry.",
            "                required: false",
            "              value:",
            "                description:",
            "                - The whitelisted value for the access control list. For example,",
            "                  to grant access to a client from an external IP (IPv4 or IPv6) address",
            "                  or subnet, use that address or subnet here.",
            "                required: false",
            "          require_ssl:",
            "            description:",
            "            - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "              over IP.",
            "            required: false",
            "            type: bool",
            "      tier:",
            "        description:",
            "        - The tier or machine type for this instance, for example db-n1-standard-1.",
            "          For MySQL instances, this field determines whether the instance is Second",
            "          Generation (recommended) or First Generation.",
            "        required: false",
            "      availability_type:",
            "        description:",
            "        - The availabilityType define if your postgres instance is run zonal or regional.",
            "        required: false",
            "        choices:",
            "        - ZONAL",
            "        - REGIONAL",
            "      backup_configuration:",
            "        description:",
            "        - The daily backup configuration for the instance.",
            "        required: false",
            "        suboptions:",
            "          enabled:",
            "            description:",
            "            - Enable Autobackup for your instance.",
            "            required: false",
            "            type: bool",
            "          binary_log_enabled:",
            "            description:",
            "            - Whether binary log is enabled. If backup configuration is disabled,",
            "              binary log must be disabled as well. MySQL only.",
            "            required: false",
            "            type: bool",
            "          start_time:",
            "            description:",
            "            - Define the backup start time in UTC (HH:MM) .",
            "            required: false",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance",
            "  gcp_sql_instance:",
            "    name: \"{{resource_name}}-2\"",
            "    settings:",
            "      ip_configuration:",
            "        authorized_networks:",
            "        - name: google dns server",
            "          value: 8.8.8.8/32",
            "      tier: db-n1-standard-1",
            "    region: us-central1",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "backendType:",
            "  description:",
            "  - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "  - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "  - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "  returned: success",
            "  type: str",
            "connectionName:",
            "  description:",
            "  - Connection name of the Cloud SQL instance used in connection strings.",
            "  returned: success",
            "  type: str",
            "databaseVersion:",
            "  description:",
            "  - The database engine type and version. For First Generation instances, can be MYSQL_5_5,",
            "    or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or MYSQL_5_7.",
            "    Defaults to MYSQL_5_6.",
            "  - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be changed",
            "    after instance creation.'",
            "  returned: success",
            "  type: str",
            "failoverReplica:",
            "  description:",
            "  - The name and status of the failover replica. This property is applicable only",
            "    to Second Generation instances.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    available:",
            "      description:",
            "      - The availability status of the failover replica. A false status indicates",
            "        that the failover replica is out of sync. The master can only failover to",
            "        the failover replica when the status is true.",
            "      returned: success",
            "      type: bool",
            "    name:",
            "      description:",
            "      - The name of the failover replica. If specified at instance creation, a failover",
            "        replica is created for the instance. The name doesn't include the project",
            "        ID. This property is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "instanceType:",
            "  description:",
            "  - The instance type. This can be one of the following.",
            "  - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "  - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "  - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "  returned: success",
            "  type: str",
            "ipAddresses:",
            "  description:",
            "  - The assigned IP addresses for the instance.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    ipAddress:",
            "      description:",
            "      - The IP address assigned.",
            "      returned: success",
            "      type: str",
            "    timeToRetire:",
            "      description:",
            "      - The due time for this IP to be retired in RFC 3339 format, for example 2012-11-15T16:19:00.094Z.",
            "        This field is only available when the IP is scheduled to be retired.",
            "      returned: success",
            "      type: str",
            "    type:",
            "      description:",
            "      - The type of this IP address. A PRIMARY address is an address that can accept",
            "        incoming connections. An OUTGOING address is the source address of connections",
            "        originating from the instance, if supported.",
            "      returned: success",
            "      type: str",
            "ipv6Address:",
            "  description:",
            "  - The IPv6 address assigned to the instance. This property is applicable only to",
            "    First Generation instances.",
            "  returned: success",
            "  type: str",
            "masterInstanceName:",
            "  description:",
            "  - The name of the instance which will act as master in the replication setup.",
            "  returned: success",
            "  type: str",
            "maxDiskSize:",
            "  description:",
            "  - The maximum disk size of the instance in bytes.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the Cloud SQL instance. This does not include the project ID.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - The geographical region. Defaults to us-central or us-central1 depending on the",
            "    instance type (First Generation or Second Generation/PostgreSQL).",
            "  returned: success",
            "  type: str",
            "replicaConfiguration:",
            "  description:",
            "  - Configuration specific to failover replicas and read replicas.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    failoverTarget:",
            "      description:",
            "      - Specifies if the replica is the failover target. If the field is set to true",
            "        the replica will be designated as a failover replica.",
            "      - In case the master instance fails, the replica instance will be promoted as",
            "        the new master instance.",
            "      - Only one replica can be specified as failover target, and the replica has",
            "        to be in different zone with the master instance.",
            "      returned: success",
            "      type: bool",
            "    mysqlReplicaConfiguration:",
            "      description:",
            "      - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "        Replication configuration information such as the username, password, certificates,",
            "        and keys are not stored in the instance metadata. The configuration information",
            "        is used only to set up the replication connection and is stored by MySQL in",
            "        a file named master.info in the data directory.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        caCertificate:",
            "          description:",
            "          - PEM representation of the trusted CA's x509 certificate.",
            "          returned: success",
            "          type: str",
            "        clientCertificate:",
            "          description:",
            "          - PEM representation of the slave's x509 certificate .",
            "          returned: success",
            "          type: str",
            "        clientKey:",
            "          description:",
            "          - PEM representation of the slave's private key. The corresponding public",
            "            key is encoded in the client's certificate.",
            "          returned: success",
            "          type: str",
            "        connectRetryInterval:",
            "          description:",
            "          - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "          returned: success",
            "          type: int",
            "        dumpFilePath:",
            "          description:",
            "          - Path to a SQL dump file in Google Cloud Storage from which the slave instance",
            "            is to be created. The URI is in the form gs://bucketName/fileName. Compressed",
            "            gzip files (.gz) are also supported. Dumps should have the binlog co-ordinates",
            "            from which replication should begin. This can be accomplished by setting",
            "            --master-data to 1 when using mysqldump.",
            "          returned: success",
            "          type: str",
            "        masterHeartbeatPeriod:",
            "          description:",
            "          - Interval in milliseconds between replication heartbeats.",
            "          returned: success",
            "          type: int",
            "        password:",
            "          description:",
            "          - The password for the replication connection.",
            "          returned: success",
            "          type: str",
            "        sslCipher:",
            "          description:",
            "          - A list of permissible ciphers to use for SSL encryption.",
            "          returned: success",
            "          type: str",
            "        username:",
            "          description:",
            "          - The username for the replication connection.",
            "          returned: success",
            "          type: str",
            "        verifyServerCertificate:",
            "          description:",
            "          - Whether or not to check the master's Common Name value in the certificate",
            "            that it sends during the SSL handshake.",
            "          returned: success",
            "          type: bool",
            "    replicaNames:",
            "      description:",
            "      - The replicas of the instance.",
            "      returned: success",
            "      type: list",
            "    serviceAccountEmailAddress:",
            "      description:",
            "      - The service account email address assigned to the instance. This property",
            "        is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "settings:",
            "  description:",
            "  - The user settings.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    ipConfiguration:",
            "      description:",
            "      - The settings for IP Management. This allows to enable or disable the instance",
            "        IP and manage which external networks can connect to the instance. The IPv4",
            "        address cannot be disabled for Second Generation instances.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        ipv4Enabled:",
            "          description:",
            "          - Whether the instance should be assigned an IP address or not.",
            "          returned: success",
            "          type: bool",
            "        authorizedNetworks:",
            "          description:",
            "          - The list of external networks that are allowed to connect to the instance",
            "            using the IP. In CIDR notation, also known as 'slash' notation (e.g. 192.168.100.0/24).",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            expirationTime:",
            "              description:",
            "              - The time when this access control entry expires in RFC 3339 format,",
            "                for example 2012-11-15T16:19:00.094Z.",
            "              returned: success",
            "              type: str",
            "            name:",
            "              description:",
            "              - An optional label to identify this entry.",
            "              returned: success",
            "              type: str",
            "            value:",
            "              description:",
            "              - The whitelisted value for the access control list. For example, to",
            "                grant access to a client from an external IP (IPv4 or IPv6) address",
            "                or subnet, use that address or subnet here.",
            "              returned: success",
            "              type: str",
            "        requireSsl:",
            "          description:",
            "          - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "            over IP.",
            "          returned: success",
            "          type: bool",
            "    tier:",
            "      description:",
            "      - The tier or machine type for this instance, for example db-n1-standard-1.",
            "        For MySQL instances, this field determines whether the instance is Second",
            "        Generation (recommended) or First Generation.",
            "      returned: success",
            "      type: str",
            "    availabilityType:",
            "      description:",
            "      - The availabilityType define if your postgres instance is run zonal or regional.",
            "      returned: success",
            "      type: str",
            "    backupConfiguration:",
            "      description:",
            "      - The daily backup configuration for the instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        enabled:",
            "          description:",
            "          - Enable Autobackup for your instance.",
            "          returned: success",
            "          type: bool",
            "        binaryLogEnabled:",
            "          description:",
            "          - Whether binary log is enabled. If backup configuration is disabled, binary",
            "            log must be disabled as well. MySQL only.",
            "          returned: success",
            "          type: bool",
            "        startTime:",
            "          description:",
            "          - Define the backup start time in UTC (HH:MM) .",
            "          returned: success",
            "          type: str",
            "    settingsVersion:",
            "      description:",
            "      - The version of instance settings. This is a required field for update method",
            "        to make sure concurrent updates are handled properly. During update, use the",
            "        most recent settingsVersion value for this instance and do not try to update",
            "        this value.",
            "      returned: success",
            "      type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            backend_type=dict(type='str', choices=['FIRST_GEN', 'SECOND_GEN', 'EXTERNAL']),",
            "            connection_name=dict(type='str'),",
            "            database_version=dict(type='str', choices=['MYSQL_5_5', 'MYSQL_5_6', 'MYSQL_5_7', 'POSTGRES_9_6']),",
            "            failover_replica=dict(type='dict', options=dict(name=dict(type='str'))),",
            "            instance_type=dict(type='str', choices=['CLOUD_SQL_INSTANCE', 'ON_PREMISES_INSTANCE', 'READ_REPLICA_INSTANCE']),",
            "            ipv6_address=dict(type='str'),",
            "            master_instance_name=dict(type='str'),",
            "            max_disk_size=dict(type='int'),",
            "            name=dict(required=True, type='str'),",
            "            region=dict(type='str'),",
            "            replica_configuration=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    failover_target=dict(type='bool'),",
            "                    mysql_replica_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ca_certificate=dict(type='str'),",
            "                            client_certificate=dict(type='str'),",
            "                            client_key=dict(type='str'),",
            "                            connect_retry_interval=dict(type='int'),",
            "                            dump_file_path=dict(type='str'),",
            "                            master_heartbeat_period=dict(type='int'),",
            "                            password=dict(type='str'),",
            "                            ssl_cipher=dict(type='str'),",
            "                            username=dict(type='str'),",
            "                            verify_server_certificate=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    replica_names=dict(type='list', elements='str'),",
            "                    service_account_email_address=dict(type='str'),",
            "                ),",
            "            ),",
            "            settings=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    ip_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ipv4_enabled=dict(type='bool'),",
            "                            authorized_networks=dict(",
            "                                type='list', elements='dict', options=dict(expiration_time=dict(type='str'), name=dict(type='str'), value=dict(type='str'))",
            "                            ),",
            "                            require_ssl=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    tier=dict(type='str'),",
            "                    availability_type=dict(type='str', choices=['ZONAL', 'REGIONAL']),",
            "                    backup_configuration=dict(",
            "                        type='dict', options=dict(enabled=dict(type='bool'), binary_log_enabled=dict(type='bool'), start_time=dict(type='str'))",
            "                    ),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/sqlservice.admin']",
            "",
            "    state = module.params['state']",
            "    kind = 'sql#instance'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind, fetch)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.put(link, resource_to_request(module)))",
            "",
            "",
            "def delete(module, link, kind, fetch):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'sql#instance',",
            "        u'backendType': module.params.get('backend_type'),",
            "        u'connectionName': module.params.get('connection_name'),",
            "        u'databaseVersion': module.params.get('database_version'),",
            "        u'failoverReplica': InstanceFailoverreplica(module.params.get('failover_replica', {}), module).to_request(),",
            "        u'instanceType': module.params.get('instance_type'),",
            "        u'ipv6Address': module.params.get('ipv6_address'),",
            "        u'masterInstanceName': module.params.get('master_instance_name'),",
            "        u'maxDiskSize': module.params.get('max_disk_size'),",
            "        u'name': module.params.get('name'),",
            "        u'region': module.params.get('region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(module.params.get('replica_configuration', {}), module).to_request(),",
            "        u'settings': InstanceSettings(module.params.get('settings', {}), module).to_request(),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'sql')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    # SQL only: return on 403 if not exist",
            "    if allow_not_found and response.status_code == 403:",
            "        return None",
            "",
            "    try:",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError) as inst:",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % inst)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'backendType': response.get(u'backendType'),",
            "        u'connectionName': response.get(u'connectionName'),",
            "        u'databaseVersion': response.get(u'databaseVersion'),",
            "        u'failoverReplica': InstanceFailoverreplica(response.get(u'failoverReplica', {}), module).from_response(),",
            "        u'instanceType': response.get(u'instanceType'),",
            "        u'ipAddresses': InstanceIpaddressesArray(response.get(u'ipAddresses', []), module).from_response(),",
            "        u'ipv6Address': response.get(u'ipv6Address'),",
            "        u'masterInstanceName': response.get(u'masterInstanceName'),",
            "        u'maxDiskSize': response.get(u'maxDiskSize'),",
            "        u'name': response.get(u'name'),",
            "        u'region': response.get(u'region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(response.get(u'replicaConfiguration', {}), module).from_response(),",
            "        u'settings': InstanceSettings(response.get(u'settings', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/sql/v1beta4/projects/{project}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'sql#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'sql#instance')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'sql#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class InstanceFailoverreplica(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'name': self.request.get('name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'name': self.request.get(u'name')})",
            "",
            "",
            "class InstanceIpaddressesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get('ip_address'), u'timeToRetire': item.get('time_to_retire'), u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get(u'ipAddress'), u'timeToRetire': item.get(u'timeToRetire'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceReplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get('failover_target'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(self.request.get('mysql_replica_configuration', {}), self.module).to_request(),",
            "                u'replicaNames': self.request.get('replica_names'),",
            "                u'serviceAccountEmailAddress': self.request.get('service_account_email_address'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get(u'failoverTarget'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(",
            "                    self.request.get(u'mysqlReplicaConfiguration', {}), self.module",
            "                ).from_response(),",
            "                u'replicaNames': self.request.get(u'replicaNames'),",
            "                u'serviceAccountEmailAddress': self.request.get(u'serviceAccountEmailAddress'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceMysqlreplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get('ca_certificate'),",
            "                u'clientCertificate': self.request.get('client_certificate'),",
            "                u'clientKey': self.request.get('client_key'),",
            "                u'connectRetryInterval': self.request.get('connect_retry_interval'),",
            "                u'dumpFilePath': self.request.get('dump_file_path'),",
            "                u'masterHeartbeatPeriod': self.request.get('master_heartbeat_period'),",
            "                u'password': self.request.get('password'),",
            "                u'sslCipher': self.request.get('ssl_cipher'),",
            "                u'username': self.request.get('username'),",
            "                u'verifyServerCertificate': self.request.get('verify_server_certificate'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get(u'caCertificate'),",
            "                u'clientCertificate': self.request.get(u'clientCertificate'),",
            "                u'clientKey': self.request.get(u'clientKey'),",
            "                u'connectRetryInterval': self.request.get(u'connectRetryInterval'),",
            "                u'dumpFilePath': self.request.get(u'dumpFilePath'),",
            "                u'masterHeartbeatPeriod': self.request.get(u'masterHeartbeatPeriod'),",
            "                u'password': self.request.get(u'password'),",
            "                u'sslCipher': self.request.get(u'sslCipher'),",
            "                u'username': self.request.get(u'username'),",
            "                u'verifyServerCertificate': self.request.get(u'verifyServerCertificate'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceSettings(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get('ip_configuration', {}), self.module).to_request(),",
            "                u'tier': self.request.get('tier'),",
            "                u'availabilityType': self.request.get('availability_type'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get('backup_configuration', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get(u'ipConfiguration', {}), self.module).from_response(),",
            "                u'tier': self.request.get(u'tier'),",
            "                u'availabilityType': self.request.get(u'availabilityType'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get(u'backupConfiguration', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceIpconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get('ipv4_enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get('authorized_networks', []), self.module).to_request(),",
            "                u'requireSsl': self.request.get('require_ssl'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get(u'ipv4Enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get(u'authorizedNetworks', []), self.module).from_response(),",
            "                u'requireSsl': self.request.get(u'requireSsl'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceAuthorizednetworksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get('expiration_time'), u'name': item.get('name'), u'value': item.get('value')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get(u'expirationTime'), u'name': item.get(u'name'), u'value': item.get(u'value')})",
            "",
            "",
            "class InstanceBackupconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get('enabled'), u'binaryLogEnabled': self.request.get('binary_log_enabled'), u'startTime': self.request.get('start_time')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get(u'enabled'), u'binaryLogEnabled': self.request.get(u'binaryLogEnabled'), u'startTime': self.request.get(u'startTime')}",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# Copyright (C) 2017 Google",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***",
            "#",
            "# ----------------------------------------------------------------------------",
            "#",
            "#     This file is automatically generated by Magic Modules and manual",
            "#     changes will be clobbered when the file is regenerated.",
            "#",
            "#     Please read more about how to change this file at",
            "#     https://www.github.com/GoogleCloudPlatform/magic-modules",
            "#",
            "# ----------------------------------------------------------------------------",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "################################################################################",
            "# Documentation",
            "################################################################################",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1', 'status': [\"preview\"], 'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: gcp_sql_instance",
            "description:",
            "- Represents a Cloud SQL instance. Cloud SQL instances are SQL databases hosted in",
            "  Google's cloud. The Instances resource provides methods for common configuration",
            "  and management tasks.",
            "short_description: Creates a GCP Instance",
            "version_added: 2.7",
            "author: Google Inc. (@googlecloudplatform)",
            "requirements:",
            "- python >= 2.6",
            "- requests >= 2.18.4",
            "- google-auth >= 1.3.0",
            "options:",
            "  state:",
            "    description:",
            "    - Whether the given object should exist in GCP",
            "    choices:",
            "    - present",
            "    - absent",
            "    default: present",
            "  backend_type:",
            "    description:",
            "    - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "    - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "    - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "    required: false",
            "    choices:",
            "    - FIRST_GEN",
            "    - SECOND_GEN",
            "    - EXTERNAL",
            "  connection_name:",
            "    description:",
            "    - Connection name of the Cloud SQL instance used in connection strings.",
            "    required: false",
            "  database_version:",
            "    description:",
            "    - The database engine type and version. For First Generation instances, can be",
            "      MYSQL_5_5, or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or",
            "      MYSQL_5_7. Defaults to MYSQL_5_6.",
            "    - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be",
            "      changed after instance creation.'",
            "    required: false",
            "    choices:",
            "    - MYSQL_5_5",
            "    - MYSQL_5_6",
            "    - MYSQL_5_7",
            "    - POSTGRES_9_6",
            "  failover_replica:",
            "    description:",
            "    - The name and status of the failover replica. This property is applicable only",
            "      to Second Generation instances.",
            "    required: false",
            "    suboptions:",
            "      name:",
            "        description:",
            "        - The name of the failover replica. If specified at instance creation, a failover",
            "          replica is created for the instance. The name doesn't include the project",
            "          ID. This property is applicable only to Second Generation instances.",
            "        required: false",
            "  instance_type:",
            "    description:",
            "    - The instance type. This can be one of the following.",
            "    - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "    - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "    - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "    required: false",
            "    choices:",
            "    - CLOUD_SQL_INSTANCE",
            "    - ON_PREMISES_INSTANCE",
            "    - READ_REPLICA_INSTANCE",
            "  ipv6_address:",
            "    description:",
            "    - The IPv6 address assigned to the instance. This property is applicable only",
            "      to First Generation instances.",
            "    required: false",
            "  master_instance_name:",
            "    description:",
            "    - The name of the instance which will act as master in the replication setup.",
            "    required: false",
            "  max_disk_size:",
            "    description:",
            "    - The maximum disk size of the instance in bytes.",
            "    required: false",
            "  name:",
            "    description:",
            "    - Name of the Cloud SQL instance. This does not include the project ID.",
            "    required: true",
            "  region:",
            "    description:",
            "    - The geographical region. Defaults to us-central or us-central1 depending on",
            "      the instance type (First Generation or Second Generation/PostgreSQL).",
            "    required: false",
            "  replica_configuration:",
            "    description:",
            "    - Configuration specific to failover replicas and read replicas.",
            "    required: false",
            "    suboptions:",
            "      failover_target:",
            "        description:",
            "        - Specifies if the replica is the failover target. If the field is set to",
            "          true the replica will be designated as a failover replica.",
            "        - In case the master instance fails, the replica instance will be promoted",
            "          as the new master instance.",
            "        - Only one replica can be specified as failover target, and the replica has",
            "          to be in different zone with the master instance.",
            "        required: false",
            "        type: bool",
            "      mysql_replica_configuration:",
            "        description:",
            "        - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "          Replication configuration information such as the username, password, certificates,",
            "          and keys are not stored in the instance metadata. The configuration information",
            "          is used only to set up the replication connection and is stored by MySQL",
            "          in a file named master.info in the data directory.",
            "        required: false",
            "        suboptions:",
            "          ca_certificate:",
            "            description:",
            "            - PEM representation of the trusted CA's x509 certificate.",
            "            required: false",
            "          client_certificate:",
            "            description:",
            "            - PEM representation of the slave's x509 certificate .",
            "            required: false",
            "          client_key:",
            "            description:",
            "            - PEM representation of the slave's private key. The corresponding public",
            "              key is encoded in the client's certificate.",
            "            required: false",
            "          connect_retry_interval:",
            "            description:",
            "            - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "            required: false",
            "          dump_file_path:",
            "            description:",
            "            - Path to a SQL dump file in Google Cloud Storage from which the slave",
            "              instance is to be created. The URI is in the form gs://bucketName/fileName.",
            "              Compressed gzip files (.gz) are also supported. Dumps should have the",
            "              binlog co-ordinates from which replication should begin. This can be",
            "              accomplished by setting --master-data to 1 when using mysqldump.",
            "            required: false",
            "          master_heartbeat_period:",
            "            description:",
            "            - Interval in milliseconds between replication heartbeats.",
            "            required: false",
            "          password:",
            "            description:",
            "            - The password for the replication connection.",
            "            required: false",
            "          ssl_cipher:",
            "            description:",
            "            - A list of permissible ciphers to use for SSL encryption.",
            "            required: false",
            "          username:",
            "            description:",
            "            - The username for the replication connection.",
            "            required: false",
            "          verify_server_certificate:",
            "            description:",
            "            - Whether or not to check the master's Common Name value in the certificate",
            "              that it sends during the SSL handshake.",
            "            required: false",
            "            type: bool",
            "      replica_names:",
            "        description:",
            "        - The replicas of the instance.",
            "        required: false",
            "      service_account_email_address:",
            "        description:",
            "        - The service account email address assigned to the instance. This property",
            "          is applicable only to Second Generation instances.",
            "        required: false",
            "  settings:",
            "    description:",
            "    - The user settings.",
            "    required: false",
            "    suboptions:",
            "      ip_configuration:",
            "        description:",
            "        - The settings for IP Management. This allows to enable or disable the instance",
            "          IP and manage which external networks can connect to the instance. The IPv4",
            "          address cannot be disabled for Second Generation instances.",
            "        required: false",
            "        suboptions:",
            "          ipv4_enabled:",
            "            description:",
            "            - Whether the instance should be assigned an IP address or not.",
            "            required: false",
            "            type: bool",
            "          authorized_networks:",
            "            description:",
            "            - The list of external networks that are allowed to connect to the instance",
            "              using the IP. In CIDR notation, also known as 'slash' notation (e.g.",
            "              192.168.100.0/24).",
            "            required: false",
            "            suboptions:",
            "              expiration_time:",
            "                description:",
            "                - The time when this access control entry expires in RFC 3339 format,",
            "                  for example 2012-11-15T16:19:00.094Z.",
            "                required: false",
            "              name:",
            "                description:",
            "                - An optional label to identify this entry.",
            "                required: false",
            "              value:",
            "                description:",
            "                - The whitelisted value for the access control list. For example,",
            "                  to grant access to a client from an external IP (IPv4 or IPv6) address",
            "                  or subnet, use that address or subnet here.",
            "                required: false",
            "          require_ssl:",
            "            description:",
            "            - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "              over IP.",
            "            required: false",
            "            type: bool",
            "      tier:",
            "        description:",
            "        - The tier or machine type for this instance, for example db-n1-standard-1.",
            "          For MySQL instances, this field determines whether the instance is Second",
            "          Generation (recommended) or First Generation.",
            "        required: false",
            "      availability_type:",
            "        description:",
            "        - The availabilityType define if your postgres instance is run zonal or regional.",
            "        required: false",
            "        choices:",
            "        - ZONAL",
            "        - REGIONAL",
            "      backup_configuration:",
            "        description:",
            "        - The daily backup configuration for the instance.",
            "        required: false",
            "        suboptions:",
            "          enabled:",
            "            description:",
            "            - Enable Autobackup for your instance.",
            "            required: false",
            "            type: bool",
            "          binary_log_enabled:",
            "            description:",
            "            - Whether binary log is enabled. If backup configuration is disabled,",
            "              binary log must be disabled as well. MySQL only.",
            "            required: false",
            "            type: bool",
            "          start_time:",
            "            description:",
            "            - Define the backup start time in UTC (HH:MM) .",
            "            required: false",
            "extends_documentation_fragment: gcp",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create a instance",
            "  gcp_sql_instance:",
            "    name: \"{{resource_name}}-2\"",
            "    settings:",
            "      ip_configuration:",
            "        authorized_networks:",
            "        - name: google dns server",
            "          value: 8.8.8.8/32",
            "      tier: db-n1-standard-1",
            "    region: us-central1",
            "    project: test_project",
            "    auth_kind: serviceaccount",
            "    service_account_file: \"/tmp/auth.pem\"",
            "    state: present",
            "'''",
            "",
            "RETURN = '''",
            "backendType:",
            "  description:",
            "  - \"* FIRST_GEN: First Generation instance. MySQL only.\"",
            "  - \"* SECOND_GEN: Second Generation instance or PostgreSQL instance.\"",
            "  - \"* EXTERNAL: A database server that is not managed by Google.\"",
            "  returned: success",
            "  type: str",
            "connectionName:",
            "  description:",
            "  - Connection name of the Cloud SQL instance used in connection strings.",
            "  returned: success",
            "  type: str",
            "databaseVersion:",
            "  description:",
            "  - The database engine type and version. For First Generation instances, can be MYSQL_5_5,",
            "    or MYSQL_5_6. For Second Generation instances, can be MYSQL_5_6 or MYSQL_5_7.",
            "    Defaults to MYSQL_5_6.",
            "  - 'PostgreSQL instances: POSTGRES_9_6 The databaseVersion property can not be changed",
            "    after instance creation.'",
            "  returned: success",
            "  type: str",
            "failoverReplica:",
            "  description:",
            "  - The name and status of the failover replica. This property is applicable only",
            "    to Second Generation instances.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    available:",
            "      description:",
            "      - The availability status of the failover replica. A false status indicates",
            "        that the failover replica is out of sync. The master can only failover to",
            "        the failover replica when the status is true.",
            "      returned: success",
            "      type: bool",
            "    name:",
            "      description:",
            "      - The name of the failover replica. If specified at instance creation, a failover",
            "        replica is created for the instance. The name doesn't include the project",
            "        ID. This property is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "instanceType:",
            "  description:",
            "  - The instance type. This can be one of the following.",
            "  - \"* CLOUD_SQL_INSTANCE: A Cloud SQL instance that is not replicating from a master.\"",
            "  - \"* ON_PREMISES_INSTANCE: An instance running on the customer's premises.\"",
            "  - \"* READ_REPLICA_INSTANCE: A Cloud SQL instance configured as a read-replica.\"",
            "  returned: success",
            "  type: str",
            "ipAddresses:",
            "  description:",
            "  - The assigned IP addresses for the instance.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    ipAddress:",
            "      description:",
            "      - The IP address assigned.",
            "      returned: success",
            "      type: str",
            "    timeToRetire:",
            "      description:",
            "      - The due time for this IP to be retired in RFC 3339 format, for example 2012-11-15T16:19:00.094Z.",
            "        This field is only available when the IP is scheduled to be retired.",
            "      returned: success",
            "      type: str",
            "    type:",
            "      description:",
            "      - The type of this IP address. A PRIMARY address is an address that can accept",
            "        incoming connections. An OUTGOING address is the source address of connections",
            "        originating from the instance, if supported.",
            "      returned: success",
            "      type: str",
            "ipv6Address:",
            "  description:",
            "  - The IPv6 address assigned to the instance. This property is applicable only to",
            "    First Generation instances.",
            "  returned: success",
            "  type: str",
            "masterInstanceName:",
            "  description:",
            "  - The name of the instance which will act as master in the replication setup.",
            "  returned: success",
            "  type: str",
            "maxDiskSize:",
            "  description:",
            "  - The maximum disk size of the instance in bytes.",
            "  returned: success",
            "  type: int",
            "name:",
            "  description:",
            "  - Name of the Cloud SQL instance. This does not include the project ID.",
            "  returned: success",
            "  type: str",
            "region:",
            "  description:",
            "  - The geographical region. Defaults to us-central or us-central1 depending on the",
            "    instance type (First Generation or Second Generation/PostgreSQL).",
            "  returned: success",
            "  type: str",
            "replicaConfiguration:",
            "  description:",
            "  - Configuration specific to failover replicas and read replicas.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    failoverTarget:",
            "      description:",
            "      - Specifies if the replica is the failover target. If the field is set to true",
            "        the replica will be designated as a failover replica.",
            "      - In case the master instance fails, the replica instance will be promoted as",
            "        the new master instance.",
            "      - Only one replica can be specified as failover target, and the replica has",
            "        to be in different zone with the master instance.",
            "      returned: success",
            "      type: bool",
            "    mysqlReplicaConfiguration:",
            "      description:",
            "      - MySQL specific configuration when replicating from a MySQL on-premises master.",
            "        Replication configuration information such as the username, password, certificates,",
            "        and keys are not stored in the instance metadata. The configuration information",
            "        is used only to set up the replication connection and is stored by MySQL in",
            "        a file named master.info in the data directory.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        caCertificate:",
            "          description:",
            "          - PEM representation of the trusted CA's x509 certificate.",
            "          returned: success",
            "          type: str",
            "        clientCertificate:",
            "          description:",
            "          - PEM representation of the slave's x509 certificate .",
            "          returned: success",
            "          type: str",
            "        clientKey:",
            "          description:",
            "          - PEM representation of the slave's private key. The corresponding public",
            "            key is encoded in the client's certificate.",
            "          returned: success",
            "          type: str",
            "        connectRetryInterval:",
            "          description:",
            "          - Seconds to wait between connect retries. MySQL's default is 60 seconds.",
            "          returned: success",
            "          type: int",
            "        dumpFilePath:",
            "          description:",
            "          - Path to a SQL dump file in Google Cloud Storage from which the slave instance",
            "            is to be created. The URI is in the form gs://bucketName/fileName. Compressed",
            "            gzip files (.gz) are also supported. Dumps should have the binlog co-ordinates",
            "            from which replication should begin. This can be accomplished by setting",
            "            --master-data to 1 when using mysqldump.",
            "          returned: success",
            "          type: str",
            "        masterHeartbeatPeriod:",
            "          description:",
            "          - Interval in milliseconds between replication heartbeats.",
            "          returned: success",
            "          type: int",
            "        password:",
            "          description:",
            "          - The password for the replication connection.",
            "          returned: success",
            "          type: str",
            "        sslCipher:",
            "          description:",
            "          - A list of permissible ciphers to use for SSL encryption.",
            "          returned: success",
            "          type: str",
            "        username:",
            "          description:",
            "          - The username for the replication connection.",
            "          returned: success",
            "          type: str",
            "        verifyServerCertificate:",
            "          description:",
            "          - Whether or not to check the master's Common Name value in the certificate",
            "            that it sends during the SSL handshake.",
            "          returned: success",
            "          type: bool",
            "    replicaNames:",
            "      description:",
            "      - The replicas of the instance.",
            "      returned: success",
            "      type: list",
            "    serviceAccountEmailAddress:",
            "      description:",
            "      - The service account email address assigned to the instance. This property",
            "        is applicable only to Second Generation instances.",
            "      returned: success",
            "      type: str",
            "settings:",
            "  description:",
            "  - The user settings.",
            "  returned: success",
            "  type: complex",
            "  contains:",
            "    ipConfiguration:",
            "      description:",
            "      - The settings for IP Management. This allows to enable or disable the instance",
            "        IP and manage which external networks can connect to the instance. The IPv4",
            "        address cannot be disabled for Second Generation instances.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        ipv4Enabled:",
            "          description:",
            "          - Whether the instance should be assigned an IP address or not.",
            "          returned: success",
            "          type: bool",
            "        authorizedNetworks:",
            "          description:",
            "          - The list of external networks that are allowed to connect to the instance",
            "            using the IP. In CIDR notation, also known as 'slash' notation (e.g. 192.168.100.0/24).",
            "          returned: success",
            "          type: complex",
            "          contains:",
            "            expirationTime:",
            "              description:",
            "              - The time when this access control entry expires in RFC 3339 format,",
            "                for example 2012-11-15T16:19:00.094Z.",
            "              returned: success",
            "              type: str",
            "            name:",
            "              description:",
            "              - An optional label to identify this entry.",
            "              returned: success",
            "              type: str",
            "            value:",
            "              description:",
            "              - The whitelisted value for the access control list. For example, to",
            "                grant access to a client from an external IP (IPv4 or IPv6) address",
            "                or subnet, use that address or subnet here.",
            "              returned: success",
            "              type: str",
            "        requireSsl:",
            "          description:",
            "          - Whether the mysqld should default to 'REQUIRE X509' for users connecting",
            "            over IP.",
            "          returned: success",
            "          type: bool",
            "    tier:",
            "      description:",
            "      - The tier or machine type for this instance, for example db-n1-standard-1.",
            "        For MySQL instances, this field determines whether the instance is Second",
            "        Generation (recommended) or First Generation.",
            "      returned: success",
            "      type: str",
            "    availabilityType:",
            "      description:",
            "      - The availabilityType define if your postgres instance is run zonal or regional.",
            "      returned: success",
            "      type: str",
            "    backupConfiguration:",
            "      description:",
            "      - The daily backup configuration for the instance.",
            "      returned: success",
            "      type: complex",
            "      contains:",
            "        enabled:",
            "          description:",
            "          - Enable Autobackup for your instance.",
            "          returned: success",
            "          type: bool",
            "        binaryLogEnabled:",
            "          description:",
            "          - Whether binary log is enabled. If backup configuration is disabled, binary",
            "            log must be disabled as well. MySQL only.",
            "          returned: success",
            "          type: bool",
            "        startTime:",
            "          description:",
            "          - Define the backup start time in UTC (HH:MM) .",
            "          returned: success",
            "          type: str",
            "    settingsVersion:",
            "      description:",
            "      - The version of instance settings. This is a required field for update method",
            "        to make sure concurrent updates are handled properly. During update, use the",
            "        most recent settingsVersion value for this instance and do not try to update",
            "        this value.",
            "      returned: success",
            "      type: int",
            "'''",
            "",
            "################################################################################",
            "# Imports",
            "################################################################################",
            "",
            "from ansible.module_utils.gcp_utils import navigate_hash, GcpSession, GcpModule, GcpRequest, remove_nones_from_dict, replace_resource_dict",
            "import json",
            "import time",
            "",
            "################################################################################",
            "# Main",
            "################################################################################",
            "",
            "",
            "def main():",
            "    \"\"\"Main function\"\"\"",
            "",
            "    module = GcpModule(",
            "        argument_spec=dict(",
            "            state=dict(default='present', choices=['present', 'absent'], type='str'),",
            "            backend_type=dict(type='str', choices=['FIRST_GEN', 'SECOND_GEN', 'EXTERNAL']),",
            "            connection_name=dict(type='str'),",
            "            database_version=dict(type='str', choices=['MYSQL_5_5', 'MYSQL_5_6', 'MYSQL_5_7', 'POSTGRES_9_6']),",
            "            failover_replica=dict(type='dict', options=dict(name=dict(type='str'))),",
            "            instance_type=dict(type='str', choices=['CLOUD_SQL_INSTANCE', 'ON_PREMISES_INSTANCE', 'READ_REPLICA_INSTANCE']),",
            "            ipv6_address=dict(type='str'),",
            "            master_instance_name=dict(type='str'),",
            "            max_disk_size=dict(type='int'),",
            "            name=dict(required=True, type='str'),",
            "            region=dict(type='str'),",
            "            replica_configuration=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    failover_target=dict(type='bool'),",
            "                    mysql_replica_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ca_certificate=dict(type='str'),",
            "                            client_certificate=dict(type='str'),",
            "                            client_key=dict(type='str', no_log=True),",
            "                            connect_retry_interval=dict(type='int'),",
            "                            dump_file_path=dict(type='str'),",
            "                            master_heartbeat_period=dict(type='int'),",
            "                            password=dict(type='str'),",
            "                            ssl_cipher=dict(type='str'),",
            "                            username=dict(type='str'),",
            "                            verify_server_certificate=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    replica_names=dict(type='list', elements='str'),",
            "                    service_account_email_address=dict(type='str'),",
            "                ),",
            "            ),",
            "            settings=dict(",
            "                type='dict',",
            "                options=dict(",
            "                    ip_configuration=dict(",
            "                        type='dict',",
            "                        options=dict(",
            "                            ipv4_enabled=dict(type='bool'),",
            "                            authorized_networks=dict(",
            "                                type='list', elements='dict', options=dict(expiration_time=dict(type='str'), name=dict(type='str'), value=dict(type='str'))",
            "                            ),",
            "                            require_ssl=dict(type='bool'),",
            "                        ),",
            "                    ),",
            "                    tier=dict(type='str'),",
            "                    availability_type=dict(type='str', choices=['ZONAL', 'REGIONAL']),",
            "                    backup_configuration=dict(",
            "                        type='dict', options=dict(enabled=dict(type='bool'), binary_log_enabled=dict(type='bool'), start_time=dict(type='str'))",
            "                    ),",
            "                ),",
            "            ),",
            "        )",
            "    )",
            "",
            "    if not module.params['scopes']:",
            "        module.params['scopes'] = ['https://www.googleapis.com/auth/sqlservice.admin']",
            "",
            "    state = module.params['state']",
            "    kind = 'sql#instance'",
            "",
            "    fetch = fetch_resource(module, self_link(module), kind)",
            "    changed = False",
            "",
            "    if fetch:",
            "        if state == 'present':",
            "            if is_different(module, fetch):",
            "                update(module, self_link(module), kind, fetch)",
            "                fetch = fetch_resource(module, self_link(module), kind)",
            "                changed = True",
            "        else:",
            "            delete(module, self_link(module), kind, fetch)",
            "            fetch = {}",
            "            changed = True",
            "    else:",
            "        if state == 'present':",
            "            fetch = create(module, collection(module), kind)",
            "            changed = True",
            "        else:",
            "            fetch = {}",
            "",
            "    fetch.update({'changed': changed})",
            "",
            "    module.exit_json(**fetch)",
            "",
            "",
            "def create(module, link, kind):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.post(link, resource_to_request(module)))",
            "",
            "",
            "def update(module, link, kind, fetch):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.put(link, resource_to_request(module)))",
            "",
            "",
            "def delete(module, link, kind, fetch):",
            "    auth = GcpSession(module, 'sql')",
            "    return wait_for_operation(module, auth.delete(link))",
            "",
            "",
            "def resource_to_request(module):",
            "    request = {",
            "        u'kind': 'sql#instance',",
            "        u'backendType': module.params.get('backend_type'),",
            "        u'connectionName': module.params.get('connection_name'),",
            "        u'databaseVersion': module.params.get('database_version'),",
            "        u'failoverReplica': InstanceFailoverreplica(module.params.get('failover_replica', {}), module).to_request(),",
            "        u'instanceType': module.params.get('instance_type'),",
            "        u'ipv6Address': module.params.get('ipv6_address'),",
            "        u'masterInstanceName': module.params.get('master_instance_name'),",
            "        u'maxDiskSize': module.params.get('max_disk_size'),",
            "        u'name': module.params.get('name'),",
            "        u'region': module.params.get('region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(module.params.get('replica_configuration', {}), module).to_request(),",
            "        u'settings': InstanceSettings(module.params.get('settings', {}), module).to_request(),",
            "    }",
            "    return_vals = {}",
            "    for k, v in request.items():",
            "        if v or v is False:",
            "            return_vals[k] = v",
            "",
            "    return return_vals",
            "",
            "",
            "def fetch_resource(module, link, kind, allow_not_found=True):",
            "    auth = GcpSession(module, 'sql')",
            "    return return_if_object(module, auth.get(link), kind, allow_not_found)",
            "",
            "",
            "def self_link(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances/{name}\".format(**module.params)",
            "",
            "",
            "def collection(module):",
            "    return \"https://www.googleapis.com/sql/v1beta4/projects/{project}/instances\".format(**module.params)",
            "",
            "",
            "def return_if_object(module, response, kind, allow_not_found=False):",
            "    # If not found, return nothing.",
            "    if allow_not_found and response.status_code == 404:",
            "        return None",
            "",
            "    # If no content, return nothing.",
            "    if response.status_code == 204:",
            "        return None",
            "",
            "    # SQL only: return on 403 if not exist",
            "    if allow_not_found and response.status_code == 403:",
            "        return None",
            "",
            "    try:",
            "        result = response.json()",
            "    except getattr(json.decoder, 'JSONDecodeError', ValueError) as inst:",
            "        module.fail_json(msg=\"Invalid JSON response with error: %s\" % inst)",
            "",
            "    if navigate_hash(result, ['error', 'errors']):",
            "        module.fail_json(msg=navigate_hash(result, ['error', 'errors']))",
            "",
            "    return result",
            "",
            "",
            "def is_different(module, response):",
            "    request = resource_to_request(module)",
            "    response = response_to_hash(module, response)",
            "",
            "    # Remove all output-only from response.",
            "    response_vals = {}",
            "    for k, v in response.items():",
            "        if k in request:",
            "            response_vals[k] = v",
            "",
            "    request_vals = {}",
            "    for k, v in request.items():",
            "        if k in response:",
            "            request_vals[k] = v",
            "",
            "    return GcpRequest(request_vals) != GcpRequest(response_vals)",
            "",
            "",
            "# Remove unnecessary properties from the response.",
            "# This is for doing comparisons with Ansible's current parameters.",
            "def response_to_hash(module, response):",
            "    return {",
            "        u'backendType': response.get(u'backendType'),",
            "        u'connectionName': response.get(u'connectionName'),",
            "        u'databaseVersion': response.get(u'databaseVersion'),",
            "        u'failoverReplica': InstanceFailoverreplica(response.get(u'failoverReplica', {}), module).from_response(),",
            "        u'instanceType': response.get(u'instanceType'),",
            "        u'ipAddresses': InstanceIpaddressesArray(response.get(u'ipAddresses', []), module).from_response(),",
            "        u'ipv6Address': response.get(u'ipv6Address'),",
            "        u'masterInstanceName': response.get(u'masterInstanceName'),",
            "        u'maxDiskSize': response.get(u'maxDiskSize'),",
            "        u'name': response.get(u'name'),",
            "        u'region': response.get(u'region'),",
            "        u'replicaConfiguration': InstanceReplicaconfiguration(response.get(u'replicaConfiguration', {}), module).from_response(),",
            "        u'settings': InstanceSettings(response.get(u'settings', {}), module).from_response(),",
            "    }",
            "",
            "",
            "def async_op_url(module, extra_data=None):",
            "    if extra_data is None:",
            "        extra_data = {}",
            "    url = \"https://www.googleapis.com/sql/v1beta4/projects/{project}/operations/{op_id}\"",
            "    combined = extra_data.copy()",
            "    combined.update(module.params)",
            "    return url.format(**combined)",
            "",
            "",
            "def wait_for_operation(module, response):",
            "    op_result = return_if_object(module, response, 'sql#operation')",
            "    if op_result is None:",
            "        return {}",
            "    status = navigate_hash(op_result, ['status'])",
            "    wait_done = wait_for_completion(status, op_result, module)",
            "    return fetch_resource(module, navigate_hash(wait_done, ['targetLink']), 'sql#instance')",
            "",
            "",
            "def wait_for_completion(status, op_result, module):",
            "    op_id = navigate_hash(op_result, ['name'])",
            "    op_uri = async_op_url(module, {'op_id': op_id})",
            "    while status != 'DONE':",
            "        raise_if_errors(op_result, ['error', 'errors'], module)",
            "        time.sleep(1.0)",
            "        op_result = fetch_resource(module, op_uri, 'sql#operation', False)",
            "        status = navigate_hash(op_result, ['status'])",
            "    return op_result",
            "",
            "",
            "def raise_if_errors(response, err_path, module):",
            "    errors = navigate_hash(response, err_path)",
            "    if errors is not None:",
            "        module.fail_json(msg=errors)",
            "",
            "",
            "class InstanceFailoverreplica(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict({u'name': self.request.get('name')})",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict({u'name': self.request.get(u'name')})",
            "",
            "",
            "class InstanceIpaddressesArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get('ip_address'), u'timeToRetire': item.get('time_to_retire'), u'type': item.get('type')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'ipAddress': item.get(u'ipAddress'), u'timeToRetire': item.get(u'timeToRetire'), u'type': item.get(u'type')})",
            "",
            "",
            "class InstanceReplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get('failover_target'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(self.request.get('mysql_replica_configuration', {}), self.module).to_request(),",
            "                u'replicaNames': self.request.get('replica_names'),",
            "                u'serviceAccountEmailAddress': self.request.get('service_account_email_address'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'failoverTarget': self.request.get(u'failoverTarget'),",
            "                u'mysqlReplicaConfiguration': InstanceMysqlreplicaconfiguration(",
            "                    self.request.get(u'mysqlReplicaConfiguration', {}), self.module",
            "                ).from_response(),",
            "                u'replicaNames': self.request.get(u'replicaNames'),",
            "                u'serviceAccountEmailAddress': self.request.get(u'serviceAccountEmailAddress'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceMysqlreplicaconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get('ca_certificate'),",
            "                u'clientCertificate': self.request.get('client_certificate'),",
            "                u'clientKey': self.request.get('client_key'),",
            "                u'connectRetryInterval': self.request.get('connect_retry_interval'),",
            "                u'dumpFilePath': self.request.get('dump_file_path'),",
            "                u'masterHeartbeatPeriod': self.request.get('master_heartbeat_period'),",
            "                u'password': self.request.get('password'),",
            "                u'sslCipher': self.request.get('ssl_cipher'),",
            "                u'username': self.request.get('username'),",
            "                u'verifyServerCertificate': self.request.get('verify_server_certificate'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'caCertificate': self.request.get(u'caCertificate'),",
            "                u'clientCertificate': self.request.get(u'clientCertificate'),",
            "                u'clientKey': self.request.get(u'clientKey'),",
            "                u'connectRetryInterval': self.request.get(u'connectRetryInterval'),",
            "                u'dumpFilePath': self.request.get(u'dumpFilePath'),",
            "                u'masterHeartbeatPeriod': self.request.get(u'masterHeartbeatPeriod'),",
            "                u'password': self.request.get(u'password'),",
            "                u'sslCipher': self.request.get(u'sslCipher'),",
            "                u'username': self.request.get(u'username'),",
            "                u'verifyServerCertificate': self.request.get(u'verifyServerCertificate'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceSettings(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get('ip_configuration', {}), self.module).to_request(),",
            "                u'tier': self.request.get('tier'),",
            "                u'availabilityType': self.request.get('availability_type'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get('backup_configuration', {}), self.module).to_request(),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipConfiguration': InstanceIpconfiguration(self.request.get(u'ipConfiguration', {}), self.module).from_response(),",
            "                u'tier': self.request.get(u'tier'),",
            "                u'availabilityType': self.request.get(u'availabilityType'),",
            "                u'backupConfiguration': InstanceBackupconfiguration(self.request.get(u'backupConfiguration', {}), self.module).from_response(),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceIpconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get('ipv4_enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get('authorized_networks', []), self.module).to_request(),",
            "                u'requireSsl': self.request.get('require_ssl'),",
            "            }",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {",
            "                u'ipv4Enabled': self.request.get(u'ipv4Enabled'),",
            "                u'authorizedNetworks': InstanceAuthorizednetworksArray(self.request.get(u'authorizedNetworks', []), self.module).from_response(),",
            "                u'requireSsl': self.request.get(u'requireSsl'),",
            "            }",
            "        )",
            "",
            "",
            "class InstanceAuthorizednetworksArray(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = []",
            "",
            "    def to_request(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._request_for_item(item))",
            "        return items",
            "",
            "    def from_response(self):",
            "        items = []",
            "        for item in self.request:",
            "            items.append(self._response_from_item(item))",
            "        return items",
            "",
            "    def _request_for_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get('expiration_time'), u'name': item.get('name'), u'value': item.get('value')})",
            "",
            "    def _response_from_item(self, item):",
            "        return remove_nones_from_dict({u'expirationTime': item.get(u'expirationTime'), u'name': item.get(u'name'), u'value': item.get(u'value')})",
            "",
            "",
            "class InstanceBackupconfiguration(object):",
            "    def __init__(self, request, module):",
            "        self.module = module",
            "        if request:",
            "            self.request = request",
            "        else:",
            "            self.request = {}",
            "",
            "    def to_request(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get('enabled'), u'binaryLogEnabled': self.request.get('binary_log_enabled'), u'startTime': self.request.get('start_time')}",
            "        )",
            "",
            "    def from_response(self):",
            "        return remove_nones_from_dict(",
            "            {u'enabled': self.request.get(u'enabled'), u'binaryLogEnabled': self.request.get(u'binaryLogEnabled'), u'startTime': self.request.get(u'startTime')}",
            "        )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "629": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/misc/ovirt.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 380,
                "afterPatchRowNumber": 380,
                "PatchRowcode": "             instance_gateway=dict(type='str', aliases=['gateway']),"
            },
            "1": {
                "beforePatchRowNumber": 381,
                "afterPatchRowNumber": 381,
                "PatchRowcode": "             instance_domain=dict(type='str', aliases=['domain']),"
            },
            "2": {
                "beforePatchRowNumber": 382,
                "afterPatchRowNumber": 382,
                "PatchRowcode": "             instance_dns=dict(type='str', aliases=['dns']),"
            },
            "3": {
                "beforePatchRowNumber": 383,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            instance_rootpw=dict(type='str', aliases=['rootpw']),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 383,
                "PatchRowcode": "+            instance_rootpw=dict(type='str', aliases=['rootpw'], no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "             instance_key=dict(type='str', aliases=['key']),"
            },
            "6": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "             sdomain=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "             region=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright: (c) 2013, Vincent Van der Kussen <vincent at vanderkussen.org>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: ovirt",
            "author:",
            "- Vincent Van der Kussen (@vincentvdk)",
            "short_description: oVirt/RHEV platform management",
            "description:",
            "    - This module only supports oVirt/RHEV version 3. A newer module M(ovirt_vm) supports oVirt/RHV version 4.",
            "    - Allows you to create new instances, either from scratch or an image, in addition to deleting or stopping instances on the oVirt/RHEV platform.",
            "version_added: \"1.4\"",
            "options:",
            "  user:",
            "    description:",
            "     - The user to authenticate with.",
            "    required: true",
            "  url:",
            "    description:",
            "     - The url of the oVirt instance.",
            "    required: true",
            "  instance_name:",
            "    description:",
            "     - The name of the instance to use.",
            "    required: true",
            "    aliases: [ vmname ]",
            "  password:",
            "    description:",
            "     - Password of the user to authenticate with.",
            "    required: true",
            "  image:",
            "    description:",
            "     - The template to use for the instance.",
            "  resource_type:",
            "    description:",
            "     - Whether you want to deploy an image or create an instance from scratch.",
            "    choices: [ new, template ]",
            "  zone:",
            "    description:",
            "     - Deploy the image to this oVirt cluster.",
            "  instance_disksize:",
            "    description:",
            "     - Size of the instance's disk in GB.",
            "    aliases: [ vm_disksize]",
            "  instance_cpus:",
            "    description:",
            "     - The instance's number of CPUs.",
            "    default: 1",
            "    aliases: [ vmcpus ]",
            "  instance_nic:",
            "    description:",
            "     - The name of the network interface in oVirt/RHEV.",
            "    aliases: [ vmnic  ]",
            "  instance_network:",
            "    description:",
            "     - The logical network the machine should belong to.",
            "    default: rhevm",
            "    aliases: [ vmnetwork ]",
            "  instance_mem:",
            "    description:",
            "     - The instance's amount of memory in MB.",
            "    aliases: [ vmmem ]",
            "  instance_type:",
            "    description:",
            "     - Define whether the instance is a server, desktop or high_performance.",
            "     - I(high_performance) is supported since Ansible 2.5 and oVirt/RHV 4.2.",
            "    choices: [ desktop, server, high_performance ]",
            "    default: server",
            "    aliases: [ vmtype ]",
            "  disk_alloc:",
            "    description:",
            "     - Define whether disk is thin or preallocated.",
            "    choices: [ preallocated, thin ]",
            "    default: thin",
            "  disk_int:",
            "    description:",
            "     - Interface type of the disk.",
            "    choices: [ ide, virtio ]",
            "    default: virtio",
            "  instance_os:",
            "    description:",
            "     - Type of Operating System.",
            "    aliases: [ vmos ]",
            "  instance_cores:",
            "    description:",
            "     - Define the instance's number of cores.",
            "    default: 1",
            "    aliases: [ vmcores ]",
            "  sdomain:",
            "    description:",
            "     - The Storage Domain where you want to create the instance's disk on.",
            "  region:",
            "    description:",
            "     - The oVirt/RHEV datacenter where you want to deploy to.",
            "  instance_dns:",
            "    description:",
            "     - Define the instance's Primary DNS server.",
            "    aliases: [ dns ]",
            "    version_added: \"2.1\"",
            "  instance_domain:",
            "    description:",
            "     - Define the instance's Domain.",
            "    aliases: [ domain ]",
            "    version_added: \"2.1\"",
            "  instance_hostname:",
            "    description:",
            "     - Define the instance's Hostname.",
            "    aliases: [ hostname ]",
            "    version_added: \"2.1\"",
            "  instance_ip:",
            "    description:",
            "     - Define the instance's IP.",
            "    aliases: [ ip ]",
            "    version_added: \"2.1\"",
            "  instance_netmask:",
            "    description:",
            "     - Define the instance's Netmask.",
            "    aliases: [ netmask ]",
            "    version_added: \"2.1\"",
            "  instance_rootpw:",
            "    description:",
            "     - Define the instance's Root password.",
            "    aliases: [ rootpw ]",
            "    version_added: \"2.1\"",
            "  instance_key:",
            "    description:",
            "     - Define the instance's Authorized key.",
            "    aliases: [ key ]",
            "    version_added: \"2.1\"",
            "  state:",
            "    description:",
            "     - Create, terminate or remove instances.",
            "    choices: [ absent, present, restarted, shutdown, started ]",
            "    default: present",
            "requirements:",
            "  - ovirt-engine-sdk-python",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Basic example to provision from image",
            "  ovirt:",
            "    user: admin@internal",
            "    url: https://ovirt.example.com",
            "    instance_name: ansiblevm04",
            "    password: secret",
            "    image: centos_64",
            "    zone: cluster01",
            "    resource_type: template",
            "",
            "- name: Full example to create new instance from scratch",
            "  ovirt:",
            "    instance_name: testansible",
            "    resource_type: new",
            "    instance_type: server",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    instance_disksize: 10",
            "    zone: cluster01",
            "    region: datacenter1",
            "    instance_cpus: 1",
            "    instance_nic: nic1",
            "    instance_network: rhevm",
            "    instance_mem: 1000",
            "    disk_alloc: thin",
            "    sdomain: FIBER01",
            "    instance_cores: 1",
            "    instance_os: rhel_6x64",
            "    disk_int: virtio",
            "",
            "- name: Stopping an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: stopped",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an instance with cloud init information",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    hostname: testansible",
            "    domain: ansible.local",
            "    ip: 192.0.2.100",
            "    netmask: 255.255.255.0",
            "    gateway: 192.0.2.1",
            "    rootpw: bigsecret",
            "'''",
            "",
            "import time",
            "",
            "try:",
            "    from ovirtsdk.api import API",
            "    from ovirtsdk.xml import params",
            "    HAS_OVIRTSDK = True",
            "except ImportError:",
            "    HAS_OVIRTSDK = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# create connection with API",
            "#",
            "def conn(url, user, password):",
            "    api = API(url=url, username=user, password=password, insecure=True)",
            "    try:",
            "        value = api.test()",
            "    except Exception:",
            "        raise Exception(\"error connecting to the oVirt API\")",
            "    return api",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# Create VM from scratch",
            "def create_vm(conn, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int):",
            "    if vmdisk_alloc == 'thin':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=True, interface=vmdisk_int, type_=\"System\",",
            "                             format='cow',",
            "                             storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name='nic1', network=network_net, interface='virtio')",
            "    elif vmdisk_alloc == 'preallocated':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=False, interface=vmdisk_int, type_=\"System\",",
            "                             format='raw', storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name=vmnic, network=network_net, interface='virtio')",
            "",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception(\"Error creating VM with specified parameters\")",
            "    vm = conn.vms.get(name=vmname)",
            "    try:",
            "        vm.disks.add(vmdisk)",
            "    except Exception:",
            "        raise Exception(\"Error attaching disk\")",
            "    try:",
            "        vm.nics.add(nic_net1)",
            "    except Exception:",
            "        raise Exception(\"Error adding nic\")",
            "",
            "",
            "# create an instance from a template",
            "def create_vm_template(conn, vmname, image, zone):",
            "    vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), template=conn.templates.get(name=image), disks=params.Disks(clone=True))",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception('error adding template %s' % image)",
            "",
            "",
            "# start instance",
            "def vm_start(conn, vmname, hostname=None, ip=None, netmask=None, gateway=None,",
            "             domain=None, dns=None, rootpw=None, key=None):",
            "    vm = conn.vms.get(name=vmname)",
            "    use_cloud_init = False",
            "    nics = None",
            "    nic = None",
            "    if hostname or ip or netmask or gateway or domain or dns or rootpw or key:",
            "        use_cloud_init = True",
            "    if ip and netmask and gateway:",
            "        ipinfo = params.IP(address=ip, netmask=netmask, gateway=gateway)",
            "        nic = params.GuestNicConfiguration(name='eth0', boot_protocol='STATIC', ip=ipinfo, on_boot=True)",
            "        nics = params.Nics()",
            "    nics = params.GuestNicsConfiguration(nic_configuration=[nic])",
            "    initialization = params.Initialization(regenerate_ssh_keys=True, host_name=hostname, domain=domain, user_name='root',",
            "                                           root_password=rootpw, nic_configurations=nics, dns_servers=dns,",
            "                                           authorized_ssh_keys=key)",
            "    action = params.Action(use_cloud_init=use_cloud_init, vm=params.VM(initialization=initialization))",
            "    vm.start(action=action)",
            "",
            "",
            "# Stop instance",
            "def vm_stop(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "",
            "",
            "# restart instance",
            "def vm_restart(conn, vmname):",
            "    state = vm_status(conn, vmname)",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "    while conn.vms.get(vmname).get_status().get_state() != 'down':",
            "        time.sleep(5)",
            "    vm.start()",
            "",
            "",
            "# remove an instance",
            "def vm_remove(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.delete()",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# VM statuses",
            "#",
            "# Get the VMs status",
            "def vm_status(conn, vmname):",
            "    status = conn.vms.get(name=vmname).status.state",
            "    return status",
            "",
            "",
            "# Get VM object and return it's name if object exists",
            "def get_vm(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    if vm is None:",
            "        name = \"empty\"",
            "    else:",
            "        name = vm.get_name()",
            "    return name",
            "",
            "# ------------------------------------------------------------------- #",
            "# Hypervisor operations",
            "#",
            "# not available yet",
            "# ------------------------------------------------------------------- #",
            "# Main",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            state=dict(type='str', default='present', choices=['absent', 'present', 'restart', 'shutdown', 'started']),",
            "            user=dict(type='str', required=True),",
            "            url=dict(type='str', required=True),",
            "            instance_name=dict(type='str', required=True, aliases=['vmname']),",
            "            password=dict(type='str', required=True, no_log=True),",
            "            image=dict(type='str'),",
            "            resource_type=dict(type='str', choices=['new', 'template']),",
            "            zone=dict(type='str'),",
            "            instance_disksize=dict(type='str', aliases=['vm_disksize']),",
            "            instance_cpus=dict(type='str', default=1, aliases=['vmcpus']),",
            "            instance_nic=dict(type='str', aliases=['vmnic']),",
            "            instance_network=dict(type='str', default='rhevm', aliases=['vmnetwork']),",
            "            instance_mem=dict(type='str', aliases=['vmmem']),",
            "            instance_type=dict(type='str', default='server', aliases=['vmtype'], choices=['desktop', 'server', 'high_performance']),",
            "            disk_alloc=dict(type='str', default='thin', choices=['preallocated', 'thin']),",
            "            disk_int=dict(type='str', default='virtio', choices=['ide', 'virtio']),",
            "            instance_os=dict(type='str', aliases=['vmos']),",
            "            instance_cores=dict(type='str', default=1, aliases=['vmcores']),",
            "            instance_hostname=dict(type='str', aliases=['hostname']),",
            "            instance_ip=dict(type='str', aliases=['ip']),",
            "            instance_netmask=dict(type='str', aliases=['netmask']),",
            "            instance_gateway=dict(type='str', aliases=['gateway']),",
            "            instance_domain=dict(type='str', aliases=['domain']),",
            "            instance_dns=dict(type='str', aliases=['dns']),",
            "            instance_rootpw=dict(type='str', aliases=['rootpw']),",
            "            instance_key=dict(type='str', aliases=['key']),",
            "            sdomain=dict(type='str'),",
            "            region=dict(type='str'),",
            "        ),",
            "    )",
            "",
            "    if not HAS_OVIRTSDK:",
            "        module.fail_json(msg='ovirtsdk required for this module')",
            "",
            "    state = module.params['state']",
            "    user = module.params['user']",
            "    url = module.params['url']",
            "    vmname = module.params['instance_name']",
            "    password = module.params['password']",
            "    image = module.params['image']  # name of the image to deploy",
            "    resource_type = module.params['resource_type']  # template or from scratch",
            "    zone = module.params['zone']  # oVirt cluster",
            "    vmdisk_size = module.params['instance_disksize']  # disksize",
            "    vmcpus = module.params['instance_cpus']  # number of cpu",
            "    vmnic = module.params['instance_nic']  # network interface",
            "    vmnetwork = module.params['instance_network']  # logical network",
            "    vmmem = module.params['instance_mem']  # mem size",
            "    vmdisk_alloc = module.params['disk_alloc']  # thin, preallocated",
            "    vmdisk_int = module.params['disk_int']  # disk interface virtio or ide",
            "    vmos = module.params['instance_os']  # Operating System",
            "    vmtype = module.params['instance_type']  # server, desktop or high_performance",
            "    vmcores = module.params['instance_cores']  # number of cores",
            "    sdomain = module.params['sdomain']  # storage domain to store disk on",
            "    region = module.params['region']  # oVirt Datacenter",
            "    hostname = module.params['instance_hostname']",
            "    ip = module.params['instance_ip']",
            "    netmask = module.params['instance_netmask']",
            "    gateway = module.params['instance_gateway']",
            "    domain = module.params['instance_domain']",
            "    dns = module.params['instance_dns']",
            "    rootpw = module.params['instance_rootpw']",
            "    key = module.params['instance_key']",
            "    # initialize connection",
            "    try:",
            "        c = conn(url + \"/api\", user, password)",
            "    except Exception as e:",
            "        module.fail_json(msg='%s' % e)",
            "",
            "    if state == 'present':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            if resource_type == 'template':",
            "                try:",
            "                    create_vm_template(c, vmname, image, zone)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from template %s\" % (vmname, image))",
            "            elif resource_type == 'new':",
            "                # FIXME: refactor, use keyword args.",
            "                try:",
            "                    create_vm(c, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from scratch\" % vmname)",
            "            else:",
            "                module.exit_json(changed=False, msg=\"You did not specify a resource type\")",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s already exists\" % vmname)",
            "",
            "    if state == 'started':",
            "        if vm_status(c, vmname) == 'up':",
            "            module.exit_json(changed=False, msg=\"VM %s is already running\" % vmname)",
            "        else:",
            "            # vm_start(c, vmname)",
            "            vm_start(c, vmname, hostname, ip, netmask, gateway, domain, dns, rootpw, key)",
            "            module.exit_json(changed=True, msg=\"VM %s started\" % vmname)",
            "",
            "    if state == 'shutdown':",
            "        if vm_status(c, vmname) == 'down':",
            "            module.exit_json(changed=False, msg=\"VM %s is already shutdown\" % vmname)",
            "        else:",
            "            vm_stop(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is shutting down\" % vmname)",
            "",
            "    if state == 'restart':",
            "        if vm_status(c, vmname) == 'up':",
            "            vm_restart(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is restarted\" % vmname)",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s is not running\" % vmname)",
            "",
            "    if state == 'absent':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            module.exit_json(changed=False, msg=\"VM %s does not exist\" % vmname)",
            "        else:",
            "            vm_remove(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s removed\" % vmname)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright: (c) 2013, Vincent Van der Kussen <vincent at vanderkussen.org>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: ovirt",
            "author:",
            "- Vincent Van der Kussen (@vincentvdk)",
            "short_description: oVirt/RHEV platform management",
            "description:",
            "    - This module only supports oVirt/RHEV version 3. A newer module M(ovirt_vm) supports oVirt/RHV version 4.",
            "    - Allows you to create new instances, either from scratch or an image, in addition to deleting or stopping instances on the oVirt/RHEV platform.",
            "version_added: \"1.4\"",
            "options:",
            "  user:",
            "    description:",
            "     - The user to authenticate with.",
            "    required: true",
            "  url:",
            "    description:",
            "     - The url of the oVirt instance.",
            "    required: true",
            "  instance_name:",
            "    description:",
            "     - The name of the instance to use.",
            "    required: true",
            "    aliases: [ vmname ]",
            "  password:",
            "    description:",
            "     - Password of the user to authenticate with.",
            "    required: true",
            "  image:",
            "    description:",
            "     - The template to use for the instance.",
            "  resource_type:",
            "    description:",
            "     - Whether you want to deploy an image or create an instance from scratch.",
            "    choices: [ new, template ]",
            "  zone:",
            "    description:",
            "     - Deploy the image to this oVirt cluster.",
            "  instance_disksize:",
            "    description:",
            "     - Size of the instance's disk in GB.",
            "    aliases: [ vm_disksize]",
            "  instance_cpus:",
            "    description:",
            "     - The instance's number of CPUs.",
            "    default: 1",
            "    aliases: [ vmcpus ]",
            "  instance_nic:",
            "    description:",
            "     - The name of the network interface in oVirt/RHEV.",
            "    aliases: [ vmnic  ]",
            "  instance_network:",
            "    description:",
            "     - The logical network the machine should belong to.",
            "    default: rhevm",
            "    aliases: [ vmnetwork ]",
            "  instance_mem:",
            "    description:",
            "     - The instance's amount of memory in MB.",
            "    aliases: [ vmmem ]",
            "  instance_type:",
            "    description:",
            "     - Define whether the instance is a server, desktop or high_performance.",
            "     - I(high_performance) is supported since Ansible 2.5 and oVirt/RHV 4.2.",
            "    choices: [ desktop, server, high_performance ]",
            "    default: server",
            "    aliases: [ vmtype ]",
            "  disk_alloc:",
            "    description:",
            "     - Define whether disk is thin or preallocated.",
            "    choices: [ preallocated, thin ]",
            "    default: thin",
            "  disk_int:",
            "    description:",
            "     - Interface type of the disk.",
            "    choices: [ ide, virtio ]",
            "    default: virtio",
            "  instance_os:",
            "    description:",
            "     - Type of Operating System.",
            "    aliases: [ vmos ]",
            "  instance_cores:",
            "    description:",
            "     - Define the instance's number of cores.",
            "    default: 1",
            "    aliases: [ vmcores ]",
            "  sdomain:",
            "    description:",
            "     - The Storage Domain where you want to create the instance's disk on.",
            "  region:",
            "    description:",
            "     - The oVirt/RHEV datacenter where you want to deploy to.",
            "  instance_dns:",
            "    description:",
            "     - Define the instance's Primary DNS server.",
            "    aliases: [ dns ]",
            "    version_added: \"2.1\"",
            "  instance_domain:",
            "    description:",
            "     - Define the instance's Domain.",
            "    aliases: [ domain ]",
            "    version_added: \"2.1\"",
            "  instance_hostname:",
            "    description:",
            "     - Define the instance's Hostname.",
            "    aliases: [ hostname ]",
            "    version_added: \"2.1\"",
            "  instance_ip:",
            "    description:",
            "     - Define the instance's IP.",
            "    aliases: [ ip ]",
            "    version_added: \"2.1\"",
            "  instance_netmask:",
            "    description:",
            "     - Define the instance's Netmask.",
            "    aliases: [ netmask ]",
            "    version_added: \"2.1\"",
            "  instance_rootpw:",
            "    description:",
            "     - Define the instance's Root password.",
            "    aliases: [ rootpw ]",
            "    version_added: \"2.1\"",
            "  instance_key:",
            "    description:",
            "     - Define the instance's Authorized key.",
            "    aliases: [ key ]",
            "    version_added: \"2.1\"",
            "  state:",
            "    description:",
            "     - Create, terminate or remove instances.",
            "    choices: [ absent, present, restarted, shutdown, started ]",
            "    default: present",
            "requirements:",
            "  - ovirt-engine-sdk-python",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Basic example to provision from image",
            "  ovirt:",
            "    user: admin@internal",
            "    url: https://ovirt.example.com",
            "    instance_name: ansiblevm04",
            "    password: secret",
            "    image: centos_64",
            "    zone: cluster01",
            "    resource_type: template",
            "",
            "- name: Full example to create new instance from scratch",
            "  ovirt:",
            "    instance_name: testansible",
            "    resource_type: new",
            "    instance_type: server",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    instance_disksize: 10",
            "    zone: cluster01",
            "    region: datacenter1",
            "    instance_cpus: 1",
            "    instance_nic: nic1",
            "    instance_network: rhevm",
            "    instance_mem: 1000",
            "    disk_alloc: thin",
            "    sdomain: FIBER01",
            "    instance_cores: 1",
            "    instance_os: rhel_6x64",
            "    disk_int: virtio",
            "",
            "- name: Stopping an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: stopped",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an existing instance",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "",
            "- name: Start an instance with cloud init information",
            "  ovirt:",
            "    instance_name: testansible",
            "    state: started",
            "    user: admin@internal",
            "    password: secret",
            "    url: https://ovirt.example.com",
            "    hostname: testansible",
            "    domain: ansible.local",
            "    ip: 192.0.2.100",
            "    netmask: 255.255.255.0",
            "    gateway: 192.0.2.1",
            "    rootpw: bigsecret",
            "'''",
            "",
            "import time",
            "",
            "try:",
            "    from ovirtsdk.api import API",
            "    from ovirtsdk.xml import params",
            "    HAS_OVIRTSDK = True",
            "except ImportError:",
            "    HAS_OVIRTSDK = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# create connection with API",
            "#",
            "def conn(url, user, password):",
            "    api = API(url=url, username=user, password=password, insecure=True)",
            "    try:",
            "        value = api.test()",
            "    except Exception:",
            "        raise Exception(\"error connecting to the oVirt API\")",
            "    return api",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# Create VM from scratch",
            "def create_vm(conn, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int):",
            "    if vmdisk_alloc == 'thin':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=True, interface=vmdisk_int, type_=\"System\",",
            "                             format='cow',",
            "                             storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name='nic1', network=network_net, interface='virtio')",
            "    elif vmdisk_alloc == 'preallocated':",
            "        # define VM params",
            "        vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), os=params.OperatingSystem(type_=vmos),",
            "                             template=conn.templates.get(name=\"Blank\"), memory=1024 * 1024 * int(vmmem),",
            "                             cpu=params.CPU(topology=params.CpuTopology(cores=int(vmcores))), type_=vmtype)",
            "        # define disk params",
            "        vmdisk = params.Disk(size=1024 * 1024 * 1024 * int(vmdisk_size), wipe_after_delete=True, sparse=False, interface=vmdisk_int, type_=\"System\",",
            "                             format='raw', storage_domains=params.StorageDomains(storage_domain=[conn.storagedomains.get(name=sdomain)]))",
            "        # define network parameters",
            "        network_net = params.Network(name=vmnetwork)",
            "        nic_net1 = params.NIC(name=vmnic, network=network_net, interface='virtio')",
            "",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception(\"Error creating VM with specified parameters\")",
            "    vm = conn.vms.get(name=vmname)",
            "    try:",
            "        vm.disks.add(vmdisk)",
            "    except Exception:",
            "        raise Exception(\"Error attaching disk\")",
            "    try:",
            "        vm.nics.add(nic_net1)",
            "    except Exception:",
            "        raise Exception(\"Error adding nic\")",
            "",
            "",
            "# create an instance from a template",
            "def create_vm_template(conn, vmname, image, zone):",
            "    vmparams = params.VM(name=vmname, cluster=conn.clusters.get(name=zone), template=conn.templates.get(name=image), disks=params.Disks(clone=True))",
            "    try:",
            "        conn.vms.add(vmparams)",
            "    except Exception:",
            "        raise Exception('error adding template %s' % image)",
            "",
            "",
            "# start instance",
            "def vm_start(conn, vmname, hostname=None, ip=None, netmask=None, gateway=None,",
            "             domain=None, dns=None, rootpw=None, key=None):",
            "    vm = conn.vms.get(name=vmname)",
            "    use_cloud_init = False",
            "    nics = None",
            "    nic = None",
            "    if hostname or ip or netmask or gateway or domain or dns or rootpw or key:",
            "        use_cloud_init = True",
            "    if ip and netmask and gateway:",
            "        ipinfo = params.IP(address=ip, netmask=netmask, gateway=gateway)",
            "        nic = params.GuestNicConfiguration(name='eth0', boot_protocol='STATIC', ip=ipinfo, on_boot=True)",
            "        nics = params.Nics()",
            "    nics = params.GuestNicsConfiguration(nic_configuration=[nic])",
            "    initialization = params.Initialization(regenerate_ssh_keys=True, host_name=hostname, domain=domain, user_name='root',",
            "                                           root_password=rootpw, nic_configurations=nics, dns_servers=dns,",
            "                                           authorized_ssh_keys=key)",
            "    action = params.Action(use_cloud_init=use_cloud_init, vm=params.VM(initialization=initialization))",
            "    vm.start(action=action)",
            "",
            "",
            "# Stop instance",
            "def vm_stop(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "",
            "",
            "# restart instance",
            "def vm_restart(conn, vmname):",
            "    state = vm_status(conn, vmname)",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.stop()",
            "    while conn.vms.get(vmname).get_status().get_state() != 'down':",
            "        time.sleep(5)",
            "    vm.start()",
            "",
            "",
            "# remove an instance",
            "def vm_remove(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    vm.delete()",
            "",
            "",
            "# ------------------------------------------------------------------- #",
            "# VM statuses",
            "#",
            "# Get the VMs status",
            "def vm_status(conn, vmname):",
            "    status = conn.vms.get(name=vmname).status.state",
            "    return status",
            "",
            "",
            "# Get VM object and return it's name if object exists",
            "def get_vm(conn, vmname):",
            "    vm = conn.vms.get(name=vmname)",
            "    if vm is None:",
            "        name = \"empty\"",
            "    else:",
            "        name = vm.get_name()",
            "    return name",
            "",
            "# ------------------------------------------------------------------- #",
            "# Hypervisor operations",
            "#",
            "# not available yet",
            "# ------------------------------------------------------------------- #",
            "# Main",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            state=dict(type='str', default='present', choices=['absent', 'present', 'restart', 'shutdown', 'started']),",
            "            user=dict(type='str', required=True),",
            "            url=dict(type='str', required=True),",
            "            instance_name=dict(type='str', required=True, aliases=['vmname']),",
            "            password=dict(type='str', required=True, no_log=True),",
            "            image=dict(type='str'),",
            "            resource_type=dict(type='str', choices=['new', 'template']),",
            "            zone=dict(type='str'),",
            "            instance_disksize=dict(type='str', aliases=['vm_disksize']),",
            "            instance_cpus=dict(type='str', default=1, aliases=['vmcpus']),",
            "            instance_nic=dict(type='str', aliases=['vmnic']),",
            "            instance_network=dict(type='str', default='rhevm', aliases=['vmnetwork']),",
            "            instance_mem=dict(type='str', aliases=['vmmem']),",
            "            instance_type=dict(type='str', default='server', aliases=['vmtype'], choices=['desktop', 'server', 'high_performance']),",
            "            disk_alloc=dict(type='str', default='thin', choices=['preallocated', 'thin']),",
            "            disk_int=dict(type='str', default='virtio', choices=['ide', 'virtio']),",
            "            instance_os=dict(type='str', aliases=['vmos']),",
            "            instance_cores=dict(type='str', default=1, aliases=['vmcores']),",
            "            instance_hostname=dict(type='str', aliases=['hostname']),",
            "            instance_ip=dict(type='str', aliases=['ip']),",
            "            instance_netmask=dict(type='str', aliases=['netmask']),",
            "            instance_gateway=dict(type='str', aliases=['gateway']),",
            "            instance_domain=dict(type='str', aliases=['domain']),",
            "            instance_dns=dict(type='str', aliases=['dns']),",
            "            instance_rootpw=dict(type='str', aliases=['rootpw'], no_log=True),",
            "            instance_key=dict(type='str', aliases=['key']),",
            "            sdomain=dict(type='str'),",
            "            region=dict(type='str'),",
            "        ),",
            "    )",
            "",
            "    if not HAS_OVIRTSDK:",
            "        module.fail_json(msg='ovirtsdk required for this module')",
            "",
            "    state = module.params['state']",
            "    user = module.params['user']",
            "    url = module.params['url']",
            "    vmname = module.params['instance_name']",
            "    password = module.params['password']",
            "    image = module.params['image']  # name of the image to deploy",
            "    resource_type = module.params['resource_type']  # template or from scratch",
            "    zone = module.params['zone']  # oVirt cluster",
            "    vmdisk_size = module.params['instance_disksize']  # disksize",
            "    vmcpus = module.params['instance_cpus']  # number of cpu",
            "    vmnic = module.params['instance_nic']  # network interface",
            "    vmnetwork = module.params['instance_network']  # logical network",
            "    vmmem = module.params['instance_mem']  # mem size",
            "    vmdisk_alloc = module.params['disk_alloc']  # thin, preallocated",
            "    vmdisk_int = module.params['disk_int']  # disk interface virtio or ide",
            "    vmos = module.params['instance_os']  # Operating System",
            "    vmtype = module.params['instance_type']  # server, desktop or high_performance",
            "    vmcores = module.params['instance_cores']  # number of cores",
            "    sdomain = module.params['sdomain']  # storage domain to store disk on",
            "    region = module.params['region']  # oVirt Datacenter",
            "    hostname = module.params['instance_hostname']",
            "    ip = module.params['instance_ip']",
            "    netmask = module.params['instance_netmask']",
            "    gateway = module.params['instance_gateway']",
            "    domain = module.params['instance_domain']",
            "    dns = module.params['instance_dns']",
            "    rootpw = module.params['instance_rootpw']",
            "    key = module.params['instance_key']",
            "    # initialize connection",
            "    try:",
            "        c = conn(url + \"/api\", user, password)",
            "    except Exception as e:",
            "        module.fail_json(msg='%s' % e)",
            "",
            "    if state == 'present':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            if resource_type == 'template':",
            "                try:",
            "                    create_vm_template(c, vmname, image, zone)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from template %s\" % (vmname, image))",
            "            elif resource_type == 'new':",
            "                # FIXME: refactor, use keyword args.",
            "                try:",
            "                    create_vm(c, vmtype, vmname, zone, vmdisk_size, vmcpus, vmnic, vmnetwork, vmmem, vmdisk_alloc, sdomain, vmcores, vmos, vmdisk_int)",
            "                except Exception as e:",
            "                    module.fail_json(msg='%s' % e)",
            "                module.exit_json(changed=True, msg=\"deployed VM %s from scratch\" % vmname)",
            "            else:",
            "                module.exit_json(changed=False, msg=\"You did not specify a resource type\")",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s already exists\" % vmname)",
            "",
            "    if state == 'started':",
            "        if vm_status(c, vmname) == 'up':",
            "            module.exit_json(changed=False, msg=\"VM %s is already running\" % vmname)",
            "        else:",
            "            # vm_start(c, vmname)",
            "            vm_start(c, vmname, hostname, ip, netmask, gateway, domain, dns, rootpw, key)",
            "            module.exit_json(changed=True, msg=\"VM %s started\" % vmname)",
            "",
            "    if state == 'shutdown':",
            "        if vm_status(c, vmname) == 'down':",
            "            module.exit_json(changed=False, msg=\"VM %s is already shutdown\" % vmname)",
            "        else:",
            "            vm_stop(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is shutting down\" % vmname)",
            "",
            "    if state == 'restart':",
            "        if vm_status(c, vmname) == 'up':",
            "            vm_restart(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s is restarted\" % vmname)",
            "        else:",
            "            module.exit_json(changed=False, msg=\"VM %s is not running\" % vmname)",
            "",
            "    if state == 'absent':",
            "        if get_vm(c, vmname) == \"empty\":",
            "            module.exit_json(changed=False, msg=\"VM %s does not exist\" % vmname)",
            "        else:",
            "            vm_remove(c, vmname)",
            "            module.exit_json(changed=True, msg=\"VM %s removed\" % vmname)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "383": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_firewall_policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 504,
                "afterPatchRowNumber": 504,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 505,
                "afterPatchRowNumber": 505,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 506,
                "afterPatchRowNumber": 506,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 507,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 507,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 508,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 508,
                "afterPatchRowNumber": 509,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 509,
                "afterPatchRowNumber": 510,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 510,
                "afterPatchRowNumber": 511,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_firewall_policy",
            "short_description: Configure 1&1 firewall policy.",
            "description:",
            "     - Create, remove, reconfigure, update firewall policies.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a firewall policy state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environment variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Firewall policy name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  firewall_policy:",
            "    description:",
            "      - The identifier (id or name) of the firewall policy used with update state.",
            "    required: true",
            "  rules:",
            "    description:",
            "      - A list of rules that will be set for the firewall policy.",
            "        Each rule must contain protocol parameter, in addition to three optional parameters",
            "        (port_from, port_to, and source)",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a firewall policy.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a firewall policy. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing firewall policy.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing firewall policy. Used in combination with update state.",
            "    required: false",
            "  description:",
            "    description:",
            "      - Firewall policy description. maxLength=256",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible-firewall-policy",
            "    description: Testing creation of firewall policies with ansible",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 80",
            "       port_to: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible-firewall-policy",
            "",
            "# Update a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    firewall_policy: ansible-firewall-policy",
            "    name: ansible-firewall-policy-updated",
            "    description: Testing creation of firewall policies with ansible - updated",
            "",
            "# Add server to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    add_server_ips:",
            "     - server_identifier (id or name)",
            "     - server_identifier #2 (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's IP id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    description: Adding rules to an existing firewall policy",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 70",
            "       port_to: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_from: 60",
            "       port_to: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "'''",
            "",
            "RETURN = '''",
            "firewall_policy:",
            "    description: Information about the firewall policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_firewall_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, firewall_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in server_ids:",
            "            server = get_server(oneandone_conn, _server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.attach_server_firewall_policy(",
            "            firewall_id=firewall_id,",
            "            server_ips=attach_servers)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_server(module, oneandone_conn, firewall_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            firewall_server = oneandone_conn.get_firewall_server(",
            "                firewall_id=firewall_id,",
            "                server_ip_id=server_ip_id)",
            "            if firewall_server:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_server(",
            "            firewall_id=firewall_id,",
            "            server_ip_id=server_ip_id)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _add_firewall_rules(module, oneandone_conn, firewall_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        if module.check_mode:",
            "            firewall_policy_id = get_firewall_policy(oneandone_conn, firewall_id)",
            "            if (firewall_rules and firewall_policy_id):",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.add_firewall_policy_rule(",
            "            firewall_id=firewall_id,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_rule(module, oneandone_conn, firewall_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_firewall_policy_rule(",
            "                firewall_id=firewall_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_rule(",
            "            firewall_id=firewall_id,",
            "            rule_id=rule_id",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a firewall policy based on input arguments.",
            "    Firewall rules and server ips can be added/removed to/from",
            "    firewall policy. Firewall policy name and description can be",
            "    updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        firewall_policy_id = module.params.get('firewall_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        add_server_ips = module.params.get('add_server_ips')",
            "        remove_server_ips = module.params.get('remove_server_ips')",
            "        add_rules = module.params.get('add_rules')",
            "        remove_rules = module.params.get('remove_rules')",
            "",
            "        changed = False",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy_id, True)",
            "        if firewall_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        if name or description:",
            "            _check_mode(module, True)",
            "            firewall_policy = oneandone_conn.modify_firewall(",
            "                firewall_id=firewall_policy['id'],",
            "                name=name,",
            "                description=description)",
            "            changed = True",
            "",
            "        if add_server_ips:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_server_ips(module,",
            "                                                    oneandone_conn,",
            "                                                    firewall_policy['id'],",
            "                                                    add_server_ips))",
            "",
            "            firewall_policy = _add_server_ips(module, oneandone_conn, firewall_policy['id'], add_server_ips)",
            "            changed = True",
            "",
            "        if remove_server_ips:",
            "            chk_changed = False",
            "            for server_ip_id in remove_server_ips:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_server(module,",
            "                                                           oneandone_conn,",
            "                                                           firewall_policy['id'],",
            "                                                           server_ip_id)",
            "",
            "                _remove_firewall_server(module,",
            "                                        oneandone_conn,",
            "                                        firewall_policy['id'],",
            "                                        server_ip_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_rules:",
            "            firewall_policy = _add_firewall_rules(module,",
            "                                                  oneandone_conn,",
            "                                                  firewall_policy['id'],",
            "                                                  add_rules)",
            "            _check_mode(module, firewall_policy)",
            "            changed = True",
            "",
            "        if remove_rules:",
            "            chk_changed = False",
            "            for rule_id in remove_rules:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_rule(module,",
            "                                                         oneandone_conn,",
            "                                                         firewall_policy['id'],",
            "                                                         rule_id)",
            "",
            "                _remove_firewall_rule(module,",
            "                                      oneandone_conn,",
            "                                      firewall_policy['id'],",
            "                                      rule_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def create_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        firewall_policy_obj = oneandone.client.FirewallPolicy(",
            "            name=name,",
            "            description=description",
            "        )",
            "",
            "        _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.create_firewall_policy(",
            "            firewall_policy=firewall_policy_obj,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.firewall_policy,",
            "                firewall_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)  # refresh",
            "        changed = True if firewall_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def remove_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        fp_id = module.params.get('name')",
            "        firewall_policy_id = get_firewall_policy(oneandone_conn, fp_id)",
            "        if module.check_mode:",
            "            if firewall_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.delete_firewall(firewall_policy_id)",
            "",
            "        changed = True if firewall_policy else False",
            "",
            "        return (changed, {",
            "            'id': firewall_policy['id'],",
            "            'name': firewall_policy['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            firewall_policy=dict(type='str'),",
            "            description=dict(type='str'),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='The \"auth_token\" parameter or ' +",
            "            'ONEANDONE_AUTH_TOKEN environment variable is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = remove_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'update':",
            "        if not module.params.get('firewall_policy'):",
            "            module.fail_json(",
            "                msg=\"'firewall_policy' parameter is required to update a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = update_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new firewall policies.\" % param)",
            "        try:",
            "            (changed, firewall_policy) = create_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, firewall_policy=firewall_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_firewall_policy",
            "short_description: Configure 1&1 firewall policy.",
            "description:",
            "     - Create, remove, reconfigure, update firewall policies.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a firewall policy state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environment variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Firewall policy name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  firewall_policy:",
            "    description:",
            "      - The identifier (id or name) of the firewall policy used with update state.",
            "    required: true",
            "  rules:",
            "    description:",
            "      - A list of rules that will be set for the firewall policy.",
            "        Each rule must contain protocol parameter, in addition to three optional parameters",
            "        (port_from, port_to, and source)",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a firewall policy.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a firewall policy. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing firewall policy.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing firewall policy. Used in combination with update state.",
            "    required: false",
            "  description:",
            "    description:",
            "      - Firewall policy description. maxLength=256",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible-firewall-policy",
            "    description: Testing creation of firewall policies with ansible",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 80",
            "       port_to: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible-firewall-policy",
            "",
            "# Update a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    firewall_policy: ansible-firewall-policy",
            "    name: ansible-firewall-policy-updated",
            "    description: Testing creation of firewall policies with ansible - updated",
            "",
            "# Add server to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    add_server_ips:",
            "     - server_identifier (id or name)",
            "     - server_identifier #2 (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's IP id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    description: Adding rules to an existing firewall policy",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_from: 70",
            "       port_to: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_from: 60",
            "       port_to: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a firewall policy.",
            "",
            "- oneandone_firewall_policy:",
            "    auth_token: oneandone_private_api_key",
            "    firewall_policy: ansible-firewall-policy-updated",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "'''",
            "",
            "RETURN = '''",
            "firewall_policy:",
            "    description: Information about the firewall policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_firewall_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, firewall_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in server_ids:",
            "            server = get_server(oneandone_conn, _server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.attach_server_firewall_policy(",
            "            firewall_id=firewall_id,",
            "            server_ips=attach_servers)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_server(module, oneandone_conn, firewall_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            firewall_server = oneandone_conn.get_firewall_server(",
            "                firewall_id=firewall_id,",
            "                server_ip_id=server_ip_id)",
            "            if firewall_server:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_server(",
            "            firewall_id=firewall_id,",
            "            server_ip_id=server_ip_id)",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _add_firewall_rules(module, oneandone_conn, firewall_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        if module.check_mode:",
            "            firewall_policy_id = get_firewall_policy(oneandone_conn, firewall_id)",
            "            if (firewall_rules and firewall_policy_id):",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.add_firewall_policy_rule(",
            "            firewall_id=firewall_id,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_firewall_rule(module, oneandone_conn, firewall_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a firewall policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_firewall_policy_rule(",
            "                firewall_id=firewall_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        firewall_policy = oneandone_conn.remove_firewall_rule(",
            "            firewall_id=firewall_id,",
            "            rule_id=rule_id",
            "        )",
            "        return firewall_policy",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a firewall policy based on input arguments.",
            "    Firewall rules and server ips can be added/removed to/from",
            "    firewall policy. Firewall policy name and description can be",
            "    updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        firewall_policy_id = module.params.get('firewall_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        add_server_ips = module.params.get('add_server_ips')",
            "        remove_server_ips = module.params.get('remove_server_ips')",
            "        add_rules = module.params.get('add_rules')",
            "        remove_rules = module.params.get('remove_rules')",
            "",
            "        changed = False",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy_id, True)",
            "        if firewall_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        if name or description:",
            "            _check_mode(module, True)",
            "            firewall_policy = oneandone_conn.modify_firewall(",
            "                firewall_id=firewall_policy['id'],",
            "                name=name,",
            "                description=description)",
            "            changed = True",
            "",
            "        if add_server_ips:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_server_ips(module,",
            "                                                    oneandone_conn,",
            "                                                    firewall_policy['id'],",
            "                                                    add_server_ips))",
            "",
            "            firewall_policy = _add_server_ips(module, oneandone_conn, firewall_policy['id'], add_server_ips)",
            "            changed = True",
            "",
            "        if remove_server_ips:",
            "            chk_changed = False",
            "            for server_ip_id in remove_server_ips:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_server(module,",
            "                                                           oneandone_conn,",
            "                                                           firewall_policy['id'],",
            "                                                           server_ip_id)",
            "",
            "                _remove_firewall_server(module,",
            "                                        oneandone_conn,",
            "                                        firewall_policy['id'],",
            "                                        server_ip_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_rules:",
            "            firewall_policy = _add_firewall_rules(module,",
            "                                                  oneandone_conn,",
            "                                                  firewall_policy['id'],",
            "                                                  add_rules)",
            "            _check_mode(module, firewall_policy)",
            "            changed = True",
            "",
            "        if remove_rules:",
            "            chk_changed = False",
            "            for rule_id in remove_rules:",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_firewall_rule(module,",
            "                                                         oneandone_conn,",
            "                                                         firewall_policy['id'],",
            "                                                         rule_id)",
            "",
            "                _remove_firewall_rule(module,",
            "                                      oneandone_conn,",
            "                                      firewall_policy['id'],",
            "                                      rule_id)",
            "            _check_mode(module, chk_changed)",
            "            firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def create_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        firewall_rules = []",
            "",
            "        for rule in rules:",
            "            firewall_rule = oneandone.client.FirewallPolicyRule(",
            "                protocol=rule['protocol'],",
            "                port_from=rule['port_from'],",
            "                port_to=rule['port_to'],",
            "                source=rule['source'])",
            "            firewall_rules.append(firewall_rule)",
            "",
            "        firewall_policy_obj = oneandone.client.FirewallPolicy(",
            "            name=name,",
            "            description=description",
            "        )",
            "",
            "        _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.create_firewall_policy(",
            "            firewall_policy=firewall_policy_obj,",
            "            firewall_policy_rules=firewall_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.firewall_policy,",
            "                firewall_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        firewall_policy = get_firewall_policy(oneandone_conn, firewall_policy['id'], True)  # refresh",
            "        changed = True if firewall_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, firewall_policy)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def remove_firewall_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a firewall policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        fp_id = module.params.get('name')",
            "        firewall_policy_id = get_firewall_policy(oneandone_conn, fp_id)",
            "        if module.check_mode:",
            "            if firewall_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        firewall_policy = oneandone_conn.delete_firewall(firewall_policy_id)",
            "",
            "        changed = True if firewall_policy else False",
            "",
            "        return (changed, {",
            "            'id': firewall_policy['id'],",
            "            'name': firewall_policy['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            firewall_policy=dict(type='str'),",
            "            description=dict(type='str'),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='The \"auth_token\" parameter or ' +",
            "            'ONEANDONE_AUTH_TOKEN environment variable is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = remove_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'update':",
            "        if not module.params.get('firewall_policy'):",
            "            module.fail_json(",
            "                msg=\"'firewall_policy' parameter is required to update a firewall policy.\")",
            "        try:",
            "            (changed, firewall_policy) = update_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new firewall policies.\" % param)",
            "        try:",
            "            (changed, firewall_policy) = create_firewall_policy(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, firewall_policy=firewall_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "507": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_load_balancer.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 595,
                "afterPatchRowNumber": 595,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 596,
                "afterPatchRowNumber": 596,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 597,
                "afterPatchRowNumber": 597,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 598,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 598,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 599,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 599,
                "afterPatchRowNumber": 600,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 600,
                "afterPatchRowNumber": 601,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 601,
                "afterPatchRowNumber": 602,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_load_balancer",
            "short_description: Configure 1&1 load balancer.",
            "description:",
            "     - Create, remove, update load balancers.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a load balancer state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  load_balancer:",
            "    description:",
            "      - The identifier (id or name) of the load balancer used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Load balancer name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  health_check_test:",
            "    description:",
            "      - Type of the health check. At the moment, HTTP is not allowed.",
            "    choices: [ \"NONE\", \"TCP\", \"HTTP\", \"ICMP\" ]",
            "    required: true",
            "  health_check_interval:",
            "    description:",
            "      - Health check period in seconds. minimum=5, maximum=300, multipleOf=1",
            "    required: true",
            "  health_check_path:",
            "    description:",
            "      - Url to call for checking. Required for HTTP health check. maxLength=1000",
            "    required: false",
            "  health_check_parse:",
            "    description:",
            "      - Regular expression to check. Required for HTTP health check. maxLength=64",
            "    required: false",
            "  persistence:",
            "    description:",
            "      - Persistence.",
            "    required: true",
            "    type: bool",
            "  persistence_time:",
            "    description:",
            "      - Persistence time in seconds. Required if persistence is enabled. minimum=30, maximum=1200, multipleOf=1",
            "    required: true",
            "  method:",
            "    description:",
            "      - Balancing procedure.",
            "    choices: [ \"ROUND_ROBIN\", \"LEAST_CONNECTIONS\" ]",
            "    required: true",
            "  datacenter:",
            "    description:",
            "      - ID or country code of the datacenter where the load balancer will be created.",
            "    default: US",
            "    choices: [ \"US\", \"ES\", \"DE\", \"GB\" ]",
            "    required: false",
            "  rules:",
            "    description:",
            "      - A list of rule objects that will be set for the load balancer. Each rule must contain protocol,",
            "        port_balancer, and port_server parameters, in addition to source parameter, which is optional.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Description of the load balancer. maxLength=256",
            "    required: false",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a load balancer.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a load balancer. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing load balancer.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing load balancer. Used in combination with update state.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    description: Testing creation of load balancer with ansible",
            "    health_check_test: TCP",
            "    health_check_interval: 40",
            "    persistence: true",
            "    persistence_time: 1200",
            "    method: ROUND_ROBIN",
            "    datacenter: US",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 80",
            "       port_server: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: absent",
            "",
            "# Update a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer",
            "    name: ansible load balancer updated",
            "    description: Testing the update of a load balancer with ansible",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add server to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding server to a load balancer with ansible",
            "    add_server_ips:",
            "     - server identifier (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Removing server from a load balancer with ansible",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's ip id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 70",
            "       port_server: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 60",
            "       port_server: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "load_balancer:",
            "    description: Information about the load balancer that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Balancer\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_load_balancer,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "HEALTH_CHECK_TESTS = ['NONE', 'TCP', 'HTTP', 'ICMP']",
            "METHODS = ['ROUND_ROBIN', 'LEAST_CONNECTIONS']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, load_balancer_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a load balancer.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for server_id in server_ids:",
            "            server = get_server(oneandone_conn, server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.attach_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ips=attach_servers)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_server(module, oneandone_conn, load_balancer_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a load balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            lb_server = oneandone_conn.get_load_balancer_server(",
            "                load_balancer_id=load_balancer_id,",
            "                server_ip_id=server_ip_id)",
            "            if lb_server:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ip_id=server_ip_id)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_load_balancer_rules(module, oneandone_conn, load_balancer_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        load_balancer_rules = []",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        if module.check_mode:",
            "            lb_id = get_load_balancer(oneandone_conn, load_balancer_id)",
            "            if (load_balancer_rules and lb_id):",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.add_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_rule(module, oneandone_conn, load_balancer_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_load_balancer_rule(",
            "                load_balancer_id=load_balancer_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            rule_id=rule_id",
            "        )",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a load_balancer based on input arguments.",
            "    Load balancer rules and server ips can be added/removed to/from",
            "    load balancer. Load balancer name, description, health_check_test,",
            "    health_check_interval, persistence, persistence_time, and method",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    load_balancer_id = module.params.get('load_balancer')",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    health_check_test = module.params.get('health_check_test')",
            "    health_check_interval = module.params.get('health_check_interval')",
            "    health_check_path = module.params.get('health_check_path')",
            "    health_check_parse = module.params.get('health_check_parse')",
            "    persistence = module.params.get('persistence')",
            "    persistence_time = module.params.get('persistence_time')",
            "    method = module.params.get('method')",
            "    add_server_ips = module.params.get('add_server_ips')",
            "    remove_server_ips = module.params.get('remove_server_ips')",
            "    add_rules = module.params.get('add_rules')",
            "    remove_rules = module.params.get('remove_rules')",
            "",
            "    changed = False",
            "",
            "    load_balancer = get_load_balancer(oneandone_conn, load_balancer_id, True)",
            "    if load_balancer is None:",
            "        _check_mode(module, False)",
            "",
            "    if (name or description or health_check_test or health_check_interval or health_check_path or",
            "            health_check_parse or persistence or persistence_time or method):",
            "        _check_mode(module, True)",
            "        load_balancer = oneandone_conn.modify_load_balancer(",
            "            load_balancer_id=load_balancer['id'],",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method)",
            "        changed = True",
            "",
            "    if add_server_ips:",
            "        if module.check_mode:",
            "            _check_mode(module, _add_server_ips(module,",
            "                                                oneandone_conn,",
            "                                                load_balancer['id'],",
            "                                                add_server_ips))",
            "",
            "        load_balancer = _add_server_ips(module, oneandone_conn, load_balancer['id'], add_server_ips)",
            "        changed = True",
            "",
            "    if remove_server_ips:",
            "        chk_changed = False",
            "        for server_ip_id in remove_server_ips:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_server(module,",
            "                                                            oneandone_conn,",
            "                                                            load_balancer['id'],",
            "                                                            server_ip_id)",
            "",
            "            _remove_load_balancer_server(module,",
            "                                         oneandone_conn,",
            "                                         load_balancer['id'],",
            "                                         server_ip_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    if add_rules:",
            "        load_balancer = _add_load_balancer_rules(module,",
            "                                                 oneandone_conn,",
            "                                                 load_balancer['id'],",
            "                                                 add_rules)",
            "        _check_mode(module, load_balancer)",
            "        changed = True",
            "",
            "    if remove_rules:",
            "        chk_changed = False",
            "        for rule_id in remove_rules:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_rule(module,",
            "                                                          oneandone_conn,",
            "                                                          load_balancer['id'],",
            "                                                          rule_id)",
            "",
            "            _remove_load_balancer_rule(module,",
            "                                       oneandone_conn,",
            "                                       load_balancer['id'],",
            "                                       rule_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    try:",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        health_check_test = module.params.get('health_check_test')",
            "        health_check_interval = module.params.get('health_check_interval')",
            "        health_check_path = module.params.get('health_check_path')",
            "        health_check_parse = module.params.get('health_check_parse')",
            "        persistence = module.params.get('persistence')",
            "        persistence_time = module.params.get('persistence_time')",
            "        method = module.params.get('method')",
            "        datacenter = module.params.get('datacenter')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        load_balancer_rules = []",
            "",
            "        datacenter_id = None",
            "        if datacenter is not None:",
            "            datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "            if datacenter_id is None:",
            "                module.fail_json(",
            "                    msg='datacenter %s not found.' % datacenter)",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        _check_mode(module, True)",
            "        load_balancer_obj = oneandone.client.LoadBalancer(",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method,",
            "            datacenter_id=datacenter_id",
            "        )",
            "",
            "        load_balancer = oneandone_conn.create_load_balancer(",
            "            load_balancer=load_balancer_obj,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.load_balancer,",
            "                                                  load_balancer['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)  # refresh",
            "        changed = True if load_balancer else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        lb_id = module.params.get('name')",
            "        load_balancer_id = get_load_balancer(oneandone_conn, lb_id)",
            "        if module.check_mode:",
            "            if load_balancer_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        load_balancer = oneandone_conn.delete_load_balancer(load_balancer_id)",
            "",
            "        changed = True if load_balancer else False",
            "",
            "        return (changed, {",
            "            'id': load_balancer['id'],",
            "            'name': load_balancer['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            load_balancer=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            health_check_test=dict(",
            "                choices=HEALTH_CHECK_TESTS),",
            "            health_check_interval=dict(type='str'),",
            "            health_check_path=dict(type='str'),",
            "            health_check_parse=dict(type='str'),",
            "            persistence=dict(type='bool'),",
            "            persistence_time=dict(type='str'),",
            "            method=dict(",
            "                choices=METHODS),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = remove_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('load_balancer'):",
            "            module.fail_json(",
            "                msg=\"'load_balancer' parameter is required for updating a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = update_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'health_check_test', 'health_check_interval', 'persistence',",
            "                      'persistence_time', 'method', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new load balancers.\" % param)",
            "        try:",
            "            (changed, load_balancer) = create_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, load_balancer=load_balancer)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_load_balancer",
            "short_description: Configure 1&1 load balancer.",
            "description:",
            "     - Create, remove, update load balancers.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a load balancer state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  load_balancer:",
            "    description:",
            "      - The identifier (id or name) of the load balancer used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Load balancer name used with present state. Used as identifier (id or name) when used with absent state.",
            "        maxLength=128",
            "    required: true",
            "  health_check_test:",
            "    description:",
            "      - Type of the health check. At the moment, HTTP is not allowed.",
            "    choices: [ \"NONE\", \"TCP\", \"HTTP\", \"ICMP\" ]",
            "    required: true",
            "  health_check_interval:",
            "    description:",
            "      - Health check period in seconds. minimum=5, maximum=300, multipleOf=1",
            "    required: true",
            "  health_check_path:",
            "    description:",
            "      - Url to call for checking. Required for HTTP health check. maxLength=1000",
            "    required: false",
            "  health_check_parse:",
            "    description:",
            "      - Regular expression to check. Required for HTTP health check. maxLength=64",
            "    required: false",
            "  persistence:",
            "    description:",
            "      - Persistence.",
            "    required: true",
            "    type: bool",
            "  persistence_time:",
            "    description:",
            "      - Persistence time in seconds. Required if persistence is enabled. minimum=30, maximum=1200, multipleOf=1",
            "    required: true",
            "  method:",
            "    description:",
            "      - Balancing procedure.",
            "    choices: [ \"ROUND_ROBIN\", \"LEAST_CONNECTIONS\" ]",
            "    required: true",
            "  datacenter:",
            "    description:",
            "      - ID or country code of the datacenter where the load balancer will be created.",
            "    default: US",
            "    choices: [ \"US\", \"ES\", \"DE\", \"GB\" ]",
            "    required: false",
            "  rules:",
            "    description:",
            "      - A list of rule objects that will be set for the load balancer. Each rule must contain protocol,",
            "        port_balancer, and port_server parameters, in addition to source parameter, which is optional.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Description of the load balancer. maxLength=256",
            "    required: false",
            "  add_server_ips:",
            "    description:",
            "      - A list of server identifiers (id or name) to be assigned to a load balancer.",
            "        Used in combination with update state.",
            "    required: false",
            "  remove_server_ips:",
            "    description:",
            "      - A list of server IP ids to be unassigned from a load balancer. Used in combination with update state.",
            "    required: false",
            "  add_rules:",
            "    description:",
            "      - A list of rules that will be added to an existing load balancer.",
            "        It is syntax is the same as the one used for rules parameter. Used in combination with update state.",
            "    required: false",
            "  remove_rules:",
            "    description:",
            "      - A list of rule ids that will be removed from an existing load balancer. Used in combination with update state.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    description: Testing creation of load balancer with ansible",
            "    health_check_test: TCP",
            "    health_check_interval: 40",
            "    persistence: true",
            "    persistence_time: 1200",
            "    method: ROUND_ROBIN",
            "    datacenter: US",
            "    rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 80",
            "       port_server: 80",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible load balancer",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: absent",
            "",
            "# Update a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer",
            "    name: ansible load balancer updated",
            "    description: Testing the update of a load balancer with ansible",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add server to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding server to a load balancer with ansible",
            "    add_server_ips:",
            "     - server identifier (id or name)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove server from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Removing server from a load balancer with ansible",
            "    remove_server_ips:",
            "     - B2504878540DBC5F7634EB00A07C1EBD (server's ip id)",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Add rules to a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    add_rules:",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 70",
            "       port_server: 70",
            "       source: 0.0.0.0",
            "     -",
            "       protocol: TCP",
            "       port_balancer: 60",
            "       port_server: 60",
            "       source: 0.0.0.0",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "",
            "# Remove rules from a load balancer.",
            "",
            "- oneandone_load_balancer:",
            "    auth_token: oneandone_private_api_key",
            "    load_balancer: ansible load balancer updated",
            "    description: Adding rules to a load balancer with ansible",
            "    remove_rules:",
            "     - rule_id #1",
            "     - rule_id #2",
            "     - ...",
            "    wait: true",
            "    wait_timeout: 500",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "load_balancer:",
            "    description: Information about the load balancer that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Balancer\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_load_balancer,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "HEALTH_CHECK_TESTS = ['NONE', 'TCP', 'HTTP', 'ICMP']",
            "METHODS = ['ROUND_ROBIN', 'LEAST_CONNECTIONS']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_server_ips(module, oneandone_conn, load_balancer_id, server_ids):",
            "    \"\"\"",
            "    Assigns servers to a load balancer.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for server_id in server_ids:",
            "            server = get_server(oneandone_conn, server_id, True)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server['id'],",
            "                server_ip_id=next(iter(server['ips'] or []), None)['id']",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.attach_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ips=attach_servers)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_server(module, oneandone_conn, load_balancer_id, server_ip_id):",
            "    \"\"\"",
            "    Unassigns a server/IP from a load balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            lb_server = oneandone_conn.get_load_balancer_server(",
            "                load_balancer_id=load_balancer_id,",
            "                server_ip_id=server_ip_id)",
            "            if lb_server:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_server(",
            "            load_balancer_id=load_balancer_id,",
            "            server_ip_id=server_ip_id)",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_load_balancer_rules(module, oneandone_conn, load_balancer_id, rules):",
            "    \"\"\"",
            "    Adds new rules to a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        load_balancer_rules = []",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        if module.check_mode:",
            "            lb_id = get_load_balancer(oneandone_conn, load_balancer_id)",
            "            if (load_balancer_rules and lb_id):",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.add_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _remove_load_balancer_rule(module, oneandone_conn, load_balancer_id, rule_id):",
            "    \"\"\"",
            "    Removes a rule from a load_balancer.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            rule = oneandone_conn.get_load_balancer_rule(",
            "                load_balancer_id=load_balancer_id,",
            "                rule_id=rule_id)",
            "            if rule:",
            "                return True",
            "            return False",
            "",
            "        load_balancer = oneandone_conn.remove_load_balancer_rule(",
            "            load_balancer_id=load_balancer_id,",
            "            rule_id=rule_id",
            "        )",
            "        return load_balancer",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a load_balancer based on input arguments.",
            "    Load balancer rules and server ips can be added/removed to/from",
            "    load balancer. Load balancer name, description, health_check_test,",
            "    health_check_interval, persistence, persistence_time, and method",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    load_balancer_id = module.params.get('load_balancer')",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    health_check_test = module.params.get('health_check_test')",
            "    health_check_interval = module.params.get('health_check_interval')",
            "    health_check_path = module.params.get('health_check_path')",
            "    health_check_parse = module.params.get('health_check_parse')",
            "    persistence = module.params.get('persistence')",
            "    persistence_time = module.params.get('persistence_time')",
            "    method = module.params.get('method')",
            "    add_server_ips = module.params.get('add_server_ips')",
            "    remove_server_ips = module.params.get('remove_server_ips')",
            "    add_rules = module.params.get('add_rules')",
            "    remove_rules = module.params.get('remove_rules')",
            "",
            "    changed = False",
            "",
            "    load_balancer = get_load_balancer(oneandone_conn, load_balancer_id, True)",
            "    if load_balancer is None:",
            "        _check_mode(module, False)",
            "",
            "    if (name or description or health_check_test or health_check_interval or health_check_path or",
            "            health_check_parse or persistence or persistence_time or method):",
            "        _check_mode(module, True)",
            "        load_balancer = oneandone_conn.modify_load_balancer(",
            "            load_balancer_id=load_balancer['id'],",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method)",
            "        changed = True",
            "",
            "    if add_server_ips:",
            "        if module.check_mode:",
            "            _check_mode(module, _add_server_ips(module,",
            "                                                oneandone_conn,",
            "                                                load_balancer['id'],",
            "                                                add_server_ips))",
            "",
            "        load_balancer = _add_server_ips(module, oneandone_conn, load_balancer['id'], add_server_ips)",
            "        changed = True",
            "",
            "    if remove_server_ips:",
            "        chk_changed = False",
            "        for server_ip_id in remove_server_ips:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_server(module,",
            "                                                            oneandone_conn,",
            "                                                            load_balancer['id'],",
            "                                                            server_ip_id)",
            "",
            "            _remove_load_balancer_server(module,",
            "                                         oneandone_conn,",
            "                                         load_balancer['id'],",
            "                                         server_ip_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    if add_rules:",
            "        load_balancer = _add_load_balancer_rules(module,",
            "                                                 oneandone_conn,",
            "                                                 load_balancer['id'],",
            "                                                 add_rules)",
            "        _check_mode(module, load_balancer)",
            "        changed = True",
            "",
            "    if remove_rules:",
            "        chk_changed = False",
            "        for rule_id in remove_rules:",
            "            if module.check_mode:",
            "                chk_changed |= _remove_load_balancer_rule(module,",
            "                                                          oneandone_conn,",
            "                                                          load_balancer['id'],",
            "                                                          rule_id)",
            "",
            "            _remove_load_balancer_rule(module,",
            "                                       oneandone_conn,",
            "                                       load_balancer['id'],",
            "                                       rule_id)",
            "        _check_mode(module, chk_changed)",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)",
            "        changed = True",
            "",
            "    try:",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Create a new load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        health_check_test = module.params.get('health_check_test')",
            "        health_check_interval = module.params.get('health_check_interval')",
            "        health_check_path = module.params.get('health_check_path')",
            "        health_check_parse = module.params.get('health_check_parse')",
            "        persistence = module.params.get('persistence')",
            "        persistence_time = module.params.get('persistence_time')",
            "        method = module.params.get('method')",
            "        datacenter = module.params.get('datacenter')",
            "        rules = module.params.get('rules')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        load_balancer_rules = []",
            "",
            "        datacenter_id = None",
            "        if datacenter is not None:",
            "            datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "            if datacenter_id is None:",
            "                module.fail_json(",
            "                    msg='datacenter %s not found.' % datacenter)",
            "",
            "        for rule in rules:",
            "            load_balancer_rule = oneandone.client.LoadBalancerRule(",
            "                protocol=rule['protocol'],",
            "                port_balancer=rule['port_balancer'],",
            "                port_server=rule['port_server'],",
            "                source=rule['source'])",
            "            load_balancer_rules.append(load_balancer_rule)",
            "",
            "        _check_mode(module, True)",
            "        load_balancer_obj = oneandone.client.LoadBalancer(",
            "            health_check_path=health_check_path,",
            "            health_check_parse=health_check_parse,",
            "            name=name,",
            "            description=description,",
            "            health_check_test=health_check_test,",
            "            health_check_interval=health_check_interval,",
            "            persistence=persistence,",
            "            persistence_time=persistence_time,",
            "            method=method,",
            "            datacenter_id=datacenter_id",
            "        )",
            "",
            "        load_balancer = oneandone_conn.create_load_balancer(",
            "            load_balancer=load_balancer_obj,",
            "            load_balancer_rules=load_balancer_rules",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.load_balancer,",
            "                                                  load_balancer['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "",
            "        load_balancer = get_load_balancer(oneandone_conn, load_balancer['id'], True)  # refresh",
            "        changed = True if load_balancer else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, load_balancer)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_load_balancer(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a load_balancer.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        lb_id = module.params.get('name')",
            "        load_balancer_id = get_load_balancer(oneandone_conn, lb_id)",
            "        if module.check_mode:",
            "            if load_balancer_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        load_balancer = oneandone_conn.delete_load_balancer(load_balancer_id)",
            "",
            "        changed = True if load_balancer else False",
            "",
            "        return (changed, {",
            "            'id': load_balancer['id'],",
            "            'name': load_balancer['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            load_balancer=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            health_check_test=dict(",
            "                choices=HEALTH_CHECK_TESTS),",
            "            health_check_interval=dict(type='str'),",
            "            health_check_path=dict(type='str'),",
            "            health_check_parse=dict(type='str'),",
            "            persistence=dict(type='bool'),",
            "            persistence_time=dict(type='str'),",
            "            method=dict(",
            "                choices=METHODS),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            rules=dict(type='list', default=[]),",
            "            add_server_ips=dict(type='list', default=[]),",
            "            remove_server_ips=dict(type='list', default=[]),",
            "            add_rules=dict(type='list', default=[]),",
            "            remove_rules=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = remove_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('load_balancer'):",
            "            module.fail_json(",
            "                msg=\"'load_balancer' parameter is required for updating a load balancer.\")",
            "        try:",
            "            (changed, load_balancer) = update_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'health_check_test', 'health_check_interval', 'persistence',",
            "                      'persistence_time', 'method', 'rules'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for new load balancers.\" % param)",
            "        try:",
            "            (changed, load_balancer) = create_load_balancer(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, load_balancer=load_balancer)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "598": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_monitoring_policy.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 950,
                "afterPatchRowNumber": 950,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 951,
                "afterPatchRowNumber": 951,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 952,
                "afterPatchRowNumber": 952,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 953,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 953,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 954,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 954,
                "afterPatchRowNumber": 955,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 955,
                "afterPatchRowNumber": 956,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 956,
                "afterPatchRowNumber": 957,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_monitoring_policy",
            "short_description: Configure 1&1 monitoring policy.",
            "description:",
            "     - Create, remove, update monitoring policies",
            "       (and add/remove ports, processes, and servers).",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a monitoring policy's state to create, remove, update.",
            "    required: false",
            "    default: present",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Monitoring policy name used with present state. Used as identifier (id or name) when used with absent state. maxLength=128",
            "    required: true",
            "  monitoring_policy:",
            "    description:",
            "      - The identifier (id or name) of the monitoring policy used with update state.",
            "    required: true",
            "  agent:",
            "    description:",
            "      - Set true for using agent.",
            "    required: true",
            "  email:",
            "    description:",
            "      - User's email. maxLength=128",
            "    required: true",
            "  description:",
            "    description:",
            "      - Monitoring policy description. maxLength=256",
            "    required: false",
            "  thresholds:",
            "    description:",
            "      - Monitoring policy thresholds. Each of the suboptions have warning and critical,",
            "        which both have alert and value suboptions. Warning is used to set limits for",
            "        warning alerts, critical is used to set critical alerts. alert enables alert,",
            "        and value is used to advise when the value is exceeded.",
            "    required: true",
            "    suboptions:",
            "      cpu:",
            "        description:",
            "          - Consumption limits of CPU.",
            "        required: true",
            "      ram:",
            "        description:",
            "          - Consumption limits of RAM.",
            "        required: true",
            "      disk:",
            "        description:",
            "          - Consumption limits of hard disk.",
            "        required: true",
            "      internal_ping:",
            "        description:",
            "          - Response limits of internal ping.",
            "        required: true",
            "      transfer:",
            "        description:",
            "          - Consumption limits for transfer.",
            "        required: true",
            "  ports:",
            "    description:",
            "      - Array of ports that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      protocol:",
            "        description:",
            "          - Internet protocol.",
            "        choices: [ \"TCP\", \"UDP\" ]",
            "        required: true",
            "      port:",
            "        description:",
            "          - Port number. minimum=1, maximum=65535",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RESPONDING\", \"NOT_RESPONDING\" ]",
            "        required: true",
            "      email_notification:",
            "        description:",
            "          - Set true for sending e-mail notifications.",
            "        required: true",
            "  processes:",
            "    description:",
            "      - Array of processes that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      process:",
            "        description:",
            "          - Name of the process. maxLength=50",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RUNNING\", \"NOT_RUNNING\" ]",
            "        required: true",
            "  add_ports:",
            "    description:",
            "      - Ports to add to the monitoring policy.",
            "    required: false",
            "  add_processes:",
            "    description:",
            "      - Processes to add to the monitoring policy.",
            "    required: false",
            "  add_servers:",
            "    description:",
            "      - Servers to add to the monitoring policy.",
            "    required: false",
            "  remove_ports:",
            "    description:",
            "      - Ports to remove from the monitoring policy.",
            "    required: false",
            "  remove_processes:",
            "    description:",
            "      - Processes to remove from the monitoring policy.",
            "    required: false",
            "  remove_servers:",
            "    description:",
            "      - Servers to remove from the monitoring policy.",
            "    required: false",
            "  update_ports:",
            "    description:",
            "      - Ports to be updated on the monitoring policy.",
            "    required: false",
            "  update_processes:",
            "    description:",
            "      - Processes to be updated on the monitoring policy.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible monitoring policy",
            "    description: Testing creation of a monitoring policy with ansible",
            "    email: your@emailaddress.com",
            "    agent: true",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 92",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 50",
            "           alert: false",
            "         critical:",
            "           value: 100",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 1000",
            "           alert: false",
            "         critical:",
            "           value: 2000",
            "           alert: false",
            "    ports:",
            "     -",
            "       protocol: TCP",
            "       port: 22",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    processes:",
            "     -",
            "       process: test",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible monitoring policy",
            "",
            "# Update a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy",
            "    name: ansible monitoring policy updated",
            "    description: Testing creation of a monitoring policy with ansible updated",
            "    email: another@emailaddress.com",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 60",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 900",
            "           alert: false",
            "         critical:",
            "           value: 1900",
            "           alert: false",
            "    wait: true",
            "    state: update",
            "",
            "# Add a port to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_ports:",
            "     -",
            "       protocol: TCP",
            "       port: 33",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing ports of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_ports:",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 34",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 23",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a port from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_ports:",
            "     - port_id",
            "    state: update",
            "",
            "# Add a process to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_processes:",
            "     -",
            "       process: test_2",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing processes of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_processes:",
            "     -",
            "       id: process_id",
            "       process: test_1",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "     -",
            "       id: process_id",
            "       process: test_3",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a process from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_processes:",
            "     - process_id",
            "    wait: true",
            "    state: update",
            "",
            "# Add server to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_servers:",
            "     - server id or name",
            "    wait: true",
            "    state: update",
            "",
            "# Remove server from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_servers:",
            "     - server01",
            "    wait: true",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "monitoring_policy:",
            "    description: Information about the monitoring policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_monitoring_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_ports(module, oneandone_conn, monitoring_policy_id, ports):",
            "    \"\"\"",
            "    Adds new ports to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_ports = []",
            "",
            "        for _port in ports:",
            "            monitoring_policy_port = oneandone.client.Port(",
            "                protocol=_port['protocol'],",
            "                port=_port['port'],",
            "                alert_if=_port['alert_if'],",
            "                email_notification=_port['email_notification']",
            "            )",
            "            monitoring_policy_ports.append(monitoring_policy_port)",
            "",
            "        if module.check_mode:",
            "            if monitoring_policy_ports:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            ports=monitoring_policy_ports)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_port(module, oneandone_conn, monitoring_policy_id, port_id):",
            "    \"\"\"",
            "    Removes a port from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if monitoring_policy:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_port(module, oneandone_conn, monitoring_policy_id, port_id, port):",
            "    \"\"\"",
            "    Modifies a monitoring policy port.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_port = oneandone_conn.get_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if cm_port:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_port = oneandone.client.Port(",
            "            protocol=port['protocol'],",
            "            port=port['port'],",
            "            alert_if=port['alert_if'],",
            "            email_notification=port['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id,",
            "            port=monitoring_policy_port)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_processes(module, oneandone_conn, monitoring_policy_id, processes):",
            "    \"\"\"",
            "    Adds new processes to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_processes = []",
            "",
            "        for _process in processes:",
            "            monitoring_policy_process = oneandone.client.Process(",
            "                process=_process['process'],",
            "                alert_if=_process['alert_if'],",
            "                email_notification=_process['email_notification']",
            "            )",
            "            monitoring_policy_processes.append(monitoring_policy_process)",
            "",
            "        if module.check_mode:",
            "            mp_id = get_monitoring_policy(oneandone_conn, monitoring_policy_id)",
            "            if (monitoring_policy_processes and mp_id):",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            processes=monitoring_policy_processes)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_process(module, oneandone_conn, monitoring_policy_id, process_id):",
            "    \"\"\"",
            "    Removes a process from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id",
            "            )",
            "            if process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_process(module, oneandone_conn, monitoring_policy_id, process_id, process):",
            "    \"\"\"",
            "    Modifies a monitoring policy process.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id)",
            "            if cm_process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_process = oneandone.client.Process(",
            "            process=process['process'],",
            "            alert_if=process['alert_if'],",
            "            email_notification=process['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id,",
            "            process=monitoring_policy_process)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _attach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, servers):",
            "    \"\"\"",
            "    Attaches servers to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in servers:",
            "            server_id = get_server(oneandone_conn, _server_id)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server_id",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.attach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            servers=attach_servers)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _detach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, server_id):",
            "    \"\"\"",
            "    Detaches a server from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            mp_server = oneandone_conn.get_monitoring_policy_server(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                server_id=server_id)",
            "            if mp_server:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.detach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            server_id=server_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a monitoring_policy based on input arguments.",
            "    Monitoring policy ports, processes and servers can be added/removed to/from",
            "    a monitoring policy. Monitoring policy name, description, email,",
            "    thresholds for cpu, ram, disk, transfer and internal_ping",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_id = module.params.get('monitoring_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        thresholds = module.params.get('thresholds')",
            "        add_ports = module.params.get('add_ports')",
            "        update_ports = module.params.get('update_ports')",
            "        remove_ports = module.params.get('remove_ports')",
            "        add_processes = module.params.get('add_processes')",
            "        update_processes = module.params.get('update_processes')",
            "        remove_processes = module.params.get('remove_processes')",
            "        add_servers = module.params.get('add_servers')",
            "        remove_servers = module.params.get('remove_servers')",
            "",
            "        changed = False",
            "",
            "        monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy_id, True)",
            "        if monitoring_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(",
            "            name=name,",
            "            description=description,",
            "            email=email",
            "        )",
            "",
            "        _thresholds = None",
            "",
            "        if thresholds:",
            "            threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "            _thresholds = []",
            "            for treshold in thresholds:",
            "                key = treshold.keys()[0]",
            "                if key in threshold_entities:",
            "                    _threshold = oneandone.client.Threshold(",
            "                        entity=key,",
            "                        warning_value=treshold[key]['warning']['value'],",
            "                        warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                        critical_value=treshold[key]['critical']['value'],",
            "                        critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                    _thresholds.append(_threshold)",
            "",
            "        if name or description or email or thresholds:",
            "            _check_mode(module, True)",
            "            monitoring_policy = oneandone_conn.modify_monitoring_policy(",
            "                monitoring_policy_id=monitoring_policy['id'],",
            "                monitoring_policy=_monitoring_policy,",
            "                thresholds=_thresholds)",
            "            changed = True",
            "",
            "        if add_ports:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_ports(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_ports))",
            "",
            "            monitoring_policy = _add_ports(module, oneandone_conn, monitoring_policy['id'], add_ports)",
            "            changed = True",
            "",
            "        if update_ports:",
            "            chk_changed = False",
            "            for update_port in update_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_port(module,",
            "                                                oneandone_conn,",
            "                                                monitoring_policy['id'],",
            "                                                update_port['id'],",
            "                                                update_port)",
            "",
            "                _modify_port(module,",
            "                             oneandone_conn,",
            "                             monitoring_policy['id'],",
            "                             update_port['id'],",
            "                             update_port)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_ports:",
            "            chk_changed = False",
            "            for port_id in remove_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_port(module,",
            "                                                                  oneandone_conn,",
            "                                                                  monitoring_policy['id'],",
            "                                                                  port_id)",
            "",
            "                _delete_monitoring_policy_port(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               port_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_processes:",
            "            monitoring_policy = _add_processes(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_processes)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if update_processes:",
            "            chk_changed = False",
            "            for update_process in update_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_process(module,",
            "                                                   oneandone_conn,",
            "                                                   monitoring_policy['id'],",
            "                                                   update_process['id'],",
            "                                                   update_process)",
            "",
            "                _modify_process(module,",
            "                                oneandone_conn,",
            "                                monitoring_policy['id'],",
            "                                update_process['id'],",
            "                                update_process)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_processes:",
            "            chk_changed = False",
            "            for process_id in remove_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_process(module,",
            "                                                                     oneandone_conn,",
            "                                                                     monitoring_policy['id'],",
            "                                                                     process_id)",
            "",
            "                _delete_monitoring_policy_process(module,",
            "                                                  oneandone_conn,",
            "                                                  monitoring_policy['id'],",
            "                                                  process_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_servers:",
            "            monitoring_policy = _attach_monitoring_policy_server(module,",
            "                                                                 oneandone_conn,",
            "                                                                 monitoring_policy['id'],",
            "                                                                 add_servers)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if remove_servers:",
            "            chk_changed = False",
            "            for _server_id in remove_servers:",
            "                server_id = get_server(oneandone_conn, _server_id)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _detach_monitoring_policy_server(module,",
            "                                                                    oneandone_conn,",
            "                                                                    monitoring_policy['id'],",
            "                                                                    server_id)",
            "",
            "                _detach_monitoring_policy_server(module,",
            "                                                 oneandone_conn,",
            "                                                 monitoring_policy['id'],",
            "                                                 server_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Creates a new monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        agent = module.params.get('agent')",
            "        thresholds = module.params.get('thresholds')",
            "        ports = module.params.get('ports')",
            "        processes = module.params.get('processes')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(name,",
            "                                                               description,",
            "                                                               email,",
            "                                                               agent, )",
            "",
            "        _monitoring_policy.specs['agent'] = str(_monitoring_policy.specs['agent']).lower()",
            "",
            "        threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "        _thresholds = []",
            "        for treshold in thresholds:",
            "            key = treshold.keys()[0]",
            "            if key in threshold_entities:",
            "                _threshold = oneandone.client.Threshold(",
            "                    entity=key,",
            "                    warning_value=treshold[key]['warning']['value'],",
            "                    warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                    critical_value=treshold[key]['critical']['value'],",
            "                    critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                _thresholds.append(_threshold)",
            "",
            "        _ports = []",
            "        for port in ports:",
            "            _port = oneandone.client.Port(",
            "                protocol=port['protocol'],",
            "                port=port['port'],",
            "                alert_if=port['alert_if'],",
            "                email_notification=str(port['email_notification']).lower())",
            "            _ports.append(_port)",
            "",
            "        _processes = []",
            "        for process in processes:",
            "            _process = oneandone.client.Process(",
            "                process=process['process'],",
            "                alert_if=process['alert_if'],",
            "                email_notification=str(process['email_notification']).lower())",
            "            _processes.append(_process)",
            "",
            "        _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.create_monitoring_policy(",
            "            monitoring_policy=_monitoring_policy,",
            "            thresholds=_thresholds,",
            "            ports=_ports,",
            "            processes=_processes",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.monitoring_policy,",
            "                monitoring_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        mp_id = module.params.get('name')",
            "        monitoring_policy_id = get_monitoring_policy(oneandone_conn, mp_id)",
            "        if module.check_mode:",
            "            if monitoring_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy(monitoring_policy_id)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        return (changed, {",
            "            'id': monitoring_policy['id'],",
            "            'name': monitoring_policy['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            monitoring_policy=dict(type='str'),",
            "            agent=dict(type='str'),",
            "            email=dict(type='str'),",
            "            description=dict(type='str'),",
            "            thresholds=dict(type='list', default=[]),",
            "            ports=dict(type='list', default=[]),",
            "            processes=dict(type='list', default=[]),",
            "            add_ports=dict(type='list', default=[]),",
            "            update_ports=dict(type='list', default=[]),",
            "            remove_ports=dict(type='list', default=[]),",
            "            add_processes=dict(type='list', default=[]),",
            "            update_processes=dict(type='list', default=[]),",
            "            remove_processes=dict(type='list', default=[]),",
            "            add_servers=dict(type='list', default=[]),",
            "            remove_servers=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = remove_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('monitoring_policy'):",
            "            module.fail_json(",
            "                msg=\"'monitoring_policy' parameter is required to update a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = update_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'agent', 'email', 'thresholds', 'ports', 'processes'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for a new monitoring policy.\" % param)",
            "        try:",
            "            (changed, monitoring_policy) = create_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, monitoring_policy=monitoring_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_monitoring_policy",
            "short_description: Configure 1&1 monitoring policy.",
            "description:",
            "     - Create, remove, update monitoring policies",
            "       (and add/remove ports, processes, and servers).",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a monitoring policy's state to create, remove, update.",
            "    required: false",
            "    default: present",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Monitoring policy name used with present state. Used as identifier (id or name) when used with absent state. maxLength=128",
            "    required: true",
            "  monitoring_policy:",
            "    description:",
            "      - The identifier (id or name) of the monitoring policy used with update state.",
            "    required: true",
            "  agent:",
            "    description:",
            "      - Set true for using agent.",
            "    required: true",
            "  email:",
            "    description:",
            "      - User's email. maxLength=128",
            "    required: true",
            "  description:",
            "    description:",
            "      - Monitoring policy description. maxLength=256",
            "    required: false",
            "  thresholds:",
            "    description:",
            "      - Monitoring policy thresholds. Each of the suboptions have warning and critical,",
            "        which both have alert and value suboptions. Warning is used to set limits for",
            "        warning alerts, critical is used to set critical alerts. alert enables alert,",
            "        and value is used to advise when the value is exceeded.",
            "    required: true",
            "    suboptions:",
            "      cpu:",
            "        description:",
            "          - Consumption limits of CPU.",
            "        required: true",
            "      ram:",
            "        description:",
            "          - Consumption limits of RAM.",
            "        required: true",
            "      disk:",
            "        description:",
            "          - Consumption limits of hard disk.",
            "        required: true",
            "      internal_ping:",
            "        description:",
            "          - Response limits of internal ping.",
            "        required: true",
            "      transfer:",
            "        description:",
            "          - Consumption limits for transfer.",
            "        required: true",
            "  ports:",
            "    description:",
            "      - Array of ports that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      protocol:",
            "        description:",
            "          - Internet protocol.",
            "        choices: [ \"TCP\", \"UDP\" ]",
            "        required: true",
            "      port:",
            "        description:",
            "          - Port number. minimum=1, maximum=65535",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RESPONDING\", \"NOT_RESPONDING\" ]",
            "        required: true",
            "      email_notification:",
            "        description:",
            "          - Set true for sending e-mail notifications.",
            "        required: true",
            "  processes:",
            "    description:",
            "      - Array of processes that will be monitoring.",
            "    required: true",
            "    suboptions:",
            "      process:",
            "        description:",
            "          - Name of the process. maxLength=50",
            "        required: true",
            "      alert_if:",
            "        description:",
            "          - Case of alert.",
            "        choices: [ \"RUNNING\", \"NOT_RUNNING\" ]",
            "        required: true",
            "  add_ports:",
            "    description:",
            "      - Ports to add to the monitoring policy.",
            "    required: false",
            "  add_processes:",
            "    description:",
            "      - Processes to add to the monitoring policy.",
            "    required: false",
            "  add_servers:",
            "    description:",
            "      - Servers to add to the monitoring policy.",
            "    required: false",
            "  remove_ports:",
            "    description:",
            "      - Ports to remove from the monitoring policy.",
            "    required: false",
            "  remove_processes:",
            "    description:",
            "      - Processes to remove from the monitoring policy.",
            "    required: false",
            "  remove_servers:",
            "    description:",
            "      - Servers to remove from the monitoring policy.",
            "    required: false",
            "  update_ports:",
            "    description:",
            "      - Ports to be updated on the monitoring policy.",
            "    required: false",
            "  update_processes:",
            "    description:",
            "      - Processes to be updated on the monitoring policy.",
            "    required: false",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "  - \"1and1\"",
            "  - \"python >= 2.6\"",
            "",
            "author:",
            "  -  \"Amel Ajdinovic (@aajdinov)\"",
            "  -  \"Ethan Devenport (@edevenport)\"",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    name: ansible monitoring policy",
            "    description: Testing creation of a monitoring policy with ansible",
            "    email: your@emailaddress.com",
            "    agent: true",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 92",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 80",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 50",
            "           alert: false",
            "         critical:",
            "           value: 100",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 1000",
            "           alert: false",
            "         critical:",
            "           value: 2000",
            "           alert: false",
            "    ports:",
            "     -",
            "       protocol: TCP",
            "       port: 22",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    processes:",
            "     -",
            "       process: test",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: ansible monitoring policy",
            "",
            "# Update a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy",
            "    name: ansible monitoring policy updated",
            "    description: Testing creation of a monitoring policy with ansible updated",
            "    email: another@emailaddress.com",
            "    thresholds:",
            "     -",
            "       cpu:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       ram:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       disk:",
            "         warning:",
            "           value: 70",
            "           alert: false",
            "         critical:",
            "           value: 80",
            "           alert: false",
            "     -",
            "       internal_ping:",
            "         warning:",
            "           value: 60",
            "           alert: false",
            "         critical:",
            "           value: 90",
            "           alert: false",
            "     -",
            "       transfer:",
            "         warning:",
            "           value: 900",
            "           alert: false",
            "         critical:",
            "           value: 1900",
            "           alert: false",
            "    wait: true",
            "    state: update",
            "",
            "# Add a port to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_ports:",
            "     -",
            "       protocol: TCP",
            "       port: 33",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing ports of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_ports:",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 34",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "     -",
            "       id: existing_port_id",
            "       protocol: TCP",
            "       port: 23",
            "       alert_if: RESPONDING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a port from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_ports:",
            "     - port_id",
            "    state: update",
            "",
            "# Add a process to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_processes:",
            "     -",
            "       process: test_2",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Update existing processes of a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    update_processes:",
            "     -",
            "       id: process_id",
            "       process: test_1",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "     -",
            "       id: process_id",
            "       process: test_3",
            "       alert_if: NOT_RUNNING",
            "       email_notification: false",
            "    wait: true",
            "    state: update",
            "",
            "# Remove a process from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_processes:",
            "     - process_id",
            "    wait: true",
            "    state: update",
            "",
            "# Add server to a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    add_servers:",
            "     - server id or name",
            "    wait: true",
            "    state: update",
            "",
            "# Remove server from a monitoring policy.",
            "",
            "- oneandone_moitoring_policy:",
            "    auth_token: oneandone_private_api_key",
            "    monitoring_policy: ansible monitoring policy updated",
            "    remove_servers:",
            "     - server01",
            "    wait: true",
            "    state: update",
            "'''",
            "",
            "RETURN = '''",
            "monitoring_policy:",
            "    description: Information about the monitoring policy that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"92B74394A397ECC3359825C1656D67A6\", \"name\": \"Default Policy\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_monitoring_policy,",
            "    get_server,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_ports(module, oneandone_conn, monitoring_policy_id, ports):",
            "    \"\"\"",
            "    Adds new ports to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_ports = []",
            "",
            "        for _port in ports:",
            "            monitoring_policy_port = oneandone.client.Port(",
            "                protocol=_port['protocol'],",
            "                port=_port['port'],",
            "                alert_if=_port['alert_if'],",
            "                email_notification=_port['email_notification']",
            "            )",
            "            monitoring_policy_ports.append(monitoring_policy_port)",
            "",
            "        if module.check_mode:",
            "            if monitoring_policy_ports:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            ports=monitoring_policy_ports)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_port(module, oneandone_conn, monitoring_policy_id, port_id):",
            "    \"\"\"",
            "    Removes a port from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if monitoring_policy:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_port(module, oneandone_conn, monitoring_policy_id, port_id, port):",
            "    \"\"\"",
            "    Modifies a monitoring policy port.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_port = oneandone_conn.get_monitoring_policy_port(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                port_id=port_id)",
            "            if cm_port:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_port = oneandone.client.Port(",
            "            protocol=port['protocol'],",
            "            port=port['port'],",
            "            alert_if=port['alert_if'],",
            "            email_notification=port['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_port(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            port_id=port_id,",
            "            port=monitoring_policy_port)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _add_processes(module, oneandone_conn, monitoring_policy_id, processes):",
            "    \"\"\"",
            "    Adds new processes to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_processes = []",
            "",
            "        for _process in processes:",
            "            monitoring_policy_process = oneandone.client.Process(",
            "                process=_process['process'],",
            "                alert_if=_process['alert_if'],",
            "                email_notification=_process['email_notification']",
            "            )",
            "            monitoring_policy_processes.append(monitoring_policy_process)",
            "",
            "        if module.check_mode:",
            "            mp_id = get_monitoring_policy(oneandone_conn, monitoring_policy_id)",
            "            if (monitoring_policy_processes and mp_id):",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.add_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            processes=monitoring_policy_processes)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _delete_monitoring_policy_process(module, oneandone_conn, monitoring_policy_id, process_id):",
            "    \"\"\"",
            "    Removes a process from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id",
            "            )",
            "            if process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _modify_process(module, oneandone_conn, monitoring_policy_id, process_id, process):",
            "    \"\"\"",
            "    Modifies a monitoring policy process.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            cm_process = oneandone_conn.get_monitoring_policy_process(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                process_id=process_id)",
            "            if cm_process:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy_process = oneandone.client.Process(",
            "            process=process['process'],",
            "            alert_if=process['alert_if'],",
            "            email_notification=process['email_notification']",
            "        )",
            "",
            "        monitoring_policy = oneandone_conn.modify_process(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            process_id=process_id,",
            "            process=monitoring_policy_process)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _attach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, servers):",
            "    \"\"\"",
            "    Attaches servers to a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        attach_servers = []",
            "",
            "        for _server_id in servers:",
            "            server_id = get_server(oneandone_conn, _server_id)",
            "            attach_server = oneandone.client.AttachServer(",
            "                server_id=server_id",
            "            )",
            "            attach_servers.append(attach_server)",
            "",
            "        if module.check_mode:",
            "            if attach_servers:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.attach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            servers=attach_servers)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def _detach_monitoring_policy_server(module, oneandone_conn, monitoring_policy_id, server_id):",
            "    \"\"\"",
            "    Detaches a server from a monitoring policy.",
            "    \"\"\"",
            "    try:",
            "        if module.check_mode:",
            "            mp_server = oneandone_conn.get_monitoring_policy_server(",
            "                monitoring_policy_id=monitoring_policy_id,",
            "                server_id=server_id)",
            "            if mp_server:",
            "                return True",
            "            return False",
            "",
            "        monitoring_policy = oneandone_conn.detach_monitoring_policy_server(",
            "            monitoring_policy_id=monitoring_policy_id,",
            "            server_id=server_id)",
            "        return monitoring_policy",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def update_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Updates a monitoring_policy based on input arguments.",
            "    Monitoring policy ports, processes and servers can be added/removed to/from",
            "    a monitoring policy. Monitoring policy name, description, email,",
            "    thresholds for cpu, ram, disk, transfer and internal_ping",
            "    can be updated as well.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        monitoring_policy_id = module.params.get('monitoring_policy')",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        thresholds = module.params.get('thresholds')",
            "        add_ports = module.params.get('add_ports')",
            "        update_ports = module.params.get('update_ports')",
            "        remove_ports = module.params.get('remove_ports')",
            "        add_processes = module.params.get('add_processes')",
            "        update_processes = module.params.get('update_processes')",
            "        remove_processes = module.params.get('remove_processes')",
            "        add_servers = module.params.get('add_servers')",
            "        remove_servers = module.params.get('remove_servers')",
            "",
            "        changed = False",
            "",
            "        monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy_id, True)",
            "        if monitoring_policy is None:",
            "            _check_mode(module, False)",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(",
            "            name=name,",
            "            description=description,",
            "            email=email",
            "        )",
            "",
            "        _thresholds = None",
            "",
            "        if thresholds:",
            "            threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "            _thresholds = []",
            "            for treshold in thresholds:",
            "                key = treshold.keys()[0]",
            "                if key in threshold_entities:",
            "                    _threshold = oneandone.client.Threshold(",
            "                        entity=key,",
            "                        warning_value=treshold[key]['warning']['value'],",
            "                        warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                        critical_value=treshold[key]['critical']['value'],",
            "                        critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                    _thresholds.append(_threshold)",
            "",
            "        if name or description or email or thresholds:",
            "            _check_mode(module, True)",
            "            monitoring_policy = oneandone_conn.modify_monitoring_policy(",
            "                monitoring_policy_id=monitoring_policy['id'],",
            "                monitoring_policy=_monitoring_policy,",
            "                thresholds=_thresholds)",
            "            changed = True",
            "",
            "        if add_ports:",
            "            if module.check_mode:",
            "                _check_mode(module, _add_ports(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_ports))",
            "",
            "            monitoring_policy = _add_ports(module, oneandone_conn, monitoring_policy['id'], add_ports)",
            "            changed = True",
            "",
            "        if update_ports:",
            "            chk_changed = False",
            "            for update_port in update_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_port(module,",
            "                                                oneandone_conn,",
            "                                                monitoring_policy['id'],",
            "                                                update_port['id'],",
            "                                                update_port)",
            "",
            "                _modify_port(module,",
            "                             oneandone_conn,",
            "                             monitoring_policy['id'],",
            "                             update_port['id'],",
            "                             update_port)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_ports:",
            "            chk_changed = False",
            "            for port_id in remove_ports:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_port(module,",
            "                                                                  oneandone_conn,",
            "                                                                  monitoring_policy['id'],",
            "                                                                  port_id)",
            "",
            "                _delete_monitoring_policy_port(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               port_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_processes:",
            "            monitoring_policy = _add_processes(module,",
            "                                               oneandone_conn,",
            "                                               monitoring_policy['id'],",
            "                                               add_processes)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if update_processes:",
            "            chk_changed = False",
            "            for update_process in update_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _modify_process(module,",
            "                                                   oneandone_conn,",
            "                                                   monitoring_policy['id'],",
            "                                                   update_process['id'],",
            "                                                   update_process)",
            "",
            "                _modify_process(module,",
            "                                oneandone_conn,",
            "                                monitoring_policy['id'],",
            "                                update_process['id'],",
            "                                update_process)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if remove_processes:",
            "            chk_changed = False",
            "            for process_id in remove_processes:",
            "                if module.check_mode:",
            "                    chk_changed |= _delete_monitoring_policy_process(module,",
            "                                                                     oneandone_conn,",
            "                                                                     monitoring_policy['id'],",
            "                                                                     process_id)",
            "",
            "                _delete_monitoring_policy_process(module,",
            "                                                  oneandone_conn,",
            "                                                  monitoring_policy['id'],",
            "                                                  process_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        if add_servers:",
            "            monitoring_policy = _attach_monitoring_policy_server(module,",
            "                                                                 oneandone_conn,",
            "                                                                 monitoring_policy['id'],",
            "                                                                 add_servers)",
            "            _check_mode(module, monitoring_policy)",
            "            changed = True",
            "",
            "        if remove_servers:",
            "            chk_changed = False",
            "            for _server_id in remove_servers:",
            "                server_id = get_server(oneandone_conn, _server_id)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _detach_monitoring_policy_server(module,",
            "                                                                    oneandone_conn,",
            "                                                                    monitoring_policy['id'],",
            "                                                                    server_id)",
            "",
            "                _detach_monitoring_policy_server(module,",
            "                                                 oneandone_conn,",
            "                                                 monitoring_policy['id'],",
            "                                                 server_id)",
            "            _check_mode(module, chk_changed)",
            "            monitoring_policy = get_monitoring_policy(oneandone_conn, monitoring_policy['id'], True)",
            "            changed = True",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Creates a new monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        name = module.params.get('name')",
            "        description = module.params.get('description')",
            "        email = module.params.get('email')",
            "        agent = module.params.get('agent')",
            "        thresholds = module.params.get('thresholds')",
            "        ports = module.params.get('ports')",
            "        processes = module.params.get('processes')",
            "        wait = module.params.get('wait')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        _monitoring_policy = oneandone.client.MonitoringPolicy(name,",
            "                                                               description,",
            "                                                               email,",
            "                                                               agent, )",
            "",
            "        _monitoring_policy.specs['agent'] = str(_monitoring_policy.specs['agent']).lower()",
            "",
            "        threshold_entities = ['cpu', 'ram', 'disk', 'internal_ping', 'transfer']",
            "",
            "        _thresholds = []",
            "        for treshold in thresholds:",
            "            key = treshold.keys()[0]",
            "            if key in threshold_entities:",
            "                _threshold = oneandone.client.Threshold(",
            "                    entity=key,",
            "                    warning_value=treshold[key]['warning']['value'],",
            "                    warning_alert=str(treshold[key]['warning']['alert']).lower(),",
            "                    critical_value=treshold[key]['critical']['value'],",
            "                    critical_alert=str(treshold[key]['critical']['alert']).lower())",
            "                _thresholds.append(_threshold)",
            "",
            "        _ports = []",
            "        for port in ports:",
            "            _port = oneandone.client.Port(",
            "                protocol=port['protocol'],",
            "                port=port['port'],",
            "                alert_if=port['alert_if'],",
            "                email_notification=str(port['email_notification']).lower())",
            "            _ports.append(_port)",
            "",
            "        _processes = []",
            "        for process in processes:",
            "            _process = oneandone.client.Process(",
            "                process=process['process'],",
            "                alert_if=process['alert_if'],",
            "                email_notification=str(process['email_notification']).lower())",
            "            _processes.append(_process)",
            "",
            "        _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.create_monitoring_policy(",
            "            monitoring_policy=_monitoring_policy,",
            "            thresholds=_thresholds,",
            "            ports=_ports,",
            "            processes=_processes",
            "        )",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.monitoring_policy,",
            "                monitoring_policy['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, monitoring_policy)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_monitoring_policy(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a monitoring policy.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        mp_id = module.params.get('name')",
            "        monitoring_policy_id = get_monitoring_policy(oneandone_conn, mp_id)",
            "        if module.check_mode:",
            "            if monitoring_policy_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        monitoring_policy = oneandone_conn.delete_monitoring_policy(monitoring_policy_id)",
            "",
            "        changed = True if monitoring_policy else False",
            "",
            "        return (changed, {",
            "            'id': monitoring_policy['id'],",
            "            'name': monitoring_policy['name']",
            "        })",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            name=dict(type='str'),",
            "            monitoring_policy=dict(type='str'),",
            "            agent=dict(type='str'),",
            "            email=dict(type='str'),",
            "            description=dict(type='str'),",
            "            thresholds=dict(type='list', default=[]),",
            "            ports=dict(type='list', default=[]),",
            "            processes=dict(type='list', default=[]),",
            "            add_ports=dict(type='list', default=[]),",
            "            update_ports=dict(type='list', default=[]),",
            "            remove_ports=dict(type='list', default=[]),",
            "            add_processes=dict(type='list', default=[]),",
            "            update_processes=dict(type='list', default=[]),",
            "            remove_processes=dict(type='list', default=[]),",
            "            add_servers=dict(type='list', default=[]),",
            "            remove_servers=dict(type='list', default=[]),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required to delete a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = remove_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "    elif state == 'update':",
            "        if not module.params.get('monitoring_policy'):",
            "            module.fail_json(",
            "                msg=\"'monitoring_policy' parameter is required to update a monitoring policy.\")",
            "        try:",
            "            (changed, monitoring_policy) = update_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    elif state == 'present':",
            "        for param in ('name', 'agent', 'email', 'thresholds', 'ports', 'processes'):",
            "            if not module.params.get(param):",
            "                module.fail_json(",
            "                    msg=\"%s parameter is required for a new monitoring policy.\" % param)",
            "        try:",
            "            (changed, monitoring_policy) = create_monitoring_policy(module, oneandone_conn)",
            "        except Exception as ex:",
            "            module.fail_json(msg=str(ex))",
            "",
            "    module.exit_json(changed=changed, monitoring_policy=monitoring_policy)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "953": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_private_network.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 384,
                "afterPatchRowNumber": 384,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 385,
                "afterPatchRowNumber": 385,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 386,
                "afterPatchRowNumber": 386,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 387,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 387,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 388,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 388,
                "afterPatchRowNumber": 389,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 389,
                "afterPatchRowNumber": 390,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 390,
                "afterPatchRowNumber": 391,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_private_network",
            "short_description: Configure 1&1 private networking.",
            "description:",
            "     - Create, remove, reconfigure, update a private network.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a network's state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  private_network:",
            "    description:",
            "      - The identifier (id or name) of the network used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Private network name used with present state. Used as identifier (id or name) when used with absent state.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Set a description for the network.",
            "  datacenter:",
            "    description:",
            "      - The identifier of the datacenter where the private network will be created",
            "  network_address:",
            "    description:",
            "      - Set a private network space, i.e. 192.168.1.0",
            "  subnet_mask:",
            "    description:",
            "      - Set the netmask for the private network, i.e. 255.255.255.0",
            "  add_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be added to the private network.",
            "  remove_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be removed from the private network.",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy private networks.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    name: backup_network",
            "    description: Testing creation of a private network with ansible",
            "    network_address: 70.35.193.100",
            "    subnet_mask: 255.0.0.0",
            "    datacenter: US",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: backup_network",
            "",
            "# Modify the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    network_address: 192.168.2.0",
            "    subnet_mask: 255.255.255.0",
            "",
            "# Add members to the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    add_members:",
            "     - server identifier (id or name)",
            "",
            "# Remove members from the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    remove_members:",
            "     - server identifier (id or name)",
            "",
            "'''",
            "",
            "RETURN = '''",
            "private_network:",
            "    description: Information about the private network.",
            "    type: dict",
            "    sample: '{\"name\": \"backup_network\", \"id\": \"55726DEDA20C99CF6F2AF8F18CAC9963\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_private_network,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion,",
            "    wait_for_resource_deletion_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_servers(module, oneandone_conn, name, members):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id and members:",
            "                return True",
            "            return False",
            "",
            "        network = oneandone_conn.attach_private_network_servers(",
            "            private_network_id=private_network_id,",
            "            server_ids=members)",
            "",
            "        return network",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_member(module, oneandone_conn, name, member_id):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id:",
            "                network_member = oneandone_conn.get_private_network_server(",
            "                    private_network_id=private_network_id,",
            "                    server_id=member_id)",
            "                if network_member:",
            "                    return True",
            "            return False",
            "",
            "        network = oneandone_conn.remove_private_network_server(",
            "            private_network_id=name,",
            "            server_id=member_id)",
            "",
            "        return network",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new private network",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any network was added.",
            "    \"\"\"",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    network_address = module.params.get('network_address')",
            "    subnet_mask = module.params.get('subnet_mask')",
            "    datacenter = module.params.get('datacenter')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        network = oneandone_conn.create_private_network(",
            "            private_network=oneandone.client.PrivateNetwork(",
            "                name=name,",
            "                description=description,",
            "                network_address=network_address,",
            "                subnet_mask=subnet_mask,",
            "                datacenter_id=datacenter_id",
            "            ))",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.private_network,",
            "                network['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "            network = get_private_network(oneandone_conn,",
            "                                          network['id'],",
            "                                          True)",
            "",
            "        changed = True if network else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, network)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Modifies a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        _private_network_id = module.params.get('private_network')",
            "        _name = module.params.get('name')",
            "        _description = module.params.get('description')",
            "        _network_address = module.params.get('network_address')",
            "        _subnet_mask = module.params.get('subnet_mask')",
            "        _add_members = module.params.get('add_members')",
            "        _remove_members = module.params.get('remove_members')",
            "",
            "        changed = False",
            "",
            "        private_network = get_private_network(oneandone_conn,",
            "                                              _private_network_id,",
            "                                              True)",
            "        if private_network is None:",
            "            _check_mode(module, False)",
            "",
            "        if _name or _description or _network_address or _subnet_mask:",
            "            _check_mode(module, True)",
            "            private_network = oneandone_conn.modify_private_network(",
            "                private_network_id=private_network['id'],",
            "                name=_name,",
            "                description=_description,",
            "                network_address=_network_address,",
            "                subnet_mask=_subnet_mask)",
            "            changed = True",
            "",
            "        if _add_members:",
            "            instances = []",
            "",
            "            for member in _add_members:",
            "                instance_id = get_server(oneandone_conn, member)",
            "                instance_obj = oneandone.client.AttachServer(server_id=instance_id)",
            "",
            "                instances.extend([instance_obj])",
            "            private_network = _add_servers(module, oneandone_conn, private_network['id'], instances)",
            "            _check_mode(module, private_network)",
            "            changed = True",
            "",
            "        if _remove_members:",
            "            chk_changed = False",
            "            for member in _remove_members:",
            "                instance = get_server(oneandone_conn, member, True)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_member(module,",
            "                                                  oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  instance['id'])",
            "                _check_mode(module, instance and chk_changed)",
            "",
            "                _remove_member(module,",
            "                               oneandone_conn,",
            "                               private_network['id'],",
            "                               instance['id'])",
            "            private_network = get_private_network(oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  True)",
            "            changed = True",
            "",
            "        return (changed, private_network)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object.",
            "    \"\"\"",
            "    try:",
            "        pn_id = module.params.get('name')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        private_network_id = get_private_network(oneandone_conn, pn_id)",
            "        if module.check_mode:",
            "            if private_network_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        private_network = oneandone_conn.delete_private_network(private_network_id)",
            "        wait_for_resource_deletion_completion(oneandone_conn,",
            "                                              OneAndOneResources.private_network,",
            "                                              private_network['id'],",
            "                                              wait_timeout,",
            "                                              wait_interval)",
            "",
            "        changed = True if private_network else False",
            "",
            "        return (changed, {",
            "            'id': private_network['id'],",
            "            'name': private_network['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            private_network=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            network_address=dict(type='str'),",
            "            subnet_mask=dict(type='str'),",
            "            add_members=dict(type='list', default=[]),",
            "            remove_members=dict(type='list', default=[]),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a network.\")",
            "        try:",
            "            (changed, private_network) = remove_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('private_network'):",
            "            module.fail_json(",
            "                msg=\"'private_network' parameter is required for updating a network.\")",
            "        try:",
            "            (changed, private_network) = update_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'present':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for new networks.\")",
            "        try:",
            "            (changed, private_network) = create_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, private_network=private_network)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_private_network",
            "short_description: Configure 1&1 private networking.",
            "description:",
            "     - Create, remove, reconfigure, update a private network.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a network's state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  private_network:",
            "    description:",
            "      - The identifier (id or name) of the network used with update state.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  name:",
            "    description:",
            "      - Private network name used with present state. Used as identifier (id or name) when used with absent state.",
            "    required: true",
            "  description:",
            "    description:",
            "      - Set a description for the network.",
            "  datacenter:",
            "    description:",
            "      - The identifier of the datacenter where the private network will be created",
            "  network_address:",
            "    description:",
            "      - Set a private network space, i.e. 192.168.1.0",
            "  subnet_mask:",
            "    description:",
            "      - Set the netmask for the private network, i.e. 255.255.255.0",
            "  add_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be added to the private network.",
            "  remove_members:",
            "    description:",
            "      - List of server identifiers (name or id) to be removed from the private network.",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Provisioning example. Create and destroy private networks.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    name: backup_network",
            "    description: Testing creation of a private network with ansible",
            "    network_address: 70.35.193.100",
            "    subnet_mask: 255.0.0.0",
            "    datacenter: US",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: absent",
            "    name: backup_network",
            "",
            "# Modify the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    network_address: 192.168.2.0",
            "    subnet_mask: 255.255.255.0",
            "",
            "# Add members to the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    add_members:",
            "     - server identifier (id or name)",
            "",
            "# Remove members from the private network.",
            "",
            "- oneandone_private_network:",
            "    auth_token: oneandone_private_api_key",
            "    state: update",
            "    private_network: backup_network",
            "    remove_members:",
            "     - server identifier (id or name)",
            "",
            "'''",
            "",
            "RETURN = '''",
            "private_network:",
            "    description: Information about the private network.",
            "    type: dict",
            "    sample: '{\"name\": \"backup_network\", \"id\": \"55726DEDA20C99CF6F2AF8F18CAC9963\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_private_network,",
            "    get_server,",
            "    get_datacenter,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion,",
            "    wait_for_resource_deletion_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def _add_servers(module, oneandone_conn, name, members):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id and members:",
            "                return True",
            "            return False",
            "",
            "        network = oneandone_conn.attach_private_network_servers(",
            "            private_network_id=private_network_id,",
            "            server_ids=members)",
            "",
            "        return network",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def _remove_member(module, oneandone_conn, name, member_id):",
            "    try:",
            "        private_network_id = get_private_network(oneandone_conn, name)",
            "",
            "        if module.check_mode:",
            "            if private_network_id:",
            "                network_member = oneandone_conn.get_private_network_server(",
            "                    private_network_id=private_network_id,",
            "                    server_id=member_id)",
            "                if network_member:",
            "                    return True",
            "            return False",
            "",
            "        network = oneandone_conn.remove_private_network_server(",
            "            private_network_id=name,",
            "            server_id=member_id)",
            "",
            "        return network",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def create_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new private network",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any network was added.",
            "    \"\"\"",
            "    name = module.params.get('name')",
            "    description = module.params.get('description')",
            "    network_address = module.params.get('network_address')",
            "    subnet_mask = module.params.get('subnet_mask')",
            "    datacenter = module.params.get('datacenter')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        network = oneandone_conn.create_private_network(",
            "            private_network=oneandone.client.PrivateNetwork(",
            "                name=name,",
            "                description=description,",
            "                network_address=network_address,",
            "                subnet_mask=subnet_mask,",
            "                datacenter_id=datacenter_id",
            "            ))",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(",
            "                oneandone_conn,",
            "                OneAndOneResources.private_network,",
            "                network['id'],",
            "                wait_timeout,",
            "                wait_interval)",
            "            network = get_private_network(oneandone_conn,",
            "                                          network['id'],",
            "                                          True)",
            "",
            "        changed = True if network else False",
            "",
            "        _check_mode(module, False)",
            "",
            "        return (changed, network)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Modifies a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "    \"\"\"",
            "    try:",
            "        _private_network_id = module.params.get('private_network')",
            "        _name = module.params.get('name')",
            "        _description = module.params.get('description')",
            "        _network_address = module.params.get('network_address')",
            "        _subnet_mask = module.params.get('subnet_mask')",
            "        _add_members = module.params.get('add_members')",
            "        _remove_members = module.params.get('remove_members')",
            "",
            "        changed = False",
            "",
            "        private_network = get_private_network(oneandone_conn,",
            "                                              _private_network_id,",
            "                                              True)",
            "        if private_network is None:",
            "            _check_mode(module, False)",
            "",
            "        if _name or _description or _network_address or _subnet_mask:",
            "            _check_mode(module, True)",
            "            private_network = oneandone_conn.modify_private_network(",
            "                private_network_id=private_network['id'],",
            "                name=_name,",
            "                description=_description,",
            "                network_address=_network_address,",
            "                subnet_mask=_subnet_mask)",
            "            changed = True",
            "",
            "        if _add_members:",
            "            instances = []",
            "",
            "            for member in _add_members:",
            "                instance_id = get_server(oneandone_conn, member)",
            "                instance_obj = oneandone.client.AttachServer(server_id=instance_id)",
            "",
            "                instances.extend([instance_obj])",
            "            private_network = _add_servers(module, oneandone_conn, private_network['id'], instances)",
            "            _check_mode(module, private_network)",
            "            changed = True",
            "",
            "        if _remove_members:",
            "            chk_changed = False",
            "            for member in _remove_members:",
            "                instance = get_server(oneandone_conn, member, True)",
            "",
            "                if module.check_mode:",
            "                    chk_changed |= _remove_member(module,",
            "                                                  oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  instance['id'])",
            "                _check_mode(module, instance and chk_changed)",
            "",
            "                _remove_member(module,",
            "                               oneandone_conn,",
            "                               private_network['id'],",
            "                               instance['id'])",
            "            private_network = get_private_network(oneandone_conn,",
            "                                                  private_network['id'],",
            "                                                  True)",
            "            changed = True",
            "",
            "        return (changed, private_network)",
            "    except Exception as ex:",
            "        module.fail_json(msg=str(ex))",
            "",
            "",
            "def remove_network(module, oneandone_conn):",
            "    \"\"\"",
            "    Removes a private network.",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object.",
            "    \"\"\"",
            "    try:",
            "        pn_id = module.params.get('name')",
            "        wait_timeout = module.params.get('wait_timeout')",
            "        wait_interval = module.params.get('wait_interval')",
            "",
            "        private_network_id = get_private_network(oneandone_conn, pn_id)",
            "        if module.check_mode:",
            "            if private_network_id is None:",
            "                _check_mode(module, False)",
            "            _check_mode(module, True)",
            "        private_network = oneandone_conn.delete_private_network(private_network_id)",
            "        wait_for_resource_deletion_completion(oneandone_conn,",
            "                                              OneAndOneResources.private_network,",
            "                                              private_network['id'],",
            "                                              wait_timeout,",
            "                                              wait_interval)",
            "",
            "        changed = True if private_network else False",
            "",
            "        return (changed, {",
            "            'id': private_network['id'],",
            "            'name': private_network['name']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            private_network=dict(type='str'),",
            "            name=dict(type='str'),",
            "            description=dict(type='str'),",
            "            network_address=dict(type='str'),",
            "            subnet_mask=dict(type='str'),",
            "            add_members=dict(type='list', default=[]),",
            "            remove_members=dict(type='list', default=[]),",
            "            datacenter=dict(",
            "                choices=DATACENTERS),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for deleting a network.\")",
            "        try:",
            "            (changed, private_network) = remove_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('private_network'):",
            "            module.fail_json(",
            "                msg=\"'private_network' parameter is required for updating a network.\")",
            "        try:",
            "            (changed, private_network) = update_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'present':",
            "        if not module.params.get('name'):",
            "            module.fail_json(",
            "                msg=\"'name' parameter is required for new networks.\")",
            "        try:",
            "            (changed, private_network) = create_network(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, private_network=private_network)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "387": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/oneandone/oneandone_public_ip.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 277,
                "afterPatchRowNumber": 277,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 278,
                "afterPatchRowNumber": 278,
                "PatchRowcode": "             auth_token=dict("
            },
            "2": {
                "beforePatchRowNumber": 279,
                "afterPatchRowNumber": 279,
                "PatchRowcode": "                 type='str',"
            },
            "3": {
                "beforePatchRowNumber": 280,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 280,
                "PatchRowcode": "+                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 281,
                "PatchRowcode": "+                no_log=True),"
            },
            "6": {
                "beforePatchRowNumber": 281,
                "afterPatchRowNumber": 282,
                "PatchRowcode": "             api_url=dict("
            },
            "7": {
                "beforePatchRowNumber": 282,
                "afterPatchRowNumber": 283,
                "PatchRowcode": "                 type='str',"
            },
            "8": {
                "beforePatchRowNumber": 283,
                "afterPatchRowNumber": 284,
                "PatchRowcode": "                 default=os.environ.get('ONEANDONE_API_URL')),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_public_ip",
            "short_description: Configure 1&1 public IPs.",
            "description:",
            "     - Create, update, and remove public IPs.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a public ip state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  reverse_dns:",
            "    description:",
            "      - Reverse DNS name. maxLength=256",
            "    required: false",
            "  datacenter:",
            "    description:",
            "      - ID of the datacenter where the IP will be created (only for unassigned IPs).",
            "    required: false",
            "  type:",
            "    description:",
            "      - Type of IP. Currently, only IPV4 is available.",
            "    choices: [\"IPV4\", \"IPV6\"]",
            "    default: 'IPV4'",
            "    required: false",
            "  public_ip_id:",
            "    description:",
            "      - The ID of the public IP used with update and delete states.",
            "    required: true",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Create a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    reverse_dns: example.com",
            "    datacenter: US",
            "    type: IPV4",
            "",
            "# Update a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    reverse_dns: secondexample.com",
            "    state: update",
            "",
            "",
            "# Delete a public IP",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    state: absent",
            "",
            "'''",
            "",
            "RETURN = '''",
            "public_ip:",
            "    description: Information about the public ip that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"F77CC589EBC120905B4F4719217BFF6D\", \"ip\": \"10.5.132.106\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_datacenter,",
            "    get_public_ip,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "TYPES = ['IPV4', 'IPV6']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def create_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was added.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    datacenter = module.params.get('datacenter')",
            "    ip_type = module.params.get('type')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            _check_mode(module, False)",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.create_public_ip(",
            "            reverse_dns=reverse_dns,",
            "            ip_type=ip_type,",
            "            datacenter_id=datacenter_id)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Update a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was changed.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    public_ip_id = module.params.get('public_ip_id')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.modify_public_ip(",
            "            ip_id=public_ip['id'],",
            "            reverse_dns=reverse_dns)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def delete_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Delete a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was deleted.",
            "    \"\"\"",
            "    public_ip_id = module.params.get('public_ip_id')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        deleted_public_ip = oneandone_conn.delete_public_ip(",
            "            ip_id=public_ip['id'])",
            "",
            "        changed = True if deleted_public_ip else False",
            "",
            "        return (changed, {",
            "            'id': public_ip['id']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN')),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            public_ip_id=dict(type='str'),",
            "            reverse_dns=dict(type='str'),",
            "            datacenter=dict(",
            "                choices=DATACENTERS,",
            "                default='US'),",
            "            type=dict(",
            "                choices=TYPES,",
            "                default='IPV4'),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to delete a public ip.\")",
            "        try:",
            "            (changed, public_ip) = delete_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to update a public ip.\")",
            "        try:",
            "            (changed, public_ip) = update_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        try:",
            "            (changed, public_ip) = create_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, public_ip=public_ip)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: oneandone_public_ip",
            "short_description: Configure 1&1 public IPs.",
            "description:",
            "     - Create, update, and remove public IPs.",
            "       This module has a dependency on 1and1 >= 1.0",
            "version_added: \"2.5\"",
            "options:",
            "  state:",
            "    description:",
            "      - Define a public ip state to create, remove, or update.",
            "    required: false",
            "    default: 'present'",
            "    choices: [ \"present\", \"absent\", \"update\" ]",
            "  auth_token:",
            "    description:",
            "      - Authenticating API token provided by 1&1.",
            "    required: true",
            "  api_url:",
            "    description:",
            "      - Custom API URL. Overrides the",
            "        ONEANDONE_API_URL environement variable.",
            "    required: false",
            "  reverse_dns:",
            "    description:",
            "      - Reverse DNS name. maxLength=256",
            "    required: false",
            "  datacenter:",
            "    description:",
            "      - ID of the datacenter where the IP will be created (only for unassigned IPs).",
            "    required: false",
            "  type:",
            "    description:",
            "      - Type of IP. Currently, only IPV4 is available.",
            "    choices: [\"IPV4\", \"IPV6\"]",
            "    default: 'IPV4'",
            "    required: false",
            "  public_ip_id:",
            "    description:",
            "      - The ID of the public IP used with update and delete states.",
            "    required: true",
            "  wait:",
            "    description:",
            "      - wait for the instance to be in state 'running' before returning",
            "    required: false",
            "    default: \"yes\"",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "      - how long before wait gives up, in seconds",
            "    default: 600",
            "  wait_interval:",
            "    description:",
            "      - Defines the number of seconds to wait when using the _wait_for methods",
            "    default: 5",
            "",
            "requirements:",
            "     - \"1and1\"",
            "     - \"python >= 2.6\"",
            "",
            "author:",
            "  - Amel Ajdinovic (@aajdinov)",
            "  - Ethan Devenport (@edevenport)",
            "'''",
            "",
            "EXAMPLES = '''",
            "",
            "# Create a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    reverse_dns: example.com",
            "    datacenter: US",
            "    type: IPV4",
            "",
            "# Update a public IP.",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    reverse_dns: secondexample.com",
            "    state: update",
            "",
            "",
            "# Delete a public IP",
            "",
            "- oneandone_public_ip:",
            "    auth_token: oneandone_private_api_key",
            "    public_ip_id: public ip id",
            "    state: absent",
            "",
            "'''",
            "",
            "RETURN = '''",
            "public_ip:",
            "    description: Information about the public ip that was processed",
            "    type: dict",
            "    sample: '{\"id\": \"F77CC589EBC120905B4F4719217BFF6D\", \"ip\": \"10.5.132.106\"}'",
            "    returned: always",
            "'''",
            "",
            "import os",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.oneandone import (",
            "    get_datacenter,",
            "    get_public_ip,",
            "    OneAndOneResources,",
            "    wait_for_resource_creation_completion",
            ")",
            "",
            "HAS_ONEANDONE_SDK = True",
            "",
            "try:",
            "    import oneandone.client",
            "except ImportError:",
            "    HAS_ONEANDONE_SDK = False",
            "",
            "DATACENTERS = ['US', 'ES', 'DE', 'GB']",
            "",
            "TYPES = ['IPV4', 'IPV6']",
            "",
            "",
            "def _check_mode(module, result):",
            "    if module.check_mode:",
            "        module.exit_json(",
            "            changed=result",
            "        )",
            "",
            "",
            "def create_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Create new public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was added.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    datacenter = module.params.get('datacenter')",
            "    ip_type = module.params.get('type')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    if datacenter is not None:",
            "        datacenter_id = get_datacenter(oneandone_conn, datacenter)",
            "        if datacenter_id is None:",
            "            _check_mode(module, False)",
            "            module.fail_json(",
            "                msg='datacenter %s not found.' % datacenter)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.create_public_ip(",
            "            reverse_dns=reverse_dns,",
            "            ip_type=ip_type,",
            "            datacenter_id=datacenter_id)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def update_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Update a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was changed.",
            "    \"\"\"",
            "    reverse_dns = module.params.get('reverse_dns')",
            "    public_ip_id = module.params.get('public_ip_id')",
            "    wait = module.params.get('wait')",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_interval = module.params.get('wait_interval')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        public_ip = oneandone_conn.modify_public_ip(",
            "            ip_id=public_ip['id'],",
            "            reverse_dns=reverse_dns)",
            "",
            "        if wait:",
            "            wait_for_resource_creation_completion(oneandone_conn,",
            "                                                  OneAndOneResources.public_ip,",
            "                                                  public_ip['id'],",
            "                                                  wait_timeout,",
            "                                                  wait_interval)",
            "            public_ip = oneandone_conn.get_public_ip(public_ip['id'])",
            "",
            "        changed = True if public_ip else False",
            "",
            "        return (changed, public_ip)",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def delete_public_ip(module, oneandone_conn):",
            "    \"\"\"",
            "    Delete a public IP",
            "",
            "    module : AnsibleModule object",
            "    oneandone_conn: authenticated oneandone object",
            "",
            "    Returns a dictionary containing a 'changed' attribute indicating whether",
            "    any public IP was deleted.",
            "    \"\"\"",
            "    public_ip_id = module.params.get('public_ip_id')",
            "",
            "    public_ip = get_public_ip(oneandone_conn, public_ip_id, True)",
            "    if public_ip is None:",
            "        _check_mode(module, False)",
            "        module.fail_json(",
            "            msg='public IP %s not found.' % public_ip_id)",
            "",
            "    try:",
            "        _check_mode(module, True)",
            "        deleted_public_ip = oneandone_conn.delete_public_ip(",
            "            ip_id=public_ip['id'])",
            "",
            "        changed = True if deleted_public_ip else False",
            "",
            "        return (changed, {",
            "            'id': public_ip['id']",
            "        })",
            "    except Exception as e:",
            "        module.fail_json(msg=str(e))",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            auth_token=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_AUTH_TOKEN'),",
            "                no_log=True),",
            "            api_url=dict(",
            "                type='str',",
            "                default=os.environ.get('ONEANDONE_API_URL')),",
            "            public_ip_id=dict(type='str'),",
            "            reverse_dns=dict(type='str'),",
            "            datacenter=dict(",
            "                choices=DATACENTERS,",
            "                default='US'),",
            "            type=dict(",
            "                choices=TYPES,",
            "                default='IPV4'),",
            "            wait=dict(type='bool', default=True),",
            "            wait_timeout=dict(type='int', default=600),",
            "            wait_interval=dict(type='int', default=5),",
            "            state=dict(type='str', default='present', choices=['present', 'absent', 'update']),",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    if not HAS_ONEANDONE_SDK:",
            "        module.fail_json(msg='1and1 required for this module')",
            "",
            "    if not module.params.get('auth_token'):",
            "        module.fail_json(",
            "            msg='auth_token parameter is required.')",
            "",
            "    if not module.params.get('api_url'):",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'))",
            "    else:",
            "        oneandone_conn = oneandone.client.OneAndOneService(",
            "            api_token=module.params.get('auth_token'), api_url=module.params.get('api_url'))",
            "",
            "    state = module.params.get('state')",
            "",
            "    if state == 'absent':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to delete a public ip.\")",
            "        try:",
            "            (changed, public_ip) = delete_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "    elif state == 'update':",
            "        if not module.params.get('public_ip_id'):",
            "            module.fail_json(",
            "                msg=\"'public_ip_id' parameter is required to update a public ip.\")",
            "        try:",
            "            (changed, public_ip) = update_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    elif state == 'present':",
            "        try:",
            "            (changed, public_ip) = create_public_ip(module, oneandone_conn)",
            "        except Exception as e:",
            "            module.fail_json(msg=str(e))",
            "",
            "    module.exit_json(changed=changed, public_ip=public_ip)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "280": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/rackspace/rax_clb_ssl.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         loadbalancer=dict(required=True),"
            },
            "1": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "         state=dict(default='present', choices=['present', 'absent']),"
            },
            "2": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "         enabled=dict(type='bool', default=True),"
            },
            "3": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        private_key=dict(),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 239,
                "PatchRowcode": "+        private_key=dict(no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "         certificate=dict(),"
            },
            "6": {
                "beforePatchRowNumber": 241,
                "afterPatchRowNumber": 241,
                "PatchRowcode": "         intermediate_certificate=dict(),"
            },
            "7": {
                "beforePatchRowNumber": 242,
                "afterPatchRowNumber": 242,
                "PatchRowcode": "         secure_port=dict(type='int', default=443),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "module: rax_clb_ssl",
            "short_description: Manage SSL termination for a Rackspace Cloud Load Balancer.",
            "description:",
            "- Set up, reconfigure, or remove SSL termination for an existing load balancer.",
            "version_added: \"2.0\"",
            "options:",
            "  loadbalancer:",
            "    description:",
            "    - Name or ID of the load balancer on which to manage SSL termination.",
            "    required: true",
            "  state:",
            "    description:",
            "    - If set to \"present\", SSL termination will be added to this load balancer.",
            "    - If \"absent\", SSL termination will be removed instead.",
            "    choices:",
            "      - present",
            "      - absent",
            "    default: present",
            "  enabled:",
            "    description:",
            "    - If set to \"false\", temporarily disable SSL termination without discarding",
            "    - existing credentials.",
            "    default: true",
            "    type: bool",
            "  private_key:",
            "    description:",
            "    - The private SSL key as a string in PEM format.",
            "  certificate:",
            "    description:",
            "    - The public SSL certificates as a string in PEM format.",
            "  intermediate_certificate:",
            "    description:",
            "    - One or more intermediate certificate authorities as a string in PEM",
            "    - format, concatenated into a single string.",
            "  secure_port:",
            "    description:",
            "    - The port to listen for secure traffic.",
            "    default: 443",
            "  secure_traffic_only:",
            "    description:",
            "    - If \"true\", the load balancer will *only* accept secure traffic.",
            "    default: false",
            "    type: bool",
            "  https_redirect:",
            "    description:",
            "    - If \"true\", the load balancer will redirect HTTP traffic to HTTPS.",
            "    - Requires \"secure_traffic_only\" to be true. Incurs an implicit wait if SSL",
            "    - termination is also applied or removed.",
            "    type: bool",
            "  wait:",
            "    description:",
            "    - Wait for the balancer to be in state \"running\" before turning.",
            "    default: false",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "    - How long before \"wait\" gives up, in seconds.",
            "    default: 300",
            "author: Ash Wilson (@smashwilson)",
            "extends_documentation_fragment:",
            "  - rackspace",
            "  - rackspace.openstack",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Enable SSL termination on a load balancer",
            "  rax_clb_ssl:",
            "    loadbalancer: the_loadbalancer",
            "    state: present",
            "    private_key: \"{{ lookup('file', 'credentials/server.key' ) }}\"",
            "    certificate: \"{{ lookup('file', 'credentials/server.crt' ) }}\"",
            "    intermediate_certificate: \"{{ lookup('file', 'credentials/trust-chain.crt') }}\"",
            "    secure_traffic_only: true",
            "    wait: true",
            "",
            "- name: Disable SSL termination",
            "  rax_clb_ssl:",
            "    loadbalancer: \"{{ registered_lb.balancer.id }}\"",
            "    state: absent",
            "    wait: true",
            "'''",
            "",
            "try:",
            "    import pyrax",
            "    HAS_PYRAX = True",
            "except ImportError:",
            "    HAS_PYRAX = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.rax import (rax_argument_spec,",
            "                                      rax_find_loadbalancer,",
            "                                      rax_required_together,",
            "                                      rax_to_dict,",
            "                                      setup_rax_module,",
            "                                      )",
            "",
            "",
            "def cloud_load_balancer_ssl(module, loadbalancer, state, enabled, private_key,",
            "                            certificate, intermediate_certificate, secure_port,",
            "                            secure_traffic_only, https_redirect,",
            "                            wait, wait_timeout):",
            "    # Validate arguments.",
            "",
            "    if state == 'present':",
            "        if not private_key:",
            "            module.fail_json(msg=\"private_key must be provided.\")",
            "        else:",
            "            private_key = private_key.strip()",
            "",
            "        if not certificate:",
            "            module.fail_json(msg=\"certificate must be provided.\")",
            "        else:",
            "            certificate = certificate.strip()",
            "",
            "    attempts = wait_timeout // 5",
            "",
            "    # Locate the load balancer.",
            "",
            "    balancer = rax_find_loadbalancer(module, pyrax, loadbalancer)",
            "    existing_ssl = balancer.get_ssl_termination()",
            "",
            "    changed = False",
            "",
            "    if state == 'present':",
            "        # Apply or reconfigure SSL termination on the load balancer.",
            "        ssl_attrs = dict(",
            "            securePort=secure_port,",
            "            privatekey=private_key,",
            "            certificate=certificate,",
            "            intermediateCertificate=intermediate_certificate,",
            "            enabled=enabled,",
            "            secureTrafficOnly=secure_traffic_only",
            "        )",
            "",
            "        needs_change = False",
            "",
            "        if existing_ssl:",
            "            for ssl_attr, value in ssl_attrs.items():",
            "                if ssl_attr == 'privatekey':",
            "                    # The private key is not included in get_ssl_termination's",
            "                    # output (as it shouldn't be). Also, if you're changing the",
            "                    # private key, you'll also be changing the certificate,",
            "                    # so we don't lose anything by not checking it.",
            "                    continue",
            "",
            "                if value is not None and existing_ssl.get(ssl_attr) != value:",
            "                    # module.fail_json(msg='Unnecessary change', attr=ssl_attr, value=value, existing=existing_ssl.get(ssl_attr))",
            "                    needs_change = True",
            "        else:",
            "            needs_change = True",
            "",
            "        if needs_change:",
            "            try:",
            "                balancer.add_ssl_termination(**ssl_attrs)",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "    elif state == 'absent':",
            "        # Remove SSL termination if it's already configured.",
            "        if existing_ssl:",
            "            try:",
            "                balancer.delete_ssl_termination()",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "",
            "    if https_redirect is not None and balancer.httpsRedirect != https_redirect:",
            "        if changed:",
            "            # This wait is unavoidable because load balancers are immutable",
            "            # while the SSL termination changes above are being applied.",
            "            pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "        try:",
            "            balancer.update(httpsRedirect=https_redirect)",
            "        except pyrax.exceptions.PyraxException as e:",
            "            module.fail_json(msg='%s' % e.message)",
            "        changed = True",
            "",
            "    if changed and wait:",
            "        pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "    balancer.get()",
            "    new_ssl_termination = balancer.get_ssl_termination()",
            "",
            "    # Intentionally omit the private key from the module output, so you don't",
            "    # accidentally echo it with `ansible-playbook -v` or `debug`, and the",
            "    # certificate, which is just long. Convert other attributes to snake_case",
            "    # and include https_redirect at the top-level.",
            "    if new_ssl_termination:",
            "        new_ssl = dict(",
            "            enabled=new_ssl_termination['enabled'],",
            "            secure_port=new_ssl_termination['securePort'],",
            "            secure_traffic_only=new_ssl_termination['secureTrafficOnly']",
            "        )",
            "    else:",
            "        new_ssl = None",
            "",
            "    result = dict(",
            "        changed=changed,",
            "        https_redirect=balancer.httpsRedirect,",
            "        ssl_termination=new_ssl,",
            "        balancer=rax_to_dict(balancer, 'clb')",
            "    )",
            "    success = True",
            "",
            "    if balancer.status == 'ERROR':",
            "        result['msg'] = '%s failed to build' % balancer.id",
            "        success = False",
            "    elif wait and balancer.status not in ('ACTIVE', 'ERROR'):",
            "        result['msg'] = 'Timeout waiting on %s' % balancer.id",
            "        success = False",
            "",
            "    if success:",
            "        module.exit_json(**result)",
            "    else:",
            "        module.fail_json(**result)",
            "",
            "",
            "def main():",
            "    argument_spec = rax_argument_spec()",
            "    argument_spec.update(dict(",
            "        loadbalancer=dict(required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        enabled=dict(type='bool', default=True),",
            "        private_key=dict(),",
            "        certificate=dict(),",
            "        intermediate_certificate=dict(),",
            "        secure_port=dict(type='int', default=443),",
            "        secure_traffic_only=dict(type='bool', default=False),",
            "        https_redirect=dict(type='bool'),",
            "        wait=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int', default=300)",
            "    ))",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=argument_spec,",
            "        required_together=rax_required_together(),",
            "    )",
            "",
            "    if not HAS_PYRAX:",
            "        module.fail_json(msg='pyrax is required for this module.')",
            "",
            "    loadbalancer = module.params.get('loadbalancer')",
            "    state = module.params.get('state')",
            "    enabled = module.boolean(module.params.get('enabled'))",
            "    private_key = module.params.get('private_key')",
            "    certificate = module.params.get('certificate')",
            "    intermediate_certificate = module.params.get('intermediate_certificate')",
            "    secure_port = module.params.get('secure_port')",
            "    secure_traffic_only = module.boolean(module.params.get('secure_traffic_only'))",
            "    https_redirect = module.boolean(module.params.get('https_redirect'))",
            "    wait = module.boolean(module.params.get('wait'))",
            "    wait_timeout = module.params.get('wait_timeout')",
            "",
            "    setup_rax_module(module, pyrax)",
            "",
            "    cloud_load_balancer_ssl(",
            "        module, loadbalancer, state, enabled, private_key, certificate,",
            "        intermediate_certificate, secure_port, secure_traffic_only,",
            "        https_redirect, wait, wait_timeout",
            "    )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "module: rax_clb_ssl",
            "short_description: Manage SSL termination for a Rackspace Cloud Load Balancer.",
            "description:",
            "- Set up, reconfigure, or remove SSL termination for an existing load balancer.",
            "version_added: \"2.0\"",
            "options:",
            "  loadbalancer:",
            "    description:",
            "    - Name or ID of the load balancer on which to manage SSL termination.",
            "    required: true",
            "  state:",
            "    description:",
            "    - If set to \"present\", SSL termination will be added to this load balancer.",
            "    - If \"absent\", SSL termination will be removed instead.",
            "    choices:",
            "      - present",
            "      - absent",
            "    default: present",
            "  enabled:",
            "    description:",
            "    - If set to \"false\", temporarily disable SSL termination without discarding",
            "    - existing credentials.",
            "    default: true",
            "    type: bool",
            "  private_key:",
            "    description:",
            "    - The private SSL key as a string in PEM format.",
            "  certificate:",
            "    description:",
            "    - The public SSL certificates as a string in PEM format.",
            "  intermediate_certificate:",
            "    description:",
            "    - One or more intermediate certificate authorities as a string in PEM",
            "    - format, concatenated into a single string.",
            "  secure_port:",
            "    description:",
            "    - The port to listen for secure traffic.",
            "    default: 443",
            "  secure_traffic_only:",
            "    description:",
            "    - If \"true\", the load balancer will *only* accept secure traffic.",
            "    default: false",
            "    type: bool",
            "  https_redirect:",
            "    description:",
            "    - If \"true\", the load balancer will redirect HTTP traffic to HTTPS.",
            "    - Requires \"secure_traffic_only\" to be true. Incurs an implicit wait if SSL",
            "    - termination is also applied or removed.",
            "    type: bool",
            "  wait:",
            "    description:",
            "    - Wait for the balancer to be in state \"running\" before turning.",
            "    default: false",
            "    type: bool",
            "  wait_timeout:",
            "    description:",
            "    - How long before \"wait\" gives up, in seconds.",
            "    default: 300",
            "author: Ash Wilson (@smashwilson)",
            "extends_documentation_fragment:",
            "  - rackspace",
            "  - rackspace.openstack",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Enable SSL termination on a load balancer",
            "  rax_clb_ssl:",
            "    loadbalancer: the_loadbalancer",
            "    state: present",
            "    private_key: \"{{ lookup('file', 'credentials/server.key' ) }}\"",
            "    certificate: \"{{ lookup('file', 'credentials/server.crt' ) }}\"",
            "    intermediate_certificate: \"{{ lookup('file', 'credentials/trust-chain.crt') }}\"",
            "    secure_traffic_only: true",
            "    wait: true",
            "",
            "- name: Disable SSL termination",
            "  rax_clb_ssl:",
            "    loadbalancer: \"{{ registered_lb.balancer.id }}\"",
            "    state: absent",
            "    wait: true",
            "'''",
            "",
            "try:",
            "    import pyrax",
            "    HAS_PYRAX = True",
            "except ImportError:",
            "    HAS_PYRAX = False",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.rax import (rax_argument_spec,",
            "                                      rax_find_loadbalancer,",
            "                                      rax_required_together,",
            "                                      rax_to_dict,",
            "                                      setup_rax_module,",
            "                                      )",
            "",
            "",
            "def cloud_load_balancer_ssl(module, loadbalancer, state, enabled, private_key,",
            "                            certificate, intermediate_certificate, secure_port,",
            "                            secure_traffic_only, https_redirect,",
            "                            wait, wait_timeout):",
            "    # Validate arguments.",
            "",
            "    if state == 'present':",
            "        if not private_key:",
            "            module.fail_json(msg=\"private_key must be provided.\")",
            "        else:",
            "            private_key = private_key.strip()",
            "",
            "        if not certificate:",
            "            module.fail_json(msg=\"certificate must be provided.\")",
            "        else:",
            "            certificate = certificate.strip()",
            "",
            "    attempts = wait_timeout // 5",
            "",
            "    # Locate the load balancer.",
            "",
            "    balancer = rax_find_loadbalancer(module, pyrax, loadbalancer)",
            "    existing_ssl = balancer.get_ssl_termination()",
            "",
            "    changed = False",
            "",
            "    if state == 'present':",
            "        # Apply or reconfigure SSL termination on the load balancer.",
            "        ssl_attrs = dict(",
            "            securePort=secure_port,",
            "            privatekey=private_key,",
            "            certificate=certificate,",
            "            intermediateCertificate=intermediate_certificate,",
            "            enabled=enabled,",
            "            secureTrafficOnly=secure_traffic_only",
            "        )",
            "",
            "        needs_change = False",
            "",
            "        if existing_ssl:",
            "            for ssl_attr, value in ssl_attrs.items():",
            "                if ssl_attr == 'privatekey':",
            "                    # The private key is not included in get_ssl_termination's",
            "                    # output (as it shouldn't be). Also, if you're changing the",
            "                    # private key, you'll also be changing the certificate,",
            "                    # so we don't lose anything by not checking it.",
            "                    continue",
            "",
            "                if value is not None and existing_ssl.get(ssl_attr) != value:",
            "                    # module.fail_json(msg='Unnecessary change', attr=ssl_attr, value=value, existing=existing_ssl.get(ssl_attr))",
            "                    needs_change = True",
            "        else:",
            "            needs_change = True",
            "",
            "        if needs_change:",
            "            try:",
            "                balancer.add_ssl_termination(**ssl_attrs)",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "    elif state == 'absent':",
            "        # Remove SSL termination if it's already configured.",
            "        if existing_ssl:",
            "            try:",
            "                balancer.delete_ssl_termination()",
            "            except pyrax.exceptions.PyraxException as e:",
            "                module.fail_json(msg='%s' % e.message)",
            "            changed = True",
            "",
            "    if https_redirect is not None and balancer.httpsRedirect != https_redirect:",
            "        if changed:",
            "            # This wait is unavoidable because load balancers are immutable",
            "            # while the SSL termination changes above are being applied.",
            "            pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "        try:",
            "            balancer.update(httpsRedirect=https_redirect)",
            "        except pyrax.exceptions.PyraxException as e:",
            "            module.fail_json(msg='%s' % e.message)",
            "        changed = True",
            "",
            "    if changed and wait:",
            "        pyrax.utils.wait_for_build(balancer, interval=5, attempts=attempts)",
            "",
            "    balancer.get()",
            "    new_ssl_termination = balancer.get_ssl_termination()",
            "",
            "    # Intentionally omit the private key from the module output, so you don't",
            "    # accidentally echo it with `ansible-playbook -v` or `debug`, and the",
            "    # certificate, which is just long. Convert other attributes to snake_case",
            "    # and include https_redirect at the top-level.",
            "    if new_ssl_termination:",
            "        new_ssl = dict(",
            "            enabled=new_ssl_termination['enabled'],",
            "            secure_port=new_ssl_termination['securePort'],",
            "            secure_traffic_only=new_ssl_termination['secureTrafficOnly']",
            "        )",
            "    else:",
            "        new_ssl = None",
            "",
            "    result = dict(",
            "        changed=changed,",
            "        https_redirect=balancer.httpsRedirect,",
            "        ssl_termination=new_ssl,",
            "        balancer=rax_to_dict(balancer, 'clb')",
            "    )",
            "    success = True",
            "",
            "    if balancer.status == 'ERROR':",
            "        result['msg'] = '%s failed to build' % balancer.id",
            "        success = False",
            "    elif wait and balancer.status not in ('ACTIVE', 'ERROR'):",
            "        result['msg'] = 'Timeout waiting on %s' % balancer.id",
            "        success = False",
            "",
            "    if success:",
            "        module.exit_json(**result)",
            "    else:",
            "        module.fail_json(**result)",
            "",
            "",
            "def main():",
            "    argument_spec = rax_argument_spec()",
            "    argument_spec.update(dict(",
            "        loadbalancer=dict(required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        enabled=dict(type='bool', default=True),",
            "        private_key=dict(no_log=True),",
            "        certificate=dict(),",
            "        intermediate_certificate=dict(),",
            "        secure_port=dict(type='int', default=443),",
            "        secure_traffic_only=dict(type='bool', default=False),",
            "        https_redirect=dict(type='bool'),",
            "        wait=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int', default=300)",
            "    ))",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=argument_spec,",
            "        required_together=rax_required_together(),",
            "    )",
            "",
            "    if not HAS_PYRAX:",
            "        module.fail_json(msg='pyrax is required for this module.')",
            "",
            "    loadbalancer = module.params.get('loadbalancer')",
            "    state = module.params.get('state')",
            "    enabled = module.boolean(module.params.get('enabled'))",
            "    private_key = module.params.get('private_key')",
            "    certificate = module.params.get('certificate')",
            "    intermediate_certificate = module.params.get('intermediate_certificate')",
            "    secure_port = module.params.get('secure_port')",
            "    secure_traffic_only = module.boolean(module.params.get('secure_traffic_only'))",
            "    https_redirect = module.boolean(module.params.get('https_redirect'))",
            "    wait = module.boolean(module.params.get('wait'))",
            "    wait_timeout = module.params.get('wait_timeout')",
            "",
            "    setup_rax_module(module, pyrax)",
            "",
            "    cloud_load_balancer_ssl(",
            "        module, loadbalancer, state, enabled, private_key, certificate,",
            "        intermediate_certificate, secure_port, secure_traffic_only,",
            "        https_redirect, wait, wait_timeout",
            "    )",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "239": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/cloud/spotinst/spotinst_aws_elastigroup.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1438,
                "afterPatchRowNumber": 1438,
                "PatchRowcode": "         min_size=dict(type='int', required=True),"
            },
            "1": {
                "beforePatchRowNumber": 1439,
                "afterPatchRowNumber": 1439,
                "PatchRowcode": "         monitoring=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 1440,
                "afterPatchRowNumber": 1440,
                "PatchRowcode": "         multai_load_balancers=dict(type='list'),"
            },
            "3": {
                "beforePatchRowNumber": 1441,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        multai_token=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1441,
                "PatchRowcode": "+        multai_token=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 1442,
                "afterPatchRowNumber": 1442,
                "PatchRowcode": "         name=dict(type='str', required=True),"
            },
            "6": {
                "beforePatchRowNumber": 1443,
                "afterPatchRowNumber": 1443,
                "PatchRowcode": "         network_interfaces=dict(type='list'),"
            },
            "7": {
                "beforePatchRowNumber": 1444,
                "afterPatchRowNumber": 1444,
                "PatchRowcode": "         on_demand_count=dict(type='int'),"
            },
            "8": {
                "beforePatchRowNumber": 1462,
                "afterPatchRowNumber": 1462,
                "PatchRowcode": "         target_group_arns=dict(type='list'),"
            },
            "9": {
                "beforePatchRowNumber": 1463,
                "afterPatchRowNumber": 1463,
                "PatchRowcode": "         tenancy=dict(type='str'),"
            },
            "10": {
                "beforePatchRowNumber": 1464,
                "afterPatchRowNumber": 1464,
                "PatchRowcode": "         terminate_at_end_of_billing_hour=dict(type='bool'),"
            },
            "11": {
                "beforePatchRowNumber": 1465,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        token=dict(type='str'),"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1465,
                "PatchRowcode": "+        token=dict(type='str', no_log=True),"
            },
            "13": {
                "beforePatchRowNumber": 1466,
                "afterPatchRowNumber": 1466,
                "PatchRowcode": "         unit=dict(type='str'),"
            },
            "14": {
                "beforePatchRowNumber": 1467,
                "afterPatchRowNumber": 1467,
                "PatchRowcode": "         user_data=dict(type='str'),"
            },
            "15": {
                "beforePatchRowNumber": 1468,
                "afterPatchRowNumber": 1468,
                "PatchRowcode": "         utilize_reserved_instances=dict(type='bool'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# Copyright (c) 2017 Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "from __future__ import (absolute_import, division, print_function)",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "DOCUMENTATION = \"\"\"",
            "---",
            "module: spotinst_aws_elastigroup",
            "version_added: 2.5",
            "short_description: Create, update or delete Spotinst AWS Elastigroups",
            "author: Spotinst (@talzur)",
            "description:",
            "  - Can create, update, or delete Spotinst AWS Elastigroups",
            "    Launch configuration is part of the elastigroup configuration,",
            "    so no additional modules are necessary for handling the launch configuration.",
            "    You will have to have a credentials file in this location - <home>/.spotinst/credentials",
            "    The credentials file must contain a row that looks like this",
            "    token = <YOUR TOKEN>",
            "    Full documentation available at https://help.spotinst.com/hc/en-us/articles/115003530285-Ansible-",
            "requirements:",
            "  - python >= 2.7",
            "  - spotinst_sdk >= 1.0.38",
            "options:",
            "",
            "  credentials_path:",
            "    description:",
            "      - (String) Optional parameter that allows to set a non-default credentials path.",
            "       Default is ~/.spotinst/credentials",
            "",
            "  account_id:",
            "    description:",
            "      - (String) Optional parameter that allows to set an account-id inside the module configuration",
            "       By default this is retrieved from the credentials path",
            "",
            "  availability_vs_cost:",
            "    choices:",
            "      - availabilityOriented",
            "      - costOriented",
            "      - balanced",
            "    description:",
            "      - (String) The strategy orientation.",
            "    required: true",
            "",
            "  availability_zones:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Availability Zones that are configured in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        name (String),",
            "        subnet_id (String),",
            "        placement_group_name (String),",
            "    required: true",
            "",
            "  block_device_mappings:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Block Device Mappings for elastigroup instances;",
            "        You can specify virtual devices and EBS volumes.;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        device_name (List of Strings),",
            "        virtual_name (String),",
            "        no_device (String),",
            "        ebs (Object, expects the following keys-",
            "        delete_on_termination(Boolean),",
            "        encrypted(Boolean),",
            "        iops (Integer),",
            "        snapshot_id(Integer),",
            "        volume_type(String),",
            "        volume_size(Integer))",
            "",
            "  chef:",
            "    description:",
            "      - (Object) The Chef integration configuration.;",
            "        Expects the following keys - chef_server (String),",
            "        organization (String),",
            "        user (String),",
            "        pem_key (String),",
            "        chef_version (String)",
            "",
            "  draining_timeout:",
            "    description:",
            "      - (Integer) Time for instance to be drained from incoming requests and deregistered from ELB before termination.",
            "",
            "  ebs_optimized:",
            "    description:",
            "      - (Boolean) Enable EBS optimization for supported instances which are not enabled by default.;",
            "        Note - additional charges will be applied.",
            "    type: bool",
            "",
            "  ebs_volume_pool:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of EBS devices to reattach to the elastigroup when available;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        volume_ids (List of Strings),",
            "        device_name (String)",
            "",
            "  ecs:",
            "    description:",
            "      - (Object) The ECS integration configuration.;",
            "        Expects the following key -",
            "        cluster_name (String)",
            "",
            "",
            "  elastic_ips:",
            "    description:",
            "      - (List of Strings) List of ElasticIps Allocation Ids (Example C(eipalloc-9d4e16f8)) to associate to the group instances",
            "",
            "  fallback_to_od:",
            "    description:",
            "      - (Boolean) In case of no spots available, Elastigroup will launch an On-demand instance instead",
            "    type: bool",
            "  health_check_grace_period:",
            "    description:",
            "      - (Integer) The amount of time, in seconds, after the instance has launched to start and check its health.",
            "    default: 300",
            "",
            "  health_check_unhealthy_duration_before_replacement:",
            "    description:",
            "      - (Integer) Minimal mount of time instance should be unhealthy for us to consider it unhealthy.",
            "",
            "  health_check_type:",
            "    choices:",
            "      - ELB",
            "      - HCS",
            "      - TARGET_GROUP",
            "      - MLB",
            "      - EC2",
            "    description:",
            "      - (String) The service to use for the health check.",
            "",
            "  iam_role_name:",
            "    description:",
            "      - (String) The instance profile iamRole name",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  iam_role_arn:",
            "    description:",
            "      - (String) The instance profile iamRole arn",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  id:",
            "    description:",
            "      - (String) The group id if it already exists and you want to update, or delete it.",
            "        This will not work unless the uniqueness_by field is set to id.",
            "        When this is set, and the uniqueness_by field is set, the group will either be updated or deleted, but not created.",
            "",
            "  ignore_changes:",
            "    choices:",
            "      - image_id",
            "      - target",
            "    description:",
            "      - (List of Strings) list of fields on which changes should be ignored when updating",
            "",
            "  image_id:",
            "    description:",
            "      - (String) The image Id used to launch the instance.;",
            "        In case of conflict between Instance type and image type, an error will be returned",
            "    required: true",
            "",
            "  key_pair:",
            "    description:",
            "      - (String) Specify a Key Pair to attach to the instances",
            "    required: true",
            "",
            "  kubernetes:",
            "    description:",
            "      - (Object) The Kubernetes integration configuration.",
            "        Expects the following keys -",
            "        api_server (String),",
            "        token (String)",
            "",
            "  lifetime_period:",
            "    description:",
            "      - (String) lifetime period",
            "",
            "  load_balancers:",
            "    description:",
            "      - (List of Strings) List of classic ELB names",
            "",
            "  max_size:",
            "    description:",
            "      - (Integer) The upper limit number of instances that you can scale up to",
            "    required: true",
            "",
            "  mesosphere:",
            "    description:",
            "      - (Object) The Mesosphere integration configuration.",
            "        Expects the following key -",
            "        api_server (String)",
            "",
            "  min_size:",
            "    description:",
            "      - (Integer) The lower limit number of instances that you can scale down to",
            "    required: true",
            "",
            "  monitoring:",
            "    description:",
            "      - (Boolean) Describes whether instance Enhanced Monitoring is enabled",
            "    required: true",
            "",
            "  name:",
            "    description:",
            "      - (String) Unique name for elastigroup to be created, updated or deleted",
            "    required: true",
            "",
            "  network_interfaces:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of network interfaces to add to the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        description (String),",
            "        device_index (Integer),",
            "        secondary_private_ip_address_count (Integer),",
            "        associate_public_ip_address (Boolean),",
            "        delete_on_termination (Boolean),",
            "        groups (List of Strings),",
            "        network_interface_id (String),",
            "        private_ip_address (String),",
            "        subnet_id (String),",
            "        associate_ipv6_address (Boolean),",
            "        private_ip_addresses (List of Objects, Keys are privateIpAddress (String, required) and primary (Boolean))",
            "",
            "  on_demand_count:",
            "    description:",
            "      - (Integer) Required if risk is not set",
            "      - Number of on demand instances to launch. All other instances will be spot instances.;",
            "        Either set this parameter or the risk parameter",
            "",
            "  on_demand_instance_type:",
            "    description:",
            "      - (String) On-demand instance type that will be provisioned",
            "    required: true",
            "",
            "  opsworks:",
            "    description:",
            "      - (Object) The elastigroup OpsWorks integration configration.;",
            "        Expects the following key -",
            "        layer_id (String)",
            "",
            "  persistence:",
            "    description:",
            "      - (Object) The Stateful elastigroup configration.;",
            "        Accepts the following keys -",
            "        should_persist_root_device (Boolean),",
            "        should_persist_block_devices (Boolean),",
            "        should_persist_private_ip (Boolean)",
            "",
            "  product:",
            "    choices:",
            "      - Linux/UNIX",
            "      - SUSE Linux",
            "      - Windows",
            "      - Linux/UNIX (Amazon VPC)",
            "      - SUSE Linux (Amazon VPC)",
            "      - Windows",
            "    description:",
            "      - (String) Operation system type._",
            "    required: true",
            "",
            "  rancher:",
            "    description:",
            "      - (Object) The Rancher integration configuration.;",
            "        Expects the following keys -",
            "        version (String),",
            "        access_key (String),",
            "        secret_key (String),",
            "        master_host (String)",
            "",
            "  right_scale:",
            "    description:",
            "      - (Object) The Rightscale integration configuration.;",
            "        Expects the following keys -",
            "        account_id (String),",
            "        refresh_token (String)",
            "",
            "  risk:",
            "    description:",
            "      - (Integer) required if on demand is not set. The percentage of Spot instances to launch (0 - 100).",
            "",
            "  roll_config:",
            "    description:",
            "      - (Object) Roll configuration.;",
            "        If you would like the group to roll after updating, please use this feature.",
            "        Accepts the following keys -",
            "        batch_size_percentage(Integer, Required),",
            "        grace_period - (Integer, Required),",
            "        health_check_type(String, Optional)",
            "",
            "  scheduled_tasks:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scheduled tasks to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        adjustment (Integer),",
            "        scale_target_capacity (Integer),",
            "        scale_min_capacity (Integer),",
            "        scale_max_capacity (Integer),",
            "        adjustment_percentage (Integer),",
            "        batch_size_percentage (Integer),",
            "        cron_expression (String),",
            "        frequency (String),",
            "        grace_period (Integer),",
            "        task_type (String, required),",
            "        is_enabled (Boolean)",
            "",
            "  security_group_ids:",
            "    description:",
            "      - (List of Strings) One or more security group IDs. ;",
            "        In case of update it will override the existing Security Group with the new given array",
            "    required: true",
            "",
            "  shutdown_script:",
            "    description:",
            "      - (String) The Base64-encoded shutdown script that executes prior to instance termination.",
            "        Encode before setting.",
            "",
            "  signals:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of signals to configure in the elastigroup;",
            "        keys allowed are -",
            "        name (String, required),",
            "        timeout (Integer)",
            "",
            "  spin_up_time:",
            "    description:",
            "      - (Integer) spin up time, in seconds, for the instance",
            "",
            "  spot_instance_types:",
            "    description:",
            "      - (List of Strings) Spot instance type that will be provisioned.",
            "    required: true",
            "",
            "  state:",
            "    choices:",
            "      - present",
            "      - absent",
            "    description:",
            "      - (String) create or delete the elastigroup",
            "",
            "  tags:",
            "    description:",
            "      - (List of tagKey:tagValue paris) a list of tags to configure in the elastigroup. Please specify list of keys and values (key colon value);",
            "",
            "  target:",
            "    description:",
            "      - (Integer) The number of instances to launch",
            "    required: true",
            "",
            "  target_group_arns:",
            "    description:",
            "      - (List of Strings) List of target group arns instances should be registered to",
            "",
            "  tenancy:",
            "    choices:",
            "      - default",
            "      - dedicated",
            "    description:",
            "      - (String) dedicated vs shared tenancy",
            "",
            "  terminate_at_end_of_billing_hour:",
            "    description:",
            "      - (Boolean) terminate at the end of billing hour",
            "    type: bool",
            "  unit:",
            "    choices:",
            "      - instance",
            "      - weight",
            "    description:",
            "      - (String) The capacity unit to launch instances by.",
            "    required: true",
            "",
            "  up_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions (List of Objects, Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required)",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        min_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "",
            "  down_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions ((List of Objects), Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required),",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        max_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "  target_tracking_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of target tracking policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        source (String, required),",
            "        metric_name (String, required),",
            "        statistic (String, required),",
            "        unit (String, required),",
            "        cooldown (String, required),",
            "        target (String, required)",
            "",
            "  uniqueness_by:",
            "    choices:",
            "      - id",
            "      - name",
            "    description:",
            "      - (String) If your group names are not unique, you may use this feature to update or delete a specific group.",
            "        Whenever this property is set, you must set a group_id in order to update or delete a group, otherwise a group will be created.",
            "",
            "",
            "  user_data:",
            "    description:",
            "      - (String) Base64-encoded MIME user data. Encode before setting the value.",
            "",
            "",
            "  utilize_reserved_instances:",
            "    description:",
            "      - (Boolean) In case of any available Reserved Instances,",
            "         Elastigroup will utilize your reservations before purchasing Spot instances.",
            "    type: bool",
            "",
            "  wait_for_instances:",
            "    description:",
            "      - (Boolean) Whether or not the elastigroup creation / update actions should wait for the instances to spin",
            "    type: bool",
            "",
            "  wait_timeout:",
            "    description:",
            "      - (Integer) How long the module should wait for instances before failing the action.;",
            "        Only works if wait_for_instances is True.",
            "",
            "\"\"\"",
            "EXAMPLES = '''",
            "# Basic configuration YAML example",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup and wait 600 seconds to retrieve the instances, and use their private ips",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/sda1'",
            "              ebs:",
            "                volume_size: 100",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup with multiple block device mappings, tags, and also an account id",
            "# In organizations with more than one account, it is required to specify an account_id",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              ebs:",
            "                volume_size: 60",
            "                volume_type: gp2",
            "            - device_name: '/dev/xvdb'",
            "              ebs:",
            "                volume_size: 120",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example we have set up block device mapping with ephemeral devices",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              virtual_name: ephemeral0",
            "            - device_name: '/dev/xvdb/'",
            "              virtual_name: ephemeral1",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example we create a basic group configuration with a network interface defined.",
            "# Each network interface must have a device index",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          network_interfaces:",
            "            - associate_public_ip_address: true",
            "              device_index: 0",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "",
            "# In this example we create a basic group configuration with a target tracking scaling policy defined",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          account_id: act-92d45673",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-79da021e",
            "          image_id: ami-f173cc91",
            "          fallback_to_od: true",
            "          tags:",
            "            - Creator: ValueOfCreatorTag",
            "            - Environment: ValueOfEnvironmentTag",
            "          key_pair: spotinst-labs-oregon",
            "          max_size: 10",
            "          min_size: 0",
            "          target: 2",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-1",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-46cdc13d",
            "          spot_instance_types:",
            "            - c3.large",
            "          target_tracking_policies:",
            "            - policy_name: target-tracking-1",
            "              namespace: AWS/EC2",
            "              metric_name: CPUUtilization",
            "              statistic: average",
            "              unit: percent",
            "              target: 50",
            "              cooldown: 120",
            "          do_not_update:",
            "            - image_id",
            "      register: result",
            "    - debug: var=result",
            "",
            "'''",
            "RETURN = '''",
            "---",
            "instances:",
            "    description: List of active elastigroup instances and their details.",
            "    returned: success",
            "    type: dict",
            "    sample: [",
            "         {",
            "            \"spotInstanceRequestId\": \"sir-regs25zp\",",
            "            \"instanceId\": \"i-09640ad8678234c\",",
            "            \"instanceType\": \"m4.large\",",
            "            \"product\": \"Linux/UNIX\",",
            "            \"availabilityZone\": \"us-west-2b\",",
            "            \"privateIp\": \"180.0.2.244\",",
            "            \"createdAt\": \"2017-07-17T12:46:18.000Z\",",
            "            \"status\": \"fulfilled\"",
            "        }",
            "    ]",
            "group_id:",
            "    description: Created / Updated group's ID.",
            "    returned: success",
            "    type: str",
            "    sample: \"sig-12345\"",
            "",
            "'''",
            "",
            "HAS_SPOTINST_SDK = False",
            "__metaclass__ = type",
            "",
            "import os",
            "import time",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "try:",
            "    import spotinst_sdk as spotinst",
            "    from spotinst_sdk import SpotinstClientException",
            "",
            "    HAS_SPOTINST_SDK = True",
            "",
            "except ImportError:",
            "    pass",
            "",
            "eni_fields = ('description',",
            "              'device_index',",
            "              'secondary_private_ip_address_count',",
            "              'associate_public_ip_address',",
            "              'delete_on_termination',",
            "              'groups',",
            "              'network_interface_id',",
            "              'private_ip_address',",
            "              'subnet_id',",
            "              'associate_ipv6_address')",
            "",
            "private_ip_fields = ('private_ip_address',",
            "                     'primary')",
            "",
            "capacity_fields = (dict(ansible_field_name='min_size',",
            "                        spotinst_field_name='minimum'),",
            "                   dict(ansible_field_name='max_size',",
            "                        spotinst_field_name='maximum'),",
            "                   'target',",
            "                   'unit')",
            "",
            "lspec_fields = ('user_data',",
            "                'key_pair',",
            "                'tenancy',",
            "                'shutdown_script',",
            "                'monitoring',",
            "                'ebs_optimized',",
            "                'image_id',",
            "                'health_check_type',",
            "                'health_check_grace_period',",
            "                'health_check_unhealthy_duration_before_replacement',",
            "                'security_group_ids')",
            "",
            "iam_fields = (dict(ansible_field_name='iam_role_name',",
            "                   spotinst_field_name='name'),",
            "              dict(ansible_field_name='iam_role_arn',",
            "                   spotinst_field_name='arn'))",
            "",
            "scheduled_task_fields = ('adjustment',",
            "                         'adjustment_percentage',",
            "                         'batch_size_percentage',",
            "                         'cron_expression',",
            "                         'frequency',",
            "                         'grace_period',",
            "                         'task_type',",
            "                         'is_enabled',",
            "                         'scale_target_capacity',",
            "                         'scale_min_capacity',",
            "                         'scale_max_capacity')",
            "",
            "scaling_policy_fields = ('policy_name',",
            "                         'namespace',",
            "                         'metric_name',",
            "                         'dimensions',",
            "                         'statistic',",
            "                         'evaluation_periods',",
            "                         'period',",
            "                         'threshold',",
            "                         'cooldown',",
            "                         'unit',",
            "                         'operator')",
            "",
            "tracking_policy_fields = ('policy_name',",
            "                          'namespace',",
            "                          'source',",
            "                          'metric_name',",
            "                          'statistic',",
            "                          'unit',",
            "                          'cooldown',",
            "                          'target',",
            "                          'threshold')",
            "",
            "action_fields = (dict(ansible_field_name='action_type',",
            "                      spotinst_field_name='type'),",
            "                 'adjustment',",
            "                 'min_target_capacity',",
            "                 'max_target_capacity',",
            "                 'target',",
            "                 'minimum',",
            "                 'maximum')",
            "",
            "signal_fields = ('name',",
            "                 'timeout')",
            "",
            "multai_lb_fields = ('balancer_id',",
            "                    'project_id',",
            "                    'target_set_id',",
            "                    'az_awareness',",
            "                    'auto_weight')",
            "",
            "persistence_fields = ('should_persist_root_device',",
            "                      'should_persist_block_devices',",
            "                      'should_persist_private_ip')",
            "",
            "strategy_fields = ('risk',",
            "                   'utilize_reserved_instances',",
            "                   'fallback_to_od',",
            "                   'on_demand_count',",
            "                   'availability_vs_cost',",
            "                   'draining_timeout',",
            "                   'spin_up_time',",
            "                   'lifetime_period')",
            "",
            "ebs_fields = ('delete_on_termination',",
            "              'encrypted',",
            "              'iops',",
            "              'snapshot_id',",
            "              'volume_type',",
            "              'volume_size')",
            "",
            "bdm_fields = ('device_name',",
            "              'virtual_name',",
            "              'no_device')",
            "",
            "kubernetes_fields = ('api_server',",
            "                     'token')",
            "",
            "right_scale_fields = ('account_id',",
            "                      'refresh_token')",
            "",
            "rancher_fields = ('access_key',",
            "                  'secret_key',",
            "                  'master_host',",
            "                  'version')",
            "",
            "chef_fields = ('chef_server',",
            "               'organization',",
            "               'user',",
            "               'pem_key',",
            "               'chef_version')",
            "",
            "az_fields = ('name',",
            "             'subnet_id',",
            "             'placement_group_name')",
            "",
            "opsworks_fields = ('layer_id',)",
            "",
            "scaling_strategy_fields = ('terminate_at_end_of_billing_hour',)",
            "",
            "mesosphere_fields = ('api_server',)",
            "",
            "ecs_fields = ('cluster_name',)",
            "",
            "multai_fields = ('multai_token',)",
            "",
            "",
            "def handle_elastigroup(client, module):",
            "    has_changed = False",
            "    should_create = False",
            "    group_id = None",
            "    message = 'None'",
            "",
            "    name = module.params.get('name')",
            "    state = module.params.get('state')",
            "    uniqueness_by = module.params.get('uniqueness_by')",
            "    external_group_id = module.params.get('id')",
            "",
            "    if uniqueness_by == 'id':",
            "        if external_group_id is None:",
            "            should_create = True",
            "        else:",
            "            should_create = False",
            "            group_id = external_group_id",
            "    else:",
            "        groups = client.get_elastigroups()",
            "        should_create, group_id = find_group_with_same_name(groups, name)",
            "",
            "    if should_create is True:",
            "        if state == 'present':",
            "            eg = expand_elastigroup(module, is_update=False)",
            "            module.debug(str(\" [INFO] \" + message + \"\\n\"))",
            "            group = client.create_elastigroup(group=eg)",
            "            group_id = group['id']",
            "            message = 'Created group Successfully.'",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            message = 'Cannot delete non-existent group.'",
            "            has_changed = False",
            "    else:",
            "        eg = expand_elastigroup(module, is_update=True)",
            "",
            "        if state == 'present':",
            "            group = client.update_elastigroup(group_update=eg, group_id=group_id)",
            "            message = 'Updated group successfully.'",
            "",
            "            try:",
            "                roll_config = module.params.get('roll_config')",
            "                if roll_config:",
            "                    eg_roll = spotinst.aws_elastigroup.Roll(",
            "                        batch_size_percentage=roll_config.get('batch_size_percentage'),",
            "                        grace_period=roll_config.get('grace_period'),",
            "                        health_check_type=roll_config.get('health_check_type')",
            "                    )",
            "                    roll_response = client.roll_group(group_roll=eg_roll, group_id=group_id)",
            "                    message = 'Updated and started rolling the group successfully.'",
            "",
            "            except SpotinstClientException as exc:",
            "                message = 'Updated group successfully, but failed to perform roll. Error:' + str(exc)",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            try:",
            "                client.delete_elastigroup(group_id=group_id)",
            "            except SpotinstClientException as exc:",
            "                if \"GROUP_DOESNT_EXIST\" in exc.message:",
            "                    pass",
            "                else:",
            "                    module.fail_json(msg=\"Error while attempting to delete group : \" + exc.message)",
            "",
            "            message = 'Deleted group successfully.'",
            "            has_changed = True",
            "",
            "    return group_id, message, has_changed",
            "",
            "",
            "def retrieve_group_instances(client, module, group_id):",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_for_instances = module.params.get('wait_for_instances')",
            "",
            "    health_check_type = module.params.get('health_check_type')",
            "",
            "    if wait_timeout is None:",
            "        wait_timeout = 300",
            "",
            "    wait_timeout = time.time() + wait_timeout",
            "    target = module.params.get('target')",
            "    state = module.params.get('state')",
            "    instances = list()",
            "",
            "    if state == 'present' and group_id is not None and wait_for_instances is True:",
            "",
            "        is_amount_fulfilled = False",
            "        while is_amount_fulfilled is False and wait_timeout > time.time():",
            "            instances = list()",
            "            amount_of_fulfilled_instances = 0",
            "",
            "            if health_check_type is not None:",
            "                healthy_instances = client.get_instance_healthiness(group_id=group_id)",
            "",
            "                for healthy_instance in healthy_instances:",
            "                    if(healthy_instance.get('healthStatus') == 'HEALTHY'):",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(healthy_instance)",
            "",
            "            else:",
            "                active_instances = client.get_elastigroup_active_instances(group_id=group_id)",
            "",
            "                for active_instance in active_instances:",
            "                    if active_instance.get('private_ip') is not None:",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(active_instance)",
            "",
            "            if amount_of_fulfilled_instances >= target:",
            "                is_amount_fulfilled = True",
            "",
            "            time.sleep(10)",
            "",
            "    return instances",
            "",
            "",
            "def find_group_with_same_name(groups, name):",
            "    for group in groups:",
            "        if group['name'] == name:",
            "            return False, group.get('id')",
            "",
            "    return True, None",
            "",
            "",
            "def expand_elastigroup(module, is_update):",
            "    do_not_update = module.params['do_not_update']",
            "    name = module.params.get('name')",
            "",
            "    eg = spotinst.aws_elastigroup.Elastigroup()",
            "    description = module.params.get('description')",
            "",
            "    if name is not None:",
            "        eg.name = name",
            "    if description is not None:",
            "        eg.description = description",
            "",
            "    # Capacity",
            "    expand_capacity(eg, module, is_update, do_not_update)",
            "    # Strategy",
            "    expand_strategy(eg, module)",
            "    # Scaling",
            "    expand_scaling(eg, module)",
            "    # Third party integrations",
            "    expand_integrations(eg, module)",
            "    # Compute",
            "    expand_compute(eg, module, is_update, do_not_update)",
            "    # Multai",
            "    expand_multai(eg, module)",
            "    # Scheduling",
            "    expand_scheduled_tasks(eg, module)",
            "",
            "    return eg",
            "",
            "",
            "def expand_compute(eg, module, is_update, do_not_update):",
            "    elastic_ips = module.params['elastic_ips']",
            "    on_demand_instance_type = module.params.get('on_demand_instance_type')",
            "    spot_instance_types = module.params['spot_instance_types']",
            "    ebs_volume_pool = module.params['ebs_volume_pool']",
            "    availability_zones_list = module.params['availability_zones']",
            "    product = module.params.get('product')",
            "",
            "    eg_compute = spotinst.aws_elastigroup.Compute()",
            "",
            "    if product is not None:",
            "        # Only put product on group creation",
            "        if is_update is not True:",
            "            eg_compute.product = product",
            "",
            "    if elastic_ips is not None:",
            "        eg_compute.elastic_ips = elastic_ips",
            "",
            "    if on_demand_instance_type or spot_instance_types is not None:",
            "        eg_instance_types = spotinst.aws_elastigroup.InstanceTypes()",
            "",
            "        if on_demand_instance_type is not None:",
            "            eg_instance_types.spot = spot_instance_types",
            "        if spot_instance_types is not None:",
            "            eg_instance_types.ondemand = on_demand_instance_type",
            "",
            "        if eg_instance_types.spot is not None or eg_instance_types.ondemand is not None:",
            "            eg_compute.instance_types = eg_instance_types",
            "",
            "    expand_ebs_volume_pool(eg_compute, ebs_volume_pool)",
            "",
            "    eg_compute.availability_zones = expand_list(availability_zones_list, az_fields, 'AvailabilityZone')",
            "",
            "    expand_launch_spec(eg_compute, module, is_update, do_not_update)",
            "",
            "    eg.compute = eg_compute",
            "",
            "",
            "def expand_ebs_volume_pool(eg_compute, ebs_volumes_list):",
            "    if ebs_volumes_list is not None:",
            "        eg_volumes = []",
            "",
            "        for volume in ebs_volumes_list:",
            "            eg_volume = spotinst.aws_elastigroup.EbsVolume()",
            "",
            "            if volume.get('device_name') is not None:",
            "                eg_volume.device_name = volume.get('device_name')",
            "            if volume.get('volume_ids') is not None:",
            "                eg_volume.volume_ids = volume.get('volume_ids')",
            "",
            "            if eg_volume.device_name is not None:",
            "                eg_volumes.append(eg_volume)",
            "",
            "        if len(eg_volumes) > 0:",
            "            eg_compute.ebs_volume_pool = eg_volumes",
            "",
            "",
            "def expand_launch_spec(eg_compute, module, is_update, do_not_update):",
            "    eg_launch_spec = expand_fields(lspec_fields, module.params, 'LaunchSpecification')",
            "",
            "    if module.params['iam_role_arn'] is not None or module.params['iam_role_name'] is not None:",
            "        eg_launch_spec.iam_role = expand_fields(iam_fields, module.params, 'IamRole')",
            "",
            "    tags = module.params['tags']",
            "    load_balancers = module.params['load_balancers']",
            "    target_group_arns = module.params['target_group_arns']",
            "    block_device_mappings = module.params['block_device_mappings']",
            "    network_interfaces = module.params['network_interfaces']",
            "",
            "    if is_update is True:",
            "        if 'image_id' in do_not_update:",
            "            delattr(eg_launch_spec, 'image_id')",
            "",
            "    expand_tags(eg_launch_spec, tags)",
            "",
            "    expand_load_balancers(eg_launch_spec, load_balancers, target_group_arns)",
            "",
            "    expand_block_device_mappings(eg_launch_spec, block_device_mappings)",
            "",
            "    expand_network_interfaces(eg_launch_spec, network_interfaces)",
            "",
            "    eg_compute.launch_specification = eg_launch_spec",
            "",
            "",
            "def expand_integrations(eg, module):",
            "    rancher = module.params.get('rancher')",
            "    mesosphere = module.params.get('mesosphere')",
            "    ecs = module.params.get('ecs')",
            "    kubernetes = module.params.get('kubernetes')",
            "    right_scale = module.params.get('right_scale')",
            "    opsworks = module.params.get('opsworks')",
            "    chef = module.params.get('chef')",
            "",
            "    integration_exists = False",
            "",
            "    eg_integrations = spotinst.aws_elastigroup.ThirdPartyIntegrations()",
            "",
            "    if mesosphere is not None:",
            "        eg_integrations.mesosphere = expand_fields(mesosphere_fields, mesosphere, 'Mesosphere')",
            "        integration_exists = True",
            "",
            "    if ecs is not None:",
            "        eg_integrations.ecs = expand_fields(ecs_fields, ecs, 'EcsConfiguration')",
            "        integration_exists = True",
            "",
            "    if kubernetes is not None:",
            "        eg_integrations.kubernetes = expand_fields(kubernetes_fields, kubernetes, 'KubernetesConfiguration')",
            "        integration_exists = True",
            "",
            "    if right_scale is not None:",
            "        eg_integrations.right_scale = expand_fields(right_scale_fields, right_scale, 'RightScaleConfiguration')",
            "        integration_exists = True",
            "",
            "    if opsworks is not None:",
            "        eg_integrations.opsworks = expand_fields(opsworks_fields, opsworks, 'OpsWorksConfiguration')",
            "        integration_exists = True",
            "",
            "    if rancher is not None:",
            "        eg_integrations.rancher = expand_fields(rancher_fields, rancher, 'Rancher')",
            "        integration_exists = True",
            "",
            "    if chef is not None:",
            "        eg_integrations.chef = expand_fields(chef_fields, chef, 'ChefConfiguration')",
            "        integration_exists = True",
            "",
            "    if integration_exists:",
            "        eg.third_parties_integration = eg_integrations",
            "",
            "",
            "def expand_capacity(eg, module, is_update, do_not_update):",
            "    eg_capacity = expand_fields(capacity_fields, module.params, 'Capacity')",
            "",
            "    if is_update is True:",
            "        delattr(eg_capacity, 'unit')",
            "",
            "        if 'target' in do_not_update:",
            "            delattr(eg_capacity, 'target')",
            "",
            "    eg.capacity = eg_capacity",
            "",
            "",
            "def expand_strategy(eg, module):",
            "    persistence = module.params.get('persistence')",
            "    signals = module.params.get('signals')",
            "",
            "    eg_strategy = expand_fields(strategy_fields, module.params, 'Strategy')",
            "",
            "    terminate_at_end_of_billing_hour = module.params.get('terminate_at_end_of_billing_hour')",
            "",
            "    if terminate_at_end_of_billing_hour is not None:",
            "        eg_strategy.eg_scaling_strategy = expand_fields(scaling_strategy_fields,",
            "                                                        module.params, 'ScalingStrategy')",
            "",
            "    if persistence is not None:",
            "        eg_strategy.persistence = expand_fields(persistence_fields, persistence, 'Persistence')",
            "",
            "    if signals is not None:",
            "        eg_signals = expand_list(signals, signal_fields, 'Signal')",
            "",
            "        if len(eg_signals) > 0:",
            "            eg_strategy.signals = eg_signals",
            "",
            "    eg.strategy = eg_strategy",
            "",
            "",
            "def expand_multai(eg, module):",
            "    multai_load_balancers = module.params.get('multai_load_balancers')",
            "",
            "    eg_multai = expand_fields(multai_fields, module.params, 'Multai')",
            "",
            "    if multai_load_balancers is not None:",
            "        eg_multai_load_balancers = expand_list(multai_load_balancers, multai_lb_fields, 'MultaiLoadBalancer')",
            "",
            "        if len(eg_multai_load_balancers) > 0:",
            "            eg_multai.balancers = eg_multai_load_balancers",
            "            eg.multai = eg_multai",
            "",
            "",
            "def expand_scheduled_tasks(eg, module):",
            "    scheduled_tasks = module.params.get('scheduled_tasks')",
            "",
            "    if scheduled_tasks is not None:",
            "        eg_scheduling = spotinst.aws_elastigroup.Scheduling()",
            "",
            "        eg_tasks = expand_list(scheduled_tasks, scheduled_task_fields, 'ScheduledTask')",
            "",
            "        if len(eg_tasks) > 0:",
            "            eg_scheduling.tasks = eg_tasks",
            "            eg.scheduling = eg_scheduling",
            "",
            "",
            "def expand_load_balancers(eg_launchspec, load_balancers, target_group_arns):",
            "    if load_balancers is not None or target_group_arns is not None:",
            "        eg_load_balancers_config = spotinst.aws_elastigroup.LoadBalancersConfig()",
            "        eg_total_lbs = []",
            "",
            "        if load_balancers is not None:",
            "            for elb_name in load_balancers:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if elb_name is not None:",
            "                    eg_elb.name = elb_name",
            "                    eg_elb.type = 'CLASSIC'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if target_group_arns is not None:",
            "            for target_arn in target_group_arns:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if target_arn is not None:",
            "                    eg_elb.arn = target_arn",
            "                    eg_elb.type = 'TARGET_GROUP'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if len(eg_total_lbs) > 0:",
            "            eg_load_balancers_config.load_balancers = eg_total_lbs",
            "            eg_launchspec.load_balancers_config = eg_load_balancers_config",
            "",
            "",
            "def expand_tags(eg_launchspec, tags):",
            "    if tags is not None:",
            "        eg_tags = []",
            "",
            "        for tag in tags:",
            "            eg_tag = spotinst.aws_elastigroup.Tag()",
            "            if tag.keys():",
            "                eg_tag.tag_key = tag.keys()[0]",
            "            if tag.values():",
            "                eg_tag.tag_value = tag.values()[0]",
            "",
            "            eg_tags.append(eg_tag)",
            "",
            "        if len(eg_tags) > 0:",
            "            eg_launchspec.tags = eg_tags",
            "",
            "",
            "def expand_block_device_mappings(eg_launchspec, bdms):",
            "    if bdms is not None:",
            "        eg_bdms = []",
            "",
            "        for bdm in bdms:",
            "            eg_bdm = expand_fields(bdm_fields, bdm, 'BlockDeviceMapping')",
            "",
            "            if bdm.get('ebs') is not None:",
            "                eg_bdm.ebs = expand_fields(ebs_fields, bdm.get('ebs'), 'EBS')",
            "",
            "            eg_bdms.append(eg_bdm)",
            "",
            "        if len(eg_bdms) > 0:",
            "            eg_launchspec.block_device_mappings = eg_bdms",
            "",
            "",
            "def expand_network_interfaces(eg_launchspec, enis):",
            "    if enis is not None:",
            "        eg_enis = []",
            "",
            "        for eni in enis:",
            "            eg_eni = expand_fields(eni_fields, eni, 'NetworkInterface')",
            "",
            "            eg_pias = expand_list(eni.get('private_ip_addresses'), private_ip_fields, 'PrivateIpAddress')",
            "",
            "            if eg_pias is not None:",
            "                eg_eni.private_ip_addresses = eg_pias",
            "",
            "            eg_enis.append(eg_eni)",
            "",
            "        if len(eg_enis) > 0:",
            "            eg_launchspec.network_interfaces = eg_enis",
            "",
            "",
            "def expand_scaling(eg, module):",
            "    up_scaling_policies = module.params['up_scaling_policies']",
            "    down_scaling_policies = module.params['down_scaling_policies']",
            "    target_tracking_policies = module.params['target_tracking_policies']",
            "",
            "    eg_scaling = spotinst.aws_elastigroup.Scaling()",
            "",
            "    if up_scaling_policies is not None:",
            "        eg_up_scaling_policies = expand_scaling_policies(up_scaling_policies)",
            "        if len(eg_up_scaling_policies) > 0:",
            "            eg_scaling.up = eg_up_scaling_policies",
            "",
            "    if down_scaling_policies is not None:",
            "        eg_down_scaling_policies = expand_scaling_policies(down_scaling_policies)",
            "        if len(eg_down_scaling_policies) > 0:",
            "            eg_scaling.down = eg_down_scaling_policies",
            "",
            "    if target_tracking_policies is not None:",
            "        eg_target_tracking_policies = expand_target_tracking_policies(target_tracking_policies)",
            "        if len(eg_target_tracking_policies) > 0:",
            "            eg_scaling.target = eg_target_tracking_policies",
            "",
            "    if eg_scaling.down is not None or eg_scaling.up is not None or eg_scaling.target is not None:",
            "        eg.scaling = eg_scaling",
            "",
            "",
            "def expand_list(items, fields, class_name):",
            "    if items is not None:",
            "        new_objects_list = []",
            "        for item in items:",
            "            new_obj = expand_fields(fields, item, class_name)",
            "            new_objects_list.append(new_obj)",
            "",
            "        return new_objects_list",
            "",
            "",
            "def expand_fields(fields, item, class_name):",
            "    class_ = getattr(spotinst.aws_elastigroup, class_name)",
            "    new_obj = class_()",
            "",
            "    # Handle primitive fields",
            "    if item is not None:",
            "        for field in fields:",
            "            if isinstance(field, dict):",
            "                ansible_field_name = field['ansible_field_name']",
            "                spotinst_field_name = field['spotinst_field_name']",
            "            else:",
            "                ansible_field_name = field",
            "                spotinst_field_name = field",
            "            if item.get(ansible_field_name) is not None:",
            "                setattr(new_obj, spotinst_field_name, item.get(ansible_field_name))",
            "",
            "    return new_obj",
            "",
            "",
            "def expand_scaling_policies(scaling_policies):",
            "    eg_scaling_policies = []",
            "",
            "    for policy in scaling_policies:",
            "        eg_policy = expand_fields(scaling_policy_fields, policy, 'ScalingPolicy')",
            "        eg_policy.action = expand_fields(action_fields, policy, 'ScalingPolicyAction')",
            "        eg_scaling_policies.append(eg_policy)",
            "",
            "    return eg_scaling_policies",
            "",
            "",
            "def expand_target_tracking_policies(tracking_policies):",
            "    eg_tracking_policies = []",
            "",
            "    for policy in tracking_policies:",
            "        eg_policy = expand_fields(tracking_policy_fields, policy, 'TargetTrackingPolicy')",
            "        eg_tracking_policies.append(eg_policy)",
            "",
            "    return eg_tracking_policies",
            "",
            "",
            "def main():",
            "    fields = dict(",
            "        account_id=dict(type='str'),",
            "        availability_vs_cost=dict(type='str', required=True),",
            "        availability_zones=dict(type='list', required=True),",
            "        block_device_mappings=dict(type='list'),",
            "        chef=dict(type='dict'),",
            "        credentials_path=dict(type='path', default=\"~/.spotinst/credentials\"),",
            "        do_not_update=dict(default=[], type='list'),",
            "        down_scaling_policies=dict(type='list'),",
            "        draining_timeout=dict(type='int'),",
            "        ebs_optimized=dict(type='bool'),",
            "        ebs_volume_pool=dict(type='list'),",
            "        ecs=dict(type='dict'),",
            "        elastic_beanstalk=dict(type='dict'),",
            "        elastic_ips=dict(type='list'),",
            "        fallback_to_od=dict(type='bool'),",
            "        id=dict(type='str'),",
            "        health_check_grace_period=dict(type='int'),",
            "        health_check_type=dict(type='str'),",
            "        health_check_unhealthy_duration_before_replacement=dict(type='int'),",
            "        iam_role_arn=dict(type='str'),",
            "        iam_role_name=dict(type='str'),",
            "        image_id=dict(type='str', required=True),",
            "        key_pair=dict(type='str'),",
            "        kubernetes=dict(type='dict'),",
            "        lifetime_period=dict(type='int'),",
            "        load_balancers=dict(type='list'),",
            "        max_size=dict(type='int', required=True),",
            "        mesosphere=dict(type='dict'),",
            "        min_size=dict(type='int', required=True),",
            "        monitoring=dict(type='str'),",
            "        multai_load_balancers=dict(type='list'),",
            "        multai_token=dict(type='str'),",
            "        name=dict(type='str', required=True),",
            "        network_interfaces=dict(type='list'),",
            "        on_demand_count=dict(type='int'),",
            "        on_demand_instance_type=dict(type='str'),",
            "        opsworks=dict(type='dict'),",
            "        persistence=dict(type='dict'),",
            "        product=dict(type='str', required=True),",
            "        rancher=dict(type='dict'),",
            "        right_scale=dict(type='dict'),",
            "        risk=dict(type='int'),",
            "        roll_config=dict(type='dict'),",
            "        scheduled_tasks=dict(type='list'),",
            "        security_group_ids=dict(type='list', required=True),",
            "        shutdown_script=dict(type='str'),",
            "        signals=dict(type='list'),",
            "        spin_up_time=dict(type='int'),",
            "        spot_instance_types=dict(type='list', required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        tags=dict(type='list'),",
            "        target=dict(type='int', required=True),",
            "        target_group_arns=dict(type='list'),",
            "        tenancy=dict(type='str'),",
            "        terminate_at_end_of_billing_hour=dict(type='bool'),",
            "        token=dict(type='str'),",
            "        unit=dict(type='str'),",
            "        user_data=dict(type='str'),",
            "        utilize_reserved_instances=dict(type='bool'),",
            "        uniqueness_by=dict(default='name', choices=['name', 'id']),",
            "        up_scaling_policies=dict(type='list'),",
            "        target_tracking_policies=dict(type='list'),",
            "        wait_for_instances=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int')",
            "    )",
            "",
            "    module = AnsibleModule(argument_spec=fields)",
            "",
            "    if not HAS_SPOTINST_SDK:",
            "        module.fail_json(msg=\"the Spotinst SDK library is required. (pip install spotinst_sdk)\")",
            "",
            "    # Retrieve creds file variables",
            "    creds_file_loaded_vars = dict()",
            "",
            "    credentials_path = module.params.get('credentials_path')",
            "",
            "    try:",
            "        with open(credentials_path, \"r\") as creds:",
            "            for line in creds:",
            "                eq_index = line.find('=')",
            "                var_name = line[:eq_index].strip()",
            "                string_value = line[eq_index + 1:].strip()",
            "                creds_file_loaded_vars[var_name] = string_value",
            "    except IOError:",
            "        pass",
            "    # End of creds file retrieval",
            "",
            "    token = module.params.get('token')",
            "    if not token:",
            "        token = os.environ.get('SPOTINST_TOKEN')",
            "    if not token:",
            "        token = creds_file_loaded_vars.get(\"token\")",
            "",
            "    account = module.params.get('account_id')",
            "    if not account:",
            "        account = os.environ.get('SPOTINST_ACCOUNT_ID') or os.environ.get('ACCOUNT')",
            "    if not account:",
            "        account = creds_file_loaded_vars.get(\"account\")",
            "",
            "    client = spotinst.SpotinstClient(auth_token=token, print_output=False)",
            "",
            "    if account is not None:",
            "        client = spotinst.SpotinstClient(auth_token=token, print_output=False, account_id=account)",
            "",
            "    group_id, message, has_changed = handle_elastigroup(client=client, module=module)",
            "",
            "    instances = retrieve_group_instances(client=client, module=module, group_id=group_id)",
            "",
            "    module.exit_json(changed=has_changed, group_id=group_id, message=message, instances=instances)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# Copyright (c) 2017 Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "from __future__ import (absolute_import, division, print_function)",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "DOCUMENTATION = \"\"\"",
            "---",
            "module: spotinst_aws_elastigroup",
            "version_added: 2.5",
            "short_description: Create, update or delete Spotinst AWS Elastigroups",
            "author: Spotinst (@talzur)",
            "description:",
            "  - Can create, update, or delete Spotinst AWS Elastigroups",
            "    Launch configuration is part of the elastigroup configuration,",
            "    so no additional modules are necessary for handling the launch configuration.",
            "    You will have to have a credentials file in this location - <home>/.spotinst/credentials",
            "    The credentials file must contain a row that looks like this",
            "    token = <YOUR TOKEN>",
            "    Full documentation available at https://help.spotinst.com/hc/en-us/articles/115003530285-Ansible-",
            "requirements:",
            "  - python >= 2.7",
            "  - spotinst_sdk >= 1.0.38",
            "options:",
            "",
            "  credentials_path:",
            "    description:",
            "      - (String) Optional parameter that allows to set a non-default credentials path.",
            "       Default is ~/.spotinst/credentials",
            "",
            "  account_id:",
            "    description:",
            "      - (String) Optional parameter that allows to set an account-id inside the module configuration",
            "       By default this is retrieved from the credentials path",
            "",
            "  availability_vs_cost:",
            "    choices:",
            "      - availabilityOriented",
            "      - costOriented",
            "      - balanced",
            "    description:",
            "      - (String) The strategy orientation.",
            "    required: true",
            "",
            "  availability_zones:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Availability Zones that are configured in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        name (String),",
            "        subnet_id (String),",
            "        placement_group_name (String),",
            "    required: true",
            "",
            "  block_device_mappings:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of Block Device Mappings for elastigroup instances;",
            "        You can specify virtual devices and EBS volumes.;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are",
            "        device_name (List of Strings),",
            "        virtual_name (String),",
            "        no_device (String),",
            "        ebs (Object, expects the following keys-",
            "        delete_on_termination(Boolean),",
            "        encrypted(Boolean),",
            "        iops (Integer),",
            "        snapshot_id(Integer),",
            "        volume_type(String),",
            "        volume_size(Integer))",
            "",
            "  chef:",
            "    description:",
            "      - (Object) The Chef integration configuration.;",
            "        Expects the following keys - chef_server (String),",
            "        organization (String),",
            "        user (String),",
            "        pem_key (String),",
            "        chef_version (String)",
            "",
            "  draining_timeout:",
            "    description:",
            "      - (Integer) Time for instance to be drained from incoming requests and deregistered from ELB before termination.",
            "",
            "  ebs_optimized:",
            "    description:",
            "      - (Boolean) Enable EBS optimization for supported instances which are not enabled by default.;",
            "        Note - additional charges will be applied.",
            "    type: bool",
            "",
            "  ebs_volume_pool:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of EBS devices to reattach to the elastigroup when available;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        volume_ids (List of Strings),",
            "        device_name (String)",
            "",
            "  ecs:",
            "    description:",
            "      - (Object) The ECS integration configuration.;",
            "        Expects the following key -",
            "        cluster_name (String)",
            "",
            "",
            "  elastic_ips:",
            "    description:",
            "      - (List of Strings) List of ElasticIps Allocation Ids (Example C(eipalloc-9d4e16f8)) to associate to the group instances",
            "",
            "  fallback_to_od:",
            "    description:",
            "      - (Boolean) In case of no spots available, Elastigroup will launch an On-demand instance instead",
            "    type: bool",
            "  health_check_grace_period:",
            "    description:",
            "      - (Integer) The amount of time, in seconds, after the instance has launched to start and check its health.",
            "    default: 300",
            "",
            "  health_check_unhealthy_duration_before_replacement:",
            "    description:",
            "      - (Integer) Minimal mount of time instance should be unhealthy for us to consider it unhealthy.",
            "",
            "  health_check_type:",
            "    choices:",
            "      - ELB",
            "      - HCS",
            "      - TARGET_GROUP",
            "      - MLB",
            "      - EC2",
            "    description:",
            "      - (String) The service to use for the health check.",
            "",
            "  iam_role_name:",
            "    description:",
            "      - (String) The instance profile iamRole name",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  iam_role_arn:",
            "    description:",
            "      - (String) The instance profile iamRole arn",
            "      - Only use iam_role_arn, or iam_role_name",
            "",
            "  id:",
            "    description:",
            "      - (String) The group id if it already exists and you want to update, or delete it.",
            "        This will not work unless the uniqueness_by field is set to id.",
            "        When this is set, and the uniqueness_by field is set, the group will either be updated or deleted, but not created.",
            "",
            "  ignore_changes:",
            "    choices:",
            "      - image_id",
            "      - target",
            "    description:",
            "      - (List of Strings) list of fields on which changes should be ignored when updating",
            "",
            "  image_id:",
            "    description:",
            "      - (String) The image Id used to launch the instance.;",
            "        In case of conflict between Instance type and image type, an error will be returned",
            "    required: true",
            "",
            "  key_pair:",
            "    description:",
            "      - (String) Specify a Key Pair to attach to the instances",
            "    required: true",
            "",
            "  kubernetes:",
            "    description:",
            "      - (Object) The Kubernetes integration configuration.",
            "        Expects the following keys -",
            "        api_server (String),",
            "        token (String)",
            "",
            "  lifetime_period:",
            "    description:",
            "      - (String) lifetime period",
            "",
            "  load_balancers:",
            "    description:",
            "      - (List of Strings) List of classic ELB names",
            "",
            "  max_size:",
            "    description:",
            "      - (Integer) The upper limit number of instances that you can scale up to",
            "    required: true",
            "",
            "  mesosphere:",
            "    description:",
            "      - (Object) The Mesosphere integration configuration.",
            "        Expects the following key -",
            "        api_server (String)",
            "",
            "  min_size:",
            "    description:",
            "      - (Integer) The lower limit number of instances that you can scale down to",
            "    required: true",
            "",
            "  monitoring:",
            "    description:",
            "      - (Boolean) Describes whether instance Enhanced Monitoring is enabled",
            "    required: true",
            "",
            "  name:",
            "    description:",
            "      - (String) Unique name for elastigroup to be created, updated or deleted",
            "    required: true",
            "",
            "  network_interfaces:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of network interfaces to add to the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        description (String),",
            "        device_index (Integer),",
            "        secondary_private_ip_address_count (Integer),",
            "        associate_public_ip_address (Boolean),",
            "        delete_on_termination (Boolean),",
            "        groups (List of Strings),",
            "        network_interface_id (String),",
            "        private_ip_address (String),",
            "        subnet_id (String),",
            "        associate_ipv6_address (Boolean),",
            "        private_ip_addresses (List of Objects, Keys are privateIpAddress (String, required) and primary (Boolean))",
            "",
            "  on_demand_count:",
            "    description:",
            "      - (Integer) Required if risk is not set",
            "      - Number of on demand instances to launch. All other instances will be spot instances.;",
            "        Either set this parameter or the risk parameter",
            "",
            "  on_demand_instance_type:",
            "    description:",
            "      - (String) On-demand instance type that will be provisioned",
            "    required: true",
            "",
            "  opsworks:",
            "    description:",
            "      - (Object) The elastigroup OpsWorks integration configration.;",
            "        Expects the following key -",
            "        layer_id (String)",
            "",
            "  persistence:",
            "    description:",
            "      - (Object) The Stateful elastigroup configration.;",
            "        Accepts the following keys -",
            "        should_persist_root_device (Boolean),",
            "        should_persist_block_devices (Boolean),",
            "        should_persist_private_ip (Boolean)",
            "",
            "  product:",
            "    choices:",
            "      - Linux/UNIX",
            "      - SUSE Linux",
            "      - Windows",
            "      - Linux/UNIX (Amazon VPC)",
            "      - SUSE Linux (Amazon VPC)",
            "      - Windows",
            "    description:",
            "      - (String) Operation system type._",
            "    required: true",
            "",
            "  rancher:",
            "    description:",
            "      - (Object) The Rancher integration configuration.;",
            "        Expects the following keys -",
            "        version (String),",
            "        access_key (String),",
            "        secret_key (String),",
            "        master_host (String)",
            "",
            "  right_scale:",
            "    description:",
            "      - (Object) The Rightscale integration configuration.;",
            "        Expects the following keys -",
            "        account_id (String),",
            "        refresh_token (String)",
            "",
            "  risk:",
            "    description:",
            "      - (Integer) required if on demand is not set. The percentage of Spot instances to launch (0 - 100).",
            "",
            "  roll_config:",
            "    description:",
            "      - (Object) Roll configuration.;",
            "        If you would like the group to roll after updating, please use this feature.",
            "        Accepts the following keys -",
            "        batch_size_percentage(Integer, Required),",
            "        grace_period - (Integer, Required),",
            "        health_check_type(String, Optional)",
            "",
            "  scheduled_tasks:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scheduled tasks to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        adjustment (Integer),",
            "        scale_target_capacity (Integer),",
            "        scale_min_capacity (Integer),",
            "        scale_max_capacity (Integer),",
            "        adjustment_percentage (Integer),",
            "        batch_size_percentage (Integer),",
            "        cron_expression (String),",
            "        frequency (String),",
            "        grace_period (Integer),",
            "        task_type (String, required),",
            "        is_enabled (Boolean)",
            "",
            "  security_group_ids:",
            "    description:",
            "      - (List of Strings) One or more security group IDs. ;",
            "        In case of update it will override the existing Security Group with the new given array",
            "    required: true",
            "",
            "  shutdown_script:",
            "    description:",
            "      - (String) The Base64-encoded shutdown script that executes prior to instance termination.",
            "        Encode before setting.",
            "",
            "  signals:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of signals to configure in the elastigroup;",
            "        keys allowed are -",
            "        name (String, required),",
            "        timeout (Integer)",
            "",
            "  spin_up_time:",
            "    description:",
            "      - (Integer) spin up time, in seconds, for the instance",
            "",
            "  spot_instance_types:",
            "    description:",
            "      - (List of Strings) Spot instance type that will be provisioned.",
            "    required: true",
            "",
            "  state:",
            "    choices:",
            "      - present",
            "      - absent",
            "    description:",
            "      - (String) create or delete the elastigroup",
            "",
            "  tags:",
            "    description:",
            "      - (List of tagKey:tagValue paris) a list of tags to configure in the elastigroup. Please specify list of keys and values (key colon value);",
            "",
            "  target:",
            "    description:",
            "      - (Integer) The number of instances to launch",
            "    required: true",
            "",
            "  target_group_arns:",
            "    description:",
            "      - (List of Strings) List of target group arns instances should be registered to",
            "",
            "  tenancy:",
            "    choices:",
            "      - default",
            "      - dedicated",
            "    description:",
            "      - (String) dedicated vs shared tenancy",
            "",
            "  terminate_at_end_of_billing_hour:",
            "    description:",
            "      - (Boolean) terminate at the end of billing hour",
            "    type: bool",
            "  unit:",
            "    choices:",
            "      - instance",
            "      - weight",
            "    description:",
            "      - (String) The capacity unit to launch instances by.",
            "    required: true",
            "",
            "  up_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions (List of Objects, Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required)",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        min_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "",
            "  down_scaling_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of scaling policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        metric_name (String, required),",
            "        dimensions ((List of Objects), Keys allowed are name (String, required) and value (String)),",
            "        statistic (String, required),",
            "        evaluation_periods (String, required),",
            "        period (String, required),",
            "        threshold (String, required),",
            "        cooldown (String, required),",
            "        unit (String, required),",
            "        operator (String, required),",
            "        action_type (String, required),",
            "        adjustment (String),",
            "        max_target_capacity (String),",
            "        target (String),",
            "        maximum (String),",
            "        minimum (String)",
            "",
            "  target_tracking_policies:",
            "    description:",
            "      - (List of Objects) a list of hash/dictionaries of target tracking policies to configure in the elastigroup;",
            "        '[{\"key\":\"value\", \"key\":\"value\"}]';",
            "        keys allowed are -",
            "        policy_name (String, required),",
            "        namespace (String, required),",
            "        source (String, required),",
            "        metric_name (String, required),",
            "        statistic (String, required),",
            "        unit (String, required),",
            "        cooldown (String, required),",
            "        target (String, required)",
            "",
            "  uniqueness_by:",
            "    choices:",
            "      - id",
            "      - name",
            "    description:",
            "      - (String) If your group names are not unique, you may use this feature to update or delete a specific group.",
            "        Whenever this property is set, you must set a group_id in order to update or delete a group, otherwise a group will be created.",
            "",
            "",
            "  user_data:",
            "    description:",
            "      - (String) Base64-encoded MIME user data. Encode before setting the value.",
            "",
            "",
            "  utilize_reserved_instances:",
            "    description:",
            "      - (Boolean) In case of any available Reserved Instances,",
            "         Elastigroup will utilize your reservations before purchasing Spot instances.",
            "    type: bool",
            "",
            "  wait_for_instances:",
            "    description:",
            "      - (Boolean) Whether or not the elastigroup creation / update actions should wait for the instances to spin",
            "    type: bool",
            "",
            "  wait_timeout:",
            "    description:",
            "      - (Integer) How long the module should wait for instances before failing the action.;",
            "        Only works if wait_for_instances is True.",
            "",
            "\"\"\"",
            "EXAMPLES = '''",
            "# Basic configuration YAML example",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup and wait 600 seconds to retrieve the instances, and use their private ips",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/sda1'",
            "              ebs:",
            "                volume_size: 100",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example, we create an elastigroup with multiple block device mappings, tags, and also an account id",
            "# In organizations with more than one account, it is required to specify an account_id",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          account_id: act-1a9dd2b",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          tags:",
            "            - Environment: someEnvValue",
            "            - OtherTagKey: otherValue",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 5",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-tal",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              ebs:",
            "                volume_size: 60",
            "                volume_type: gp2",
            "            - device_name: '/dev/xvdb'",
            "              ebs:",
            "                volume_size: 120",
            "                volume_type: gp2",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "          wait_for_instances: True",
            "          wait_timeout: 600",
            "      register: result",
            "",
            "    - name: Store private ips to file",
            "      shell: echo {{ item.private_ip }}\\\\n >> list-of-private-ips",
            "      with_items: \"{{ result.instances }}\"",
            "    - debug: var=result",
            "",
            "# In this example we have set up block device mapping with ephemeral devices",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          block_device_mappings:",
            "            - device_name: '/dev/xvda'",
            "              virtual_name: ephemeral0",
            "            - device_name: '/dev/xvdb/'",
            "              virtual_name: ephemeral1",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "# In this example we create a basic group configuration with a network interface defined.",
            "# Each network interface must have a device index",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          network_interfaces:",
            "            - associate_public_ip_address: true",
            "              device_index: 0",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-2b68a15c",
            "          image_id: ami-f173cc91",
            "          key_pair: spotinst-oregon",
            "          max_size: 15",
            "          min_size: 0",
            "          target: 0",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          load_balancers:",
            "            - test-lb-1",
            "          security_group_ids:",
            "            - sg-8f4b8fe9",
            "          spot_instance_types:",
            "            - c3.large",
            "          do_not_update:",
            "            - image_id",
            "            - target",
            "      register: result",
            "    - debug: var=result",
            "",
            "",
            "# In this example we create a basic group configuration with a target tracking scaling policy defined",
            "",
            "- hosts: localhost",
            "  tasks:",
            "    - name: create elastigroup",
            "      spotinst_aws_elastigroup:",
            "          account_id: act-92d45673",
            "          state: present",
            "          risk: 100",
            "          availability_vs_cost: balanced",
            "          availability_zones:",
            "            - name: us-west-2a",
            "              subnet_id: subnet-79da021e",
            "          image_id: ami-f173cc91",
            "          fallback_to_od: true",
            "          tags:",
            "            - Creator: ValueOfCreatorTag",
            "            - Environment: ValueOfEnvironmentTag",
            "          key_pair: spotinst-labs-oregon",
            "          max_size: 10",
            "          min_size: 0",
            "          target: 2",
            "          unit: instance",
            "          monitoring: True",
            "          name: ansible-group-1",
            "          on_demand_instance_type: c3.large",
            "          product: Linux/UNIX",
            "          security_group_ids:",
            "            - sg-46cdc13d",
            "          spot_instance_types:",
            "            - c3.large",
            "          target_tracking_policies:",
            "            - policy_name: target-tracking-1",
            "              namespace: AWS/EC2",
            "              metric_name: CPUUtilization",
            "              statistic: average",
            "              unit: percent",
            "              target: 50",
            "              cooldown: 120",
            "          do_not_update:",
            "            - image_id",
            "      register: result",
            "    - debug: var=result",
            "",
            "'''",
            "RETURN = '''",
            "---",
            "instances:",
            "    description: List of active elastigroup instances and their details.",
            "    returned: success",
            "    type: dict",
            "    sample: [",
            "         {",
            "            \"spotInstanceRequestId\": \"sir-regs25zp\",",
            "            \"instanceId\": \"i-09640ad8678234c\",",
            "            \"instanceType\": \"m4.large\",",
            "            \"product\": \"Linux/UNIX\",",
            "            \"availabilityZone\": \"us-west-2b\",",
            "            \"privateIp\": \"180.0.2.244\",",
            "            \"createdAt\": \"2017-07-17T12:46:18.000Z\",",
            "            \"status\": \"fulfilled\"",
            "        }",
            "    ]",
            "group_id:",
            "    description: Created / Updated group's ID.",
            "    returned: success",
            "    type: str",
            "    sample: \"sig-12345\"",
            "",
            "'''",
            "",
            "HAS_SPOTINST_SDK = False",
            "__metaclass__ = type",
            "",
            "import os",
            "import time",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "try:",
            "    import spotinst_sdk as spotinst",
            "    from spotinst_sdk import SpotinstClientException",
            "",
            "    HAS_SPOTINST_SDK = True",
            "",
            "except ImportError:",
            "    pass",
            "",
            "eni_fields = ('description',",
            "              'device_index',",
            "              'secondary_private_ip_address_count',",
            "              'associate_public_ip_address',",
            "              'delete_on_termination',",
            "              'groups',",
            "              'network_interface_id',",
            "              'private_ip_address',",
            "              'subnet_id',",
            "              'associate_ipv6_address')",
            "",
            "private_ip_fields = ('private_ip_address',",
            "                     'primary')",
            "",
            "capacity_fields = (dict(ansible_field_name='min_size',",
            "                        spotinst_field_name='minimum'),",
            "                   dict(ansible_field_name='max_size',",
            "                        spotinst_field_name='maximum'),",
            "                   'target',",
            "                   'unit')",
            "",
            "lspec_fields = ('user_data',",
            "                'key_pair',",
            "                'tenancy',",
            "                'shutdown_script',",
            "                'monitoring',",
            "                'ebs_optimized',",
            "                'image_id',",
            "                'health_check_type',",
            "                'health_check_grace_period',",
            "                'health_check_unhealthy_duration_before_replacement',",
            "                'security_group_ids')",
            "",
            "iam_fields = (dict(ansible_field_name='iam_role_name',",
            "                   spotinst_field_name='name'),",
            "              dict(ansible_field_name='iam_role_arn',",
            "                   spotinst_field_name='arn'))",
            "",
            "scheduled_task_fields = ('adjustment',",
            "                         'adjustment_percentage',",
            "                         'batch_size_percentage',",
            "                         'cron_expression',",
            "                         'frequency',",
            "                         'grace_period',",
            "                         'task_type',",
            "                         'is_enabled',",
            "                         'scale_target_capacity',",
            "                         'scale_min_capacity',",
            "                         'scale_max_capacity')",
            "",
            "scaling_policy_fields = ('policy_name',",
            "                         'namespace',",
            "                         'metric_name',",
            "                         'dimensions',",
            "                         'statistic',",
            "                         'evaluation_periods',",
            "                         'period',",
            "                         'threshold',",
            "                         'cooldown',",
            "                         'unit',",
            "                         'operator')",
            "",
            "tracking_policy_fields = ('policy_name',",
            "                          'namespace',",
            "                          'source',",
            "                          'metric_name',",
            "                          'statistic',",
            "                          'unit',",
            "                          'cooldown',",
            "                          'target',",
            "                          'threshold')",
            "",
            "action_fields = (dict(ansible_field_name='action_type',",
            "                      spotinst_field_name='type'),",
            "                 'adjustment',",
            "                 'min_target_capacity',",
            "                 'max_target_capacity',",
            "                 'target',",
            "                 'minimum',",
            "                 'maximum')",
            "",
            "signal_fields = ('name',",
            "                 'timeout')",
            "",
            "multai_lb_fields = ('balancer_id',",
            "                    'project_id',",
            "                    'target_set_id',",
            "                    'az_awareness',",
            "                    'auto_weight')",
            "",
            "persistence_fields = ('should_persist_root_device',",
            "                      'should_persist_block_devices',",
            "                      'should_persist_private_ip')",
            "",
            "strategy_fields = ('risk',",
            "                   'utilize_reserved_instances',",
            "                   'fallback_to_od',",
            "                   'on_demand_count',",
            "                   'availability_vs_cost',",
            "                   'draining_timeout',",
            "                   'spin_up_time',",
            "                   'lifetime_period')",
            "",
            "ebs_fields = ('delete_on_termination',",
            "              'encrypted',",
            "              'iops',",
            "              'snapshot_id',",
            "              'volume_type',",
            "              'volume_size')",
            "",
            "bdm_fields = ('device_name',",
            "              'virtual_name',",
            "              'no_device')",
            "",
            "kubernetes_fields = ('api_server',",
            "                     'token')",
            "",
            "right_scale_fields = ('account_id',",
            "                      'refresh_token')",
            "",
            "rancher_fields = ('access_key',",
            "                  'secret_key',",
            "                  'master_host',",
            "                  'version')",
            "",
            "chef_fields = ('chef_server',",
            "               'organization',",
            "               'user',",
            "               'pem_key',",
            "               'chef_version')",
            "",
            "az_fields = ('name',",
            "             'subnet_id',",
            "             'placement_group_name')",
            "",
            "opsworks_fields = ('layer_id',)",
            "",
            "scaling_strategy_fields = ('terminate_at_end_of_billing_hour',)",
            "",
            "mesosphere_fields = ('api_server',)",
            "",
            "ecs_fields = ('cluster_name',)",
            "",
            "multai_fields = ('multai_token',)",
            "",
            "",
            "def handle_elastigroup(client, module):",
            "    has_changed = False",
            "    should_create = False",
            "    group_id = None",
            "    message = 'None'",
            "",
            "    name = module.params.get('name')",
            "    state = module.params.get('state')",
            "    uniqueness_by = module.params.get('uniqueness_by')",
            "    external_group_id = module.params.get('id')",
            "",
            "    if uniqueness_by == 'id':",
            "        if external_group_id is None:",
            "            should_create = True",
            "        else:",
            "            should_create = False",
            "            group_id = external_group_id",
            "    else:",
            "        groups = client.get_elastigroups()",
            "        should_create, group_id = find_group_with_same_name(groups, name)",
            "",
            "    if should_create is True:",
            "        if state == 'present':",
            "            eg = expand_elastigroup(module, is_update=False)",
            "            module.debug(str(\" [INFO] \" + message + \"\\n\"))",
            "            group = client.create_elastigroup(group=eg)",
            "            group_id = group['id']",
            "            message = 'Created group Successfully.'",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            message = 'Cannot delete non-existent group.'",
            "            has_changed = False",
            "    else:",
            "        eg = expand_elastigroup(module, is_update=True)",
            "",
            "        if state == 'present':",
            "            group = client.update_elastigroup(group_update=eg, group_id=group_id)",
            "            message = 'Updated group successfully.'",
            "",
            "            try:",
            "                roll_config = module.params.get('roll_config')",
            "                if roll_config:",
            "                    eg_roll = spotinst.aws_elastigroup.Roll(",
            "                        batch_size_percentage=roll_config.get('batch_size_percentage'),",
            "                        grace_period=roll_config.get('grace_period'),",
            "                        health_check_type=roll_config.get('health_check_type')",
            "                    )",
            "                    roll_response = client.roll_group(group_roll=eg_roll, group_id=group_id)",
            "                    message = 'Updated and started rolling the group successfully.'",
            "",
            "            except SpotinstClientException as exc:",
            "                message = 'Updated group successfully, but failed to perform roll. Error:' + str(exc)",
            "            has_changed = True",
            "",
            "        elif state == 'absent':",
            "            try:",
            "                client.delete_elastigroup(group_id=group_id)",
            "            except SpotinstClientException as exc:",
            "                if \"GROUP_DOESNT_EXIST\" in exc.message:",
            "                    pass",
            "                else:",
            "                    module.fail_json(msg=\"Error while attempting to delete group : \" + exc.message)",
            "",
            "            message = 'Deleted group successfully.'",
            "            has_changed = True",
            "",
            "    return group_id, message, has_changed",
            "",
            "",
            "def retrieve_group_instances(client, module, group_id):",
            "    wait_timeout = module.params.get('wait_timeout')",
            "    wait_for_instances = module.params.get('wait_for_instances')",
            "",
            "    health_check_type = module.params.get('health_check_type')",
            "",
            "    if wait_timeout is None:",
            "        wait_timeout = 300",
            "",
            "    wait_timeout = time.time() + wait_timeout",
            "    target = module.params.get('target')",
            "    state = module.params.get('state')",
            "    instances = list()",
            "",
            "    if state == 'present' and group_id is not None and wait_for_instances is True:",
            "",
            "        is_amount_fulfilled = False",
            "        while is_amount_fulfilled is False and wait_timeout > time.time():",
            "            instances = list()",
            "            amount_of_fulfilled_instances = 0",
            "",
            "            if health_check_type is not None:",
            "                healthy_instances = client.get_instance_healthiness(group_id=group_id)",
            "",
            "                for healthy_instance in healthy_instances:",
            "                    if(healthy_instance.get('healthStatus') == 'HEALTHY'):",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(healthy_instance)",
            "",
            "            else:",
            "                active_instances = client.get_elastigroup_active_instances(group_id=group_id)",
            "",
            "                for active_instance in active_instances:",
            "                    if active_instance.get('private_ip') is not None:",
            "                        amount_of_fulfilled_instances += 1",
            "                        instances.append(active_instance)",
            "",
            "            if amount_of_fulfilled_instances >= target:",
            "                is_amount_fulfilled = True",
            "",
            "            time.sleep(10)",
            "",
            "    return instances",
            "",
            "",
            "def find_group_with_same_name(groups, name):",
            "    for group in groups:",
            "        if group['name'] == name:",
            "            return False, group.get('id')",
            "",
            "    return True, None",
            "",
            "",
            "def expand_elastigroup(module, is_update):",
            "    do_not_update = module.params['do_not_update']",
            "    name = module.params.get('name')",
            "",
            "    eg = spotinst.aws_elastigroup.Elastigroup()",
            "    description = module.params.get('description')",
            "",
            "    if name is not None:",
            "        eg.name = name",
            "    if description is not None:",
            "        eg.description = description",
            "",
            "    # Capacity",
            "    expand_capacity(eg, module, is_update, do_not_update)",
            "    # Strategy",
            "    expand_strategy(eg, module)",
            "    # Scaling",
            "    expand_scaling(eg, module)",
            "    # Third party integrations",
            "    expand_integrations(eg, module)",
            "    # Compute",
            "    expand_compute(eg, module, is_update, do_not_update)",
            "    # Multai",
            "    expand_multai(eg, module)",
            "    # Scheduling",
            "    expand_scheduled_tasks(eg, module)",
            "",
            "    return eg",
            "",
            "",
            "def expand_compute(eg, module, is_update, do_not_update):",
            "    elastic_ips = module.params['elastic_ips']",
            "    on_demand_instance_type = module.params.get('on_demand_instance_type')",
            "    spot_instance_types = module.params['spot_instance_types']",
            "    ebs_volume_pool = module.params['ebs_volume_pool']",
            "    availability_zones_list = module.params['availability_zones']",
            "    product = module.params.get('product')",
            "",
            "    eg_compute = spotinst.aws_elastigroup.Compute()",
            "",
            "    if product is not None:",
            "        # Only put product on group creation",
            "        if is_update is not True:",
            "            eg_compute.product = product",
            "",
            "    if elastic_ips is not None:",
            "        eg_compute.elastic_ips = elastic_ips",
            "",
            "    if on_demand_instance_type or spot_instance_types is not None:",
            "        eg_instance_types = spotinst.aws_elastigroup.InstanceTypes()",
            "",
            "        if on_demand_instance_type is not None:",
            "            eg_instance_types.spot = spot_instance_types",
            "        if spot_instance_types is not None:",
            "            eg_instance_types.ondemand = on_demand_instance_type",
            "",
            "        if eg_instance_types.spot is not None or eg_instance_types.ondemand is not None:",
            "            eg_compute.instance_types = eg_instance_types",
            "",
            "    expand_ebs_volume_pool(eg_compute, ebs_volume_pool)",
            "",
            "    eg_compute.availability_zones = expand_list(availability_zones_list, az_fields, 'AvailabilityZone')",
            "",
            "    expand_launch_spec(eg_compute, module, is_update, do_not_update)",
            "",
            "    eg.compute = eg_compute",
            "",
            "",
            "def expand_ebs_volume_pool(eg_compute, ebs_volumes_list):",
            "    if ebs_volumes_list is not None:",
            "        eg_volumes = []",
            "",
            "        for volume in ebs_volumes_list:",
            "            eg_volume = spotinst.aws_elastigroup.EbsVolume()",
            "",
            "            if volume.get('device_name') is not None:",
            "                eg_volume.device_name = volume.get('device_name')",
            "            if volume.get('volume_ids') is not None:",
            "                eg_volume.volume_ids = volume.get('volume_ids')",
            "",
            "            if eg_volume.device_name is not None:",
            "                eg_volumes.append(eg_volume)",
            "",
            "        if len(eg_volumes) > 0:",
            "            eg_compute.ebs_volume_pool = eg_volumes",
            "",
            "",
            "def expand_launch_spec(eg_compute, module, is_update, do_not_update):",
            "    eg_launch_spec = expand_fields(lspec_fields, module.params, 'LaunchSpecification')",
            "",
            "    if module.params['iam_role_arn'] is not None or module.params['iam_role_name'] is not None:",
            "        eg_launch_spec.iam_role = expand_fields(iam_fields, module.params, 'IamRole')",
            "",
            "    tags = module.params['tags']",
            "    load_balancers = module.params['load_balancers']",
            "    target_group_arns = module.params['target_group_arns']",
            "    block_device_mappings = module.params['block_device_mappings']",
            "    network_interfaces = module.params['network_interfaces']",
            "",
            "    if is_update is True:",
            "        if 'image_id' in do_not_update:",
            "            delattr(eg_launch_spec, 'image_id')",
            "",
            "    expand_tags(eg_launch_spec, tags)",
            "",
            "    expand_load_balancers(eg_launch_spec, load_balancers, target_group_arns)",
            "",
            "    expand_block_device_mappings(eg_launch_spec, block_device_mappings)",
            "",
            "    expand_network_interfaces(eg_launch_spec, network_interfaces)",
            "",
            "    eg_compute.launch_specification = eg_launch_spec",
            "",
            "",
            "def expand_integrations(eg, module):",
            "    rancher = module.params.get('rancher')",
            "    mesosphere = module.params.get('mesosphere')",
            "    ecs = module.params.get('ecs')",
            "    kubernetes = module.params.get('kubernetes')",
            "    right_scale = module.params.get('right_scale')",
            "    opsworks = module.params.get('opsworks')",
            "    chef = module.params.get('chef')",
            "",
            "    integration_exists = False",
            "",
            "    eg_integrations = spotinst.aws_elastigroup.ThirdPartyIntegrations()",
            "",
            "    if mesosphere is not None:",
            "        eg_integrations.mesosphere = expand_fields(mesosphere_fields, mesosphere, 'Mesosphere')",
            "        integration_exists = True",
            "",
            "    if ecs is not None:",
            "        eg_integrations.ecs = expand_fields(ecs_fields, ecs, 'EcsConfiguration')",
            "        integration_exists = True",
            "",
            "    if kubernetes is not None:",
            "        eg_integrations.kubernetes = expand_fields(kubernetes_fields, kubernetes, 'KubernetesConfiguration')",
            "        integration_exists = True",
            "",
            "    if right_scale is not None:",
            "        eg_integrations.right_scale = expand_fields(right_scale_fields, right_scale, 'RightScaleConfiguration')",
            "        integration_exists = True",
            "",
            "    if opsworks is not None:",
            "        eg_integrations.opsworks = expand_fields(opsworks_fields, opsworks, 'OpsWorksConfiguration')",
            "        integration_exists = True",
            "",
            "    if rancher is not None:",
            "        eg_integrations.rancher = expand_fields(rancher_fields, rancher, 'Rancher')",
            "        integration_exists = True",
            "",
            "    if chef is not None:",
            "        eg_integrations.chef = expand_fields(chef_fields, chef, 'ChefConfiguration')",
            "        integration_exists = True",
            "",
            "    if integration_exists:",
            "        eg.third_parties_integration = eg_integrations",
            "",
            "",
            "def expand_capacity(eg, module, is_update, do_not_update):",
            "    eg_capacity = expand_fields(capacity_fields, module.params, 'Capacity')",
            "",
            "    if is_update is True:",
            "        delattr(eg_capacity, 'unit')",
            "",
            "        if 'target' in do_not_update:",
            "            delattr(eg_capacity, 'target')",
            "",
            "    eg.capacity = eg_capacity",
            "",
            "",
            "def expand_strategy(eg, module):",
            "    persistence = module.params.get('persistence')",
            "    signals = module.params.get('signals')",
            "",
            "    eg_strategy = expand_fields(strategy_fields, module.params, 'Strategy')",
            "",
            "    terminate_at_end_of_billing_hour = module.params.get('terminate_at_end_of_billing_hour')",
            "",
            "    if terminate_at_end_of_billing_hour is not None:",
            "        eg_strategy.eg_scaling_strategy = expand_fields(scaling_strategy_fields,",
            "                                                        module.params, 'ScalingStrategy')",
            "",
            "    if persistence is not None:",
            "        eg_strategy.persistence = expand_fields(persistence_fields, persistence, 'Persistence')",
            "",
            "    if signals is not None:",
            "        eg_signals = expand_list(signals, signal_fields, 'Signal')",
            "",
            "        if len(eg_signals) > 0:",
            "            eg_strategy.signals = eg_signals",
            "",
            "    eg.strategy = eg_strategy",
            "",
            "",
            "def expand_multai(eg, module):",
            "    multai_load_balancers = module.params.get('multai_load_balancers')",
            "",
            "    eg_multai = expand_fields(multai_fields, module.params, 'Multai')",
            "",
            "    if multai_load_balancers is not None:",
            "        eg_multai_load_balancers = expand_list(multai_load_balancers, multai_lb_fields, 'MultaiLoadBalancer')",
            "",
            "        if len(eg_multai_load_balancers) > 0:",
            "            eg_multai.balancers = eg_multai_load_balancers",
            "            eg.multai = eg_multai",
            "",
            "",
            "def expand_scheduled_tasks(eg, module):",
            "    scheduled_tasks = module.params.get('scheduled_tasks')",
            "",
            "    if scheduled_tasks is not None:",
            "        eg_scheduling = spotinst.aws_elastigroup.Scheduling()",
            "",
            "        eg_tasks = expand_list(scheduled_tasks, scheduled_task_fields, 'ScheduledTask')",
            "",
            "        if len(eg_tasks) > 0:",
            "            eg_scheduling.tasks = eg_tasks",
            "            eg.scheduling = eg_scheduling",
            "",
            "",
            "def expand_load_balancers(eg_launchspec, load_balancers, target_group_arns):",
            "    if load_balancers is not None or target_group_arns is not None:",
            "        eg_load_balancers_config = spotinst.aws_elastigroup.LoadBalancersConfig()",
            "        eg_total_lbs = []",
            "",
            "        if load_balancers is not None:",
            "            for elb_name in load_balancers:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if elb_name is not None:",
            "                    eg_elb.name = elb_name",
            "                    eg_elb.type = 'CLASSIC'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if target_group_arns is not None:",
            "            for target_arn in target_group_arns:",
            "                eg_elb = spotinst.aws_elastigroup.LoadBalancer()",
            "                if target_arn is not None:",
            "                    eg_elb.arn = target_arn",
            "                    eg_elb.type = 'TARGET_GROUP'",
            "                    eg_total_lbs.append(eg_elb)",
            "",
            "        if len(eg_total_lbs) > 0:",
            "            eg_load_balancers_config.load_balancers = eg_total_lbs",
            "            eg_launchspec.load_balancers_config = eg_load_balancers_config",
            "",
            "",
            "def expand_tags(eg_launchspec, tags):",
            "    if tags is not None:",
            "        eg_tags = []",
            "",
            "        for tag in tags:",
            "            eg_tag = spotinst.aws_elastigroup.Tag()",
            "            if tag.keys():",
            "                eg_tag.tag_key = tag.keys()[0]",
            "            if tag.values():",
            "                eg_tag.tag_value = tag.values()[0]",
            "",
            "            eg_tags.append(eg_tag)",
            "",
            "        if len(eg_tags) > 0:",
            "            eg_launchspec.tags = eg_tags",
            "",
            "",
            "def expand_block_device_mappings(eg_launchspec, bdms):",
            "    if bdms is not None:",
            "        eg_bdms = []",
            "",
            "        for bdm in bdms:",
            "            eg_bdm = expand_fields(bdm_fields, bdm, 'BlockDeviceMapping')",
            "",
            "            if bdm.get('ebs') is not None:",
            "                eg_bdm.ebs = expand_fields(ebs_fields, bdm.get('ebs'), 'EBS')",
            "",
            "            eg_bdms.append(eg_bdm)",
            "",
            "        if len(eg_bdms) > 0:",
            "            eg_launchspec.block_device_mappings = eg_bdms",
            "",
            "",
            "def expand_network_interfaces(eg_launchspec, enis):",
            "    if enis is not None:",
            "        eg_enis = []",
            "",
            "        for eni in enis:",
            "            eg_eni = expand_fields(eni_fields, eni, 'NetworkInterface')",
            "",
            "            eg_pias = expand_list(eni.get('private_ip_addresses'), private_ip_fields, 'PrivateIpAddress')",
            "",
            "            if eg_pias is not None:",
            "                eg_eni.private_ip_addresses = eg_pias",
            "",
            "            eg_enis.append(eg_eni)",
            "",
            "        if len(eg_enis) > 0:",
            "            eg_launchspec.network_interfaces = eg_enis",
            "",
            "",
            "def expand_scaling(eg, module):",
            "    up_scaling_policies = module.params['up_scaling_policies']",
            "    down_scaling_policies = module.params['down_scaling_policies']",
            "    target_tracking_policies = module.params['target_tracking_policies']",
            "",
            "    eg_scaling = spotinst.aws_elastigroup.Scaling()",
            "",
            "    if up_scaling_policies is not None:",
            "        eg_up_scaling_policies = expand_scaling_policies(up_scaling_policies)",
            "        if len(eg_up_scaling_policies) > 0:",
            "            eg_scaling.up = eg_up_scaling_policies",
            "",
            "    if down_scaling_policies is not None:",
            "        eg_down_scaling_policies = expand_scaling_policies(down_scaling_policies)",
            "        if len(eg_down_scaling_policies) > 0:",
            "            eg_scaling.down = eg_down_scaling_policies",
            "",
            "    if target_tracking_policies is not None:",
            "        eg_target_tracking_policies = expand_target_tracking_policies(target_tracking_policies)",
            "        if len(eg_target_tracking_policies) > 0:",
            "            eg_scaling.target = eg_target_tracking_policies",
            "",
            "    if eg_scaling.down is not None or eg_scaling.up is not None or eg_scaling.target is not None:",
            "        eg.scaling = eg_scaling",
            "",
            "",
            "def expand_list(items, fields, class_name):",
            "    if items is not None:",
            "        new_objects_list = []",
            "        for item in items:",
            "            new_obj = expand_fields(fields, item, class_name)",
            "            new_objects_list.append(new_obj)",
            "",
            "        return new_objects_list",
            "",
            "",
            "def expand_fields(fields, item, class_name):",
            "    class_ = getattr(spotinst.aws_elastigroup, class_name)",
            "    new_obj = class_()",
            "",
            "    # Handle primitive fields",
            "    if item is not None:",
            "        for field in fields:",
            "            if isinstance(field, dict):",
            "                ansible_field_name = field['ansible_field_name']",
            "                spotinst_field_name = field['spotinst_field_name']",
            "            else:",
            "                ansible_field_name = field",
            "                spotinst_field_name = field",
            "            if item.get(ansible_field_name) is not None:",
            "                setattr(new_obj, spotinst_field_name, item.get(ansible_field_name))",
            "",
            "    return new_obj",
            "",
            "",
            "def expand_scaling_policies(scaling_policies):",
            "    eg_scaling_policies = []",
            "",
            "    for policy in scaling_policies:",
            "        eg_policy = expand_fields(scaling_policy_fields, policy, 'ScalingPolicy')",
            "        eg_policy.action = expand_fields(action_fields, policy, 'ScalingPolicyAction')",
            "        eg_scaling_policies.append(eg_policy)",
            "",
            "    return eg_scaling_policies",
            "",
            "",
            "def expand_target_tracking_policies(tracking_policies):",
            "    eg_tracking_policies = []",
            "",
            "    for policy in tracking_policies:",
            "        eg_policy = expand_fields(tracking_policy_fields, policy, 'TargetTrackingPolicy')",
            "        eg_tracking_policies.append(eg_policy)",
            "",
            "    return eg_tracking_policies",
            "",
            "",
            "def main():",
            "    fields = dict(",
            "        account_id=dict(type='str'),",
            "        availability_vs_cost=dict(type='str', required=True),",
            "        availability_zones=dict(type='list', required=True),",
            "        block_device_mappings=dict(type='list'),",
            "        chef=dict(type='dict'),",
            "        credentials_path=dict(type='path', default=\"~/.spotinst/credentials\"),",
            "        do_not_update=dict(default=[], type='list'),",
            "        down_scaling_policies=dict(type='list'),",
            "        draining_timeout=dict(type='int'),",
            "        ebs_optimized=dict(type='bool'),",
            "        ebs_volume_pool=dict(type='list'),",
            "        ecs=dict(type='dict'),",
            "        elastic_beanstalk=dict(type='dict'),",
            "        elastic_ips=dict(type='list'),",
            "        fallback_to_od=dict(type='bool'),",
            "        id=dict(type='str'),",
            "        health_check_grace_period=dict(type='int'),",
            "        health_check_type=dict(type='str'),",
            "        health_check_unhealthy_duration_before_replacement=dict(type='int'),",
            "        iam_role_arn=dict(type='str'),",
            "        iam_role_name=dict(type='str'),",
            "        image_id=dict(type='str', required=True),",
            "        key_pair=dict(type='str'),",
            "        kubernetes=dict(type='dict'),",
            "        lifetime_period=dict(type='int'),",
            "        load_balancers=dict(type='list'),",
            "        max_size=dict(type='int', required=True),",
            "        mesosphere=dict(type='dict'),",
            "        min_size=dict(type='int', required=True),",
            "        monitoring=dict(type='str'),",
            "        multai_load_balancers=dict(type='list'),",
            "        multai_token=dict(type='str', no_log=True),",
            "        name=dict(type='str', required=True),",
            "        network_interfaces=dict(type='list'),",
            "        on_demand_count=dict(type='int'),",
            "        on_demand_instance_type=dict(type='str'),",
            "        opsworks=dict(type='dict'),",
            "        persistence=dict(type='dict'),",
            "        product=dict(type='str', required=True),",
            "        rancher=dict(type='dict'),",
            "        right_scale=dict(type='dict'),",
            "        risk=dict(type='int'),",
            "        roll_config=dict(type='dict'),",
            "        scheduled_tasks=dict(type='list'),",
            "        security_group_ids=dict(type='list', required=True),",
            "        shutdown_script=dict(type='str'),",
            "        signals=dict(type='list'),",
            "        spin_up_time=dict(type='int'),",
            "        spot_instance_types=dict(type='list', required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "        tags=dict(type='list'),",
            "        target=dict(type='int', required=True),",
            "        target_group_arns=dict(type='list'),",
            "        tenancy=dict(type='str'),",
            "        terminate_at_end_of_billing_hour=dict(type='bool'),",
            "        token=dict(type='str', no_log=True),",
            "        unit=dict(type='str'),",
            "        user_data=dict(type='str'),",
            "        utilize_reserved_instances=dict(type='bool'),",
            "        uniqueness_by=dict(default='name', choices=['name', 'id']),",
            "        up_scaling_policies=dict(type='list'),",
            "        target_tracking_policies=dict(type='list'),",
            "        wait_for_instances=dict(type='bool', default=False),",
            "        wait_timeout=dict(type='int')",
            "    )",
            "",
            "    module = AnsibleModule(argument_spec=fields)",
            "",
            "    if not HAS_SPOTINST_SDK:",
            "        module.fail_json(msg=\"the Spotinst SDK library is required. (pip install spotinst_sdk)\")",
            "",
            "    # Retrieve creds file variables",
            "    creds_file_loaded_vars = dict()",
            "",
            "    credentials_path = module.params.get('credentials_path')",
            "",
            "    try:",
            "        with open(credentials_path, \"r\") as creds:",
            "            for line in creds:",
            "                eq_index = line.find('=')",
            "                var_name = line[:eq_index].strip()",
            "                string_value = line[eq_index + 1:].strip()",
            "                creds_file_loaded_vars[var_name] = string_value",
            "    except IOError:",
            "        pass",
            "    # End of creds file retrieval",
            "",
            "    token = module.params.get('token')",
            "    if not token:",
            "        token = os.environ.get('SPOTINST_TOKEN')",
            "    if not token:",
            "        token = creds_file_loaded_vars.get(\"token\")",
            "",
            "    account = module.params.get('account_id')",
            "    if not account:",
            "        account = os.environ.get('SPOTINST_ACCOUNT_ID') or os.environ.get('ACCOUNT')",
            "    if not account:",
            "        account = creds_file_loaded_vars.get(\"account\")",
            "",
            "    client = spotinst.SpotinstClient(auth_token=token, print_output=False)",
            "",
            "    if account is not None:",
            "        client = spotinst.SpotinstClient(auth_token=token, print_output=False, account_id=account)",
            "",
            "    group_id, message, has_changed = handle_elastigroup(client=client, module=module)",
            "",
            "    instances = retrieve_group_instances(client=client, module=module, group_id=group_id)",
            "",
            "    module.exit_json(changed=has_changed, group_id=group_id, message=message, instances=instances)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1441": [
                "main"
            ],
            "1465": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/monitoring/librato_annotation.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 146,
                "afterPatchRowNumber": 146,
                "PatchRowcode": "     module = AnsibleModule("
            },
            "1": {
                "beforePatchRowNumber": 147,
                "afterPatchRowNumber": 147,
                "PatchRowcode": "         argument_spec=dict("
            },
            "2": {
                "beforePatchRowNumber": 148,
                "afterPatchRowNumber": 148,
                "PatchRowcode": "             user=dict(required=True),"
            },
            "3": {
                "beforePatchRowNumber": 149,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            api_key=dict(required=True),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 149,
                "PatchRowcode": "+            api_key=dict(required=True, no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 150,
                "afterPatchRowNumber": 150,
                "PatchRowcode": "             name=dict(required=False),"
            },
            "6": {
                "beforePatchRowNumber": 151,
                "afterPatchRowNumber": 151,
                "PatchRowcode": "             title=dict(required=True),"
            },
            "7": {
                "beforePatchRowNumber": 152,
                "afterPatchRowNumber": 152,
                "PatchRowcode": "             source=dict(required=False),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# (C) Seth Edwards, 2014",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: librato_annotation",
            "short_description: create an annotation in librato",
            "description:",
            "    - Create an annotation event on the given annotation stream :name. If the annotation stream does not exist, it will be created automatically",
            "version_added: \"1.6\"",
            "author: \"Seth Edwards (@Sedward)\"",
            "requirements: []",
            "options:",
            "    user:",
            "        description:",
            "           - Librato account username",
            "        required: true",
            "    api_key:",
            "        description:",
            "           - Librato account api key",
            "        required: true",
            "    name:",
            "        description:",
            "            - The annotation stream name",
            "            - If the annotation stream does not exist, it will be created automatically",
            "        required: false",
            "    title:",
            "        description:",
            "            - The title of an annotation is a string and may contain spaces",
            "            - The title should be a short, high-level summary of the annotation e.g. v45 Deployment",
            "        required: true",
            "    source:",
            "        description:",
            "            - A string which describes the originating source of an annotation when that annotation is tracked across multiple members of a population",
            "        required: false",
            "    description:",
            "        description:",
            "            - The description contains extra metadata about a particular annotation",
            "            - The description should contain specifics on the individual annotation e.g. Deployed 9b562b2 shipped new feature foo!",
            "        required: false",
            "    start_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation started",
            "        required: false",
            "    end_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation ended",
            "            - For events that have a duration, this is a useful way to annotate the duration of the event",
            "        required: false",
            "    links:",
            "        description:",
            "            - See examples",
            "        required: true",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Create a simple annotation event with a source",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXX",
            "    title: App Config Change",
            "    source: foo.bar",
            "    description: This is a detailed description of the config change",
            "",
            "# Create an annotation that includes a link",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: code.deploy",
            "    title: app code deploy",
            "    description: this is a detailed description of a deployment",
            "    links:",
            "      - rel: example",
            "        href: http://www.example.com/deploy",
            "",
            "# Create an annotation with a start_time and end_time",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: maintenance",
            "    title: Maintenance window",
            "    description: This is a detailed description of maintenance",
            "    start_time: 1395940006",
            "    end_time: 1395954406",
            "'''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "",
            "",
            "def post_annotation(module):",
            "    user = module.params['user']",
            "    api_key = module.params['api_key']",
            "    name = module.params['name']",
            "    title = module.params['title']",
            "",
            "    url = 'https://metrics-api.librato.com/v1/annotations/%s' % name",
            "    params = {}",
            "    params['title'] = title",
            "",
            "    if module.params['source'] is not None:",
            "        params['source'] = module.params['source']",
            "    if module.params['description'] is not None:",
            "        params['description'] = module.params['description']",
            "    if module.params['start_time'] is not None:",
            "        params['start_time'] = module.params['start_time']",
            "    if module.params['end_time'] is not None:",
            "        params['end_time'] = module.params['end_time']",
            "    if module.params['links'] is not None:",
            "        params['links'] = module.params['links']",
            "",
            "    json_body = module.jsonify(params)",
            "",
            "    headers = {}",
            "    headers['Content-Type'] = 'application/json'",
            "",
            "    # Hack send parameters the way fetch_url wants them",
            "    module.params['url_username'] = user",
            "    module.params['url_password'] = api_key",
            "    response, info = fetch_url(module, url, data=json_body, headers=headers)",
            "    response_code = str(info['status'])",
            "    response_body = info['body']",
            "    if info['status'] != 201:",
            "        if info['status'] >= 400:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code + \" Response body: \" + response_body)",
            "        else:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code)",
            "    response = response.read()",
            "    module.exit_json(changed=True, annotation=response)",
            "",
            "",
            "def main():",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            user=dict(required=True),",
            "            api_key=dict(required=True),",
            "            name=dict(required=False),",
            "            title=dict(required=True),",
            "            source=dict(required=False),",
            "            description=dict(required=False),",
            "            start_time=dict(required=False, default=None, type='int'),",
            "            end_time=dict(require=False, default=None, type='int'),",
            "            links=dict(type='list')",
            "        )",
            "    )",
            "",
            "    post_annotation(module)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "#",
            "# (C) Seth Edwards, 2014",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: librato_annotation",
            "short_description: create an annotation in librato",
            "description:",
            "    - Create an annotation event on the given annotation stream :name. If the annotation stream does not exist, it will be created automatically",
            "version_added: \"1.6\"",
            "author: \"Seth Edwards (@Sedward)\"",
            "requirements: []",
            "options:",
            "    user:",
            "        description:",
            "           - Librato account username",
            "        required: true",
            "    api_key:",
            "        description:",
            "           - Librato account api key",
            "        required: true",
            "    name:",
            "        description:",
            "            - The annotation stream name",
            "            - If the annotation stream does not exist, it will be created automatically",
            "        required: false",
            "    title:",
            "        description:",
            "            - The title of an annotation is a string and may contain spaces",
            "            - The title should be a short, high-level summary of the annotation e.g. v45 Deployment",
            "        required: true",
            "    source:",
            "        description:",
            "            - A string which describes the originating source of an annotation when that annotation is tracked across multiple members of a population",
            "        required: false",
            "    description:",
            "        description:",
            "            - The description contains extra metadata about a particular annotation",
            "            - The description should contain specifics on the individual annotation e.g. Deployed 9b562b2 shipped new feature foo!",
            "        required: false",
            "    start_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation started",
            "        required: false",
            "    end_time:",
            "        description:",
            "            - The unix timestamp indicating the time at which the event referenced by this annotation ended",
            "            - For events that have a duration, this is a useful way to annotate the duration of the event",
            "        required: false",
            "    links:",
            "        description:",
            "            - See examples",
            "        required: true",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Create a simple annotation event with a source",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXX",
            "    title: App Config Change",
            "    source: foo.bar",
            "    description: This is a detailed description of the config change",
            "",
            "# Create an annotation that includes a link",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: code.deploy",
            "    title: app code deploy",
            "    description: this is a detailed description of a deployment",
            "    links:",
            "      - rel: example",
            "        href: http://www.example.com/deploy",
            "",
            "# Create an annotation with a start_time and end_time",
            "- librato_annotation:",
            "    user: user@example.com",
            "    api_key: XXXXXXXXXXXXXXXXXX",
            "    name: maintenance",
            "    title: Maintenance window",
            "    description: This is a detailed description of maintenance",
            "    start_time: 1395940006",
            "    end_time: 1395954406",
            "'''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "",
            "",
            "def post_annotation(module):",
            "    user = module.params['user']",
            "    api_key = module.params['api_key']",
            "    name = module.params['name']",
            "    title = module.params['title']",
            "",
            "    url = 'https://metrics-api.librato.com/v1/annotations/%s' % name",
            "    params = {}",
            "    params['title'] = title",
            "",
            "    if module.params['source'] is not None:",
            "        params['source'] = module.params['source']",
            "    if module.params['description'] is not None:",
            "        params['description'] = module.params['description']",
            "    if module.params['start_time'] is not None:",
            "        params['start_time'] = module.params['start_time']",
            "    if module.params['end_time'] is not None:",
            "        params['end_time'] = module.params['end_time']",
            "    if module.params['links'] is not None:",
            "        params['links'] = module.params['links']",
            "",
            "    json_body = module.jsonify(params)",
            "",
            "    headers = {}",
            "    headers['Content-Type'] = 'application/json'",
            "",
            "    # Hack send parameters the way fetch_url wants them",
            "    module.params['url_username'] = user",
            "    module.params['url_password'] = api_key",
            "    response, info = fetch_url(module, url, data=json_body, headers=headers)",
            "    response_code = str(info['status'])",
            "    response_body = info['body']",
            "    if info['status'] != 201:",
            "        if info['status'] >= 400:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code + \" Response body: \" + response_body)",
            "        else:",
            "            module.fail_json(msg=\"Request Failed. Response code: \" + response_code)",
            "    response = response.read()",
            "    module.exit_json(changed=True, annotation=response)",
            "",
            "",
            "def main():",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            user=dict(required=True),",
            "            api_key=dict(required=True, no_log=True),",
            "            name=dict(required=False),",
            "            title=dict(required=True),",
            "            source=dict(required=False),",
            "            description=dict(required=False),",
            "            start_time=dict(required=False, default=None, type='int'),",
            "            end_time=dict(require=False, default=None, type='int'),",
            "            links=dict(type='list')",
            "        )",
            "    )",
            "",
            "    post_annotation(module)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "149": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/monitoring/pagerduty_alert.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 190,
                "afterPatchRowNumber": 190,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 191,
                "afterPatchRowNumber": 191,
                "PatchRowcode": "             name=dict(required=False),"
            },
            "2": {
                "beforePatchRowNumber": 192,
                "afterPatchRowNumber": 192,
                "PatchRowcode": "             service_id=dict(required=True),"
            },
            "3": {
                "beforePatchRowNumber": 193,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            service_key=dict(require=False),"
            },
            "4": {
                "beforePatchRowNumber": 194,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            integration_key=dict(require=False),"
            },
            "5": {
                "beforePatchRowNumber": 195,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            api_key=dict(required=True),"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 193,
                "PatchRowcode": "+            service_key=dict(required=False, no_log=True),"
            },
            "7": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 194,
                "PatchRowcode": "+            integration_key=dict(required=False, no_log=True),"
            },
            "8": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 195,
                "PatchRowcode": "+            api_key=dict(required=True, no_log=True),"
            },
            "9": {
                "beforePatchRowNumber": 196,
                "afterPatchRowNumber": 196,
                "PatchRowcode": "             state=dict(required=True,"
            },
            "10": {
                "beforePatchRowNumber": 197,
                "afterPatchRowNumber": 197,
                "PatchRowcode": "                        choices=['triggered', 'acknowledged', 'resolved']),"
            },
            "11": {
                "beforePatchRowNumber": 198,
                "afterPatchRowNumber": 198,
                "PatchRowcode": "             client=dict(required=False, default=None),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "",
            "module: pagerduty_alert",
            "short_description: Trigger, acknowledge or resolve PagerDuty incidents",
            "description:",
            "    - This module will let you trigger, acknowledge or resolve a PagerDuty incident by sending events",
            "version_added: \"1.9\"",
            "author:",
            "    - \"Amanpreet Singh (@ApsOps)\"",
            "requirements:",
            "    - PagerDuty API access",
            "options:",
            "    name:",
            "        description:",
            "            - PagerDuty unique subdomain. Obsolete. It is not used with PagerDuty REST v2 API.",
            "    service_id:",
            "        description:",
            "            - ID of PagerDuty service when incidents will be triggered, acknowledged or resolved.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    service_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services. Obsolete. Please use I(integration_key).",
            "    integration_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services.",
            "            - This is the \"integration key\" listed on a \"Integrations\" tab of PagerDuty service.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    state:",
            "        description:",
            "            - Type of event to be sent.",
            "        required: true",
            "        choices:",
            "            - 'triggered'",
            "            - 'acknowledged'",
            "            - 'resolved'",
            "    api_key:",
            "        description:",
            "            - The pagerduty API key (readonly access), generated on the pagerduty site.",
            "        required: true",
            "    desc:",
            "        description:",
            "            - For C(triggered) I(state) - Required. Short description of the problem that led to this trigger. This field (or a truncated version)",
            "              will be used when generating phone calls, SMS messages and alert emails. It will also appear on the incidents tables in the PagerDuty UI.",
            "              The maximum length is 1024 characters.",
            "            - For C(acknowledged) or C(resolved) I(state) - Text that will appear in the incident's log associated with this event.",
            "        required: false",
            "        default: Created via Ansible",
            "    incident_key:",
            "        description:",
            "            - Identifies the incident to which this I(state) should be applied.",
            "            - For C(triggered) I(state) - If there's no open (i.e. unresolved) incident with this key, a new one will be created. If there's already an",
            "              open incident with a matching key, this event will be appended to that incident's log. The event key provides an easy way to \"de-dup\"",
            "              problem reports.",
            "            - For C(acknowledged) or C(resolved) I(state) - This should be the incident_key you received back when the incident was first opened by a",
            "              trigger event. Acknowledge events referencing resolved or nonexistent incidents will be discarded.",
            "        required: false",
            "        version_added: \"2.7\"",
            "    client:",
            "        description:",
            "        - The name of the monitoring client that is triggering this event.",
            "        required: false",
            "    client_url:",
            "        description:",
            "        -  The URL of the monitoring client that is triggering this event.",
            "        required: false",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Trigger an incident with just the basic options",
            "- pagerduty_alert:",
            "    name: companyabc",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "",
            "# Trigger an incident with more options",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "    incident_key: somekey",
            "    client: Sample Monitoring Service",
            "    client_url: http://service.example.com",
            "",
            "# Acknowledge an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: acknowledged",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "",
            "# Resolve an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: resolved",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "'''",
            "import json",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlparse, urlencode, urlunparse",
            "",
            "",
            "def check(module, name, state, service_id, integration_key, api_key, incident_key=None, http_call=fetch_url):",
            "    url = 'https://api.pagerduty.com/incidents'",
            "    headers = {",
            "        \"Content-type\": \"application/json\",",
            "        \"Authorization\": \"Token token=%s\" % api_key,",
            "        'Accept': 'application/vnd.pagerduty+json;version=2'",
            "    }",
            "",
            "    params = {",
            "        'service_ids[]': service_id,",
            "        'sort_by': 'incident_number:desc',",
            "        'time_zone': 'UTC'",
            "    }",
            "    if incident_key:",
            "        params['incident_key'] = incident_key",
            "",
            "    url_parts = list(urlparse(url))",
            "    url_parts[4] = urlencode(params, True)",
            "",
            "    url = urlunparse(url_parts)",
            "",
            "    response, info = http_call(module, url, method='get', headers=headers)",
            "",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to check current incident status.\"",
            "                             \"Reason: %s\" % info['msg'])",
            "    json_out = json.loads(response.read())[\"incidents\"][0]",
            "",
            "    if state != json_out[\"status\"]:",
            "        return json_out, True",
            "    return json_out, False",
            "",
            "",
            "def send_event(module, service_key, event_type, desc,",
            "               incident_key=None, client=None, client_url=None):",
            "    url = \"https://events.pagerduty.com/generic/2010-04-15/create_event.json\"",
            "    headers = {",
            "        \"Content-type\": \"application/json\"",
            "    }",
            "",
            "    data = {",
            "        \"service_key\": service_key,",
            "        \"event_type\": event_type,",
            "        \"incident_key\": incident_key,",
            "        \"description\": desc,",
            "        \"client\": client,",
            "        \"client_url\": client_url",
            "    }",
            "",
            "    response, info = fetch_url(module, url, method='post',",
            "                               headers=headers, data=json.dumps(data))",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to %s. Reason: %s\" %",
            "                         (event_type, info['msg']))",
            "    json_out = json.loads(response.read())",
            "    return json_out",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            name=dict(required=False),",
            "            service_id=dict(required=True),",
            "            service_key=dict(require=False),",
            "            integration_key=dict(require=False),",
            "            api_key=dict(required=True),",
            "            state=dict(required=True,",
            "                       choices=['triggered', 'acknowledged', 'resolved']),",
            "            client=dict(required=False, default=None),",
            "            client_url=dict(required=False, default=None),",
            "            desc=dict(required=False, default='Created via Ansible'),",
            "            incident_key=dict(required=False, default=None)",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    name = module.params['name']",
            "    service_id = module.params['service_id']",
            "    integration_key = module.params['integration_key']",
            "    service_key = module.params['service_key']",
            "    api_key = module.params['api_key']",
            "    state = module.params['state']",
            "    client = module.params['client']",
            "    client_url = module.params['client_url']",
            "    desc = module.params['desc']",
            "    incident_key = module.params['incident_key']",
            "",
            "    if integration_key is None:",
            "        if service_key is not None:",
            "            integration_key = service_key",
            "            module.warn('\"service_key\" is obsolete parameter and will be removed.'",
            "                        ' Please, use \"integration_key\" instead')",
            "        else:",
            "            module.fail_json(msg=\"'integration_key' is required parameter\")",
            "",
            "    state_event_dict = {",
            "        'triggered': 'trigger',",
            "        'acknowledged': 'acknowledge',",
            "        'resolved': 'resolve'",
            "    }",
            "",
            "    event_type = state_event_dict[state]",
            "",
            "    if event_type != 'trigger' and incident_key is None:",
            "        module.fail_json(msg=\"incident_key is required for \"",
            "                             \"acknowledge or resolve events\")",
            "",
            "    out, changed = check(module, name, state, service_id,",
            "                         integration_key, api_key, incident_key)",
            "",
            "    if not module.check_mode and changed is True:",
            "        out = send_event(module, integration_key, event_type, desc,",
            "                         incident_key, client, client_url)",
            "",
            "    module.exit_json(result=out, changed=changed)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "# Copyright: Ansible Project",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "",
            "module: pagerduty_alert",
            "short_description: Trigger, acknowledge or resolve PagerDuty incidents",
            "description:",
            "    - This module will let you trigger, acknowledge or resolve a PagerDuty incident by sending events",
            "version_added: \"1.9\"",
            "author:",
            "    - \"Amanpreet Singh (@ApsOps)\"",
            "requirements:",
            "    - PagerDuty API access",
            "options:",
            "    name:",
            "        description:",
            "            - PagerDuty unique subdomain. Obsolete. It is not used with PagerDuty REST v2 API.",
            "    service_id:",
            "        description:",
            "            - ID of PagerDuty service when incidents will be triggered, acknowledged or resolved.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    service_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services. Obsolete. Please use I(integration_key).",
            "    integration_key:",
            "        description:",
            "            - The GUID of one of your \"Generic API\" services.",
            "            - This is the \"integration key\" listed on a \"Integrations\" tab of PagerDuty service.",
            "        required: true",
            "        version_added: \"2.7\"",
            "    state:",
            "        description:",
            "            - Type of event to be sent.",
            "        required: true",
            "        choices:",
            "            - 'triggered'",
            "            - 'acknowledged'",
            "            - 'resolved'",
            "    api_key:",
            "        description:",
            "            - The pagerduty API key (readonly access), generated on the pagerduty site.",
            "        required: true",
            "    desc:",
            "        description:",
            "            - For C(triggered) I(state) - Required. Short description of the problem that led to this trigger. This field (or a truncated version)",
            "              will be used when generating phone calls, SMS messages and alert emails. It will also appear on the incidents tables in the PagerDuty UI.",
            "              The maximum length is 1024 characters.",
            "            - For C(acknowledged) or C(resolved) I(state) - Text that will appear in the incident's log associated with this event.",
            "        required: false",
            "        default: Created via Ansible",
            "    incident_key:",
            "        description:",
            "            - Identifies the incident to which this I(state) should be applied.",
            "            - For C(triggered) I(state) - If there's no open (i.e. unresolved) incident with this key, a new one will be created. If there's already an",
            "              open incident with a matching key, this event will be appended to that incident's log. The event key provides an easy way to \"de-dup\"",
            "              problem reports.",
            "            - For C(acknowledged) or C(resolved) I(state) - This should be the incident_key you received back when the incident was first opened by a",
            "              trigger event. Acknowledge events referencing resolved or nonexistent incidents will be discarded.",
            "        required: false",
            "        version_added: \"2.7\"",
            "    client:",
            "        description:",
            "        - The name of the monitoring client that is triggering this event.",
            "        required: false",
            "    client_url:",
            "        description:",
            "        -  The URL of the monitoring client that is triggering this event.",
            "        required: false",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Trigger an incident with just the basic options",
            "- pagerduty_alert:",
            "    name: companyabc",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "",
            "# Trigger an incident with more options",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: triggered",
            "    desc: problem that led to this trigger",
            "    incident_key: somekey",
            "    client: Sample Monitoring Service",
            "    client_url: http://service.example.com",
            "",
            "# Acknowledge an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: acknowledged",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "",
            "# Resolve an incident based on incident_key",
            "- pagerduty_alert:",
            "    integration_key: xxx",
            "    api_key: yourapikey",
            "    service_id: PDservice",
            "    state: resolved",
            "    incident_key: somekey",
            "    desc: \"some text for incident's log\"",
            "'''",
            "import json",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "from ansible.module_utils.six.moves.urllib.parse import urlparse, urlencode, urlunparse",
            "",
            "",
            "def check(module, name, state, service_id, integration_key, api_key, incident_key=None, http_call=fetch_url):",
            "    url = 'https://api.pagerduty.com/incidents'",
            "    headers = {",
            "        \"Content-type\": \"application/json\",",
            "        \"Authorization\": \"Token token=%s\" % api_key,",
            "        'Accept': 'application/vnd.pagerduty+json;version=2'",
            "    }",
            "",
            "    params = {",
            "        'service_ids[]': service_id,",
            "        'sort_by': 'incident_number:desc',",
            "        'time_zone': 'UTC'",
            "    }",
            "    if incident_key:",
            "        params['incident_key'] = incident_key",
            "",
            "    url_parts = list(urlparse(url))",
            "    url_parts[4] = urlencode(params, True)",
            "",
            "    url = urlunparse(url_parts)",
            "",
            "    response, info = http_call(module, url, method='get', headers=headers)",
            "",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to check current incident status.\"",
            "                             \"Reason: %s\" % info['msg'])",
            "    json_out = json.loads(response.read())[\"incidents\"][0]",
            "",
            "    if state != json_out[\"status\"]:",
            "        return json_out, True",
            "    return json_out, False",
            "",
            "",
            "def send_event(module, service_key, event_type, desc,",
            "               incident_key=None, client=None, client_url=None):",
            "    url = \"https://events.pagerduty.com/generic/2010-04-15/create_event.json\"",
            "    headers = {",
            "        \"Content-type\": \"application/json\"",
            "    }",
            "",
            "    data = {",
            "        \"service_key\": service_key,",
            "        \"event_type\": event_type,",
            "        \"incident_key\": incident_key,",
            "        \"description\": desc,",
            "        \"client\": client,",
            "        \"client_url\": client_url",
            "    }",
            "",
            "    response, info = fetch_url(module, url, method='post',",
            "                               headers=headers, data=json.dumps(data))",
            "    if info['status'] != 200:",
            "        module.fail_json(msg=\"failed to %s. Reason: %s\" %",
            "                         (event_type, info['msg']))",
            "    json_out = json.loads(response.read())",
            "    return json_out",
            "",
            "",
            "def main():",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            name=dict(required=False),",
            "            service_id=dict(required=True),",
            "            service_key=dict(required=False, no_log=True),",
            "            integration_key=dict(required=False, no_log=True),",
            "            api_key=dict(required=True, no_log=True),",
            "            state=dict(required=True,",
            "                       choices=['triggered', 'acknowledged', 'resolved']),",
            "            client=dict(required=False, default=None),",
            "            client_url=dict(required=False, default=None),",
            "            desc=dict(required=False, default='Created via Ansible'),",
            "            incident_key=dict(required=False, default=None)",
            "        ),",
            "        supports_check_mode=True",
            "    )",
            "",
            "    name = module.params['name']",
            "    service_id = module.params['service_id']",
            "    integration_key = module.params['integration_key']",
            "    service_key = module.params['service_key']",
            "    api_key = module.params['api_key']",
            "    state = module.params['state']",
            "    client = module.params['client']",
            "    client_url = module.params['client_url']",
            "    desc = module.params['desc']",
            "    incident_key = module.params['incident_key']",
            "",
            "    if integration_key is None:",
            "        if service_key is not None:",
            "            integration_key = service_key",
            "            module.warn('\"service_key\" is obsolete parameter and will be removed.'",
            "                        ' Please, use \"integration_key\" instead')",
            "        else:",
            "            module.fail_json(msg=\"'integration_key' is required parameter\")",
            "",
            "    state_event_dict = {",
            "        'triggered': 'trigger',",
            "        'acknowledged': 'acknowledge',",
            "        'resolved': 'resolve'",
            "    }",
            "",
            "    event_type = state_event_dict[state]",
            "",
            "    if event_type != 'trigger' and incident_key is None:",
            "        module.fail_json(msg=\"incident_key is required for \"",
            "                             \"acknowledge or resolve events\")",
            "",
            "    out, changed = check(module, name, state, service_id,",
            "                         integration_key, api_key, incident_key)",
            "",
            "    if not module.check_mode and changed is True:",
            "        out = send_event(module, integration_key, event_type, desc,",
            "                         incident_key, client, client_url)",
            "",
            "    module.exit_json(result=out, changed=changed)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "193": [
                "main"
            ],
            "194": [
                "main"
            ],
            "195": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/net_tools/nios/nios_nsgroup.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 305,
                "afterPatchRowNumber": 305,
                "PatchRowcode": "         address=dict(required=True, ib_req=True),"
            },
            "1": {
                "beforePatchRowNumber": 306,
                "afterPatchRowNumber": 306,
                "PatchRowcode": "         name=dict(required=True, ib_req=True),"
            },
            "2": {
                "beforePatchRowNumber": 307,
                "afterPatchRowNumber": 307,
                "PatchRowcode": "         stealth=dict(type='bool', default=False),"
            },
            "3": {
                "beforePatchRowNumber": 308,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        tsig_key=dict(),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 308,
                "PatchRowcode": "+        tsig_key=dict(no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 309,
                "afterPatchRowNumber": 309,
                "PatchRowcode": "         tsig_key_alg=dict(choices=['HMAC-MD5', 'HMAC-SHA256'], default='HMAC-MD5'),"
            },
            "6": {
                "beforePatchRowNumber": 310,
                "afterPatchRowNumber": 310,
                "PatchRowcode": "         tsig_key_name=dict(required=True)"
            },
            "7": {
                "beforePatchRowNumber": 311,
                "afterPatchRowNumber": 311,
                "PatchRowcode": "     )"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'certified'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: nios_nsgroup",
            "short_description: Configure InfoBlox DNS Nameserver Groups",
            "extends_documentation_fragment: nios",
            "author:",
            "  - Erich Birngruber (@ebirn)",
            "  - Sumit Jaiswal (@sjaiswal)",
            "version_added: \"2.8\"",
            "description:",
            "  - Adds and/or removes nameserver groups form Infoblox NIOS servers.",
            "    This module manages NIOS C(nsgroup) objects using the Infoblox. WAPI interface over REST.",
            "requirements:",
            "  - infoblox_client",
            "options:",
            "  name:",
            "    description:",
            "      - Specifies the name of the NIOS nameserver group to be managed.",
            "    required: true",
            "  grid_primary:",
            "    description:",
            "      - This host is to be used as primary server in this nameserver group. It must be a grid member.",
            "        This option is required when setting I(use_external_primaries) to C(false).",
            "    suboptions:",
            "      name:",
            "        description:",
            "          - Provide the name of the grid member to identify the host.",
            "        required: true",
            "      enable_preferred_primaries:",
            "        description:",
            "          - This flag represents whether the preferred_primaries field values of this member are used (see Infoblox WAPI docs).",
            "        default: false",
            "        type: bool",
            "      grid_replicate:",
            "        description:",
            "          - Use DNS zone transfers if set to C(True) or ID Grid Replication if set to C(False).",
            "        type: bool",
            "        default: false",
            "      lead:",
            "        description:",
            "          - This flag controls if the grid lead secondary nameserver performs zone transfers to non lead secondaries.",
            "        type: bool",
            "        default: false",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "  grid_secondaries:",
            "    description:",
            "     - Configures the list of grid member hosts that act as secondary nameservers.",
            "       This option is required when setting I(use_external_primaries) to C(true).",
            "    suboptions:",
            "      name:",
            "        description:",
            "          - Provide the name of the grid member to identify the host.",
            "        required: true",
            "      enable_preferred_primaries:",
            "        description:",
            "          - This flag represents whether the preferred_primaries field values of this member are used (see Infoblox WAPI docs).",
            "        default: false",
            "        type: bool",
            "      grid_replicate:",
            "        description:",
            "          - Use DNS zone transfers if set to C(True) or ID Grid Replication if set to C(False)",
            "        type: bool",
            "        default: false",
            "      lead:",
            "        description:",
            "          - This flag controls if the grid lead secondary nameserver performs zone transfers to non lead secondaries.",
            "        type: bool",
            "        default: false",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "      preferred_primaries:",
            "        description:",
            "          - Provide a list of elements like in I(external_primaries) to set the precedence of preferred primary nameservers.",
            "  is_grid_default:",
            "    description:",
            "      - If set to C(True) this nsgroup will become the default nameserver group for new zones.",
            "    type: bool",
            "    required: false",
            "    default: false",
            "  use_external_primary:",
            "    description:",
            "      - This flag controls whether the group is using an external primary nameserver.",
            "        Note that modification of this field requires passing values for I(grid_secondaries) and I(external_primaries).",
            "    type: bool",
            "    required: false",
            "    default: false",
            "  external_primaries:",
            "    description:",
            "      - Configures a list of external nameservers (non-members of the grid).",
            "        This option is required when setting I(use_external_primaries) to C(true).",
            "    suboptions:",
            "      address:",
            "        description:",
            "          - Configures the IP address of the external nameserver",
            "        required: true",
            "      name:",
            "        description:",
            "          - Set a label for the external nameserver",
            "        required: true",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "      tsig_key_name:",
            "        description:",
            "          - Sets a label for the I(tsig_key) value",
            "      tsig_key_alg:",
            "        description:",
            "          - Provides the algorithm used for the I(tsig_key) in use.",
            "        choices: ['HMAC-MD5', 'HMAC-SHA256']",
            "        default: 'HMAC-MD5'",
            "      tsig_key:",
            "        description:",
            "          - Set a DNS TSIG key for the nameserver to secure zone transfers (AFXRs).",
            "    required: false",
            "  external_secondaries:",
            "    description:",
            "      - Allows to provide a list of external secondary nameservers, that are not members of the grid.",
            "    suboptions:",
            "      address:",
            "        description:",
            "          - Configures the IP address of the external nameserver",
            "        required: true",
            "      name:",
            "        description:",
            "          - Set a label for the external nameserver",
            "        required: true",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "      tsig_key_name:",
            "        description:",
            "          - Sets a label for the I(tsig_key) value",
            "      tsig_key_alg:",
            "        description:",
            "          - Provides the algorithm used for the I(tsig_key) in use.",
            "        choices: ['HMAC-MD5', 'HMAC-SHA256']",
            "        default: 'HMAC-MD5'",
            "      tsig_key:",
            "        description:",
            "          - Set a DNS TSIG key for the nameserver to secure zone transfers (AFXRs).",
            "  extattrs:",
            "    description:",
            "      - Allows for the configuration of Extensible Attributes on the",
            "        instance of the object.  This argument accepts a set of key / value",
            "        pairs for configuration.",
            "    required: false",
            "  comment:",
            "    description:",
            "      - Configures a text string comment to be associated with the instance",
            "        of this object.  The provided text string will be configured on the",
            "        object instance.",
            "    required: false",
            "  state:",
            "    description:",
            "      - Configures the intended state of the instance of the object on",
            "        the NIOS server.  When this value is set to C(present), the object",
            "        is configured on the device and when this value is set to C(absent)",
            "        the value is removed (if necessary) from the device.",
            "    choices: [present, absent]",
            "    default: present",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create simple infoblox nameserver group",
            "  nios_nsgroup:",
            "    name: my-simple-group",
            "    comment: \"this is a simple nameserver group\"",
            "    grid_primary:",
            "      - name: infoblox-test.example.com",
            "    state: present",
            "    provider:",
            "      host: \"{{ inventory_hostname_short }}\"",
            "      username: admin",
            "      password: admin",
            "  connection: local",
            "",
            "- name: create infoblox nameserver group with external primaries",
            "  nios_nsgroup:",
            "    name: my-example-group",
            "    use_external_primary: true",
            "    comment: \"this is my example nameserver group\"",
            "    external_primaries: \"{{ ext_nameservers }}\"",
            "    grid_secondaries:",
            "      - name: infoblox-test.example.com",
            "        lead: True",
            "        preferred_primaries: \"{{ ext_nameservers }}\"",
            "    state: present",
            "    provider:",
            "      host: \"{{ inventory_hostname_short }}\"",
            "      username: admin",
            "      password: admin",
            "  connection: local",
            "",
            "- name: delete infoblox nameserver group",
            "  nios_nsgroup:",
            "    name: my-simple-group",
            "    comment: \"this is a simple nameserver group\"",
            "    grid_primary:",
            "      - name: infoblox-test.example.com",
            "    state: absent",
            "    provider:",
            "      host: \"{{ inventory_hostname_short }}\"",
            "      username: admin",
            "      password: admin",
            "  connection: local",
            "'''",
            "",
            "RETURN = ''' # '''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.net_tools.nios.api import WapiModule",
            "from ansible.module_utils.net_tools.nios.api import NIOS_NSGROUP",
            "",
            "",
            "# from infoblox documentation",
            "# Fields List",
            "# Field         Type            Req     R/O     Base    Search",
            "# comment               String          N       N       Y       : = ~",
            "# extattrs              Extattr         N       N       N       ext",
            "# external_primaries    [struct]        N       N       N       N/A",
            "# external_secondaries  [struct]        N       N       N       N/A",
            "# grid_primary          [struct]        N       N       N       N/A",
            "# grid_secondaries      [struct]        N       N       N       N/A",
            "# is_grid_default       Bool            N       N       N       N/A",
            "# is_multimaster        Bool            N       Y       N       N/A",
            "# name                  String          Y               N       Y       : = ~",
            "# use_external_primary  Bool            N       N       N       N/A",
            "",
            "",
            "def main():",
            "    '''entrypoint for module execution.'''",
            "    argument_spec = dict(",
            "        provider=dict(required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "    )",
            "",
            "    # cleanup tsig fields",
            "    def clean_tsig(ext):",
            "        if 'tsig_key' in ext and not ext['tsig_key']:",
            "            del ext['tsig_key']",
            "        if 'tsig_key' not in ext and 'tsig_key_name' in ext and not ext['tsig_key_name']:",
            "            del ext['tsig_key_name']",
            "        if 'tsig_key' not in ext and 'tsig_key_alg' in ext:",
            "            del ext['tsig_key_alg']",
            "",
            "    def clean_grid_member(member):",
            "        if member['preferred_primaries']:",
            "            for ext in member['preferred_primaries']:",
            "                clean_tsig(ext)",
            "        if member['enable_preferred_primaries'] is False:",
            "            del member['enable_preferred_primaries']",
            "            del member['preferred_primaries']",
            "        if member['lead'] is False:",
            "            del member['lead']",
            "        if member['grid_replicate'] is False:",
            "            del member['grid_replicate']",
            "",
            "    def ext_primaries_transform(module):",
            "        if module.params['external_primaries']:",
            "            for ext in module.params['external_primaries']:",
            "                clean_tsig(ext)",
            "        return module.params['external_primaries']",
            "",
            "    def ext_secondaries_transform(module):",
            "        if module.params['external_secondaries']:",
            "            for ext in module.params['external_secondaries']:",
            "                clean_tsig(ext)",
            "        return module.params['external_secondaries']",
            "",
            "    def grid_primary_preferred_transform(module):",
            "        for member in module.params['grid_primary']:",
            "            clean_grid_member(member)",
            "        return module.params['grid_primary']",
            "",
            "    def grid_secondaries_preferred_primaries_transform(module):",
            "        for member in module.params['grid_secondaries']:",
            "            clean_grid_member(member)",
            "        return module.params['grid_secondaries']",
            "",
            "    extserver_spec = dict(",
            "        address=dict(required=True, ib_req=True),",
            "        name=dict(required=True, ib_req=True),",
            "        stealth=dict(type='bool', default=False),",
            "        tsig_key=dict(),",
            "        tsig_key_alg=dict(choices=['HMAC-MD5', 'HMAC-SHA256'], default='HMAC-MD5'),",
            "        tsig_key_name=dict(required=True)",
            "    )",
            "",
            "    memberserver_spec = dict(",
            "        name=dict(required=True, ib_req=True),",
            "        enable_preferred_primaries=dict(type='bool', default=False),",
            "        grid_replicate=dict(type='bool', default=False),",
            "        lead=dict(type='bool', default=False),",
            "        preferred_primaries=dict(type='list', elements='dict', options=extserver_spec, default=[]),",
            "        stealth=dict(type='bool', default=False),",
            "    )",
            "",
            "    ib_spec = dict(",
            "        name=dict(required=True, ib_req=True),",
            "        grid_primary=dict(type='list', elements='dict', options=memberserver_spec,",
            "                          transform=grid_primary_preferred_transform),",
            "        grid_secondaries=dict(type='list', elements='dict', options=memberserver_spec,",
            "                              transform=grid_secondaries_preferred_primaries_transform),",
            "        external_primaries=dict(type='list', elements='dict', options=extserver_spec, transform=ext_primaries_transform),",
            "        external_secondaries=dict(type='list', elements='dict', options=extserver_spec,",
            "                                  transform=ext_secondaries_transform),",
            "        is_grid_default=dict(type='bool', default=False),",
            "        use_external_primary=dict(type='bool', default=False),",
            "        extattrs=dict(),",
            "        comment=dict(),",
            "    )",
            "",
            "    argument_spec.update(ib_spec)",
            "    argument_spec.update(WapiModule.provider_spec)",
            "",
            "    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)",
            "",
            "    wapi = WapiModule(module)",
            "    result = wapi.run(NIOS_NSGROUP, ib_spec)",
            "",
            "    module.exit_json(**result)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'certified'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: nios_nsgroup",
            "short_description: Configure InfoBlox DNS Nameserver Groups",
            "extends_documentation_fragment: nios",
            "author:",
            "  - Erich Birngruber (@ebirn)",
            "  - Sumit Jaiswal (@sjaiswal)",
            "version_added: \"2.8\"",
            "description:",
            "  - Adds and/or removes nameserver groups form Infoblox NIOS servers.",
            "    This module manages NIOS C(nsgroup) objects using the Infoblox. WAPI interface over REST.",
            "requirements:",
            "  - infoblox_client",
            "options:",
            "  name:",
            "    description:",
            "      - Specifies the name of the NIOS nameserver group to be managed.",
            "    required: true",
            "  grid_primary:",
            "    description:",
            "      - This host is to be used as primary server in this nameserver group. It must be a grid member.",
            "        This option is required when setting I(use_external_primaries) to C(false).",
            "    suboptions:",
            "      name:",
            "        description:",
            "          - Provide the name of the grid member to identify the host.",
            "        required: true",
            "      enable_preferred_primaries:",
            "        description:",
            "          - This flag represents whether the preferred_primaries field values of this member are used (see Infoblox WAPI docs).",
            "        default: false",
            "        type: bool",
            "      grid_replicate:",
            "        description:",
            "          - Use DNS zone transfers if set to C(True) or ID Grid Replication if set to C(False).",
            "        type: bool",
            "        default: false",
            "      lead:",
            "        description:",
            "          - This flag controls if the grid lead secondary nameserver performs zone transfers to non lead secondaries.",
            "        type: bool",
            "        default: false",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "  grid_secondaries:",
            "    description:",
            "     - Configures the list of grid member hosts that act as secondary nameservers.",
            "       This option is required when setting I(use_external_primaries) to C(true).",
            "    suboptions:",
            "      name:",
            "        description:",
            "          - Provide the name of the grid member to identify the host.",
            "        required: true",
            "      enable_preferred_primaries:",
            "        description:",
            "          - This flag represents whether the preferred_primaries field values of this member are used (see Infoblox WAPI docs).",
            "        default: false",
            "        type: bool",
            "      grid_replicate:",
            "        description:",
            "          - Use DNS zone transfers if set to C(True) or ID Grid Replication if set to C(False)",
            "        type: bool",
            "        default: false",
            "      lead:",
            "        description:",
            "          - This flag controls if the grid lead secondary nameserver performs zone transfers to non lead secondaries.",
            "        type: bool",
            "        default: false",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "      preferred_primaries:",
            "        description:",
            "          - Provide a list of elements like in I(external_primaries) to set the precedence of preferred primary nameservers.",
            "  is_grid_default:",
            "    description:",
            "      - If set to C(True) this nsgroup will become the default nameserver group for new zones.",
            "    type: bool",
            "    required: false",
            "    default: false",
            "  use_external_primary:",
            "    description:",
            "      - This flag controls whether the group is using an external primary nameserver.",
            "        Note that modification of this field requires passing values for I(grid_secondaries) and I(external_primaries).",
            "    type: bool",
            "    required: false",
            "    default: false",
            "  external_primaries:",
            "    description:",
            "      - Configures a list of external nameservers (non-members of the grid).",
            "        This option is required when setting I(use_external_primaries) to C(true).",
            "    suboptions:",
            "      address:",
            "        description:",
            "          - Configures the IP address of the external nameserver",
            "        required: true",
            "      name:",
            "        description:",
            "          - Set a label for the external nameserver",
            "        required: true",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "      tsig_key_name:",
            "        description:",
            "          - Sets a label for the I(tsig_key) value",
            "      tsig_key_alg:",
            "        description:",
            "          - Provides the algorithm used for the I(tsig_key) in use.",
            "        choices: ['HMAC-MD5', 'HMAC-SHA256']",
            "        default: 'HMAC-MD5'",
            "      tsig_key:",
            "        description:",
            "          - Set a DNS TSIG key for the nameserver to secure zone transfers (AFXRs).",
            "    required: false",
            "  external_secondaries:",
            "    description:",
            "      - Allows to provide a list of external secondary nameservers, that are not members of the grid.",
            "    suboptions:",
            "      address:",
            "        description:",
            "          - Configures the IP address of the external nameserver",
            "        required: true",
            "      name:",
            "        description:",
            "          - Set a label for the external nameserver",
            "        required: true",
            "      stealth:",
            "        description:",
            "          - Configure the external nameserver as stealth server (without NS record) in the zones.",
            "        type: bool",
            "        default: false",
            "      tsig_key_name:",
            "        description:",
            "          - Sets a label for the I(tsig_key) value",
            "      tsig_key_alg:",
            "        description:",
            "          - Provides the algorithm used for the I(tsig_key) in use.",
            "        choices: ['HMAC-MD5', 'HMAC-SHA256']",
            "        default: 'HMAC-MD5'",
            "      tsig_key:",
            "        description:",
            "          - Set a DNS TSIG key for the nameserver to secure zone transfers (AFXRs).",
            "  extattrs:",
            "    description:",
            "      - Allows for the configuration of Extensible Attributes on the",
            "        instance of the object.  This argument accepts a set of key / value",
            "        pairs for configuration.",
            "    required: false",
            "  comment:",
            "    description:",
            "      - Configures a text string comment to be associated with the instance",
            "        of this object.  The provided text string will be configured on the",
            "        object instance.",
            "    required: false",
            "  state:",
            "    description:",
            "      - Configures the intended state of the instance of the object on",
            "        the NIOS server.  When this value is set to C(present), the object",
            "        is configured on the device and when this value is set to C(absent)",
            "        the value is removed (if necessary) from the device.",
            "    choices: [present, absent]",
            "    default: present",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: create simple infoblox nameserver group",
            "  nios_nsgroup:",
            "    name: my-simple-group",
            "    comment: \"this is a simple nameserver group\"",
            "    grid_primary:",
            "      - name: infoblox-test.example.com",
            "    state: present",
            "    provider:",
            "      host: \"{{ inventory_hostname_short }}\"",
            "      username: admin",
            "      password: admin",
            "  connection: local",
            "",
            "- name: create infoblox nameserver group with external primaries",
            "  nios_nsgroup:",
            "    name: my-example-group",
            "    use_external_primary: true",
            "    comment: \"this is my example nameserver group\"",
            "    external_primaries: \"{{ ext_nameservers }}\"",
            "    grid_secondaries:",
            "      - name: infoblox-test.example.com",
            "        lead: True",
            "        preferred_primaries: \"{{ ext_nameservers }}\"",
            "    state: present",
            "    provider:",
            "      host: \"{{ inventory_hostname_short }}\"",
            "      username: admin",
            "      password: admin",
            "  connection: local",
            "",
            "- name: delete infoblox nameserver group",
            "  nios_nsgroup:",
            "    name: my-simple-group",
            "    comment: \"this is a simple nameserver group\"",
            "    grid_primary:",
            "      - name: infoblox-test.example.com",
            "    state: absent",
            "    provider:",
            "      host: \"{{ inventory_hostname_short }}\"",
            "      username: admin",
            "      password: admin",
            "  connection: local",
            "'''",
            "",
            "RETURN = ''' # '''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.net_tools.nios.api import WapiModule",
            "from ansible.module_utils.net_tools.nios.api import NIOS_NSGROUP",
            "",
            "",
            "# from infoblox documentation",
            "# Fields List",
            "# Field         Type            Req     R/O     Base    Search",
            "# comment               String          N       N       Y       : = ~",
            "# extattrs              Extattr         N       N       N       ext",
            "# external_primaries    [struct]        N       N       N       N/A",
            "# external_secondaries  [struct]        N       N       N       N/A",
            "# grid_primary          [struct]        N       N       N       N/A",
            "# grid_secondaries      [struct]        N       N       N       N/A",
            "# is_grid_default       Bool            N       N       N       N/A",
            "# is_multimaster        Bool            N       Y       N       N/A",
            "# name                  String          Y               N       Y       : = ~",
            "# use_external_primary  Bool            N       N       N       N/A",
            "",
            "",
            "def main():",
            "    '''entrypoint for module execution.'''",
            "    argument_spec = dict(",
            "        provider=dict(required=True),",
            "        state=dict(default='present', choices=['present', 'absent']),",
            "    )",
            "",
            "    # cleanup tsig fields",
            "    def clean_tsig(ext):",
            "        if 'tsig_key' in ext and not ext['tsig_key']:",
            "            del ext['tsig_key']",
            "        if 'tsig_key' not in ext and 'tsig_key_name' in ext and not ext['tsig_key_name']:",
            "            del ext['tsig_key_name']",
            "        if 'tsig_key' not in ext and 'tsig_key_alg' in ext:",
            "            del ext['tsig_key_alg']",
            "",
            "    def clean_grid_member(member):",
            "        if member['preferred_primaries']:",
            "            for ext in member['preferred_primaries']:",
            "                clean_tsig(ext)",
            "        if member['enable_preferred_primaries'] is False:",
            "            del member['enable_preferred_primaries']",
            "            del member['preferred_primaries']",
            "        if member['lead'] is False:",
            "            del member['lead']",
            "        if member['grid_replicate'] is False:",
            "            del member['grid_replicate']",
            "",
            "    def ext_primaries_transform(module):",
            "        if module.params['external_primaries']:",
            "            for ext in module.params['external_primaries']:",
            "                clean_tsig(ext)",
            "        return module.params['external_primaries']",
            "",
            "    def ext_secondaries_transform(module):",
            "        if module.params['external_secondaries']:",
            "            for ext in module.params['external_secondaries']:",
            "                clean_tsig(ext)",
            "        return module.params['external_secondaries']",
            "",
            "    def grid_primary_preferred_transform(module):",
            "        for member in module.params['grid_primary']:",
            "            clean_grid_member(member)",
            "        return module.params['grid_primary']",
            "",
            "    def grid_secondaries_preferred_primaries_transform(module):",
            "        for member in module.params['grid_secondaries']:",
            "            clean_grid_member(member)",
            "        return module.params['grid_secondaries']",
            "",
            "    extserver_spec = dict(",
            "        address=dict(required=True, ib_req=True),",
            "        name=dict(required=True, ib_req=True),",
            "        stealth=dict(type='bool', default=False),",
            "        tsig_key=dict(no_log=True),",
            "        tsig_key_alg=dict(choices=['HMAC-MD5', 'HMAC-SHA256'], default='HMAC-MD5'),",
            "        tsig_key_name=dict(required=True)",
            "    )",
            "",
            "    memberserver_spec = dict(",
            "        name=dict(required=True, ib_req=True),",
            "        enable_preferred_primaries=dict(type='bool', default=False),",
            "        grid_replicate=dict(type='bool', default=False),",
            "        lead=dict(type='bool', default=False),",
            "        preferred_primaries=dict(type='list', elements='dict', options=extserver_spec, default=[]),",
            "        stealth=dict(type='bool', default=False),",
            "    )",
            "",
            "    ib_spec = dict(",
            "        name=dict(required=True, ib_req=True),",
            "        grid_primary=dict(type='list', elements='dict', options=memberserver_spec,",
            "                          transform=grid_primary_preferred_transform),",
            "        grid_secondaries=dict(type='list', elements='dict', options=memberserver_spec,",
            "                              transform=grid_secondaries_preferred_primaries_transform),",
            "        external_primaries=dict(type='list', elements='dict', options=extserver_spec, transform=ext_primaries_transform),",
            "        external_secondaries=dict(type='list', elements='dict', options=extserver_spec,",
            "                                  transform=ext_secondaries_transform),",
            "        is_grid_default=dict(type='bool', default=False),",
            "        use_external_primary=dict(type='bool', default=False),",
            "        extattrs=dict(),",
            "        comment=dict(),",
            "    )",
            "",
            "    argument_spec.update(ib_spec)",
            "    argument_spec.update(WapiModule.provider_spec)",
            "",
            "    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)",
            "",
            "    wapi = WapiModule(module)",
            "    result = wapi.run(NIOS_NSGROUP, ib_spec)",
            "",
            "    module.exit_json(**result)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "308": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/network/cloudengine/ce_vrrp.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 1316,
                "afterPatchRowNumber": 1316,
                "PatchRowcode": "         holding_multiplier=dict(type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 1317,
                "afterPatchRowNumber": 1317,
                "PatchRowcode": "         auth_mode=dict(type='str', choices=['simple', 'md5', 'none']),"
            },
            "2": {
                "beforePatchRowNumber": 1318,
                "afterPatchRowNumber": 1318,
                "PatchRowcode": "         is_plain=dict(type='bool', default=False),"
            },
            "3": {
                "beforePatchRowNumber": 1319,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        auth_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 1319,
                "PatchRowcode": "+        auth_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 1320,
                "afterPatchRowNumber": 1320,
                "PatchRowcode": "         fast_resume=dict(type='str', choices=['enable', 'disable']),"
            },
            "6": {
                "beforePatchRowNumber": 1321,
                "afterPatchRowNumber": 1321,
                "PatchRowcode": "         state=dict(type='str', default='present',"
            },
            "7": {
                "beforePatchRowNumber": 1322,
                "afterPatchRowNumber": 1322,
                "PatchRowcode": "                    choices=['present', 'absent'])"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "#",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: ce_vrrp",
            "version_added: \"2.4\"",
            "short_description: Manages VRRP interfaces on HUAWEI CloudEngine devices.",
            "description:",
            "    - Manages VRRP interface attributes on HUAWEI CloudEngine devices.",
            "author:",
            "    - Li Yanfeng (@numone213)",
            "notes:",
            "    - This module requires the netconf system service be enabled on the remote device being managed.",
            "    - Recommended connection is C(netconf).",
            "    - This module also works with C(local) connections for legacy playbooks.",
            "options:",
            "    interface:",
            "        description:",
            "            - Name of an interface. The value is a string of 1 to 63 characters.",
            "    vrid:",
            "        description:",
            "            - VRRP backup group ID.",
            "              The value is an integer ranging from 1 to 255.",
            "        default: present",
            "    virtual_ip :",
            "        description:",
            "            - Virtual IP address. The value is a string of 0 to 255 characters.",
            "    vrrp_type:",
            "        description:",
            "            - Type of a VRRP backup group.",
            "        choices: ['normal', 'member', 'admin']",
            "    admin_ignore_if_down:",
            "        description:",
            "            - mVRRP ignores an interface Down event.",
            "        type: bool",
            "        default: 'false'",
            "    admin_vrid:",
            "        description:",
            "            - Tracked mVRRP ID. The value is an integer ranging from 1 to 255.",
            "    admin_interface:",
            "        description:",
            "            - Tracked mVRRP interface name. The value is a string of 1 to 63 characters.",
            "    admin_flowdown:",
            "        description:",
            "            - Disable the flowdown function for service VRRP.",
            "        type: bool",
            "        default: 'false'",
            "    priority:",
            "        description:",
            "            - Configured VRRP priority.",
            "              The value ranges from 1 to 254. The default value is 100. A larger value indicates a higher priority.",
            "    version:",
            "        description:",
            "            - VRRP version. The default version is v2.",
            "        choices: ['v2','v3']",
            "    advertise_interval:",
            "        description:",
            "            - Configured interval between sending advertisements, in milliseconds.",
            "              Only the master router sends VRRP advertisements. The default value is 1000 milliseconds.",
            "    preempt_timer_delay:",
            "        description:",
            "            - Preemption delay.",
            "              The value is an integer ranging from 0 to 3600. The default value is 0.",
            "    gratuitous_arp_interval:",
            "        description:",
            "            - Interval at which gratuitous ARP packets are sent, in seconds.",
            "              The value ranges from 30 to 1200.The default value is 300.",
            "    recover_delay:",
            "        description:",
            "            - Delay in recovering after an interface goes Up.",
            "              The delay is used for interface flapping suppression.",
            "              The value is an integer ranging from 0 to 3600.",
            "              The default value is 0 seconds.",
            "    holding_multiplier:",
            "        description:",
            "            - The configured holdMultiplier.The value is an integer ranging from 3 to 10. The default value is 3.",
            "    auth_mode:",
            "        description:",
            "            - Authentication type used for VRRP packet exchanges between virtual routers.",
            "              The values are noAuthentication, simpleTextPassword, md5Authentication.",
            "              The default value is noAuthentication.",
            "        choices: ['simple','md5','none']",
            "    is_plain:",
            "        description:",
            "            - Select the display mode of an authentication key.",
            "              By default, an authentication key is displayed in ciphertext.",
            "        type: bool",
            "        default: 'false'",
            "    auth_key:",
            "        description:",
            "            - This object is set based on the authentication type.",
            "              When noAuthentication is specified, the value is empty.",
            "              When simpleTextPassword or md5Authentication is specified, the value is a string of 1 to 8 characters",
            "              in plaintext and displayed as a blank text for security.",
            "    fast_resume:",
            "        description:",
            "            - mVRRP's fast resume mode.",
            "        choices: ['enable','disable']",
            "    state:",
            "        description:",
            "            - Specify desired state of the resource.",
            "        default: present",
            "        choices: ['present','absent']",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: vrrp module test",
            "  hosts: cloudengine",
            "  connection: local",
            "  gather_facts: no",
            "  vars:",
            "    cli:",
            "      host: \"{{ inventory_hostname }}\"",
            "      port: \"{{ ansible_ssh_port }}\"",
            "      username: \"{{ username }}\"",
            "      password: \"{{ password }}\"",
            "      transport: cli",
            "  tasks:",
            "  - name: Set vrrp version",
            "    ce_vrrp:",
            "      version: v3",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp gratuitous-arp interval",
            "    ce_vrrp:",
            "      gratuitous_arp_interval: 40",
            "      mlag_id: 4",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp recover-delay",
            "    ce_vrrp:",
            "      recover_delay: 10",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid virtual-ip",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      virtual_ip: 10.14.2.7",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid admin",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      vrrp_type: admin",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid fast_resume",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      fast_resume: enable",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid holding-multiplier",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      holding_multiplier: 4",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid preempt timer delay",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      preempt_timer_delay: 10",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid admin-vrrp",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      admin_interface: 40GE2/0/9",
            "      admin_vrid: 2",
            "      vrrp_type: member",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid authentication-mode",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      is_plain: true",
            "      auth_mode: simple",
            "      auth_key: aaa",
            "      provider: \"{{ cli }}\"",
            "'''",
            "",
            "RETURN = '''",
            "changed:",
            "    description: check to see if a change was made on the device",
            "    returned: always",
            "    type: bool",
            "    sample: true",
            "proposed:",
            "    description: k/v pairs of parameters passed into module",
            "    returned: always",
            "    type: dict",
            "    sample: {",
            "                \"auth_key\": \"aaa\",",
            "                \"auth_mode\": \"simple\",",
            "                \"interface\": \"40GE2/0/8\",",
            "                \"is_plain\": true,",
            "                \"state\": \"present\",",
            "                \"vrid\": \"1\"",
            "            }",
            "existing:",
            "    description: k/v pairs of existing aaa server",
            "    returned: always",
            "    type: dict",
            "    sample: {",
            "                \"auth_mode\": \"none\",",
            "                \"interface\": \"40GE2/0/8\",",
            "                \"is_plain\": \"false\",",
            "                \"vrid\": \"1\",",
            "                \"vrrp_type\": \"normal\"",
            "            }",
            "end_state:",
            "    description: k/v pairs of aaa params after module execution",
            "    returned: always",
            "    type: dict",
            "    sample: {",
            "                \"auth_mode\": \"simple\",",
            "                \"interface\": \"40GE2/0/8\",",
            "                \"is_plain\": \"true\",",
            "                \"vrid\": \"1\",",
            "                \"vrrp_type\": \"normal\"",
            "    }",
            "updates:",
            "    description: command sent to the device",
            "    returned: always",
            "    type: list",
            "    sample: { \"interface 40GE2/0/8\",",
            "              \"vrrp vrid 1 authentication-mode simple plain aaa\"}",
            "'''",
            "",
            "from xml.etree import ElementTree",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.network.cloudengine.ce import get_nc_config, set_nc_config, ce_argument_spec",
            "",
            "",
            "CE_NC_GET_VRRP_GROUP_INFO = \"\"\"",
            "<filter type=\"subtree\">",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <ifName>%s</ifName>",
            "        <vrrpId>%s</vrrpId>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</filter>",
            "\"\"\"",
            "",
            "CE_NC_SET_VRRP_GROUP_INFO_HEAD = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup operation=\"merge\">",
            "        <ifName>%s</ifName>",
            "        <vrrpId>%s</vrrpId>",
            "\"\"\"",
            "CE_NC_SET_VRRP_GROUP_INFO_TAIL = \"\"\"",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "CE_NC_GET_VRRP_GLOBAL_INFO = \"\"\"",
            "<filter type=\"subtree\">",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGlobalCfg>",
            "      <gratuitousArpFlag></gratuitousArpFlag>",
            "      <gratuitousArpTimeOut></gratuitousArpTimeOut>",
            "      <recoverDelay></recoverDelay>",
            "      <version></version>",
            "    </vrrpGlobalCfg>",
            "  </vrrp>",
            "</filter>",
            "\"\"\"",
            "",
            "CE_NC_SET_VRRP_GLOBAL_HEAD = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGlobalCfg operation=\"merge\">",
            "\"\"\"",
            "CE_NC_SET_VRRP_GLOBAL_TAIL = \"\"\"",
            "    </vrrpGlobalCfg>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "",
            "CE_NC_GET_VRRP_VIRTUAL_IP_INFO = \"\"\"",
            "<filter type=\"subtree\">",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <vrrpId>%s</vrrpId>",
            "        <ifName>%s</ifName>",
            "        <virtualIps>",
            "          <virtualIp>",
            "            <virtualIpAddress></virtualIpAddress>",
            "          </virtualIp>",
            "        </virtualIps>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</filter>",
            "\"\"\"",
            "CE_NC_CREATE_VRRP_VIRTUAL_IP_INFO = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <vrrpId>%s</vrrpId>",
            "        <ifName>%s</ifName>",
            "        <virtualIps>",
            "          <virtualIp operation=\"create\">",
            "            <virtualIpAddress>%s</virtualIpAddress>",
            "          </virtualIp>",
            "        </virtualIps>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "CE_NC_DELETE_VRRP_VIRTUAL_IP_INFO = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <vrrpId>%s</vrrpId>",
            "        <ifName>%s</ifName>",
            "        <virtualIps>",
            "          <virtualIp operation=\"delete\">",
            "            <virtualIpAddress>%s</virtualIpAddress>",
            "          </virtualIp>",
            "        </virtualIps>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "",
            "",
            "def is_valid_address(address):",
            "    \"\"\"check ip-address is valid\"\"\"",
            "",
            "    if address.find('.') != -1:",
            "        addr_list = address.split('.')",
            "        if len(addr_list) != 4:",
            "            return False",
            "        for each_num in addr_list:",
            "            if not each_num.isdigit():",
            "                return False",
            "            if int(each_num) > 255:",
            "                return False",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def get_interface_type(interface):",
            "    \"\"\"Gets the type of interface, such as 10GE, ETH-TRUNK, VLANIF...\"\"\"",
            "",
            "    if interface is None:",
            "        return None",
            "",
            "    iftype = None",
            "",
            "    if interface.upper().startswith('GE'):",
            "        iftype = 'ge'",
            "    elif interface.upper().startswith('10GE'):",
            "        iftype = '10ge'",
            "    elif interface.upper().startswith('25GE'):",
            "        iftype = '25ge'",
            "    elif interface.upper().startswith('40GE'):",
            "        iftype = '40ge'",
            "    elif interface.upper().startswith('100GE'):",
            "        iftype = '100ge'",
            "    elif interface.upper().startswith('ETH-TRUNK'):",
            "        iftype = 'eth-trunk'",
            "    elif interface.upper().startswith('NULL'):",
            "        iftype = 'null'",
            "    elif interface.upper().startswith('VLANIF'):",
            "        iftype = 'vlanif'",
            "    else:",
            "        return None",
            "",
            "    return iftype.lower()",
            "",
            "",
            "class Vrrp(object):",
            "    \"\"\"",
            "    Manages Manages vrrp information.",
            "    \"\"\"",
            "",
            "    def __init__(self, argument_spec):",
            "        self.spec = argument_spec",
            "        self.module = None",
            "        self.init_module()",
            "",
            "        # module input info",
            "        self.interface = self.module.params['interface']",
            "        self.vrid = self.module.params['vrid']",
            "        self.virtual_ip = self.module.params['virtual_ip']",
            "        self.vrrp_type = self.module.params['vrrp_type']",
            "        self.admin_ignore_if_down = 'false' if self.module.params['admin_ignore_if_down'] is False else 'true'",
            "        self.admin_vrid = self.module.params['admin_vrid']",
            "        self.admin_interface = self.module.params['admin_interface']",
            "        self.admin_flowdown = 'false' if self.module.params['admin_flowdown'] is False else 'true'",
            "        self.priority = self.module.params['priority']",
            "        self.version = self.module.params['version']",
            "        self.advertise_interval = self.module.params['advertise_interval']",
            "        self.preempt_timer_delay = self.module.params['preempt_timer_delay']",
            "        self.gratuitous_arp_interval = self.module.params[",
            "            'gratuitous_arp_interval']",
            "        self.recover_delay = self.module.params['recover_delay']",
            "        self.holding_multiplier = self.module.params['holding_multiplier']",
            "        self.auth_mode = self.module.params['auth_mode']",
            "        self.is_plain = 'false' if self.module.params['is_plain'] is False else 'true'",
            "        self.auth_key = self.module.params['auth_key']",
            "        self.fast_resume = self.module.params['fast_resume']",
            "        self.state = self.module.params['state']",
            "",
            "        # vrrp info",
            "        self.vrrp_global_info = None",
            "        self.virtual_ip_info = None",
            "        self.vrrp_group_info = None",
            "",
            "        # state",
            "        self.changed = False",
            "        self.updates_cmd = list()",
            "        self.results = dict()",
            "        self.existing = dict()",
            "        self.proposed = dict()",
            "        self.end_state = dict()",
            "",
            "    def init_module(self):",
            "        \"\"\" init module \"\"\"",
            "",
            "        self.module = AnsibleModule(",
            "            argument_spec=self.spec, supports_check_mode=True)",
            "",
            "    def get_virtual_ip_info(self):",
            "        \"\"\" get vrrp virtual ip info.\"\"\"",
            "        virtual_ip_info = dict()",
            "        conf_str = CE_NC_GET_VRRP_VIRTUAL_IP_INFO % (self.vrid, self.interface)",
            "        xml_str = get_nc_config(self.module, conf_str)",
            "        if \"<data/>\" in xml_str:",
            "            return virtual_ip_info",
            "        else:",
            "            xml_str = xml_str.replace('\\r', '').replace('\\n', '').\\",
            "                replace('xmlns=\"urn:ietf:params:xml:ns:netconf:base:1.0\"', \"\").\\",
            "                replace('xmlns=\"http://www.huawei.com/netconf/vrp\"', \"\")",
            "            virtual_ip_info[\"vrrpVirtualIpInfos\"] = list()",
            "            root = ElementTree.fromstring(xml_str)",
            "            vrrp_virtual_ip_infos = root.findall(",
            "                \"vrrp/vrrpGroups/vrrpGroup/virtualIps/virtualIp\")",
            "            if vrrp_virtual_ip_infos:",
            "                for vrrp_virtual_ip_info in vrrp_virtual_ip_infos:",
            "                    virtual_ip_dict = dict()",
            "                    for ele in vrrp_virtual_ip_info:",
            "                        if ele.tag in [\"virtualIpAddress\"]:",
            "                            virtual_ip_dict[ele.tag] = ele.text",
            "                    virtual_ip_info[\"vrrpVirtualIpInfos\"].append(",
            "                        virtual_ip_dict)",
            "            return virtual_ip_info",
            "",
            "    def get_vrrp_global_info(self):",
            "        \"\"\" get vrrp global info.\"\"\"",
            "",
            "        vrrp_global_info = dict()",
            "        conf_str = CE_NC_GET_VRRP_GLOBAL_INFO",
            "        xml_str = get_nc_config(self.module, conf_str)",
            "        if \"<data/>\" in xml_str:",
            "            return vrrp_global_info",
            "        else:",
            "            xml_str = xml_str.replace('\\r', '').replace('\\n', '').\\",
            "                replace('xmlns=\"urn:ietf:params:xml:ns:netconf:base:1.0\"', \"\").\\",
            "                replace('xmlns=\"http://www.huawei.com/netconf/vrp\"', \"\")",
            "",
            "            root = ElementTree.fromstring(xml_str)",
            "            global_info = root.findall(",
            "                \"vrrp/vrrpGlobalCfg\")",
            "",
            "            if global_info:",
            "                for tmp in global_info:",
            "                    for site in tmp:",
            "                        if site.tag in [\"gratuitousArpTimeOut\", \"gratuitousArpFlag\", \"recoverDelay\", \"version\"]:",
            "                            vrrp_global_info[site.tag] = site.text",
            "            return vrrp_global_info",
            "",
            "    def get_vrrp_group_info(self):",
            "        \"\"\" get vrrp group info.\"\"\"",
            "",
            "        vrrp_group_info = dict()",
            "        conf_str = CE_NC_GET_VRRP_GROUP_INFO % (self.interface, self.vrid)",
            "        xml_str = get_nc_config(self.module, conf_str)",
            "        if \"<data/>\" in xml_str:",
            "            return vrrp_group_info",
            "        else:",
            "            xml_str = xml_str.replace('\\r', '').replace('\\n', '').\\",
            "                replace('xmlns=\"urn:ietf:params:xml:ns:netconf:base:1.0\"', \"\").\\",
            "                replace('xmlns=\"http://www.huawei.com/netconf/vrp\"', \"\")",
            "",
            "            root = ElementTree.fromstring(xml_str)",
            "            global_info = root.findall(",
            "                \"vrrp/vrrpGroups/vrrpGroup\")",
            "",
            "            if global_info:",
            "                for tmp in global_info:",
            "                    for site in tmp:",
            "                        if site.tag in [\"ifName\", \"vrrpId\", \"priority\", \"advertiseInterval\", \"preemptMode\", \"delayTime\",",
            "                                        \"authenticationMode\", \"authenticationKey\", \"vrrpType\", \"adminVrrpId\",",
            "                                        \"adminIfName\", \"adminIgnoreIfDown\", \"isPlain\", \"unflowdown\", \"fastResume\",",
            "                                        \"holdMultiplier\"]:",
            "                            vrrp_group_info[site.tag] = site.text",
            "            return vrrp_group_info",
            "",
            "    def check_params(self):",
            "        \"\"\"Check all input params\"\"\"",
            "",
            "        # interface check",
            "        if self.interface:",
            "            intf_type = get_interface_type(self.interface)",
            "            if not intf_type:",
            "                self.module.fail_json(",
            "                    msg='Error: Interface name of %s '",
            "                        'is error.' % self.interface)",
            "",
            "        # vrid check",
            "        if self.vrid:",
            "            if not self.vrid.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of vrid is an integer.')",
            "            if int(self.vrid) < 1 or int(self.vrid) > 255:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of vrid ranges from 1 to 255.')",
            "",
            "        # virtual_ip check",
            "        if self.virtual_ip:",
            "            if not is_valid_address(self.virtual_ip):",
            "                self.module.fail_json(",
            "                    msg='Error: The %s is not a valid ip address.' % self.virtual_ip)",
            "",
            "        # admin_vrid check",
            "        if self.admin_vrid:",
            "            if not self.admin_vrid.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of admin_vrid is an integer.')",
            "            if int(self.admin_vrid) < 1 or int(self.admin_vrid) > 255:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of admin_vrid ranges from 1 to 255.')",
            "",
            "        # admin_interface check",
            "        if self.admin_interface:",
            "            intf_type = get_interface_type(self.admin_interface)",
            "            if not intf_type:",
            "                self.module.fail_json(",
            "                    msg='Error: Admin interface name of %s '",
            "                        'is error.' % self.admin_interface)",
            "",
            "        # priority check",
            "        if self.priority:",
            "            if not self.priority.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of priority is an integer.')",
            "            if int(self.priority) < 1 or int(self.priority) > 254:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of priority ranges from 1 to 254. The default value is 100.')",
            "",
            "        # advertise_interval check",
            "        if self.advertise_interval:",
            "            if not self.advertise_interval.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of advertise_interval is an integer.')",
            "            if int(self.advertise_interval) < 1000 or int(self.advertise_interval) > 255000:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of advertise_interval ranges from 1000 to 255000 milliseconds. The default value is 1000 milliseconds.')",
            "            if int(self.advertise_interval) % 1000 != 0:",
            "                self.module.fail_json(",
            "                    msg='Error: The advertisement interval value of VRRP must be a multiple of 1000 milliseconds.')",
            "        # preempt_timer_delay check",
            "        if self.preempt_timer_delay:",
            "            if not self.preempt_timer_delay.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of preempt_timer_delay is an integer.')",
            "            if int(self.preempt_timer_delay) < 1 or int(self.preempt_timer_delay) > 3600:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of preempt_timer_delay ranges from 1 to 3600. The default value is 0.')",
            "",
            "        # holding_multiplier check",
            "        if self.holding_multiplier:",
            "            if not self.holding_multiplier.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of holding_multiplier is an integer.')",
            "            if int(self.holding_multiplier) < 3 or int(self.holding_multiplier) > 10:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of holding_multiplier ranges from 3 to 10. The default value is 3.')",
            "",
            "        # auth_key check",
            "        if self.auth_key:",
            "            if len(self.auth_key) > 16 \\",
            "                    or len(self.auth_key.replace(' ', '')) < 1:",
            "                self.module.fail_json(",
            "                    msg='Error: The length of auth_key is not in the range from 1 to 16.')",
            "",
            "    def is_virtual_ip_change(self):",
            "        \"\"\"whether virtual ip change\"\"\"",
            "",
            "        if not self.virtual_ip_info:",
            "            return True",
            "",
            "        for info in self.virtual_ip_info[\"vrrpVirtualIpInfos\"]:",
            "            if info[\"virtualIpAddress\"] == self.virtual_ip:",
            "                return False",
            "        return True",
            "",
            "    def is_virtual_ip_exist(self):",
            "        \"\"\"whether virtual ip info exist\"\"\"",
            "",
            "        if not self.virtual_ip_info:",
            "            return False",
            "",
            "        for info in self.virtual_ip_info[\"vrrpVirtualIpInfos\"]:",
            "            if info[\"virtualIpAddress\"] == self.virtual_ip:",
            "                return True",
            "        return False",
            "",
            "    def is_vrrp_global_info_change(self):",
            "        \"\"\"whether vrrp global attribute info change\"\"\"",
            "",
            "        if not self.vrrp_global_info:",
            "            return True",
            "",
            "        if self.gratuitous_arp_interval:",
            "            if self.vrrp_global_info[\"gratuitousArpFlag\"] == \"false\":",
            "                self.module.fail_json(msg=\"Error: gratuitousArpFlag is false.\")",
            "            if self.vrrp_global_info[\"gratuitousArpTimeOut\"] != self.gratuitous_arp_interval:",
            "                return True",
            "        if self.recover_delay:",
            "            if self.vrrp_global_info[\"recoverDelay\"] != self.recover_delay:",
            "                return True",
            "        if self.version:",
            "            if self.vrrp_global_info[\"version\"] != self.version:",
            "                return True",
            "        return False",
            "",
            "    def is_vrrp_global_info_exist(self):",
            "        \"\"\"whether vrrp global attribute info exist\"\"\"",
            "",
            "        if self.gratuitous_arp_interval or self.recover_delay or self.version:",
            "            if self.gratuitous_arp_interval:",
            "                if self.vrrp_global_info[\"gratuitousArpFlag\"] == \"false\":",
            "                    self.module.fail_json(",
            "                        msg=\"Error: gratuitousArpFlag is false.\")",
            "                if self.vrrp_global_info[\"gratuitousArpTimeOut\"] != self.gratuitous_arp_interval:",
            "                    return False",
            "            if self.recover_delay:",
            "                if self.vrrp_global_info[\"recoverDelay\"] != self.recover_delay:",
            "                    return False",
            "            if self.version:",
            "                if self.vrrp_global_info[\"version\"] != self.version:",
            "                    return False",
            "            return True",
            "",
            "        return False",
            "",
            "    def is_vrrp_group_info_change(self):",
            "        \"\"\"whether vrrp group attribute info change\"\"\"",
            "        if self.vrrp_type:",
            "            if self.vrrp_group_info[\"vrrpType\"] != self.vrrp_type:",
            "                return True",
            "        if self.admin_ignore_if_down:",
            "            if self.vrrp_group_info[\"adminIgnoreIfDown\"] != str(self.admin_ignore_if_down).lower():",
            "                return True",
            "        if self.admin_vrid:",
            "            if self.vrrp_group_info[\"adminVrrpId\"] != self.admin_vrid:",
            "                return True",
            "        if self.admin_interface:",
            "            if self.vrrp_group_info[\"adminIfName\"] != self.admin_interface:",
            "                return True",
            "        if self.admin_flowdown:",
            "            if self.vrrp_group_info[\"unflowdown\"] != self.admin_flowdown:",
            "                return True",
            "        if self.priority:",
            "            if self.vrrp_group_info[\"priority\"] != self.priority:",
            "                return True",
            "        if self.fast_resume:",
            "            fast_resume = \"false\"",
            "            if self.fast_resume == \"enable\":",
            "                fast_resume = \"true\"",
            "            if self.vrrp_group_info[\"fastResume\"] != fast_resume:",
            "                return True",
            "        if self.advertise_interval:",
            "            if self.vrrp_group_info[\"advertiseInterval\"] != self.advertise_interval:",
            "                return True",
            "        if self.preempt_timer_delay:",
            "            if self.vrrp_group_info[\"delayTime\"] != self.preempt_timer_delay:",
            "                return True",
            "        if self.holding_multiplier:",
            "            if self.vrrp_group_info[\"holdMultiplier\"] != self.holding_multiplier:",
            "                return True",
            "        if self.auth_mode:",
            "            if self.vrrp_group_info[\"authenticationMode\"] != self.auth_mode:",
            "                return True",
            "        if self.auth_key:",
            "            return True",
            "        if self.is_plain:",
            "            if self.vrrp_group_info[\"isPlain\"] != self.is_plain:",
            "                return True",
            "",
            "        return False",
            "",
            "    def is_vrrp_group_info_exist(self):",
            "        \"\"\"whether vrrp group attribute info exist\"\"\"",
            "",
            "        if self.vrrp_type:",
            "            if self.vrrp_group_info[\"vrrpType\"] != self.vrrp_type:",
            "                return False",
            "        if self.admin_ignore_if_down:",
            "            if self.vrrp_group_info[\"adminIgnoreIfDown\"] != str(self.admin_ignore_if_down).lower():",
            "                return False",
            "        if self.admin_vrid:",
            "            if self.vrrp_group_info[\"adminVrrpId\"] != self.admin_vrid:",
            "                return False",
            "        if self.admin_interface:",
            "            if self.vrrp_group_info[\"adminIfName\"] != self.admin_interface:",
            "                return False",
            "        if self.admin_flowdown:",
            "            if self.vrrp_group_info[\"unflowdown\"] != self.admin_flowdown:",
            "                return False",
            "        if self.priority:",
            "            if self.vrrp_group_info[\"priority\"] != self.priority:",
            "                return False",
            "        if self.fast_resume:",
            "            fast_resume = \"false\"",
            "            if self.fast_resume == \"enable\":",
            "                fast_resume = \"true\"",
            "            if self.vrrp_group_info[\"fastResume\"] != fast_resume:",
            "                return False",
            "        if self.advertise_interval:",
            "            if self.vrrp_group_info[\"advertiseInterval\"] != self.advertise_interval:",
            "                return False",
            "        if self.preempt_timer_delay:",
            "            if self.vrrp_group_info[\"delayTime\"] != self.preempt_timer_delay:",
            "                return False",
            "        if self.holding_multiplier:",
            "            if self.vrrp_group_info[\"holdMultiplier\"] != self.holding_multiplier:",
            "                return False",
            "        if self.auth_mode:",
            "            if self.vrrp_group_info[\"authenticationMode\"] != self.auth_mode:",
            "                return False",
            "        if self.is_plain:",
            "            if self.vrrp_group_info[\"isPlain\"] != self.is_plain:",
            "                return False",
            "        return True",
            "",
            "    def create_virtual_ip(self):",
            "        \"\"\"create virtual ip info\"\"\"",
            "",
            "        if self.is_virtual_ip_change():",
            "            conf_str = CE_NC_CREATE_VRRP_VIRTUAL_IP_INFO % (",
            "                self.vrid, self.interface, self.virtual_ip)",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: create virtual ip info failed.')",
            "",
            "            self.updates_cmd.append(\"interface %s\" % self.interface)",
            "            self.updates_cmd.append(",
            "                \"vrrp vrid %s virtual-ip %s\" % (self.vrid, self.virtual_ip))",
            "            self.changed = True",
            "",
            "    def delete_virtual_ip(self):",
            "        \"\"\"delete virtual ip info\"\"\"",
            "",
            "        if self.is_virtual_ip_exist():",
            "            conf_str = CE_NC_DELETE_VRRP_VIRTUAL_IP_INFO % (",
            "                self.vrid, self.interface, self.virtual_ip)",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: delete virtual ip info failed.')",
            "",
            "            self.updates_cmd.append(\"interface %s\" % self.interface)",
            "            self.updates_cmd.append(",
            "                \"undo vrrp vrid %s virtual-ip %s \" % (self.vrid, self.virtual_ip))",
            "            self.changed = True",
            "",
            "    def set_vrrp_global(self):",
            "        \"\"\"set vrrp global attribute info\"\"\"",
            "",
            "        if self.is_vrrp_global_info_change():",
            "            conf_str = CE_NC_SET_VRRP_GLOBAL_HEAD",
            "            if self.gratuitous_arp_interval:",
            "                conf_str += \"<gratuitousArpTimeOut>%s</gratuitousArpTimeOut>\" % self.gratuitous_arp_interval",
            "            if self.recover_delay:",
            "                conf_str += \"<recoverDelay>%s</recoverDelay>\" % self.recover_delay",
            "            if self.version:",
            "                conf_str += \"<version>%s</version>\" % self.version",
            "            conf_str += CE_NC_SET_VRRP_GLOBAL_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp global attribute info failed.')",
            "",
            "            if self.gratuitous_arp_interval:",
            "                self.updates_cmd.append(",
            "                    \"vrrp gratuitous-arp interval %s\" % self.gratuitous_arp_interval)",
            "",
            "            if self.recover_delay:",
            "                self.updates_cmd.append(",
            "                    \"vrrp recover-delay %s\" % self.recover_delay)",
            "",
            "            if self.version:",
            "                version = \"3\"",
            "                if self.version == \"v2\":",
            "                    version = \"2\"",
            "                self.updates_cmd.append(\"vrrp version %s\" % version)",
            "            self.changed = True",
            "",
            "    def delete_vrrp_global(self):",
            "        \"\"\"delete vrrp global attribute info\"\"\"",
            "",
            "        if self.is_vrrp_global_info_exist():",
            "            conf_str = CE_NC_SET_VRRP_GLOBAL_HEAD",
            "            if self.gratuitous_arp_interval:",
            "                if self.gratuitous_arp_interval == \"120\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of gratuitous_arp_interval is 120.')",
            "                gratuitous_arp_interval = \"120\"",
            "                conf_str += \"<gratuitousArpTimeOut>%s</gratuitousArpTimeOut>\" % gratuitous_arp_interval",
            "            if self.recover_delay:",
            "                if self.recover_delay == \"0\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of recover_delay is 0.')",
            "                recover_delay = \"0\"",
            "                conf_str += \"<recoverDelay>%s</recoverDelay>\" % recover_delay",
            "            if self.version:",
            "                if self.version == \"v2\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of version is v2.')",
            "                version = \"v2\"",
            "                conf_str += \"<version>%s</version>\" % version",
            "            conf_str += CE_NC_SET_VRRP_GLOBAL_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp global attribute info failed.')",
            "            if self.gratuitous_arp_interval:",
            "                self.updates_cmd.append(\"undo vrrp gratuitous-arp interval\")",
            "",
            "            if self.recover_delay:",
            "                self.updates_cmd.append(\"undo vrrp recover-delay\")",
            "",
            "            if self.version == \"v3\":",
            "                self.updates_cmd.append(\"undo vrrp version\")",
            "            self.changed = True",
            "",
            "    def set_vrrp_group(self):",
            "        \"\"\"set vrrp group attribute info\"\"\"",
            "",
            "        if self.is_vrrp_group_info_change():",
            "            conf_str = CE_NC_SET_VRRP_GROUP_INFO_HEAD % (",
            "                self.interface, self.vrid)",
            "            if self.vrrp_type:",
            "                conf_str += \"<vrrpType>%s</vrrpType>\" % self.vrrp_type",
            "            if self.admin_vrid:",
            "                conf_str += \"<adminVrrpId>%s</adminVrrpId>\" % self.admin_vrid",
            "            if self.admin_interface:",
            "                conf_str += \"<adminIfName>%s</adminIfName>\" % self.admin_interface",
            "                if self.admin_flowdown is True or self.admin_flowdown is False:",
            "                    admin_flowdown = \"false\"",
            "                    if self.admin_flowdown is True:",
            "                        admin_flowdown = \"true\"",
            "                    conf_str += \"<unflowdown>%s</unflowdown>\" % admin_flowdown",
            "            if self.priority:",
            "                conf_str += \"<priority>%s</priority>\" % self.priority",
            "            if self.vrrp_type == \"admin\":",
            "                if self.admin_ignore_if_down is True or self.admin_ignore_if_down is False:",
            "                    admin_ignore_if_down = \"false\"",
            "                    if self.admin_ignore_if_down is True:",
            "                        admin_ignore_if_down = \"true\"",
            "                    conf_str += \"<adminIgnoreIfDown>%s</adminIgnoreIfDown>\" % admin_ignore_if_down",
            "            if self.fast_resume:",
            "                fast_resume = \"false\"",
            "                if self.fast_resume == \"enable\":",
            "                    fast_resume = \"true\"",
            "                conf_str += \"<fastResume>%s</fastResume>\" % fast_resume",
            "            if self.advertise_interval:",
            "                conf_str += \"<advertiseInterval>%s</advertiseInterval>\" % self.advertise_interval",
            "            if self.preempt_timer_delay:",
            "                conf_str += \"<delayTime>%s</delayTime>\" % self.preempt_timer_delay",
            "            if self.holding_multiplier:",
            "                conf_str += \"<holdMultiplier>%s</holdMultiplier>\" % self.holding_multiplier",
            "            if self.auth_mode:",
            "                conf_str += \"<authenticationMode>%s</authenticationMode>\" % self.auth_mode",
            "            if self.auth_key:",
            "                conf_str += \"<authenticationKey>%s</authenticationKey>\" % self.auth_key",
            "            if self.auth_mode == \"simple\":",
            "                is_plain = \"false\"",
            "                if self.is_plain is True:",
            "                    is_plain = \"true\"",
            "                conf_str += \"<isPlain>%s</isPlain>\" % is_plain",
            "",
            "            conf_str += CE_NC_SET_VRRP_GROUP_INFO_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp group attribute info failed.')",
            "            if self.interface and self.vrid:",
            "                self.updates_cmd.append(\"interface %s\" % self.interface)",
            "                if self.vrrp_type == \"admin\":",
            "                    if self.admin_ignore_if_down is True:",
            "                        self.updates_cmd.append(",
            "                            \"vrrp vrid %s admin ignore-if-down\" % self.vrid)",
            "                    else:",
            "                        self.updates_cmd.append(",
            "                            \"vrrp vrid %s admin\" % self.vrid)",
            "",
            "                if self.priority:",
            "                    self.updates_cmd.append(",
            "                        \"vrrp vrid %s priority %s\" % (self.vrid, self.priority))",
            "",
            "                if self.fast_resume == \"enable\":",
            "                    self.updates_cmd.append(",
            "                        \"vrrp vrid %s fast-resume\" % self.vrid)",
            "                if self.fast_resume == \"disable\":",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s fast-resume\" % self.vrid)",
            "",
            "                if self.advertise_interval:",
            "                    advertise_interval = int(self.advertise_interval) / 1000",
            "                    self.updates_cmd.append(\"vrrp vrid %s timer advertise %s<seconds>\" % (",
            "                        self.vrid, int(advertise_interval)))",
            "",
            "                if self.preempt_timer_delay:",
            "                    self.updates_cmd.append(\"vrrp vrid %s preempt timer delay %s\" % (self.vrid,",
            "                                                                                     self.preempt_timer_delay))",
            "",
            "                if self.holding_multiplier:",
            "                    self.updates_cmd.append(",
            "                        \"vrrp vrid %s holding-multiplier %s\" % (self.vrid, self.holding_multiplier))",
            "",
            "                if self.admin_vrid and self.admin_interface:",
            "                    if self.admin_flowdown == \"true\":",
            "                        self.updates_cmd.append(\"vrrp vrid %s track admin-vrrp interface %s vrid %s unflowdown\" %",
            "                                                (self.vrid, self.admin_interface, self.admin_vrid))",
            "                    else:",
            "                        self.updates_cmd.append(\"vrrp vrid %s track admin-vrrp interface %s vrid %s\" %",
            "                                                (self.vrid, self.admin_interface, self.admin_vrid))",
            "",
            "                if self.auth_mode and self.auth_key:",
            "                    if self.auth_mode == \"simple\":",
            "                        if self.is_plain == \"true\":",
            "                            self.updates_cmd.append(\"vrrp vrid %s authentication-mode simple plain %s\" %",
            "                                                    (self.vrid, self.auth_key))",
            "                        else:",
            "                            self.updates_cmd.append(\"vrrp vrid %s authentication-mode simple cipher %s\" %",
            "                                                    (self.vrid, self.auth_key))",
            "                    if self.auth_mode == \"md5\":",
            "                        self.updates_cmd.append(",
            "                            \"vrrp vrid %s authentication-mode md5 %s\" % (self.vrid, self.auth_key))",
            "                self.changed = True",
            "",
            "    def delete_vrrp_group(self):",
            "        \"\"\"delete vrrp group attribute info\"\"\"",
            "",
            "        if self.is_vrrp_group_info_exist():",
            "            conf_str = CE_NC_SET_VRRP_GROUP_INFO_HEAD % (",
            "                self.interface, self.vrid)",
            "            if self.vrrp_type:",
            "                vrrp_type = self.vrrp_type",
            "                if self.vrrp_type == \"admin\":",
            "                    vrrp_type = \"normal\"",
            "                if self.vrrp_type == \"member\" and self.admin_vrid and self.admin_interface:",
            "                    vrrp_type = \"normal\"",
            "                conf_str += \"<vrrpType>%s</vrrpType>\" % vrrp_type",
            "            if self.priority:",
            "                if self.priority == \"100\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of priority is 100.')",
            "                priority = \"100\"",
            "                conf_str += \"<priority>%s</priority>\" % priority",
            "",
            "            if self.fast_resume:",
            "                fast_resume = \"false\"",
            "                if self.fast_resume == \"enable\":",
            "                    fast_resume = \"true\"",
            "                conf_str += \"<fastResume>%s</fastResume>\" % fast_resume",
            "            if self.advertise_interval:",
            "                if self.advertise_interval == \"1000\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of advertise_interval is 1000.')",
            "                advertise_interval = \"1000\"",
            "                conf_str += \"<advertiseInterval>%s</advertiseInterval>\" % advertise_interval",
            "            if self.preempt_timer_delay:",
            "                if self.preempt_timer_delay == \"0\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of preempt_timer_delay is 0.')",
            "                preempt_timer_delay = \"0\"",
            "                conf_str += \"<delayTime>%s</delayTime>\" % preempt_timer_delay",
            "            if self.holding_multiplier:",
            "                if self.holding_multiplier == \"0\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of holding_multiplier is 3.')",
            "                holding_multiplier = \"3\"",
            "                conf_str += \"<holdMultiplier>%s</holdMultiplier>\" % holding_multiplier",
            "            if self.auth_mode:",
            "                auth_mode = self.auth_mode",
            "                if self.auth_mode == \"md5\" or self.auth_mode == \"simple\":",
            "                    auth_mode = \"none\"",
            "                conf_str += \"<authenticationMode>%s</authenticationMode>\" % auth_mode",
            "",
            "            conf_str += CE_NC_SET_VRRP_GROUP_INFO_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp global attribute info failed.')",
            "            if self.interface and self.vrid:",
            "                self.updates_cmd.append(\"interface %s\" % self.interface)",
            "                if self.vrrp_type == \"admin\":",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s admin\" % self.vrid)",
            "",
            "                if self.priority:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s priority\" % self.vrid)",
            "",
            "                if self.fast_resume:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s fast-resume\" % self.vrid)",
            "",
            "                if self.advertise_interval:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s timer advertise\" % self.vrid)",
            "",
            "                if self.preempt_timer_delay:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s preempt timer delay\" % self.vrid)",
            "",
            "                if self.holding_multiplier:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s holding-multiplier\" % self.vrid)",
            "",
            "                if self.admin_vrid and self.admin_interface:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s track admin-vrrp\" % self.vrid)",
            "",
            "                if self.auth_mode:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s authentication-mode\" % self.vrid)",
            "                self.changed = True",
            "",
            "    def get_proposed(self):",
            "        \"\"\"get proposed info\"\"\"",
            "",
            "        if self.interface:",
            "            self.proposed[\"interface\"] = self.interface",
            "        if self.vrid:",
            "            self.proposed[\"vrid\"] = self.vrid",
            "        if self.virtual_ip:",
            "            self.proposed[\"virtual_ip\"] = self.virtual_ip",
            "        if self.vrrp_type:",
            "            self.proposed[\"vrrp_type\"] = self.vrrp_type",
            "        if self.admin_vrid:",
            "            self.proposed[\"admin_vrid\"] = self.admin_vrid",
            "        if self.admin_interface:",
            "            self.proposed[\"admin_interface\"] = self.admin_interface",
            "        if self.admin_flowdown:",
            "            self.proposed[\"unflowdown\"] = self.admin_flowdown",
            "        if self.admin_ignore_if_down:",
            "            self.proposed[\"admin_ignore_if_down\"] = self.admin_ignore_if_down",
            "        if self.priority:",
            "            self.proposed[\"priority\"] = self.priority",
            "        if self.version:",
            "            self.proposed[\"version\"] = self.version",
            "        if self.advertise_interval:",
            "            self.proposed[\"advertise_interval\"] = self.advertise_interval",
            "        if self.preempt_timer_delay:",
            "            self.proposed[\"preempt_timer_delay\"] = self.preempt_timer_delay",
            "        if self.gratuitous_arp_interval:",
            "            self.proposed[",
            "                \"gratuitous_arp_interval\"] = self.gratuitous_arp_interval",
            "        if self.recover_delay:",
            "            self.proposed[\"recover_delay\"] = self.recover_delay",
            "        if self.holding_multiplier:",
            "            self.proposed[\"holding_multiplier\"] = self.holding_multiplier",
            "        if self.auth_mode:",
            "            self.proposed[\"auth_mode\"] = self.auth_mode",
            "        if self.is_plain:",
            "            self.proposed[\"is_plain\"] = self.is_plain",
            "        if self.auth_key:",
            "            self.proposed[\"auth_key\"] = self.auth_key",
            "        if self.fast_resume:",
            "            self.proposed[\"fast_resume\"] = self.fast_resume",
            "        if self.state:",
            "            self.proposed[\"state\"] = self.state",
            "",
            "    def get_existing(self):",
            "        \"\"\"get existing info\"\"\"",
            "",
            "        if self.gratuitous_arp_interval:",
            "            self.existing[\"gratuitous_arp_interval\"] = self.vrrp_global_info[",
            "                \"gratuitousArpTimeOut\"]",
            "        if self.version:",
            "            self.existing[\"version\"] = self.vrrp_global_info[\"version\"]",
            "        if self.recover_delay:",
            "            self.existing[\"recover_delay\"] = self.vrrp_global_info[",
            "                \"recoverDelay\"]",
            "",
            "        if self.virtual_ip:",
            "            if self.virtual_ip_info:",
            "                self.existing[\"interface\"] = self.interface",
            "                self.existing[\"vrid\"] = self.vrid",
            "                self.existing[\"virtual_ip_info\"] = self.virtual_ip_info[",
            "                    \"vrrpVirtualIpInfos\"]",
            "",
            "        if self.vrrp_group_info:",
            "            self.existing[\"interface\"] = self.vrrp_group_info[\"ifName\"]",
            "            self.existing[\"vrid\"] = self.vrrp_group_info[\"vrrpId\"]",
            "            self.existing[\"vrrp_type\"] = self.vrrp_group_info[\"vrrpType\"]",
            "            if self.vrrp_type == \"admin\":",
            "                self.existing[\"admin_ignore_if_down\"] = self.vrrp_group_info[",
            "                    \"adminIgnoreIfDown\"]",
            "            if self.admin_vrid and self.admin_interface:",
            "                self.existing[\"admin_vrid\"] = self.vrrp_group_info[",
            "                    \"adminVrrpId\"]",
            "                self.existing[\"admin_interface\"] = self.vrrp_group_info[",
            "                    \"adminIfName\"]",
            "                self.existing[\"admin_flowdown\"] = self.vrrp_group_info[",
            "                    \"unflowdown\"]",
            "            if self.priority:",
            "                self.existing[\"priority\"] = self.vrrp_group_info[\"priority\"]",
            "            if self.advertise_interval:",
            "                self.existing[\"advertise_interval\"] = self.vrrp_group_info[",
            "                    \"advertiseInterval\"]",
            "            if self.preempt_timer_delay:",
            "                self.existing[\"preempt_timer_delay\"] = self.vrrp_group_info[",
            "                    \"delayTime\"]",
            "            if self.holding_multiplier:",
            "                self.existing[\"holding_multiplier\"] = self.vrrp_group_info[",
            "                    \"holdMultiplier\"]",
            "            if self.fast_resume:",
            "                fast_resume_exist = \"disable\"",
            "                fast_resume = self.vrrp_group_info[\"fastResume\"]",
            "                if fast_resume == \"true\":",
            "                    fast_resume_exist = \"enable\"",
            "                self.existing[\"fast_resume\"] = fast_resume_exist",
            "            if self.auth_mode:",
            "                self.existing[\"auth_mode\"] = self.vrrp_group_info[",
            "                    \"authenticationMode\"]",
            "                self.existing[\"is_plain\"] = self.vrrp_group_info[\"isPlain\"]",
            "",
            "    def get_end_state(self):",
            "        \"\"\"get end state info\"\"\"",
            "",
            "        if self.gratuitous_arp_interval or self.version or self.recover_delay:",
            "            self.vrrp_global_info = self.get_vrrp_global_info()",
            "        if self.interface and self.vrid:",
            "            if self.virtual_ip:",
            "                self.virtual_ip_info = self.get_virtual_ip_info()",
            "            if self.virtual_ip_info:",
            "                self.vrrp_group_info = self.get_vrrp_group_info()",
            "",
            "        if self.gratuitous_arp_interval:",
            "            self.end_state[\"gratuitous_arp_interval\"] = self.vrrp_global_info[",
            "                \"gratuitousArpTimeOut\"]",
            "        if self.version:",
            "            self.end_state[\"version\"] = self.vrrp_global_info[\"version\"]",
            "        if self.recover_delay:",
            "            self.end_state[\"recover_delay\"] = self.vrrp_global_info[",
            "                \"recoverDelay\"]",
            "",
            "        if self.virtual_ip:",
            "            if self.virtual_ip_info:",
            "                self.end_state[\"interface\"] = self.interface",
            "                self.end_state[\"vrid\"] = self.vrid",
            "                self.end_state[\"virtual_ip_info\"] = self.virtual_ip_info[",
            "                    \"vrrpVirtualIpInfos\"]",
            "",
            "        if self.vrrp_group_info:",
            "            self.end_state[\"interface\"] = self.vrrp_group_info[\"ifName\"]",
            "            self.end_state[\"vrid\"] = self.vrrp_group_info[\"vrrpId\"]",
            "            self.end_state[\"vrrp_type\"] = self.vrrp_group_info[\"vrrpType\"]",
            "            if self.vrrp_type == \"admin\":",
            "                self.end_state[\"admin_ignore_if_down\"] = self.vrrp_group_info[",
            "                    \"adminIgnoreIfDown\"]",
            "            if self.admin_vrid and self.admin_interface:",
            "                self.existing[\"admin_vrid\"] = self.vrrp_group_info[",
            "                    \"adminVrrpId\"]",
            "                self.end_state[\"admin_interface\"] = self.vrrp_group_info[",
            "                    \"adminIfName\"]",
            "                self.end_state[\"admin_flowdown\"] = self.vrrp_group_info[",
            "                    \"unflowdown\"]",
            "            if self.priority:",
            "                self.end_state[\"priority\"] = self.vrrp_group_info[\"priority\"]",
            "            if self.advertise_interval:",
            "                self.end_state[\"advertise_interval\"] = self.vrrp_group_info[",
            "                    \"advertiseInterval\"]",
            "            if self.preempt_timer_delay:",
            "                self.end_state[\"preempt_timer_delay\"] = self.vrrp_group_info[",
            "                    \"delayTime\"]",
            "            if self.holding_multiplier:",
            "                self.end_state[\"holding_multiplier\"] = self.vrrp_group_info[",
            "                    \"holdMultiplier\"]",
            "            if self.fast_resume:",
            "                fast_resume_end = \"disable\"",
            "                fast_resume = self.vrrp_group_info[\"fastResume\"]",
            "                if fast_resume == \"true\":",
            "                    fast_resume_end = \"enable\"",
            "                self.end_state[\"fast_resume\"] = fast_resume_end",
            "            if self.auth_mode:",
            "                self.end_state[\"auth_mode\"] = self.vrrp_group_info[",
            "                    \"authenticationMode\"]",
            "                self.end_state[\"is_plain\"] = self.vrrp_group_info[\"isPlain\"]",
            "",
            "    def work(self):",
            "        \"\"\"worker\"\"\"",
            "",
            "        self.check_params()",
            "        if self.gratuitous_arp_interval or self.version or self.recover_delay:",
            "            self.vrrp_global_info = self.get_vrrp_global_info()",
            "        if self.interface and self.vrid:",
            "            self.virtual_ip_info = self.get_virtual_ip_info()",
            "            if self.virtual_ip_info:",
            "                self.vrrp_group_info = self.get_vrrp_group_info()",
            "        self.get_proposed()",
            "        self.get_existing()",
            "",
            "        if self.gratuitous_arp_interval or self.version or self.recover_delay:",
            "            if self.state == \"present\":",
            "                self.set_vrrp_global()",
            "            else:",
            "                self.delete_vrrp_global()",
            "        else:",
            "            if not self.interface or not self.vrid:",
            "                self.module.fail_json(",
            "                    msg='Error: interface, vrid must be config at the same time.')",
            "",
            "        if self.interface and self.vrid:",
            "            if self.virtual_ip:",
            "                if self.state == \"present\":",
            "                    self.create_virtual_ip()",
            "                else:",
            "                    self.delete_virtual_ip()",
            "            else:",
            "                if not self.vrrp_group_info:",
            "                    self.module.fail_json(",
            "                        msg='Error: The VRRP group does not exist.')",
            "                if self.admin_ignore_if_down is True:",
            "                    if self.vrrp_type != \"admin\":",
            "                        self.module.fail_json(",
            "                            msg='Error: vrrpType must be admin when admin_ignore_if_down is true.')",
            "                if self.admin_interface or self.admin_vrid:",
            "                    if self.vrrp_type != \"member\":",
            "                        self.module.fail_json(",
            "                            msg='Error: it binds a VRRP group to an mVRRP group, vrrp_type must be \"member\".')",
            "                    if not self.vrrp_type or not self.interface or not self.vrid:",
            "                        self.module.fail_json(",
            "                            msg='Error: admin_interface admin_vrid vrrp_type interface vrid must '",
            "                                'be config at the same time.')",
            "                if self.auth_mode == \"md5\" and self.is_plain == \"true\":",
            "                    self.module.fail_json(",
            "                        msg='Error: is_plain can not be True when auth_mode is md5.')",
            "",
            "                if self.state == \"present\":",
            "                    self.set_vrrp_group()",
            "                else:",
            "                    self.delete_vrrp_group()",
            "",
            "        self.get_end_state()",
            "        self.results['changed'] = self.changed",
            "        self.results['proposed'] = self.proposed",
            "        self.results['existing'] = self.existing",
            "        self.results['end_state'] = self.end_state",
            "        if self.changed:",
            "            self.results['updates'] = self.updates_cmd",
            "        else:",
            "            self.results['updates'] = list()",
            "",
            "        self.module.exit_json(**self.results)",
            "",
            "",
            "def main():",
            "    \"\"\" Module main \"\"\"",
            "",
            "    argument_spec = dict(",
            "        interface=dict(type='str'),",
            "        vrid=dict(type='str'),",
            "        virtual_ip=dict(type='str'),",
            "        vrrp_type=dict(type='str', choices=['normal', 'member', 'admin']),",
            "        admin_ignore_if_down=dict(type='bool', default=False),",
            "        admin_vrid=dict(type='str'),",
            "        admin_interface=dict(type='str'),",
            "        admin_flowdown=dict(type='bool', default=False),",
            "        priority=dict(type='str'),",
            "        version=dict(type='str', choices=['v2', 'v3']),",
            "        advertise_interval=dict(type='str'),",
            "        preempt_timer_delay=dict(type='str'),",
            "        gratuitous_arp_interval=dict(type='str'),",
            "        recover_delay=dict(type='str'),",
            "        holding_multiplier=dict(type='str'),",
            "        auth_mode=dict(type='str', choices=['simple', 'md5', 'none']),",
            "        is_plain=dict(type='bool', default=False),",
            "        auth_key=dict(type='str'),",
            "        fast_resume=dict(type='str', choices=['enable', 'disable']),",
            "        state=dict(type='str', default='present',",
            "                   choices=['present', 'absent'])",
            "    )",
            "",
            "    argument_spec.update(ce_argument_spec)",
            "    module = Vrrp(argument_spec=argument_spec)",
            "    module.work()",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "#",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: ce_vrrp",
            "version_added: \"2.4\"",
            "short_description: Manages VRRP interfaces on HUAWEI CloudEngine devices.",
            "description:",
            "    - Manages VRRP interface attributes on HUAWEI CloudEngine devices.",
            "author:",
            "    - Li Yanfeng (@numone213)",
            "notes:",
            "    - This module requires the netconf system service be enabled on the remote device being managed.",
            "    - Recommended connection is C(netconf).",
            "    - This module also works with C(local) connections for legacy playbooks.",
            "options:",
            "    interface:",
            "        description:",
            "            - Name of an interface. The value is a string of 1 to 63 characters.",
            "    vrid:",
            "        description:",
            "            - VRRP backup group ID.",
            "              The value is an integer ranging from 1 to 255.",
            "        default: present",
            "    virtual_ip :",
            "        description:",
            "            - Virtual IP address. The value is a string of 0 to 255 characters.",
            "    vrrp_type:",
            "        description:",
            "            - Type of a VRRP backup group.",
            "        choices: ['normal', 'member', 'admin']",
            "    admin_ignore_if_down:",
            "        description:",
            "            - mVRRP ignores an interface Down event.",
            "        type: bool",
            "        default: 'false'",
            "    admin_vrid:",
            "        description:",
            "            - Tracked mVRRP ID. The value is an integer ranging from 1 to 255.",
            "    admin_interface:",
            "        description:",
            "            - Tracked mVRRP interface name. The value is a string of 1 to 63 characters.",
            "    admin_flowdown:",
            "        description:",
            "            - Disable the flowdown function for service VRRP.",
            "        type: bool",
            "        default: 'false'",
            "    priority:",
            "        description:",
            "            - Configured VRRP priority.",
            "              The value ranges from 1 to 254. The default value is 100. A larger value indicates a higher priority.",
            "    version:",
            "        description:",
            "            - VRRP version. The default version is v2.",
            "        choices: ['v2','v3']",
            "    advertise_interval:",
            "        description:",
            "            - Configured interval between sending advertisements, in milliseconds.",
            "              Only the master router sends VRRP advertisements. The default value is 1000 milliseconds.",
            "    preempt_timer_delay:",
            "        description:",
            "            - Preemption delay.",
            "              The value is an integer ranging from 0 to 3600. The default value is 0.",
            "    gratuitous_arp_interval:",
            "        description:",
            "            - Interval at which gratuitous ARP packets are sent, in seconds.",
            "              The value ranges from 30 to 1200.The default value is 300.",
            "    recover_delay:",
            "        description:",
            "            - Delay in recovering after an interface goes Up.",
            "              The delay is used for interface flapping suppression.",
            "              The value is an integer ranging from 0 to 3600.",
            "              The default value is 0 seconds.",
            "    holding_multiplier:",
            "        description:",
            "            - The configured holdMultiplier.The value is an integer ranging from 3 to 10. The default value is 3.",
            "    auth_mode:",
            "        description:",
            "            - Authentication type used for VRRP packet exchanges between virtual routers.",
            "              The values are noAuthentication, simpleTextPassword, md5Authentication.",
            "              The default value is noAuthentication.",
            "        choices: ['simple','md5','none']",
            "    is_plain:",
            "        description:",
            "            - Select the display mode of an authentication key.",
            "              By default, an authentication key is displayed in ciphertext.",
            "        type: bool",
            "        default: 'false'",
            "    auth_key:",
            "        description:",
            "            - This object is set based on the authentication type.",
            "              When noAuthentication is specified, the value is empty.",
            "              When simpleTextPassword or md5Authentication is specified, the value is a string of 1 to 8 characters",
            "              in plaintext and displayed as a blank text for security.",
            "    fast_resume:",
            "        description:",
            "            - mVRRP's fast resume mode.",
            "        choices: ['enable','disable']",
            "    state:",
            "        description:",
            "            - Specify desired state of the resource.",
            "        default: present",
            "        choices: ['present','absent']",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: vrrp module test",
            "  hosts: cloudengine",
            "  connection: local",
            "  gather_facts: no",
            "  vars:",
            "    cli:",
            "      host: \"{{ inventory_hostname }}\"",
            "      port: \"{{ ansible_ssh_port }}\"",
            "      username: \"{{ username }}\"",
            "      password: \"{{ password }}\"",
            "      transport: cli",
            "  tasks:",
            "  - name: Set vrrp version",
            "    ce_vrrp:",
            "      version: v3",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp gratuitous-arp interval",
            "    ce_vrrp:",
            "      gratuitous_arp_interval: 40",
            "      mlag_id: 4",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp recover-delay",
            "    ce_vrrp:",
            "      recover_delay: 10",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid virtual-ip",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      virtual_ip: 10.14.2.7",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid admin",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      vrrp_type: admin",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid fast_resume",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      fast_resume: enable",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid holding-multiplier",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      holding_multiplier: 4",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid preempt timer delay",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      preempt_timer_delay: 10",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid admin-vrrp",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      admin_interface: 40GE2/0/9",
            "      admin_vrid: 2",
            "      vrrp_type: member",
            "      provider: \"{{ cli }}\"",
            "  - name: Set vrrp vrid authentication-mode",
            "    ce_vrrp:",
            "      interface: 40GE2/0/8",
            "      vrid: 1",
            "      is_plain: true",
            "      auth_mode: simple",
            "      auth_key: aaa",
            "      provider: \"{{ cli }}\"",
            "'''",
            "",
            "RETURN = '''",
            "changed:",
            "    description: check to see if a change was made on the device",
            "    returned: always",
            "    type: bool",
            "    sample: true",
            "proposed:",
            "    description: k/v pairs of parameters passed into module",
            "    returned: always",
            "    type: dict",
            "    sample: {",
            "                \"auth_key\": \"aaa\",",
            "                \"auth_mode\": \"simple\",",
            "                \"interface\": \"40GE2/0/8\",",
            "                \"is_plain\": true,",
            "                \"state\": \"present\",",
            "                \"vrid\": \"1\"",
            "            }",
            "existing:",
            "    description: k/v pairs of existing aaa server",
            "    returned: always",
            "    type: dict",
            "    sample: {",
            "                \"auth_mode\": \"none\",",
            "                \"interface\": \"40GE2/0/8\",",
            "                \"is_plain\": \"false\",",
            "                \"vrid\": \"1\",",
            "                \"vrrp_type\": \"normal\"",
            "            }",
            "end_state:",
            "    description: k/v pairs of aaa params after module execution",
            "    returned: always",
            "    type: dict",
            "    sample: {",
            "                \"auth_mode\": \"simple\",",
            "                \"interface\": \"40GE2/0/8\",",
            "                \"is_plain\": \"true\",",
            "                \"vrid\": \"1\",",
            "                \"vrrp_type\": \"normal\"",
            "    }",
            "updates:",
            "    description: command sent to the device",
            "    returned: always",
            "    type: list",
            "    sample: { \"interface 40GE2/0/8\",",
            "              \"vrrp vrid 1 authentication-mode simple plain aaa\"}",
            "'''",
            "",
            "from xml.etree import ElementTree",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.network.cloudengine.ce import get_nc_config, set_nc_config, ce_argument_spec",
            "",
            "",
            "CE_NC_GET_VRRP_GROUP_INFO = \"\"\"",
            "<filter type=\"subtree\">",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <ifName>%s</ifName>",
            "        <vrrpId>%s</vrrpId>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</filter>",
            "\"\"\"",
            "",
            "CE_NC_SET_VRRP_GROUP_INFO_HEAD = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup operation=\"merge\">",
            "        <ifName>%s</ifName>",
            "        <vrrpId>%s</vrrpId>",
            "\"\"\"",
            "CE_NC_SET_VRRP_GROUP_INFO_TAIL = \"\"\"",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "CE_NC_GET_VRRP_GLOBAL_INFO = \"\"\"",
            "<filter type=\"subtree\">",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGlobalCfg>",
            "      <gratuitousArpFlag></gratuitousArpFlag>",
            "      <gratuitousArpTimeOut></gratuitousArpTimeOut>",
            "      <recoverDelay></recoverDelay>",
            "      <version></version>",
            "    </vrrpGlobalCfg>",
            "  </vrrp>",
            "</filter>",
            "\"\"\"",
            "",
            "CE_NC_SET_VRRP_GLOBAL_HEAD = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGlobalCfg operation=\"merge\">",
            "\"\"\"",
            "CE_NC_SET_VRRP_GLOBAL_TAIL = \"\"\"",
            "    </vrrpGlobalCfg>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "",
            "CE_NC_GET_VRRP_VIRTUAL_IP_INFO = \"\"\"",
            "<filter type=\"subtree\">",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <vrrpId>%s</vrrpId>",
            "        <ifName>%s</ifName>",
            "        <virtualIps>",
            "          <virtualIp>",
            "            <virtualIpAddress></virtualIpAddress>",
            "          </virtualIp>",
            "        </virtualIps>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</filter>",
            "\"\"\"",
            "CE_NC_CREATE_VRRP_VIRTUAL_IP_INFO = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <vrrpId>%s</vrrpId>",
            "        <ifName>%s</ifName>",
            "        <virtualIps>",
            "          <virtualIp operation=\"create\">",
            "            <virtualIpAddress>%s</virtualIpAddress>",
            "          </virtualIp>",
            "        </virtualIps>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "CE_NC_DELETE_VRRP_VIRTUAL_IP_INFO = \"\"\"",
            "<config>",
            "  <vrrp xmlns=\"http://www.huawei.com/netconf/vrp\" content-version=\"1.0\" format-version=\"1.0\">",
            "    <vrrpGroups>",
            "      <vrrpGroup>",
            "        <vrrpId>%s</vrrpId>",
            "        <ifName>%s</ifName>",
            "        <virtualIps>",
            "          <virtualIp operation=\"delete\">",
            "            <virtualIpAddress>%s</virtualIpAddress>",
            "          </virtualIp>",
            "        </virtualIps>",
            "      </vrrpGroup>",
            "    </vrrpGroups>",
            "  </vrrp>",
            "</config>",
            "\"\"\"",
            "",
            "",
            "def is_valid_address(address):",
            "    \"\"\"check ip-address is valid\"\"\"",
            "",
            "    if address.find('.') != -1:",
            "        addr_list = address.split('.')",
            "        if len(addr_list) != 4:",
            "            return False",
            "        for each_num in addr_list:",
            "            if not each_num.isdigit():",
            "                return False",
            "            if int(each_num) > 255:",
            "                return False",
            "        return True",
            "",
            "    return False",
            "",
            "",
            "def get_interface_type(interface):",
            "    \"\"\"Gets the type of interface, such as 10GE, ETH-TRUNK, VLANIF...\"\"\"",
            "",
            "    if interface is None:",
            "        return None",
            "",
            "    iftype = None",
            "",
            "    if interface.upper().startswith('GE'):",
            "        iftype = 'ge'",
            "    elif interface.upper().startswith('10GE'):",
            "        iftype = '10ge'",
            "    elif interface.upper().startswith('25GE'):",
            "        iftype = '25ge'",
            "    elif interface.upper().startswith('40GE'):",
            "        iftype = '40ge'",
            "    elif interface.upper().startswith('100GE'):",
            "        iftype = '100ge'",
            "    elif interface.upper().startswith('ETH-TRUNK'):",
            "        iftype = 'eth-trunk'",
            "    elif interface.upper().startswith('NULL'):",
            "        iftype = 'null'",
            "    elif interface.upper().startswith('VLANIF'):",
            "        iftype = 'vlanif'",
            "    else:",
            "        return None",
            "",
            "    return iftype.lower()",
            "",
            "",
            "class Vrrp(object):",
            "    \"\"\"",
            "    Manages Manages vrrp information.",
            "    \"\"\"",
            "",
            "    def __init__(self, argument_spec):",
            "        self.spec = argument_spec",
            "        self.module = None",
            "        self.init_module()",
            "",
            "        # module input info",
            "        self.interface = self.module.params['interface']",
            "        self.vrid = self.module.params['vrid']",
            "        self.virtual_ip = self.module.params['virtual_ip']",
            "        self.vrrp_type = self.module.params['vrrp_type']",
            "        self.admin_ignore_if_down = 'false' if self.module.params['admin_ignore_if_down'] is False else 'true'",
            "        self.admin_vrid = self.module.params['admin_vrid']",
            "        self.admin_interface = self.module.params['admin_interface']",
            "        self.admin_flowdown = 'false' if self.module.params['admin_flowdown'] is False else 'true'",
            "        self.priority = self.module.params['priority']",
            "        self.version = self.module.params['version']",
            "        self.advertise_interval = self.module.params['advertise_interval']",
            "        self.preempt_timer_delay = self.module.params['preempt_timer_delay']",
            "        self.gratuitous_arp_interval = self.module.params[",
            "            'gratuitous_arp_interval']",
            "        self.recover_delay = self.module.params['recover_delay']",
            "        self.holding_multiplier = self.module.params['holding_multiplier']",
            "        self.auth_mode = self.module.params['auth_mode']",
            "        self.is_plain = 'false' if self.module.params['is_plain'] is False else 'true'",
            "        self.auth_key = self.module.params['auth_key']",
            "        self.fast_resume = self.module.params['fast_resume']",
            "        self.state = self.module.params['state']",
            "",
            "        # vrrp info",
            "        self.vrrp_global_info = None",
            "        self.virtual_ip_info = None",
            "        self.vrrp_group_info = None",
            "",
            "        # state",
            "        self.changed = False",
            "        self.updates_cmd = list()",
            "        self.results = dict()",
            "        self.existing = dict()",
            "        self.proposed = dict()",
            "        self.end_state = dict()",
            "",
            "    def init_module(self):",
            "        \"\"\" init module \"\"\"",
            "",
            "        self.module = AnsibleModule(",
            "            argument_spec=self.spec, supports_check_mode=True)",
            "",
            "    def get_virtual_ip_info(self):",
            "        \"\"\" get vrrp virtual ip info.\"\"\"",
            "        virtual_ip_info = dict()",
            "        conf_str = CE_NC_GET_VRRP_VIRTUAL_IP_INFO % (self.vrid, self.interface)",
            "        xml_str = get_nc_config(self.module, conf_str)",
            "        if \"<data/>\" in xml_str:",
            "            return virtual_ip_info",
            "        else:",
            "            xml_str = xml_str.replace('\\r', '').replace('\\n', '').\\",
            "                replace('xmlns=\"urn:ietf:params:xml:ns:netconf:base:1.0\"', \"\").\\",
            "                replace('xmlns=\"http://www.huawei.com/netconf/vrp\"', \"\")",
            "            virtual_ip_info[\"vrrpVirtualIpInfos\"] = list()",
            "            root = ElementTree.fromstring(xml_str)",
            "            vrrp_virtual_ip_infos = root.findall(",
            "                \"vrrp/vrrpGroups/vrrpGroup/virtualIps/virtualIp\")",
            "            if vrrp_virtual_ip_infos:",
            "                for vrrp_virtual_ip_info in vrrp_virtual_ip_infos:",
            "                    virtual_ip_dict = dict()",
            "                    for ele in vrrp_virtual_ip_info:",
            "                        if ele.tag in [\"virtualIpAddress\"]:",
            "                            virtual_ip_dict[ele.tag] = ele.text",
            "                    virtual_ip_info[\"vrrpVirtualIpInfos\"].append(",
            "                        virtual_ip_dict)",
            "            return virtual_ip_info",
            "",
            "    def get_vrrp_global_info(self):",
            "        \"\"\" get vrrp global info.\"\"\"",
            "",
            "        vrrp_global_info = dict()",
            "        conf_str = CE_NC_GET_VRRP_GLOBAL_INFO",
            "        xml_str = get_nc_config(self.module, conf_str)",
            "        if \"<data/>\" in xml_str:",
            "            return vrrp_global_info",
            "        else:",
            "            xml_str = xml_str.replace('\\r', '').replace('\\n', '').\\",
            "                replace('xmlns=\"urn:ietf:params:xml:ns:netconf:base:1.0\"', \"\").\\",
            "                replace('xmlns=\"http://www.huawei.com/netconf/vrp\"', \"\")",
            "",
            "            root = ElementTree.fromstring(xml_str)",
            "            global_info = root.findall(",
            "                \"vrrp/vrrpGlobalCfg\")",
            "",
            "            if global_info:",
            "                for tmp in global_info:",
            "                    for site in tmp:",
            "                        if site.tag in [\"gratuitousArpTimeOut\", \"gratuitousArpFlag\", \"recoverDelay\", \"version\"]:",
            "                            vrrp_global_info[site.tag] = site.text",
            "            return vrrp_global_info",
            "",
            "    def get_vrrp_group_info(self):",
            "        \"\"\" get vrrp group info.\"\"\"",
            "",
            "        vrrp_group_info = dict()",
            "        conf_str = CE_NC_GET_VRRP_GROUP_INFO % (self.interface, self.vrid)",
            "        xml_str = get_nc_config(self.module, conf_str)",
            "        if \"<data/>\" in xml_str:",
            "            return vrrp_group_info",
            "        else:",
            "            xml_str = xml_str.replace('\\r', '').replace('\\n', '').\\",
            "                replace('xmlns=\"urn:ietf:params:xml:ns:netconf:base:1.0\"', \"\").\\",
            "                replace('xmlns=\"http://www.huawei.com/netconf/vrp\"', \"\")",
            "",
            "            root = ElementTree.fromstring(xml_str)",
            "            global_info = root.findall(",
            "                \"vrrp/vrrpGroups/vrrpGroup\")",
            "",
            "            if global_info:",
            "                for tmp in global_info:",
            "                    for site in tmp:",
            "                        if site.tag in [\"ifName\", \"vrrpId\", \"priority\", \"advertiseInterval\", \"preemptMode\", \"delayTime\",",
            "                                        \"authenticationMode\", \"authenticationKey\", \"vrrpType\", \"adminVrrpId\",",
            "                                        \"adminIfName\", \"adminIgnoreIfDown\", \"isPlain\", \"unflowdown\", \"fastResume\",",
            "                                        \"holdMultiplier\"]:",
            "                            vrrp_group_info[site.tag] = site.text",
            "            return vrrp_group_info",
            "",
            "    def check_params(self):",
            "        \"\"\"Check all input params\"\"\"",
            "",
            "        # interface check",
            "        if self.interface:",
            "            intf_type = get_interface_type(self.interface)",
            "            if not intf_type:",
            "                self.module.fail_json(",
            "                    msg='Error: Interface name of %s '",
            "                        'is error.' % self.interface)",
            "",
            "        # vrid check",
            "        if self.vrid:",
            "            if not self.vrid.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of vrid is an integer.')",
            "            if int(self.vrid) < 1 or int(self.vrid) > 255:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of vrid ranges from 1 to 255.')",
            "",
            "        # virtual_ip check",
            "        if self.virtual_ip:",
            "            if not is_valid_address(self.virtual_ip):",
            "                self.module.fail_json(",
            "                    msg='Error: The %s is not a valid ip address.' % self.virtual_ip)",
            "",
            "        # admin_vrid check",
            "        if self.admin_vrid:",
            "            if not self.admin_vrid.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of admin_vrid is an integer.')",
            "            if int(self.admin_vrid) < 1 or int(self.admin_vrid) > 255:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of admin_vrid ranges from 1 to 255.')",
            "",
            "        # admin_interface check",
            "        if self.admin_interface:",
            "            intf_type = get_interface_type(self.admin_interface)",
            "            if not intf_type:",
            "                self.module.fail_json(",
            "                    msg='Error: Admin interface name of %s '",
            "                        'is error.' % self.admin_interface)",
            "",
            "        # priority check",
            "        if self.priority:",
            "            if not self.priority.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of priority is an integer.')",
            "            if int(self.priority) < 1 or int(self.priority) > 254:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of priority ranges from 1 to 254. The default value is 100.')",
            "",
            "        # advertise_interval check",
            "        if self.advertise_interval:",
            "            if not self.advertise_interval.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of advertise_interval is an integer.')",
            "            if int(self.advertise_interval) < 1000 or int(self.advertise_interval) > 255000:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of advertise_interval ranges from 1000 to 255000 milliseconds. The default value is 1000 milliseconds.')",
            "            if int(self.advertise_interval) % 1000 != 0:",
            "                self.module.fail_json(",
            "                    msg='Error: The advertisement interval value of VRRP must be a multiple of 1000 milliseconds.')",
            "        # preempt_timer_delay check",
            "        if self.preempt_timer_delay:",
            "            if not self.preempt_timer_delay.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of preempt_timer_delay is an integer.')",
            "            if int(self.preempt_timer_delay) < 1 or int(self.preempt_timer_delay) > 3600:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of preempt_timer_delay ranges from 1 to 3600. The default value is 0.')",
            "",
            "        # holding_multiplier check",
            "        if self.holding_multiplier:",
            "            if not self.holding_multiplier.isdigit():",
            "                self.module.fail_json(",
            "                    msg='Error: The value of holding_multiplier is an integer.')",
            "            if int(self.holding_multiplier) < 3 or int(self.holding_multiplier) > 10:",
            "                self.module.fail_json(",
            "                    msg='Error: The value of holding_multiplier ranges from 3 to 10. The default value is 3.')",
            "",
            "        # auth_key check",
            "        if self.auth_key:",
            "            if len(self.auth_key) > 16 \\",
            "                    or len(self.auth_key.replace(' ', '')) < 1:",
            "                self.module.fail_json(",
            "                    msg='Error: The length of auth_key is not in the range from 1 to 16.')",
            "",
            "    def is_virtual_ip_change(self):",
            "        \"\"\"whether virtual ip change\"\"\"",
            "",
            "        if not self.virtual_ip_info:",
            "            return True",
            "",
            "        for info in self.virtual_ip_info[\"vrrpVirtualIpInfos\"]:",
            "            if info[\"virtualIpAddress\"] == self.virtual_ip:",
            "                return False",
            "        return True",
            "",
            "    def is_virtual_ip_exist(self):",
            "        \"\"\"whether virtual ip info exist\"\"\"",
            "",
            "        if not self.virtual_ip_info:",
            "            return False",
            "",
            "        for info in self.virtual_ip_info[\"vrrpVirtualIpInfos\"]:",
            "            if info[\"virtualIpAddress\"] == self.virtual_ip:",
            "                return True",
            "        return False",
            "",
            "    def is_vrrp_global_info_change(self):",
            "        \"\"\"whether vrrp global attribute info change\"\"\"",
            "",
            "        if not self.vrrp_global_info:",
            "            return True",
            "",
            "        if self.gratuitous_arp_interval:",
            "            if self.vrrp_global_info[\"gratuitousArpFlag\"] == \"false\":",
            "                self.module.fail_json(msg=\"Error: gratuitousArpFlag is false.\")",
            "            if self.vrrp_global_info[\"gratuitousArpTimeOut\"] != self.gratuitous_arp_interval:",
            "                return True",
            "        if self.recover_delay:",
            "            if self.vrrp_global_info[\"recoverDelay\"] != self.recover_delay:",
            "                return True",
            "        if self.version:",
            "            if self.vrrp_global_info[\"version\"] != self.version:",
            "                return True",
            "        return False",
            "",
            "    def is_vrrp_global_info_exist(self):",
            "        \"\"\"whether vrrp global attribute info exist\"\"\"",
            "",
            "        if self.gratuitous_arp_interval or self.recover_delay or self.version:",
            "            if self.gratuitous_arp_interval:",
            "                if self.vrrp_global_info[\"gratuitousArpFlag\"] == \"false\":",
            "                    self.module.fail_json(",
            "                        msg=\"Error: gratuitousArpFlag is false.\")",
            "                if self.vrrp_global_info[\"gratuitousArpTimeOut\"] != self.gratuitous_arp_interval:",
            "                    return False",
            "            if self.recover_delay:",
            "                if self.vrrp_global_info[\"recoverDelay\"] != self.recover_delay:",
            "                    return False",
            "            if self.version:",
            "                if self.vrrp_global_info[\"version\"] != self.version:",
            "                    return False",
            "            return True",
            "",
            "        return False",
            "",
            "    def is_vrrp_group_info_change(self):",
            "        \"\"\"whether vrrp group attribute info change\"\"\"",
            "        if self.vrrp_type:",
            "            if self.vrrp_group_info[\"vrrpType\"] != self.vrrp_type:",
            "                return True",
            "        if self.admin_ignore_if_down:",
            "            if self.vrrp_group_info[\"adminIgnoreIfDown\"] != str(self.admin_ignore_if_down).lower():",
            "                return True",
            "        if self.admin_vrid:",
            "            if self.vrrp_group_info[\"adminVrrpId\"] != self.admin_vrid:",
            "                return True",
            "        if self.admin_interface:",
            "            if self.vrrp_group_info[\"adminIfName\"] != self.admin_interface:",
            "                return True",
            "        if self.admin_flowdown:",
            "            if self.vrrp_group_info[\"unflowdown\"] != self.admin_flowdown:",
            "                return True",
            "        if self.priority:",
            "            if self.vrrp_group_info[\"priority\"] != self.priority:",
            "                return True",
            "        if self.fast_resume:",
            "            fast_resume = \"false\"",
            "            if self.fast_resume == \"enable\":",
            "                fast_resume = \"true\"",
            "            if self.vrrp_group_info[\"fastResume\"] != fast_resume:",
            "                return True",
            "        if self.advertise_interval:",
            "            if self.vrrp_group_info[\"advertiseInterval\"] != self.advertise_interval:",
            "                return True",
            "        if self.preempt_timer_delay:",
            "            if self.vrrp_group_info[\"delayTime\"] != self.preempt_timer_delay:",
            "                return True",
            "        if self.holding_multiplier:",
            "            if self.vrrp_group_info[\"holdMultiplier\"] != self.holding_multiplier:",
            "                return True",
            "        if self.auth_mode:",
            "            if self.vrrp_group_info[\"authenticationMode\"] != self.auth_mode:",
            "                return True",
            "        if self.auth_key:",
            "            return True",
            "        if self.is_plain:",
            "            if self.vrrp_group_info[\"isPlain\"] != self.is_plain:",
            "                return True",
            "",
            "        return False",
            "",
            "    def is_vrrp_group_info_exist(self):",
            "        \"\"\"whether vrrp group attribute info exist\"\"\"",
            "",
            "        if self.vrrp_type:",
            "            if self.vrrp_group_info[\"vrrpType\"] != self.vrrp_type:",
            "                return False",
            "        if self.admin_ignore_if_down:",
            "            if self.vrrp_group_info[\"adminIgnoreIfDown\"] != str(self.admin_ignore_if_down).lower():",
            "                return False",
            "        if self.admin_vrid:",
            "            if self.vrrp_group_info[\"adminVrrpId\"] != self.admin_vrid:",
            "                return False",
            "        if self.admin_interface:",
            "            if self.vrrp_group_info[\"adminIfName\"] != self.admin_interface:",
            "                return False",
            "        if self.admin_flowdown:",
            "            if self.vrrp_group_info[\"unflowdown\"] != self.admin_flowdown:",
            "                return False",
            "        if self.priority:",
            "            if self.vrrp_group_info[\"priority\"] != self.priority:",
            "                return False",
            "        if self.fast_resume:",
            "            fast_resume = \"false\"",
            "            if self.fast_resume == \"enable\":",
            "                fast_resume = \"true\"",
            "            if self.vrrp_group_info[\"fastResume\"] != fast_resume:",
            "                return False",
            "        if self.advertise_interval:",
            "            if self.vrrp_group_info[\"advertiseInterval\"] != self.advertise_interval:",
            "                return False",
            "        if self.preempt_timer_delay:",
            "            if self.vrrp_group_info[\"delayTime\"] != self.preempt_timer_delay:",
            "                return False",
            "        if self.holding_multiplier:",
            "            if self.vrrp_group_info[\"holdMultiplier\"] != self.holding_multiplier:",
            "                return False",
            "        if self.auth_mode:",
            "            if self.vrrp_group_info[\"authenticationMode\"] != self.auth_mode:",
            "                return False",
            "        if self.is_plain:",
            "            if self.vrrp_group_info[\"isPlain\"] != self.is_plain:",
            "                return False",
            "        return True",
            "",
            "    def create_virtual_ip(self):",
            "        \"\"\"create virtual ip info\"\"\"",
            "",
            "        if self.is_virtual_ip_change():",
            "            conf_str = CE_NC_CREATE_VRRP_VIRTUAL_IP_INFO % (",
            "                self.vrid, self.interface, self.virtual_ip)",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: create virtual ip info failed.')",
            "",
            "            self.updates_cmd.append(\"interface %s\" % self.interface)",
            "            self.updates_cmd.append(",
            "                \"vrrp vrid %s virtual-ip %s\" % (self.vrid, self.virtual_ip))",
            "            self.changed = True",
            "",
            "    def delete_virtual_ip(self):",
            "        \"\"\"delete virtual ip info\"\"\"",
            "",
            "        if self.is_virtual_ip_exist():",
            "            conf_str = CE_NC_DELETE_VRRP_VIRTUAL_IP_INFO % (",
            "                self.vrid, self.interface, self.virtual_ip)",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: delete virtual ip info failed.')",
            "",
            "            self.updates_cmd.append(\"interface %s\" % self.interface)",
            "            self.updates_cmd.append(",
            "                \"undo vrrp vrid %s virtual-ip %s \" % (self.vrid, self.virtual_ip))",
            "            self.changed = True",
            "",
            "    def set_vrrp_global(self):",
            "        \"\"\"set vrrp global attribute info\"\"\"",
            "",
            "        if self.is_vrrp_global_info_change():",
            "            conf_str = CE_NC_SET_VRRP_GLOBAL_HEAD",
            "            if self.gratuitous_arp_interval:",
            "                conf_str += \"<gratuitousArpTimeOut>%s</gratuitousArpTimeOut>\" % self.gratuitous_arp_interval",
            "            if self.recover_delay:",
            "                conf_str += \"<recoverDelay>%s</recoverDelay>\" % self.recover_delay",
            "            if self.version:",
            "                conf_str += \"<version>%s</version>\" % self.version",
            "            conf_str += CE_NC_SET_VRRP_GLOBAL_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp global attribute info failed.')",
            "",
            "            if self.gratuitous_arp_interval:",
            "                self.updates_cmd.append(",
            "                    \"vrrp gratuitous-arp interval %s\" % self.gratuitous_arp_interval)",
            "",
            "            if self.recover_delay:",
            "                self.updates_cmd.append(",
            "                    \"vrrp recover-delay %s\" % self.recover_delay)",
            "",
            "            if self.version:",
            "                version = \"3\"",
            "                if self.version == \"v2\":",
            "                    version = \"2\"",
            "                self.updates_cmd.append(\"vrrp version %s\" % version)",
            "            self.changed = True",
            "",
            "    def delete_vrrp_global(self):",
            "        \"\"\"delete vrrp global attribute info\"\"\"",
            "",
            "        if self.is_vrrp_global_info_exist():",
            "            conf_str = CE_NC_SET_VRRP_GLOBAL_HEAD",
            "            if self.gratuitous_arp_interval:",
            "                if self.gratuitous_arp_interval == \"120\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of gratuitous_arp_interval is 120.')",
            "                gratuitous_arp_interval = \"120\"",
            "                conf_str += \"<gratuitousArpTimeOut>%s</gratuitousArpTimeOut>\" % gratuitous_arp_interval",
            "            if self.recover_delay:",
            "                if self.recover_delay == \"0\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of recover_delay is 0.')",
            "                recover_delay = \"0\"",
            "                conf_str += \"<recoverDelay>%s</recoverDelay>\" % recover_delay",
            "            if self.version:",
            "                if self.version == \"v2\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of version is v2.')",
            "                version = \"v2\"",
            "                conf_str += \"<version>%s</version>\" % version",
            "            conf_str += CE_NC_SET_VRRP_GLOBAL_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp global attribute info failed.')",
            "            if self.gratuitous_arp_interval:",
            "                self.updates_cmd.append(\"undo vrrp gratuitous-arp interval\")",
            "",
            "            if self.recover_delay:",
            "                self.updates_cmd.append(\"undo vrrp recover-delay\")",
            "",
            "            if self.version == \"v3\":",
            "                self.updates_cmd.append(\"undo vrrp version\")",
            "            self.changed = True",
            "",
            "    def set_vrrp_group(self):",
            "        \"\"\"set vrrp group attribute info\"\"\"",
            "",
            "        if self.is_vrrp_group_info_change():",
            "            conf_str = CE_NC_SET_VRRP_GROUP_INFO_HEAD % (",
            "                self.interface, self.vrid)",
            "            if self.vrrp_type:",
            "                conf_str += \"<vrrpType>%s</vrrpType>\" % self.vrrp_type",
            "            if self.admin_vrid:",
            "                conf_str += \"<adminVrrpId>%s</adminVrrpId>\" % self.admin_vrid",
            "            if self.admin_interface:",
            "                conf_str += \"<adminIfName>%s</adminIfName>\" % self.admin_interface",
            "                if self.admin_flowdown is True or self.admin_flowdown is False:",
            "                    admin_flowdown = \"false\"",
            "                    if self.admin_flowdown is True:",
            "                        admin_flowdown = \"true\"",
            "                    conf_str += \"<unflowdown>%s</unflowdown>\" % admin_flowdown",
            "            if self.priority:",
            "                conf_str += \"<priority>%s</priority>\" % self.priority",
            "            if self.vrrp_type == \"admin\":",
            "                if self.admin_ignore_if_down is True or self.admin_ignore_if_down is False:",
            "                    admin_ignore_if_down = \"false\"",
            "                    if self.admin_ignore_if_down is True:",
            "                        admin_ignore_if_down = \"true\"",
            "                    conf_str += \"<adminIgnoreIfDown>%s</adminIgnoreIfDown>\" % admin_ignore_if_down",
            "            if self.fast_resume:",
            "                fast_resume = \"false\"",
            "                if self.fast_resume == \"enable\":",
            "                    fast_resume = \"true\"",
            "                conf_str += \"<fastResume>%s</fastResume>\" % fast_resume",
            "            if self.advertise_interval:",
            "                conf_str += \"<advertiseInterval>%s</advertiseInterval>\" % self.advertise_interval",
            "            if self.preempt_timer_delay:",
            "                conf_str += \"<delayTime>%s</delayTime>\" % self.preempt_timer_delay",
            "            if self.holding_multiplier:",
            "                conf_str += \"<holdMultiplier>%s</holdMultiplier>\" % self.holding_multiplier",
            "            if self.auth_mode:",
            "                conf_str += \"<authenticationMode>%s</authenticationMode>\" % self.auth_mode",
            "            if self.auth_key:",
            "                conf_str += \"<authenticationKey>%s</authenticationKey>\" % self.auth_key",
            "            if self.auth_mode == \"simple\":",
            "                is_plain = \"false\"",
            "                if self.is_plain is True:",
            "                    is_plain = \"true\"",
            "                conf_str += \"<isPlain>%s</isPlain>\" % is_plain",
            "",
            "            conf_str += CE_NC_SET_VRRP_GROUP_INFO_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp group attribute info failed.')",
            "            if self.interface and self.vrid:",
            "                self.updates_cmd.append(\"interface %s\" % self.interface)",
            "                if self.vrrp_type == \"admin\":",
            "                    if self.admin_ignore_if_down is True:",
            "                        self.updates_cmd.append(",
            "                            \"vrrp vrid %s admin ignore-if-down\" % self.vrid)",
            "                    else:",
            "                        self.updates_cmd.append(",
            "                            \"vrrp vrid %s admin\" % self.vrid)",
            "",
            "                if self.priority:",
            "                    self.updates_cmd.append(",
            "                        \"vrrp vrid %s priority %s\" % (self.vrid, self.priority))",
            "",
            "                if self.fast_resume == \"enable\":",
            "                    self.updates_cmd.append(",
            "                        \"vrrp vrid %s fast-resume\" % self.vrid)",
            "                if self.fast_resume == \"disable\":",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s fast-resume\" % self.vrid)",
            "",
            "                if self.advertise_interval:",
            "                    advertise_interval = int(self.advertise_interval) / 1000",
            "                    self.updates_cmd.append(\"vrrp vrid %s timer advertise %s<seconds>\" % (",
            "                        self.vrid, int(advertise_interval)))",
            "",
            "                if self.preempt_timer_delay:",
            "                    self.updates_cmd.append(\"vrrp vrid %s preempt timer delay %s\" % (self.vrid,",
            "                                                                                     self.preempt_timer_delay))",
            "",
            "                if self.holding_multiplier:",
            "                    self.updates_cmd.append(",
            "                        \"vrrp vrid %s holding-multiplier %s\" % (self.vrid, self.holding_multiplier))",
            "",
            "                if self.admin_vrid and self.admin_interface:",
            "                    if self.admin_flowdown == \"true\":",
            "                        self.updates_cmd.append(\"vrrp vrid %s track admin-vrrp interface %s vrid %s unflowdown\" %",
            "                                                (self.vrid, self.admin_interface, self.admin_vrid))",
            "                    else:",
            "                        self.updates_cmd.append(\"vrrp vrid %s track admin-vrrp interface %s vrid %s\" %",
            "                                                (self.vrid, self.admin_interface, self.admin_vrid))",
            "",
            "                if self.auth_mode and self.auth_key:",
            "                    if self.auth_mode == \"simple\":",
            "                        if self.is_plain == \"true\":",
            "                            self.updates_cmd.append(\"vrrp vrid %s authentication-mode simple plain %s\" %",
            "                                                    (self.vrid, self.auth_key))",
            "                        else:",
            "                            self.updates_cmd.append(\"vrrp vrid %s authentication-mode simple cipher %s\" %",
            "                                                    (self.vrid, self.auth_key))",
            "                    if self.auth_mode == \"md5\":",
            "                        self.updates_cmd.append(",
            "                            \"vrrp vrid %s authentication-mode md5 %s\" % (self.vrid, self.auth_key))",
            "                self.changed = True",
            "",
            "    def delete_vrrp_group(self):",
            "        \"\"\"delete vrrp group attribute info\"\"\"",
            "",
            "        if self.is_vrrp_group_info_exist():",
            "            conf_str = CE_NC_SET_VRRP_GROUP_INFO_HEAD % (",
            "                self.interface, self.vrid)",
            "            if self.vrrp_type:",
            "                vrrp_type = self.vrrp_type",
            "                if self.vrrp_type == \"admin\":",
            "                    vrrp_type = \"normal\"",
            "                if self.vrrp_type == \"member\" and self.admin_vrid and self.admin_interface:",
            "                    vrrp_type = \"normal\"",
            "                conf_str += \"<vrrpType>%s</vrrpType>\" % vrrp_type",
            "            if self.priority:",
            "                if self.priority == \"100\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of priority is 100.')",
            "                priority = \"100\"",
            "                conf_str += \"<priority>%s</priority>\" % priority",
            "",
            "            if self.fast_resume:",
            "                fast_resume = \"false\"",
            "                if self.fast_resume == \"enable\":",
            "                    fast_resume = \"true\"",
            "                conf_str += \"<fastResume>%s</fastResume>\" % fast_resume",
            "            if self.advertise_interval:",
            "                if self.advertise_interval == \"1000\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of advertise_interval is 1000.')",
            "                advertise_interval = \"1000\"",
            "                conf_str += \"<advertiseInterval>%s</advertiseInterval>\" % advertise_interval",
            "            if self.preempt_timer_delay:",
            "                if self.preempt_timer_delay == \"0\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of preempt_timer_delay is 0.')",
            "                preempt_timer_delay = \"0\"",
            "                conf_str += \"<delayTime>%s</delayTime>\" % preempt_timer_delay",
            "            if self.holding_multiplier:",
            "                if self.holding_multiplier == \"0\":",
            "                    self.module.fail_json(",
            "                        msg='Error: The default value of holding_multiplier is 3.')",
            "                holding_multiplier = \"3\"",
            "                conf_str += \"<holdMultiplier>%s</holdMultiplier>\" % holding_multiplier",
            "            if self.auth_mode:",
            "                auth_mode = self.auth_mode",
            "                if self.auth_mode == \"md5\" or self.auth_mode == \"simple\":",
            "                    auth_mode = \"none\"",
            "                conf_str += \"<authenticationMode>%s</authenticationMode>\" % auth_mode",
            "",
            "            conf_str += CE_NC_SET_VRRP_GROUP_INFO_TAIL",
            "            recv_xml = set_nc_config(self.module, conf_str)",
            "            if \"<ok/>\" not in recv_xml:",
            "                self.module.fail_json(",
            "                    msg='Error: set vrrp global attribute info failed.')",
            "            if self.interface and self.vrid:",
            "                self.updates_cmd.append(\"interface %s\" % self.interface)",
            "                if self.vrrp_type == \"admin\":",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s admin\" % self.vrid)",
            "",
            "                if self.priority:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s priority\" % self.vrid)",
            "",
            "                if self.fast_resume:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s fast-resume\" % self.vrid)",
            "",
            "                if self.advertise_interval:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s timer advertise\" % self.vrid)",
            "",
            "                if self.preempt_timer_delay:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s preempt timer delay\" % self.vrid)",
            "",
            "                if self.holding_multiplier:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s holding-multiplier\" % self.vrid)",
            "",
            "                if self.admin_vrid and self.admin_interface:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s track admin-vrrp\" % self.vrid)",
            "",
            "                if self.auth_mode:",
            "                    self.updates_cmd.append(",
            "                        \"undo vrrp vrid %s authentication-mode\" % self.vrid)",
            "                self.changed = True",
            "",
            "    def get_proposed(self):",
            "        \"\"\"get proposed info\"\"\"",
            "",
            "        if self.interface:",
            "            self.proposed[\"interface\"] = self.interface",
            "        if self.vrid:",
            "            self.proposed[\"vrid\"] = self.vrid",
            "        if self.virtual_ip:",
            "            self.proposed[\"virtual_ip\"] = self.virtual_ip",
            "        if self.vrrp_type:",
            "            self.proposed[\"vrrp_type\"] = self.vrrp_type",
            "        if self.admin_vrid:",
            "            self.proposed[\"admin_vrid\"] = self.admin_vrid",
            "        if self.admin_interface:",
            "            self.proposed[\"admin_interface\"] = self.admin_interface",
            "        if self.admin_flowdown:",
            "            self.proposed[\"unflowdown\"] = self.admin_flowdown",
            "        if self.admin_ignore_if_down:",
            "            self.proposed[\"admin_ignore_if_down\"] = self.admin_ignore_if_down",
            "        if self.priority:",
            "            self.proposed[\"priority\"] = self.priority",
            "        if self.version:",
            "            self.proposed[\"version\"] = self.version",
            "        if self.advertise_interval:",
            "            self.proposed[\"advertise_interval\"] = self.advertise_interval",
            "        if self.preempt_timer_delay:",
            "            self.proposed[\"preempt_timer_delay\"] = self.preempt_timer_delay",
            "        if self.gratuitous_arp_interval:",
            "            self.proposed[",
            "                \"gratuitous_arp_interval\"] = self.gratuitous_arp_interval",
            "        if self.recover_delay:",
            "            self.proposed[\"recover_delay\"] = self.recover_delay",
            "        if self.holding_multiplier:",
            "            self.proposed[\"holding_multiplier\"] = self.holding_multiplier",
            "        if self.auth_mode:",
            "            self.proposed[\"auth_mode\"] = self.auth_mode",
            "        if self.is_plain:",
            "            self.proposed[\"is_plain\"] = self.is_plain",
            "        if self.auth_key:",
            "            self.proposed[\"auth_key\"] = self.auth_key",
            "        if self.fast_resume:",
            "            self.proposed[\"fast_resume\"] = self.fast_resume",
            "        if self.state:",
            "            self.proposed[\"state\"] = self.state",
            "",
            "    def get_existing(self):",
            "        \"\"\"get existing info\"\"\"",
            "",
            "        if self.gratuitous_arp_interval:",
            "            self.existing[\"gratuitous_arp_interval\"] = self.vrrp_global_info[",
            "                \"gratuitousArpTimeOut\"]",
            "        if self.version:",
            "            self.existing[\"version\"] = self.vrrp_global_info[\"version\"]",
            "        if self.recover_delay:",
            "            self.existing[\"recover_delay\"] = self.vrrp_global_info[",
            "                \"recoverDelay\"]",
            "",
            "        if self.virtual_ip:",
            "            if self.virtual_ip_info:",
            "                self.existing[\"interface\"] = self.interface",
            "                self.existing[\"vrid\"] = self.vrid",
            "                self.existing[\"virtual_ip_info\"] = self.virtual_ip_info[",
            "                    \"vrrpVirtualIpInfos\"]",
            "",
            "        if self.vrrp_group_info:",
            "            self.existing[\"interface\"] = self.vrrp_group_info[\"ifName\"]",
            "            self.existing[\"vrid\"] = self.vrrp_group_info[\"vrrpId\"]",
            "            self.existing[\"vrrp_type\"] = self.vrrp_group_info[\"vrrpType\"]",
            "            if self.vrrp_type == \"admin\":",
            "                self.existing[\"admin_ignore_if_down\"] = self.vrrp_group_info[",
            "                    \"adminIgnoreIfDown\"]",
            "            if self.admin_vrid and self.admin_interface:",
            "                self.existing[\"admin_vrid\"] = self.vrrp_group_info[",
            "                    \"adminVrrpId\"]",
            "                self.existing[\"admin_interface\"] = self.vrrp_group_info[",
            "                    \"adminIfName\"]",
            "                self.existing[\"admin_flowdown\"] = self.vrrp_group_info[",
            "                    \"unflowdown\"]",
            "            if self.priority:",
            "                self.existing[\"priority\"] = self.vrrp_group_info[\"priority\"]",
            "            if self.advertise_interval:",
            "                self.existing[\"advertise_interval\"] = self.vrrp_group_info[",
            "                    \"advertiseInterval\"]",
            "            if self.preempt_timer_delay:",
            "                self.existing[\"preempt_timer_delay\"] = self.vrrp_group_info[",
            "                    \"delayTime\"]",
            "            if self.holding_multiplier:",
            "                self.existing[\"holding_multiplier\"] = self.vrrp_group_info[",
            "                    \"holdMultiplier\"]",
            "            if self.fast_resume:",
            "                fast_resume_exist = \"disable\"",
            "                fast_resume = self.vrrp_group_info[\"fastResume\"]",
            "                if fast_resume == \"true\":",
            "                    fast_resume_exist = \"enable\"",
            "                self.existing[\"fast_resume\"] = fast_resume_exist",
            "            if self.auth_mode:",
            "                self.existing[\"auth_mode\"] = self.vrrp_group_info[",
            "                    \"authenticationMode\"]",
            "                self.existing[\"is_plain\"] = self.vrrp_group_info[\"isPlain\"]",
            "",
            "    def get_end_state(self):",
            "        \"\"\"get end state info\"\"\"",
            "",
            "        if self.gratuitous_arp_interval or self.version or self.recover_delay:",
            "            self.vrrp_global_info = self.get_vrrp_global_info()",
            "        if self.interface and self.vrid:",
            "            if self.virtual_ip:",
            "                self.virtual_ip_info = self.get_virtual_ip_info()",
            "            if self.virtual_ip_info:",
            "                self.vrrp_group_info = self.get_vrrp_group_info()",
            "",
            "        if self.gratuitous_arp_interval:",
            "            self.end_state[\"gratuitous_arp_interval\"] = self.vrrp_global_info[",
            "                \"gratuitousArpTimeOut\"]",
            "        if self.version:",
            "            self.end_state[\"version\"] = self.vrrp_global_info[\"version\"]",
            "        if self.recover_delay:",
            "            self.end_state[\"recover_delay\"] = self.vrrp_global_info[",
            "                \"recoverDelay\"]",
            "",
            "        if self.virtual_ip:",
            "            if self.virtual_ip_info:",
            "                self.end_state[\"interface\"] = self.interface",
            "                self.end_state[\"vrid\"] = self.vrid",
            "                self.end_state[\"virtual_ip_info\"] = self.virtual_ip_info[",
            "                    \"vrrpVirtualIpInfos\"]",
            "",
            "        if self.vrrp_group_info:",
            "            self.end_state[\"interface\"] = self.vrrp_group_info[\"ifName\"]",
            "            self.end_state[\"vrid\"] = self.vrrp_group_info[\"vrrpId\"]",
            "            self.end_state[\"vrrp_type\"] = self.vrrp_group_info[\"vrrpType\"]",
            "            if self.vrrp_type == \"admin\":",
            "                self.end_state[\"admin_ignore_if_down\"] = self.vrrp_group_info[",
            "                    \"adminIgnoreIfDown\"]",
            "            if self.admin_vrid and self.admin_interface:",
            "                self.existing[\"admin_vrid\"] = self.vrrp_group_info[",
            "                    \"adminVrrpId\"]",
            "                self.end_state[\"admin_interface\"] = self.vrrp_group_info[",
            "                    \"adminIfName\"]",
            "                self.end_state[\"admin_flowdown\"] = self.vrrp_group_info[",
            "                    \"unflowdown\"]",
            "            if self.priority:",
            "                self.end_state[\"priority\"] = self.vrrp_group_info[\"priority\"]",
            "            if self.advertise_interval:",
            "                self.end_state[\"advertise_interval\"] = self.vrrp_group_info[",
            "                    \"advertiseInterval\"]",
            "            if self.preempt_timer_delay:",
            "                self.end_state[\"preempt_timer_delay\"] = self.vrrp_group_info[",
            "                    \"delayTime\"]",
            "            if self.holding_multiplier:",
            "                self.end_state[\"holding_multiplier\"] = self.vrrp_group_info[",
            "                    \"holdMultiplier\"]",
            "            if self.fast_resume:",
            "                fast_resume_end = \"disable\"",
            "                fast_resume = self.vrrp_group_info[\"fastResume\"]",
            "                if fast_resume == \"true\":",
            "                    fast_resume_end = \"enable\"",
            "                self.end_state[\"fast_resume\"] = fast_resume_end",
            "            if self.auth_mode:",
            "                self.end_state[\"auth_mode\"] = self.vrrp_group_info[",
            "                    \"authenticationMode\"]",
            "                self.end_state[\"is_plain\"] = self.vrrp_group_info[\"isPlain\"]",
            "",
            "    def work(self):",
            "        \"\"\"worker\"\"\"",
            "",
            "        self.check_params()",
            "        if self.gratuitous_arp_interval or self.version or self.recover_delay:",
            "            self.vrrp_global_info = self.get_vrrp_global_info()",
            "        if self.interface and self.vrid:",
            "            self.virtual_ip_info = self.get_virtual_ip_info()",
            "            if self.virtual_ip_info:",
            "                self.vrrp_group_info = self.get_vrrp_group_info()",
            "        self.get_proposed()",
            "        self.get_existing()",
            "",
            "        if self.gratuitous_arp_interval or self.version or self.recover_delay:",
            "            if self.state == \"present\":",
            "                self.set_vrrp_global()",
            "            else:",
            "                self.delete_vrrp_global()",
            "        else:",
            "            if not self.interface or not self.vrid:",
            "                self.module.fail_json(",
            "                    msg='Error: interface, vrid must be config at the same time.')",
            "",
            "        if self.interface and self.vrid:",
            "            if self.virtual_ip:",
            "                if self.state == \"present\":",
            "                    self.create_virtual_ip()",
            "                else:",
            "                    self.delete_virtual_ip()",
            "            else:",
            "                if not self.vrrp_group_info:",
            "                    self.module.fail_json(",
            "                        msg='Error: The VRRP group does not exist.')",
            "                if self.admin_ignore_if_down is True:",
            "                    if self.vrrp_type != \"admin\":",
            "                        self.module.fail_json(",
            "                            msg='Error: vrrpType must be admin when admin_ignore_if_down is true.')",
            "                if self.admin_interface or self.admin_vrid:",
            "                    if self.vrrp_type != \"member\":",
            "                        self.module.fail_json(",
            "                            msg='Error: it binds a VRRP group to an mVRRP group, vrrp_type must be \"member\".')",
            "                    if not self.vrrp_type or not self.interface or not self.vrid:",
            "                        self.module.fail_json(",
            "                            msg='Error: admin_interface admin_vrid vrrp_type interface vrid must '",
            "                                'be config at the same time.')",
            "                if self.auth_mode == \"md5\" and self.is_plain == \"true\":",
            "                    self.module.fail_json(",
            "                        msg='Error: is_plain can not be True when auth_mode is md5.')",
            "",
            "                if self.state == \"present\":",
            "                    self.set_vrrp_group()",
            "                else:",
            "                    self.delete_vrrp_group()",
            "",
            "        self.get_end_state()",
            "        self.results['changed'] = self.changed",
            "        self.results['proposed'] = self.proposed",
            "        self.results['existing'] = self.existing",
            "        self.results['end_state'] = self.end_state",
            "        if self.changed:",
            "            self.results['updates'] = self.updates_cmd",
            "        else:",
            "            self.results['updates'] = list()",
            "",
            "        self.module.exit_json(**self.results)",
            "",
            "",
            "def main():",
            "    \"\"\" Module main \"\"\"",
            "",
            "    argument_spec = dict(",
            "        interface=dict(type='str'),",
            "        vrid=dict(type='str'),",
            "        virtual_ip=dict(type='str'),",
            "        vrrp_type=dict(type='str', choices=['normal', 'member', 'admin']),",
            "        admin_ignore_if_down=dict(type='bool', default=False),",
            "        admin_vrid=dict(type='str'),",
            "        admin_interface=dict(type='str'),",
            "        admin_flowdown=dict(type='bool', default=False),",
            "        priority=dict(type='str'),",
            "        version=dict(type='str', choices=['v2', 'v3']),",
            "        advertise_interval=dict(type='str'),",
            "        preempt_timer_delay=dict(type='str'),",
            "        gratuitous_arp_interval=dict(type='str'),",
            "        recover_delay=dict(type='str'),",
            "        holding_multiplier=dict(type='str'),",
            "        auth_mode=dict(type='str', choices=['simple', 'md5', 'none']),",
            "        is_plain=dict(type='bool', default=False),",
            "        auth_key=dict(type='str', no_log=True),",
            "        fast_resume=dict(type='str', choices=['enable', 'disable']),",
            "        state=dict(type='str', default='present',",
            "                   choices=['present', 'absent'])",
            "    )",
            "",
            "    argument_spec.update(ce_argument_spec)",
            "    module = Vrrp(argument_spec=argument_spec)",
            "    module.work()",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "1319": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/network/itential/iap_start_workflow.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 169,
                "afterPatchRowNumber": 169,
                "PatchRowcode": "         argument_spec=dict("
            },
            "1": {
                "beforePatchRowNumber": 170,
                "afterPatchRowNumber": 170,
                "PatchRowcode": "             iap_port=dict(type='str', required=True),"
            },
            "2": {
                "beforePatchRowNumber": 171,
                "afterPatchRowNumber": 171,
                "PatchRowcode": "             iap_fqdn=dict(type='str', required=True),"
            },
            "3": {
                "beforePatchRowNumber": 172,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            token_key=dict(type='str', required=True),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 172,
                "PatchRowcode": "+            token_key=dict(type='str', required=True, no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 173,
                "afterPatchRowNumber": 173,
                "PatchRowcode": "             workflow_name=dict(type='str', required=True),"
            },
            "6": {
                "beforePatchRowNumber": 174,
                "afterPatchRowNumber": 174,
                "PatchRowcode": "             description=dict(type='str', required=True),"
            },
            "7": {
                "beforePatchRowNumber": 175,
                "afterPatchRowNumber": 175,
                "PatchRowcode": "             variables=dict(type='dict', required=False),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright: (c) 2018, Itential <opensource@itential.com>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "\"\"\"",
            "This module provides the ability to start a workflow from Itential Automation Platform",
            "\"\"\"",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: iap_start_workflow",
            "version_added: \"2.8\"",
            "author: \"Itential (@cma0) <opensource@itential.com>\"",
            "short_description: Start a workflow in the Itential Automation Platform",
            "description:",
            "  - This will start a specified workflow in the Itential Automation Platform with given arguments.",
            "options:",
            "  iap_port:",
            "    description:",
            "      - Provide the port number for the Itential Automation Platform",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  iap_fqdn:",
            "    description:",
            "      - Provide the fqdn for the Itential Automation Platform",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  token_key:",
            "    description:",
            "      - Token key generated by iap_token module for the Itential Automation Platform",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  workflow_name:",
            "    description:",
            "      - Provide the workflow name",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  description:",
            "    description:",
            "      - Provide the description for the workflow",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  variables:",
            "    description:",
            "      - Provide the values to the job variables",
            "    required: true",
            "    type: dict",
            "    default: null",
            "",
            "  https:",
            "    description:",
            "      - Use HTTPS to connect",
            "      - By default using http",
            "    type: bool",
            "    default: False",
            "",
            "  validate_certs:",
            "    description:",
            "      - If C(no), SSL certificates for the target url will not be validated. This should only be used",
            "        on personally controlled sites using self-signed certificates.",
            "    type: bool",
            "    default: False",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Start a workflow in the Itential Automation Platform",
            "  iap_start_workflow:",
            "    iap_port: 3000",
            "    iap_fqdn: localhost",
            "    token_key: \"DFSFSFHFGFGF[DSFSFAADAFASD%3D\"",
            "    workflow_name: \"RouterUpgradeWorkflow\"",
            "    description: \"OS-Router-Upgrade\"",
            "    variables: {\"deviceName\":\"ASR9K\"}",
            "  register: result",
            "",
            "- debug: var=result",
            "'''",
            "",
            "RETURN = '''",
            "response:",
            "    description: The result contains the response from the call",
            "    type: dict",
            "    returned: always",
            "msg:",
            "    description: The msg will contain the error code or status of the workflow",
            "    type: str",
            "    returned: always",
            "'''",
            "",
            "# Ansible imports",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "",
            "# Standard library imports",
            "import json",
            "",
            "",
            "def start_workflow(module):",
            "    \"\"\"",
            "    :param module:",
            "    :return: response and msg",
            "    \"\"\"",
            "    # By default this will be http.",
            "    # By default when using https, self signed certificate is used",
            "    # If https needs to pass certificate then use validate_certs as true",
            "    if module.params['https']:",
            "        transport_protocol = 'https'",
            "    else:",
            "        transport_protocol = 'http'",
            "",
            "    application_token = str(module.params['token_key'])",
            "    url = str(transport_protocol) + \"://\" + str(module.params['iap_fqdn']) + \":\" + str(module.params[",
            "        'iap_port']) + \"/workflow_engine/startJobWithOptions/\" \\",
            "        + str(module.params['workflow_name']) + \"?token=\" + str(application_token)",
            "    options = {",
            "        \"variables\": module.params['variables'],",
            "        \"description\": str(module.params['description'])",
            "    }",
            "",
            "    payload = {",
            "        \"workflow\": module.params['workflow_name'],",
            "        \"options\": options",
            "    }",
            "",
            "    json_body = module.jsonify(payload)",
            "    headers = dict()",
            "    headers['Content-Type'] = 'application/json'",
            "",
            "    # Using fetch url instead of requests",
            "    response, info = fetch_url(module, url, data=json_body, headers=headers)",
            "    response_code = str(info['status'])",
            "    if info['status'] not in [200, 201]:",
            "        module.fail_json(msg=\"Failed to connect to Itential Automation Platform. Response code is \" + response_code)",
            "",
            "    # in the event of a successful module execution, you will want to",
            "    # simple AnsibleModule.exit_json(), passing the key/value results",
            "    jsonResponse = json.loads(response.read().decode('utf-8'))",
            "    module.exit_json(changed=True, msg={\"workflow_name\": module.params['workflow_name'], \"status\": \"started\"},",
            "                     response=jsonResponse)",
            "",
            "",
            "def main():",
            "    \"\"\"",
            "    :return: response and msg",
            "    \"\"\"",
            "    # define the available arguments/parameters that a user can pass to",
            "    # the module",
            "    # the AnsibleModule object will be our abstraction working with Ansible",
            "    # this includes instantiation, a couple of common attr would be the",
            "    # args/params passed to the execution, as well as if the module",
            "    # supports check mode",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            iap_port=dict(type='str', required=True),",
            "            iap_fqdn=dict(type='str', required=True),",
            "            token_key=dict(type='str', required=True),",
            "            workflow_name=dict(type='str', required=True),",
            "            description=dict(type='str', required=True),",
            "            variables=dict(type='dict', required=False),",
            "            https=(dict(type='bool', default=False)),",
            "            validate_certs=dict(type='bool', default=False)",
            "        )",
            "    )",
            "    start_workflow(module)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "",
            "# Copyright: (c) 2018, Itential <opensource@itential.com>",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "\"\"\"",
            "This module provides the ability to start a workflow from Itential Automation Platform",
            "\"\"\"",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "DOCUMENTATION = '''",
            "---",
            "module: iap_start_workflow",
            "version_added: \"2.8\"",
            "author: \"Itential (@cma0) <opensource@itential.com>\"",
            "short_description: Start a workflow in the Itential Automation Platform",
            "description:",
            "  - This will start a specified workflow in the Itential Automation Platform with given arguments.",
            "options:",
            "  iap_port:",
            "    description:",
            "      - Provide the port number for the Itential Automation Platform",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  iap_fqdn:",
            "    description:",
            "      - Provide the fqdn for the Itential Automation Platform",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  token_key:",
            "    description:",
            "      - Token key generated by iap_token module for the Itential Automation Platform",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  workflow_name:",
            "    description:",
            "      - Provide the workflow name",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  description:",
            "    description:",
            "      - Provide the description for the workflow",
            "    required: true",
            "    type: str",
            "    default: null",
            "",
            "  variables:",
            "    description:",
            "      - Provide the values to the job variables",
            "    required: true",
            "    type: dict",
            "    default: null",
            "",
            "  https:",
            "    description:",
            "      - Use HTTPS to connect",
            "      - By default using http",
            "    type: bool",
            "    default: False",
            "",
            "  validate_certs:",
            "    description:",
            "      - If C(no), SSL certificates for the target url will not be validated. This should only be used",
            "        on personally controlled sites using self-signed certificates.",
            "    type: bool",
            "    default: False",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Start a workflow in the Itential Automation Platform",
            "  iap_start_workflow:",
            "    iap_port: 3000",
            "    iap_fqdn: localhost",
            "    token_key: \"DFSFSFHFGFGF[DSFSFAADAFASD%3D\"",
            "    workflow_name: \"RouterUpgradeWorkflow\"",
            "    description: \"OS-Router-Upgrade\"",
            "    variables: {\"deviceName\":\"ASR9K\"}",
            "  register: result",
            "",
            "- debug: var=result",
            "'''",
            "",
            "RETURN = '''",
            "response:",
            "    description: The result contains the response from the call",
            "    type: dict",
            "    returned: always",
            "msg:",
            "    description: The msg will contain the error code or status of the workflow",
            "    type: str",
            "    returned: always",
            "'''",
            "",
            "# Ansible imports",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.urls import fetch_url",
            "",
            "# Standard library imports",
            "import json",
            "",
            "",
            "def start_workflow(module):",
            "    \"\"\"",
            "    :param module:",
            "    :return: response and msg",
            "    \"\"\"",
            "    # By default this will be http.",
            "    # By default when using https, self signed certificate is used",
            "    # If https needs to pass certificate then use validate_certs as true",
            "    if module.params['https']:",
            "        transport_protocol = 'https'",
            "    else:",
            "        transport_protocol = 'http'",
            "",
            "    application_token = str(module.params['token_key'])",
            "    url = str(transport_protocol) + \"://\" + str(module.params['iap_fqdn']) + \":\" + str(module.params[",
            "        'iap_port']) + \"/workflow_engine/startJobWithOptions/\" \\",
            "        + str(module.params['workflow_name']) + \"?token=\" + str(application_token)",
            "    options = {",
            "        \"variables\": module.params['variables'],",
            "        \"description\": str(module.params['description'])",
            "    }",
            "",
            "    payload = {",
            "        \"workflow\": module.params['workflow_name'],",
            "        \"options\": options",
            "    }",
            "",
            "    json_body = module.jsonify(payload)",
            "    headers = dict()",
            "    headers['Content-Type'] = 'application/json'",
            "",
            "    # Using fetch url instead of requests",
            "    response, info = fetch_url(module, url, data=json_body, headers=headers)",
            "    response_code = str(info['status'])",
            "    if info['status'] not in [200, 201]:",
            "        module.fail_json(msg=\"Failed to connect to Itential Automation Platform. Response code is \" + response_code)",
            "",
            "    # in the event of a successful module execution, you will want to",
            "    # simple AnsibleModule.exit_json(), passing the key/value results",
            "    jsonResponse = json.loads(response.read().decode('utf-8'))",
            "    module.exit_json(changed=True, msg={\"workflow_name\": module.params['workflow_name'], \"status\": \"started\"},",
            "                     response=jsonResponse)",
            "",
            "",
            "def main():",
            "    \"\"\"",
            "    :return: response and msg",
            "    \"\"\"",
            "    # define the available arguments/parameters that a user can pass to",
            "    # the module",
            "    # the AnsibleModule object will be our abstraction working with Ansible",
            "    # this includes instantiation, a couple of common attr would be the",
            "    # args/params passed to the execution, as well as if the module",
            "    # supports check mode",
            "    module = AnsibleModule(",
            "        argument_spec=dict(",
            "            iap_port=dict(type='str', required=True),",
            "            iap_fqdn=dict(type='str', required=True),",
            "            token_key=dict(type='str', required=True, no_log=True),",
            "            workflow_name=dict(type='str', required=True),",
            "            description=dict(type='str', required=True),",
            "            variables=dict(type='dict', required=False),",
            "            https=(dict(type='bool', default=False)),",
            "            validate_certs=dict(type='bool', default=False)",
            "        )",
            "    )",
            "    start_workflow(module)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "172": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/network/netscaler/netscaler_lb_monitor.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 986,
                "afterPatchRowNumber": 986,
                "PatchRowcode": "         secondarypassword=dict(type='str'),"
            },
            "1": {
                "beforePatchRowNumber": 987,
                "afterPatchRowNumber": 987,
                "PatchRowcode": "         logonpointname=dict(type='str'),"
            },
            "2": {
                "beforePatchRowNumber": 988,
                "afterPatchRowNumber": 988,
                "PatchRowcode": "         lasversion=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 989,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        radkey=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 989,
                "PatchRowcode": "+        radkey=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 990,
                "afterPatchRowNumber": 990,
                "PatchRowcode": "         radnasid=dict(type='str'),"
            },
            "6": {
                "beforePatchRowNumber": 991,
                "afterPatchRowNumber": 991,
                "PatchRowcode": "         radnasip=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 992,
                "afterPatchRowNumber": 992,
                "PatchRowcode": "         radaccounttype=dict(type='float'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "",
            "#  Copyright (c) 2017 Citrix Systems",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "module: netscaler_lb_monitor",
            "short_description: Manage load balancing monitors",
            "description:",
            "    - Manage load balancing monitors.",
            "    - This module is intended to run either on the ansible  control node or a bastion (jumpserver) with access to the actual netscaler instance.",
            "",
            "version_added: \"2.4\"",
            "",
            "author: George Nikolopoulos (@giorgos-nikolopoulos)",
            "",
            "options:",
            "",
            "    monitorname:",
            "        description:",
            "            - >-",
            "                Name for the monitor. Must begin with an ASCII alphanumeric or underscore C(_) character, and must",
            "                contain only ASCII alphanumeric, underscore, hash C(#), period C(.), space C( ), colon C(:), at C(@), equals",
            "                C(=), and hyphen C(-) characters.",
            "            - \"Minimum length = 1\"",
            "",
            "    type:",
            "        choices:",
            "            - 'PING'",
            "            - 'TCP'",
            "            - 'HTTP'",
            "            - 'TCP-ECV'",
            "            - 'HTTP-ECV'",
            "            - 'UDP-ECV'",
            "            - 'DNS'",
            "            - 'FTP'",
            "            - 'LDNS-PING'",
            "            - 'LDNS-TCP'",
            "            - 'LDNS-DNS'",
            "            - 'RADIUS'",
            "            - 'USER'",
            "            - 'HTTP-INLINE'",
            "            - 'SIP-UDP'",
            "            - 'SIP-TCP'",
            "            - 'LOAD'",
            "            - 'FTP-EXTENDED'",
            "            - 'SMTP'",
            "            - 'SNMP'",
            "            - 'NNTP'",
            "            - 'MYSQL'",
            "            - 'MYSQL-ECV'",
            "            - 'MSSQL-ECV'",
            "            - 'ORACLE-ECV'",
            "            - 'LDAP'",
            "            - 'POP3'",
            "            - 'CITRIX-XML-SERVICE'",
            "            - 'CITRIX-WEB-INTERFACE'",
            "            - 'DNS-TCP'",
            "            - 'RTSP'",
            "            - 'ARP'",
            "            - 'CITRIX-AG'",
            "            - 'CITRIX-AAC-LOGINPAGE'",
            "            - 'CITRIX-AAC-LAS'",
            "            - 'CITRIX-XD-DDC'",
            "            - 'ND6'",
            "            - 'CITRIX-WI-EXTENDED'",
            "            - 'DIAMETER'",
            "            - 'RADIUS_ACCOUNTING'",
            "            - 'STOREFRONT'",
            "            - 'APPC'",
            "            - 'SMPP'",
            "            - 'CITRIX-XNC-ECV'",
            "            - 'CITRIX-XDM'",
            "            - 'CITRIX-STA-SERVICE'",
            "            - 'CITRIX-STA-SERVICE-NHOP'",
            "        description:",
            "            - \"Type of monitor that you want to create.\"",
            "",
            "    action:",
            "        choices:",
            "            - 'NONE'",
            "            - 'LOG'",
            "            - 'DOWN'",
            "        description:",
            "            - >-",
            "                Action to perform when the response to an inline monitor (a monitor of type C(HTTP-INLINE)) indicates",
            "                that the service is down. A service monitored by an inline monitor is considered C(DOWN) if the response",
            "                code is not one of the codes that have been specified for the Response Code parameter.",
            "            - \"Available settings function as follows:\"",
            "            - >-",
            "                * C(NONE) - Do not take any action. However, the show service command and the show lb monitor command",
            "                indicate the total number of responses that were checked and the number of consecutive error",
            "                responses received after the last successful probe.",
            "            - \"* C(LOG) - Log the event in NSLOG or SYSLOG.\"",
            "            - >-",
            "                * C(DOWN) - Mark the service as being down, and then do not direct any traffic to the service until the",
            "                configured down time has expired. Persistent connections to the service are terminated as soon as the",
            "                service is marked as C(DOWN). Also, log the event in NSLOG or SYSLOG.",
            "",
            "    respcode:",
            "        description:",
            "            - >-",
            "                Response codes for which to mark the service as UP. For any other response code, the action performed",
            "                depends on the monitor type. C(HTTP) monitors and C(RADIUS) monitors mark the service as C(DOWN), while",
            "                C(HTTP-INLINE) monitors perform the action indicated by the Action parameter.",
            "",
            "    httprequest:",
            "        description:",
            "            - \"HTTP request to send to the server (for example, C(\\\\\"HEAD /file.html\\\\\")).\"",
            "",
            "    rtsprequest:",
            "        description:",
            "            - \"RTSP request to send to the server (for example, C(\\\\\"OPTIONS *\\\\\")).\"",
            "",
            "    customheaders:",
            "        description:",
            "            - \"Custom header string to include in the monitoring probes.\"",
            "",
            "    maxforwards:",
            "        description:",
            "            - >-",
            "                Maximum number of hops that the SIP request used for monitoring can traverse to reach the server.",
            "                Applicable only to monitors of type C(SIP-UDP).",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(255)\"",
            "",
            "    sipmethod:",
            "        choices:",
            "            - 'OPTIONS'",
            "            - 'INVITE'",
            "            - 'REGISTER'",
            "        description:",
            "            - \"SIP method to use for the query. Applicable only to monitors of type C(SIP-UDP).\"",
            "",
            "    sipuri:",
            "        description:",
            "            - >-",
            "                SIP URI string to send to the service (for example, C(sip:sip.test)). Applicable only to monitors of",
            "                type C(SIP-UDP).",
            "            - \"Minimum length = 1\"",
            "",
            "    sipreguri:",
            "        description:",
            "            - >-",
            "                SIP user to be registered. Applicable only if the monitor is of type C(SIP-UDP) and the SIP Method",
            "                parameter is set to C(REGISTER).",
            "            - \"Minimum length = 1\"",
            "",
            "    send:",
            "        description:",
            "            - \"String to send to the service. Applicable to C(TCP-ECV), C(HTTP-ECV), and C(UDP-ECV) monitors.\"",
            "",
            "    recv:",
            "        description:",
            "            - >-",
            "                String expected from the server for the service to be marked as UP. Applicable to C(TCP-ECV), C(HTTP-ECV),",
            "                and C(UDP-ECV) monitors.",
            "",
            "    query:",
            "        description:",
            "            - \"Domain name to resolve as part of monitoring the DNS service (for example, C(example.com)).\"",
            "",
            "    querytype:",
            "        choices:",
            "            - 'Address'",
            "            - 'Zone'",
            "            - 'AAAA'",
            "        description:",
            "            - >-",
            "                Type of DNS record for which to send monitoring queries. Set to C(Address) for querying A records, C(AAAA)",
            "                for querying AAAA records, and C(Zone) for querying the SOA record.",
            "",
            "    scriptname:",
            "        description:",
            "            - >-",
            "                Path and name of the script to execute. The script must be available on the NetScaler appliance, in",
            "                the /nsconfig/monitors/ directory.",
            "            - \"Minimum length = 1\"",
            "",
            "    scriptargs:",
            "        description:",
            "            - \"String of arguments for the script. The string is copied verbatim into the request.\"",
            "",
            "    dispatcherip:",
            "        description:",
            "            - \"IP address of the dispatcher to which to send the probe.\"",
            "",
            "    dispatcherport:",
            "        description:",
            "            - \"Port number on which the dispatcher listens for the monitoring probe.\"",
            "",
            "    username:",
            "        description:",
            "            - >-",
            "                User name with which to probe the C(RADIUS), C(NNTP), C(FTP), C(FTP-EXTENDED), C(MYSQL), C(MSSQL), C(POP3), C(CITRIX-AG),",
            "                C(CITRIX-XD-DDC), C(CITRIX-WI-EXTENDED), C(CITRIX-XNC) or C(CITRIX-XDM) server.",
            "            - \"Minimum length = 1\"",
            "",
            "    password:",
            "        description:",
            "            - >-",
            "                Password that is required for logging on to the C(RADIUS), C(NNTP), C(FTP), C(FTP-EXTENDED), C(MYSQL), C(MSSQL), C(POP3),",
            "                C(CITRIX-AG), C(CITRIX-XD-DDC), C(CITRIX-WI-EXTENDED), C(CITRIX-XNC-ECV) or C(CITRIX-XDM) server. Used in",
            "                conjunction with the user name specified for the C(username) parameter.",
            "            - \"Minimum length = 1\"",
            "",
            "    secondarypassword:",
            "        description:",
            "            - >-",
            "                Secondary password that users might have to provide to log on to the Access Gateway server.",
            "                Applicable to C(CITRIX-AG) monitors.",
            "",
            "    logonpointname:",
            "        description:",
            "            - >-",
            "                Name of the logon point that is configured for the Citrix Access Gateway Advanced Access Control",
            "                software. Required if you want to monitor the associated login page or Logon Agent. Applicable to",
            "                C(CITRIX-AAC-LAS) and C(CITRIX-AAC-LOGINPAGE) monitors.",
            "",
            "    lasversion:",
            "        description:",
            "            - >-",
            "                Version number of the Citrix Advanced Access Control Logon Agent. Required by the C(CITRIX-AAC-LAS)",
            "                monitor.",
            "",
            "    radkey:",
            "        description:",
            "            - >-",
            "                Authentication key (shared secret text string) for RADIUS clients and servers to exchange. Applicable",
            "                to monitors of type C(RADIUS) and C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    radnasid:",
            "        description:",
            "            - \"NAS-Identifier to send in the Access-Request packet. Applicable to monitors of type C(RADIUS).\"",
            "            - \"Minimum length = 1\"",
            "",
            "    radnasip:",
            "        description:",
            "            - >-",
            "                Network Access Server (NAS) IP address to use as the source IP address when monitoring a RADIUS",
            "                server. Applicable to monitors of type C(RADIUS) and C(RADIUS_ACCOUNTING).",
            "",
            "    radaccounttype:",
            "        description:",
            "            - \"Account Type to be used in Account Request Packet. Applicable to monitors of type C(RADIUS_ACCOUNTING).\"",
            "            - \"Minimum value = 0\"",
            "            - \"Maximum value = 15\"",
            "",
            "    radframedip:",
            "        description:",
            "            - \"Source ip with which the packet will go out . Applicable to monitors of type C(RADIUS_ACCOUNTING).\"",
            "",
            "    radapn:",
            "        description:",
            "            - >-",
            "                Called Station Id to be used in Account Request Packet. Applicable to monitors of type",
            "                C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    radmsisdn:",
            "        description:",
            "            - >-",
            "                Calling Stations Id to be used in Account Request Packet. Applicable to monitors of type",
            "                C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    radaccountsession:",
            "        description:",
            "            - >-",
            "                Account Session ID to be used in Account Request Packet. Applicable to monitors of type",
            "                C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    lrtm:",
            "        choices:",
            "            - 'enabled'",
            "            - 'disabled'",
            "        description:",
            "            - >-",
            "                Calculate the least response times for bound services. If this parameter is not enabled, the",
            "                appliance does not learn the response times of the bound services. Also used for LRTM load balancing.",
            "",
            "    deviation:",
            "        description:",
            "            - >-",
            "                Time value added to the learned average response time in dynamic response time monitoring (DRTM).",
            "                When a deviation is specified, the appliance learns the average response time of bound services and",
            "                adds the deviation to the average. The final value is then continually adjusted to accommodate",
            "                response time variations over time. Specified in milliseconds, seconds, or minutes.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(20939)\"",
            "",
            "    units1:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"Unit of measurement for the Deviation parameter. Cannot be changed after the monitor is created.\"",
            "",
            "    interval:",
            "        description:",
            "            - \"Time interval between two successive probes. Must be greater than the value of Response Time-out.\"",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(20940)\"",
            "",
            "    units3:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"monitor interval units.\"",
            "",
            "    resptimeout:",
            "        description:",
            "            - >-",
            "                Amount of time for which the appliance must wait before it marks a probe as FAILED. Must be less than",
            "                the value specified for the Interval parameter.",
            "            - >-",
            "                Note: For C(UDP-ECV) monitors for which a receive string is not configured, response timeout does not",
            "                apply. For C(UDP-ECV) monitors with no receive string, probe failure is indicated by an ICMP port",
            "                unreachable error received from the service.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(20939)\"",
            "",
            "    units4:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"monitor response timeout units.\"",
            "",
            "    resptimeoutthresh:",
            "        description:",
            "            - >-",
            "                Response time threshold, specified as a percentage of the Response Time-out parameter. If the",
            "                response to a monitor probe has not arrived when the threshold is reached, the appliance generates an",
            "                SNMP trap called monRespTimeoutAboveThresh. After the response time returns to a value below the",
            "                threshold, the appliance generates a monRespTimeoutBelowThresh SNMP trap. For the traps to be",
            "                generated, the \"MONITOR-RTO-THRESHOLD\" alarm must also be enabled.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(100)\"",
            "",
            "    retries:",
            "        description:",
            "            - >-",
            "                Maximum number of probes to send to establish the state of a service for which a monitoring probe",
            "                failed.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(127)\"",
            "",
            "    failureretries:",
            "        description:",
            "            - >-",
            "                Number of retries that must fail, out of the number specified for the Retries parameter, for a",
            "                service to be marked as DOWN. For example, if the Retries parameter is set to 10 and the Failure",
            "                Retries parameter is set to 6, out of the ten probes sent, at least six probes must fail if the",
            "                service is to be marked as DOWN. The default value of 0 means that all the retries must fail if the",
            "                service is to be marked as DOWN.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(32)\"",
            "",
            "    alertretries:",
            "        description:",
            "            - >-",
            "                Number of consecutive probe failures after which the appliance generates an SNMP trap called",
            "                monProbeFailed.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(32)\"",
            "",
            "    successretries:",
            "        description:",
            "            - \"Number of consecutive successful probes required to transition a service's state from DOWN to UP.\"",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(32)\"",
            "",
            "    downtime:",
            "        description:",
            "            - >-",
            "                Time duration for which to wait before probing a service that has been marked as DOWN. Expressed in",
            "                milliseconds, seconds, or minutes.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(20939)\"",
            "",
            "    units2:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"Unit of measurement for the Down Time parameter. Cannot be changed after the monitor is created.\"",
            "",
            "    destip:",
            "        description:",
            "            - >-",
            "                IP address of the service to which to send probes. If the parameter is set to 0, the IP address of",
            "                the server to which the monitor is bound is considered the destination IP address.",
            "",
            "    destport:",
            "        description:",
            "            - >-",
            "                TCP or UDP port to which to send the probe. If the parameter is set to 0, the port number of the",
            "                service to which the monitor is bound is considered the destination port. For a monitor of type C(USER),",
            "                however, the destination port is the port number that is included in the HTTP request sent to the",
            "                dispatcher. Does not apply to monitors of type C(PING).",
            "",
            "    state:",
            "        choices:",
            "            - 'enabled'",
            "            - 'disabled'",
            "        description:",
            "            - >-",
            "                State of the monitor. The C(disabled) setting disables not only the monitor being configured, but all",
            "                monitors of the same type, until the parameter is set to C(enabled). If the monitor is bound to a",
            "                service, the state of the monitor is not taken into account when the state of the service is",
            "                determined.",
            "",
            "    reverse:",
            "        description:",
            "            - >-",
            "                Mark a service as DOWN, instead of UP, when probe criteria are satisfied, and as UP instead of DOWN",
            "                when probe criteria are not satisfied.",
            "        type: bool",
            "",
            "    transparent:",
            "        description:",
            "            - >-",
            "                The monitor is bound to a transparent device such as a firewall or router. The state of a transparent",
            "                device depends on the responsiveness of the services behind it. If a transparent device is being",
            "                monitored, a destination IP address must be specified. The probe is sent to the specified IP address",
            "                by using the MAC address of the transparent device.",
            "        type: bool",
            "",
            "    iptunnel:",
            "        description:",
            "            - >-",
            "                Send the monitoring probe to the service through an IP tunnel. A destination IP address must be",
            "                specified.",
            "        type: bool",
            "",
            "    tos:",
            "        description:",
            "            - \"Probe the service by encoding the destination IP address in the IP TOS (6) bits.\"",
            "        type: bool",
            "",
            "    tosid:",
            "        description:",
            "            - \"The TOS ID of the specified destination IP. Applicable only when the TOS parameter is set.\"",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(63)\"",
            "",
            "    secure:",
            "        description:",
            "            - >-",
            "                Use a secure SSL connection when monitoring a service. Applicable only to TCP based monitors. The",
            "                secure option cannot be used with a C(CITRIX-AG) monitor, because a CITRIX-AG monitor uses a secure",
            "                connection by default.",
            "        type: bool",
            "",
            "    validatecred:",
            "        description:",
            "            - >-",
            "                Validate the credentials of the Xen Desktop DDC server user. Applicable to monitors of type",
            "                C(CITRIX-XD-DDC).",
            "        type: bool",
            "",
            "    domain:",
            "        description:",
            "            - >-",
            "                Domain in which the XenDesktop Desktop Delivery Controller (DDC) servers or Web Interface servers are",
            "                present. Required by C(CITRIX-XD-DDC) and C(CITRIX-WI-EXTENDED) monitors for logging on to the DDC servers",
            "                and Web Interface servers, respectively.",
            "",
            "    ipaddress:",
            "        description:",
            "            - >-",
            "                Set of IP addresses expected in the monitoring response from the DNS server, if the record type is A",
            "                or AAAA. Applicable to C(DNS) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    group:",
            "        description:",
            "            - >-",
            "                Name of a newsgroup available on the NNTP service that is to be monitored. The appliance periodically",
            "                generates an NNTP query for the name of the newsgroup and evaluates the response. If the newsgroup is",
            "                found on the server, the service is marked as UP. If the newsgroup does not exist or if the search",
            "                fails, the service is marked as DOWN. Applicable to NNTP monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    filename:",
            "        description:",
            "            - >-",
            "                Name of a file on the FTP server. The appliance monitors the FTP service by periodically checking the",
            "                existence of the file on the server. Applicable to C(FTP-EXTENDED) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    basedn:",
            "        description:",
            "            - >-",
            "                The base distinguished name of the LDAP service, from where the LDAP server can begin the search for",
            "                the attributes in the monitoring query. Required for C(LDAP) service monitoring.",
            "            - \"Minimum length = 1\"",
            "",
            "    binddn:",
            "        description:",
            "            - >-",
            "                The distinguished name with which an LDAP monitor can perform the Bind operation on the LDAP server.",
            "                Optional. Applicable to C(LDAP) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    filter:",
            "        description:",
            "            - \"Filter criteria for the LDAP query. Optional.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    attribute:",
            "        description:",
            "            - >-",
            "                Attribute to evaluate when the LDAP server responds to the query. Success or failure of the",
            "                monitoring probe depends on whether the attribute exists in the response. Optional.",
            "            - \"Minimum length = 1\"",
            "",
            "    database:",
            "        description:",
            "            - \"Name of the database to connect to during authentication.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    oraclesid:",
            "        description:",
            "            - \"Name of the service identifier that is used to connect to the Oracle database during authentication.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    sqlquery:",
            "        description:",
            "            - >-",
            "                SQL query for a C(MYSQL-ECV) or C(MSSQL-ECV) monitor. Sent to the database server after the server",
            "                authenticates the connection.",
            "            - \"Minimum length = 1\"",
            "",
            "    evalrule:",
            "        description:",
            "            - >-",
            "                Default syntax expression that evaluates the database server's response to a MYSQL-ECV or MSSQL-ECV",
            "                monitoring query. Must produce a Boolean result. The result determines the state of the server. If",
            "                the expression returns TRUE, the probe succeeds.",
            "            - >-",
            "                For example, if you want the appliance to evaluate the error message to determine the state of the",
            "                server, use the rule C(MYSQL.RES.ROW(10) .TEXT_ELEM(2).EQ(\"MySQL\")).",
            "",
            "    mssqlprotocolversion:",
            "        choices:",
            "            - '70'",
            "            - '2000'",
            "            - '2000SP1'",
            "            - '2005'",
            "            - '2008'",
            "            - '2008R2'",
            "            - '2012'",
            "            - '2014'",
            "        description:",
            "            - \"Version of MSSQL server that is to be monitored.\"",
            "",
            "    Snmpoid:",
            "        description:",
            "            - \"SNMP OID for C(SNMP) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    snmpcommunity:",
            "        description:",
            "            - \"Community name for C(SNMP) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    snmpthreshold:",
            "        description:",
            "            - \"Threshold for C(SNMP) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    snmpversion:",
            "        choices:",
            "            - 'V1'",
            "            - 'V2'",
            "        description:",
            "            - \"SNMP version to be used for C(SNMP) monitors.\"",
            "",
            "    metrictable:",
            "        description:",
            "            - \"Metric table to which to bind metrics.\"",
            "            - \"Minimum length = 1\"",
            "            - \"Maximum length = 99\"",
            "",
            "    application:",
            "        description:",
            "            - >-",
            "                Name of the application used to determine the state of the service. Applicable to monitors of type",
            "                C(CITRIX-XML-SERVICE).",
            "            - \"Minimum length = 1\"",
            "",
            "    sitepath:",
            "        description:",
            "            - >-",
            "                URL of the logon page. For monitors of type C(CITRIX-WEB-INTERFACE), to monitor a dynamic page under the",
            "                site path, terminate the site path with a slash C(/). Applicable to C(CITRIX-WEB-INTERFACE),",
            "                C(CITRIX-WI-EXTENDED) and C(CITRIX-XDM) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    storename:",
            "        description:",
            "            - >-",
            "                Store Name. For monitors of type C(STOREFRONT), C(storename) is an optional argument defining storefront",
            "                service store name. Applicable to C(STOREFRONT) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    storefrontacctservice:",
            "        description:",
            "            - >-",
            "                Enable/Disable probing for Account Service. Applicable only to Store Front monitors. For",
            "                multi-tenancy configuration users my skip account service.",
            "        type: bool",
            "",
            "    hostname:",
            "        description:",
            "            - \"Hostname in the FQDN format (Example: C(porche.cars.org)). Applicable to C(STOREFRONT) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    netprofile:",
            "        description:",
            "            - \"Name of the network profile.\"",
            "            - \"Minimum length = 1\"",
            "            - \"Maximum length = 127\"",
            "",
            "    originhost:",
            "        description:",
            "            - >-",
            "                Origin-Host value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "            - \"Minimum length = 1\"",
            "",
            "    originrealm:",
            "        description:",
            "            - >-",
            "                Origin-Realm value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "            - \"Minimum length = 1\"",
            "",
            "    hostipaddress:",
            "        description:",
            "            - >-",
            "                Host-IP-Address value for the Capabilities-Exchange-Request (CER) message to use for monitoring",
            "                Diameter servers. If Host-IP-Address is not specified, the appliance inserts the mapped IP (MIP)",
            "                address or subnet IP (SNIP) address from which the CER request (the monitoring probe) is sent.",
            "            - \"Minimum length = 1\"",
            "",
            "    vendorid:",
            "        description:",
            "            - >-",
            "                Vendor-Id value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "",
            "    productname:",
            "        description:",
            "            - >-",
            "                Product-Name value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "            - \"Minimum length = 1\"",
            "",
            "    firmwarerevision:",
            "        description:",
            "            - >-",
            "                Firmware-Revision value for the Capabilities-Exchange-Request (CER) message to use for monitoring",
            "                Diameter servers.",
            "",
            "    authapplicationid:",
            "        description:",
            "            - >-",
            "                List of Auth-Application-Id attribute value pairs (AVPs) for the Capabilities-Exchange-Request (CER)",
            "                message to use for monitoring Diameter servers. A maximum of eight of these AVPs are supported in a",
            "                monitoring CER message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    acctapplicationid:",
            "        description:",
            "            - >-",
            "                List of Acct-Application-Id attribute value pairs (AVPs) for the Capabilities-Exchange-Request (CER)",
            "                message to use for monitoring Diameter servers. A maximum of eight of these AVPs are supported in a",
            "                monitoring message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    inbandsecurityid:",
            "        choices:",
            "            - 'NO_INBAND_SECURITY'",
            "            - 'TLS'",
            "        description:",
            "            - >-",
            "                Inband-Security-Id for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "",
            "    supportedvendorids:",
            "        description:",
            "            - >-",
            "                List of Supported-Vendor-Id attribute value pairs (AVPs) for the Capabilities-Exchange-Request (CER)",
            "                message to use for monitoring Diameter servers. A maximum eight of these AVPs are supported in a",
            "                monitoring message.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    vendorspecificvendorid:",
            "        description:",
            "            - >-",
            "                Vendor-Id to use in the Vendor-Specific-Application-Id grouped attribute-value pair (AVP) in the",
            "                monitoring CER message. To specify Auth-Application-Id or Acct-Application-Id in",
            "                Vendor-Specific-Application-Id, use vendorSpecificAuthApplicationIds or",
            "                vendorSpecificAcctApplicationIds, respectively. Only one Vendor-Id is supported for all the",
            "                Vendor-Specific-Application-Id AVPs in a CER monitoring message.",
            "            - \"Minimum value = 1\"",
            "",
            "    vendorspecificauthapplicationids:",
            "        description:",
            "            - >-",
            "                List of Vendor-Specific-Auth-Application-Id attribute value pairs (AVPs) for the",
            "                Capabilities-Exchange-Request (CER) message to use for monitoring Diameter servers. A maximum of",
            "                eight of these AVPs are supported in a monitoring message. The specified value is combined with the",
            "                value of vendorSpecificVendorId to obtain the Vendor-Specific-Application-Id AVP in the CER",
            "                monitoring message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    vendorspecificacctapplicationids:",
            "        description:",
            "            - >-",
            "                List of Vendor-Specific-Acct-Application-Id attribute value pairs (AVPs) to use for monitoring",
            "                Diameter servers. A maximum of eight of these AVPs are supported in a monitoring message. The",
            "                specified value is combined with the value of vendorSpecificVendorId to obtain the",
            "                Vendor-Specific-Application-Id AVP in the CER monitoring message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    kcdaccount:",
            "        description:",
            "            - \"KCD Account used by C(MSSQL) monitor.\"",
            "            - \"Minimum length = 1\"",
            "            - \"Maximum length = 32\"",
            "",
            "    storedb:",
            "        choices:",
            "            - 'enabled'",
            "            - 'disabled'",
            "        description:",
            "            - >-",
            "                Store the database list populated with the responses to monitor probes. Used in database specific",
            "                load balancing if C(MSSQL-ECV)/C(MYSQL-ECV) monitor is configured.",
            "",
            "    storefrontcheckbackendservices:",
            "        description:",
            "            - >-",
            "                This option will enable monitoring of services running on storefront server. Storefront services are",
            "                monitored by probing to a Windows service that runs on the Storefront server and exposes details of",
            "                which storefront services are running.",
            "        type: bool",
            "",
            "    trofscode:",
            "        description:",
            "            - \"Code expected when the server is under maintenance.\"",
            "",
            "    trofsstring:",
            "        description:",
            "            - >-",
            "                String expected from the server for the service to be marked as trofs. Applicable to HTTP-ECV/TCP-ECV",
            "                monitors.",
            "",
            "extends_documentation_fragment: netscaler",
            "requirements:",
            "    - nitro python sdk",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Set lb monitor",
            "  local_action:",
            "    nsip: 172.18.0.2",
            "    nitro_user: nsroot",
            "    nitro_pass: nsroot",
            "    validate_certs: no",
            "",
            "",
            "    module: netscaler_lb_monitor",
            "    state: present",
            "",
            "    monitorname: monitor_1",
            "    type: HTTP-INLINE",
            "    action: DOWN",
            "    respcode: ['400']",
            "'''",
            "",
            "RETURN = '''",
            "loglines:",
            "    description: list of logged messages by the module",
            "    returned: always",
            "    type: list",
            "    sample: ['message 1', 'message 2']",
            "",
            "msg:",
            "    description: Message detailing the failure reason",
            "    returned: failure",
            "    type: str",
            "    sample: \"Action does not exist\"",
            "",
            "diff:",
            "    description: List of differences between the actual configured object and the configuration specified in the module",
            "    returned: failure",
            "    type: dict",
            "    sample: { 'targetlbvserver': 'difference. ours: (str) server1 other: (str) server2' }",
            "'''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "from ansible.module_utils.network.netscaler.netscaler import (",
            "    ConfigProxy,",
            "    get_nitro_client,",
            "    netscaler_common_arguments,",
            "    log,",
            "    loglines,",
            "    ensure_feature_is_enabled,",
            "    get_immutables_intersection",
            ")",
            "",
            "try:",
            "    from nssrc.com.citrix.netscaler.nitro.resource.config.lb.lbmonitor import lbmonitor",
            "    from nssrc.com.citrix.netscaler.nitro.exception.nitro_exception import nitro_exception",
            "    PYTHON_SDK_IMPORTED = True",
            "except ImportError as e:",
            "    PYTHON_SDK_IMPORTED = False",
            "",
            "",
            "def lbmonitor_exists(client, module):",
            "    log('Checking if monitor exists')",
            "    if lbmonitor.count_filtered(client, 'monitorname:%s' % module.params['monitorname']) > 0:",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def lbmonitor_identical(client, module, lbmonitor_proxy):",
            "    log('Checking if monitor is identical')",
            "",
            "    count = lbmonitor.count_filtered(client, 'monitorname:%s' % module.params['monitorname'])",
            "    if count == 0:",
            "        return False",
            "",
            "    lbmonitor_list = lbmonitor.get_filtered(client, 'monitorname:%s' % module.params['monitorname'])",
            "    diff_dict = lbmonitor_proxy.diff_object(lbmonitor_list[0])",
            "",
            "    # Skipping hashed fields since the cannot be compared directly",
            "    hashed_fields = [",
            "        'password',",
            "        'secondarypassword',",
            "        'radkey',",
            "    ]",
            "    for key in hashed_fields:",
            "        if key in diff_dict:",
            "            del diff_dict[key]",
            "",
            "    if diff_dict == {}:",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def diff_list(client, module, lbmonitor_proxy):",
            "    monitor_list = lbmonitor.get_filtered(client, 'monitorname:%s' % module.params['monitorname'])",
            "    return lbmonitor_proxy.diff_object(monitor_list[0])",
            "",
            "",
            "def main():",
            "",
            "    module_specific_arguments = dict(",
            "",
            "        monitorname=dict(type='str'),",
            "",
            "        type=dict(",
            "            type='str',",
            "            choices=[",
            "                'PING',",
            "                'TCP',",
            "                'HTTP',",
            "                'TCP-ECV',",
            "                'HTTP-ECV',",
            "                'UDP-ECV',",
            "                'DNS',",
            "                'FTP',",
            "                'LDNS-PING',",
            "                'LDNS-TCP',",
            "                'LDNS-DNS',",
            "                'RADIUS',",
            "                'USER',",
            "                'HTTP-INLINE',",
            "                'SIP-UDP',",
            "                'SIP-TCP',",
            "                'LOAD',",
            "                'FTP-EXTENDED',",
            "                'SMTP',",
            "                'SNMP',",
            "                'NNTP',",
            "                'MYSQL',",
            "                'MYSQL-ECV',",
            "                'MSSQL-ECV',",
            "                'ORACLE-ECV',",
            "                'LDAP',",
            "                'POP3',",
            "                'CITRIX-XML-SERVICE',",
            "                'CITRIX-WEB-INTERFACE',",
            "                'DNS-TCP',",
            "                'RTSP',",
            "                'ARP',",
            "                'CITRIX-AG',",
            "                'CITRIX-AAC-LOGINPAGE',",
            "                'CITRIX-AAC-LAS',",
            "                'CITRIX-XD-DDC',",
            "                'ND6',",
            "                'CITRIX-WI-EXTENDED',",
            "                'DIAMETER',",
            "                'RADIUS_ACCOUNTING',",
            "                'STOREFRONT',",
            "                'APPC',",
            "                'SMPP',",
            "                'CITRIX-XNC-ECV',",
            "                'CITRIX-XDM',",
            "                'CITRIX-STA-SERVICE',",
            "                'CITRIX-STA-SERVICE-NHOP',",
            "            ]",
            "        ),",
            "",
            "        action=dict(",
            "            type='str',",
            "            choices=[",
            "                'NONE',",
            "                'LOG',",
            "                'DOWN',",
            "            ]",
            "        ),",
            "        respcode=dict(type='list'),",
            "        httprequest=dict(type='str'),",
            "        rtsprequest=dict(type='str'),",
            "        customheaders=dict(type='str'),",
            "        maxforwards=dict(type='float'),",
            "        sipmethod=dict(",
            "            type='str',",
            "            choices=[",
            "                'OPTIONS',",
            "                'INVITE',",
            "                'REGISTER',",
            "            ]",
            "        ),",
            "        sipuri=dict(type='str'),",
            "        sipreguri=dict(type='str'),",
            "        send=dict(type='str'),",
            "        recv=dict(type='str'),",
            "        query=dict(type='str'),",
            "        querytype=dict(",
            "            type='str',",
            "            choices=[",
            "                'Address',",
            "                'Zone',",
            "                'AAAA',",
            "            ]",
            "        ),",
            "        scriptname=dict(type='str'),",
            "        scriptargs=dict(type='str'),",
            "        dispatcherip=dict(type='str'),",
            "        dispatcherport=dict(type='int'),",
            "        username=dict(type='str'),",
            "        password=dict(type='str'),",
            "        secondarypassword=dict(type='str'),",
            "        logonpointname=dict(type='str'),",
            "        lasversion=dict(type='str'),",
            "        radkey=dict(type='str'),",
            "        radnasid=dict(type='str'),",
            "        radnasip=dict(type='str'),",
            "        radaccounttype=dict(type='float'),",
            "        radframedip=dict(type='str'),",
            "        radapn=dict(type='str'),",
            "        radmsisdn=dict(type='str'),",
            "        radaccountsession=dict(type='str'),",
            "        lrtm=dict(",
            "            type='str',",
            "            choices=[",
            "                'enabled',",
            "                'disabled',",
            "            ]",
            "        ),",
            "        deviation=dict(type='float'),",
            "        units1=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        interval=dict(type='int'),",
            "        units3=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        resptimeout=dict(type='int'),",
            "        units4=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        resptimeoutthresh=dict(type='float'),",
            "        retries=dict(type='int'),",
            "        failureretries=dict(type='int'),",
            "        alertretries=dict(type='int'),",
            "        successretries=dict(type='int'),",
            "        downtime=dict(type='int'),",
            "        units2=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        destip=dict(type='str'),",
            "        destport=dict(type='int'),",
            "        reverse=dict(type='bool'),",
            "        transparent=dict(type='bool'),",
            "        iptunnel=dict(type='bool'),",
            "        tos=dict(type='bool'),",
            "        tosid=dict(type='float'),",
            "        secure=dict(type='bool'),",
            "        validatecred=dict(type='bool'),",
            "        domain=dict(type='str'),",
            "        ipaddress=dict(type='list'),",
            "        group=dict(type='str'),",
            "        filename=dict(type='str'),",
            "        basedn=dict(type='str'),",
            "        binddn=dict(type='str'),",
            "        filter=dict(type='str'),",
            "        attribute=dict(type='str'),",
            "        database=dict(type='str'),",
            "        oraclesid=dict(type='str'),",
            "        sqlquery=dict(type='str'),",
            "        evalrule=dict(type='str'),",
            "        mssqlprotocolversion=dict(",
            "            type='str',",
            "            choices=[",
            "                '70',",
            "                '2000',",
            "                '2000SP1',",
            "                '2005',",
            "                '2008',",
            "                '2008R2',",
            "                '2012',",
            "                '2014',",
            "            ]",
            "        ),",
            "        Snmpoid=dict(type='str'),",
            "        snmpcommunity=dict(type='str'),",
            "        snmpthreshold=dict(type='str'),",
            "        snmpversion=dict(",
            "            type='str',",
            "            choices=[",
            "                'V1',",
            "                'V2',",
            "            ]",
            "        ),",
            "        application=dict(type='str'),",
            "        sitepath=dict(type='str'),",
            "        storename=dict(type='str'),",
            "        storefrontacctservice=dict(type='bool'),",
            "        hostname=dict(type='str'),",
            "        netprofile=dict(type='str'),",
            "        originhost=dict(type='str'),",
            "        originrealm=dict(type='str'),",
            "        hostipaddress=dict(type='str'),",
            "        vendorid=dict(type='float'),",
            "        productname=dict(type='str'),",
            "        firmwarerevision=dict(type='float'),",
            "        authapplicationid=dict(type='list'),",
            "        acctapplicationid=dict(type='list'),",
            "        inbandsecurityid=dict(",
            "            type='str',",
            "            choices=[",
            "                'NO_INBAND_SECURITY',",
            "                'TLS',",
            "            ]",
            "        ),",
            "        supportedvendorids=dict(type='list'),",
            "        vendorspecificvendorid=dict(type='float'),",
            "        vendorspecificauthapplicationids=dict(type='list'),",
            "        vendorspecificacctapplicationids=dict(type='list'),",
            "        storedb=dict(",
            "            type='str',",
            "            choices=[",
            "                'enabled',",
            "                'disabled',",
            "            ]",
            "        ),",
            "        storefrontcheckbackendservices=dict(type='bool'),",
            "        trofscode=dict(type='float'),",
            "        trofsstring=dict(type='str'),",
            "    )",
            "",
            "    hand_inserted_arguments = dict()",
            "",
            "    argument_spec = dict()",
            "    argument_spec.update(module_specific_arguments)",
            "    argument_spec.update(netscaler_common_arguments)",
            "    argument_spec.update(hand_inserted_arguments)",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=argument_spec,",
            "        supports_check_mode=True,",
            "    )",
            "",
            "    module_result = dict(",
            "        changed=False,",
            "        failed=False,",
            "        loglines=loglines,",
            "    )",
            "",
            "    # Fail the module if imports failed",
            "    if not PYTHON_SDK_IMPORTED:",
            "        module.fail_json(msg='Could not load nitro python sdk', **module_result)",
            "",
            "    # Fallthrough to rest of execution",
            "    client = get_nitro_client(module)",
            "",
            "    try:",
            "        client.login()",
            "    except nitro_exception as e:",
            "        msg = \"nitro exception during login. errorcode=%s, message=%s\" % (str(e.errorcode), e.message)",
            "        module.fail_json(msg=msg)",
            "    except Exception as e:",
            "        if str(type(e)) == \"<class 'requests.exceptions.ConnectionError'>\":",
            "            module.fail_json(msg='Connection error %s' % str(e))",
            "        elif str(type(e)) == \"<class 'requests.exceptions.SSLError'>\":",
            "            module.fail_json(msg='SSL Error %s' % str(e))",
            "        else:",
            "            module.fail_json(msg='Unexpected error during login %s' % str(e))",
            "",
            "    # Instantiate lb monitor object",
            "    readwrite_attrs = [",
            "        'monitorname',",
            "        'type',",
            "        'action',",
            "        'respcode',",
            "        'httprequest',",
            "        'rtsprequest',",
            "        'customheaders',",
            "        'maxforwards',",
            "        'sipmethod',",
            "        'sipuri',",
            "        'sipreguri',",
            "        'send',",
            "        'recv',",
            "        'query',",
            "        'querytype',",
            "        'scriptname',",
            "        'scriptargs',",
            "        'dispatcherip',",
            "        'dispatcherport',",
            "        'username',",
            "        'password',",
            "        'secondarypassword',",
            "        'logonpointname',",
            "        'lasversion',",
            "        'radkey',",
            "        'radnasid',",
            "        'radnasip',",
            "        'radaccounttype',",
            "        'radframedip',",
            "        'radapn',",
            "        'radmsisdn',",
            "        'radaccountsession',",
            "        'lrtm',",
            "        'deviation',",
            "        'units1',",
            "        'interval',",
            "        'units3',",
            "        'resptimeout',",
            "        'units4',",
            "        'resptimeoutthresh',",
            "        'retries',",
            "        'failureretries',",
            "        'alertretries',",
            "        'successretries',",
            "        'downtime',",
            "        'units2',",
            "        'destip',",
            "        'destport',",
            "        'reverse',",
            "        'transparent',",
            "        'iptunnel',",
            "        'tos',",
            "        'tosid',",
            "        'secure',",
            "        'validatecred',",
            "        'domain',",
            "        'ipaddress',",
            "        'group',",
            "        'filename',",
            "        'basedn',",
            "        'binddn',",
            "        'filter',",
            "        'attribute',",
            "        'database',",
            "        'oraclesid',",
            "        'sqlquery',",
            "        'evalrule',",
            "        'mssqlprotocolversion',",
            "        'Snmpoid',",
            "        'snmpcommunity',",
            "        'snmpthreshold',",
            "        'snmpversion',",
            "        'application',",
            "        'sitepath',",
            "        'storename',",
            "        'storefrontacctservice',",
            "        'netprofile',",
            "        'originhost',",
            "        'originrealm',",
            "        'hostipaddress',",
            "        'vendorid',",
            "        'productname',",
            "        'firmwarerevision',",
            "        'authapplicationid',",
            "        'acctapplicationid',",
            "        'inbandsecurityid',",
            "        'supportedvendorids',",
            "        'vendorspecificvendorid',",
            "        'vendorspecificauthapplicationids',",
            "        'vendorspecificacctapplicationids',",
            "        'storedb',",
            "        'storefrontcheckbackendservices',",
            "        'trofscode',",
            "        'trofsstring',",
            "    ]",
            "",
            "    readonly_attrs = [",
            "        'lrtmconf',",
            "        'lrtmconfstr',",
            "        'dynamicresponsetimeout',",
            "        'dynamicinterval',",
            "        'multimetrictable',",
            "        'dup_state',",
            "        'dup_weight',",
            "        'weight',",
            "    ]",
            "",
            "    immutable_attrs = [",
            "        'monitorname',",
            "        'type',",
            "        'units1',",
            "        'units3',",
            "        'units4',",
            "        'units2',",
            "        'Snmpoid',",
            "        'hostname',",
            "        'servicename',",
            "        'servicegroupname',",
            "    ]",
            "",
            "    transforms = {",
            "        'storefrontcheckbackendservices': ['bool_yes_no'],",
            "        'secure': ['bool_yes_no'],",
            "        'tos': ['bool_yes_no'],",
            "        'validatecred': ['bool_yes_no'],",
            "        'storefrontacctservice': ['bool_yes_no'],",
            "        'iptunnel': ['bool_yes_no'],",
            "        'transparent': ['bool_yes_no'],",
            "        'reverse': ['bool_yes_no'],",
            "        'lrtm': [lambda v: v.upper()],",
            "        'storedb': [lambda v: v.upper()],",
            "    }",
            "",
            "    lbmonitor_proxy = ConfigProxy(",
            "        actual=lbmonitor(),",
            "        client=client,",
            "        attribute_values_dict=module.params,",
            "        readwrite_attrs=readwrite_attrs,",
            "        readonly_attrs=readonly_attrs,",
            "        immutable_attrs=immutable_attrs,",
            "        transforms=transforms,",
            "    )",
            "",
            "    try:",
            "        ensure_feature_is_enabled(client, 'LB')",
            "",
            "        if module.params['state'] == 'present':",
            "            log('Applying actions for state present')",
            "            if not lbmonitor_exists(client, module):",
            "                if not module.check_mode:",
            "                    log('Adding monitor')",
            "                    lbmonitor_proxy.add()",
            "                    if module.params['save_config']:",
            "                        client.save_config()",
            "                module_result['changed'] = True",
            "            elif not lbmonitor_identical(client, module, lbmonitor_proxy):",
            "",
            "                # Check if we try to change value of immutable attributes",
            "                immutables_changed = get_immutables_intersection(lbmonitor_proxy, diff_list(client, module, lbmonitor_proxy).keys())",
            "                if immutables_changed != []:",
            "                    diff = diff_list(client, module, lbmonitor_proxy)",
            "                    msg = 'Cannot update immutable attributes %s' % (immutables_changed,)",
            "                    module.fail_json(msg=msg, diff=diff, **module_result)",
            "",
            "                if not module.check_mode:",
            "                    log('Updating monitor')",
            "                    lbmonitor_proxy.update()",
            "                    if module.params['save_config']:",
            "                        client.save_config()",
            "                module_result['changed'] = True",
            "            else:",
            "                log('Doing nothing for monitor')",
            "                module_result['changed'] = False",
            "",
            "            # Sanity check for result",
            "            log('Sanity checks for state present')",
            "            if not module.check_mode:",
            "                if not lbmonitor_exists(client, module):",
            "                    module.fail_json(msg='lb monitor does not exist', **module_result)",
            "                if not lbmonitor_identical(client, module, lbmonitor_proxy):",
            "                    module.fail_json(",
            "                        msg='lb monitor is not configured correctly',",
            "                        diff=diff_list(client, module, lbmonitor_proxy),",
            "                        **module_result",
            "                    )",
            "",
            "        elif module.params['state'] == 'absent':",
            "            log('Applying actions for state absent')",
            "            if lbmonitor_exists(client, module):",
            "                if not module.check_mode:",
            "                    lbmonitor_proxy.delete()",
            "                    if module.params['save_config']:",
            "                        client.save_config()",
            "                module_result['changed'] = True",
            "            else:",
            "                module_result['changed'] = False",
            "",
            "            # Sanity check for result",
            "            log('Sanity checks for state absent')",
            "            if not module.check_mode:",
            "                if lbmonitor_exists(client, module):",
            "                    module.fail_json(msg='lb monitor still exists', **module_result)",
            "",
            "        module_result['actual_attributes'] = lbmonitor_proxy.get_actual_rw_attributes(filter='monitorname')",
            "    except nitro_exception as e:",
            "        msg = \"nitro exception errorcode=%s, message=%s\" % (str(e.errorcode), e.message)",
            "        module.fail_json(msg=msg, **module_result)",
            "",
            "    client.logout()",
            "",
            "    module.exit_json(**module_result)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "",
            "#  Copyright (c) 2017 Citrix Systems",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "from __future__ import absolute_import, division, print_function",
            "__metaclass__ = type",
            "",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'community'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "module: netscaler_lb_monitor",
            "short_description: Manage load balancing monitors",
            "description:",
            "    - Manage load balancing monitors.",
            "    - This module is intended to run either on the ansible  control node or a bastion (jumpserver) with access to the actual netscaler instance.",
            "",
            "version_added: \"2.4\"",
            "",
            "author: George Nikolopoulos (@giorgos-nikolopoulos)",
            "",
            "options:",
            "",
            "    monitorname:",
            "        description:",
            "            - >-",
            "                Name for the monitor. Must begin with an ASCII alphanumeric or underscore C(_) character, and must",
            "                contain only ASCII alphanumeric, underscore, hash C(#), period C(.), space C( ), colon C(:), at C(@), equals",
            "                C(=), and hyphen C(-) characters.",
            "            - \"Minimum length = 1\"",
            "",
            "    type:",
            "        choices:",
            "            - 'PING'",
            "            - 'TCP'",
            "            - 'HTTP'",
            "            - 'TCP-ECV'",
            "            - 'HTTP-ECV'",
            "            - 'UDP-ECV'",
            "            - 'DNS'",
            "            - 'FTP'",
            "            - 'LDNS-PING'",
            "            - 'LDNS-TCP'",
            "            - 'LDNS-DNS'",
            "            - 'RADIUS'",
            "            - 'USER'",
            "            - 'HTTP-INLINE'",
            "            - 'SIP-UDP'",
            "            - 'SIP-TCP'",
            "            - 'LOAD'",
            "            - 'FTP-EXTENDED'",
            "            - 'SMTP'",
            "            - 'SNMP'",
            "            - 'NNTP'",
            "            - 'MYSQL'",
            "            - 'MYSQL-ECV'",
            "            - 'MSSQL-ECV'",
            "            - 'ORACLE-ECV'",
            "            - 'LDAP'",
            "            - 'POP3'",
            "            - 'CITRIX-XML-SERVICE'",
            "            - 'CITRIX-WEB-INTERFACE'",
            "            - 'DNS-TCP'",
            "            - 'RTSP'",
            "            - 'ARP'",
            "            - 'CITRIX-AG'",
            "            - 'CITRIX-AAC-LOGINPAGE'",
            "            - 'CITRIX-AAC-LAS'",
            "            - 'CITRIX-XD-DDC'",
            "            - 'ND6'",
            "            - 'CITRIX-WI-EXTENDED'",
            "            - 'DIAMETER'",
            "            - 'RADIUS_ACCOUNTING'",
            "            - 'STOREFRONT'",
            "            - 'APPC'",
            "            - 'SMPP'",
            "            - 'CITRIX-XNC-ECV'",
            "            - 'CITRIX-XDM'",
            "            - 'CITRIX-STA-SERVICE'",
            "            - 'CITRIX-STA-SERVICE-NHOP'",
            "        description:",
            "            - \"Type of monitor that you want to create.\"",
            "",
            "    action:",
            "        choices:",
            "            - 'NONE'",
            "            - 'LOG'",
            "            - 'DOWN'",
            "        description:",
            "            - >-",
            "                Action to perform when the response to an inline monitor (a monitor of type C(HTTP-INLINE)) indicates",
            "                that the service is down. A service monitored by an inline monitor is considered C(DOWN) if the response",
            "                code is not one of the codes that have been specified for the Response Code parameter.",
            "            - \"Available settings function as follows:\"",
            "            - >-",
            "                * C(NONE) - Do not take any action. However, the show service command and the show lb monitor command",
            "                indicate the total number of responses that were checked and the number of consecutive error",
            "                responses received after the last successful probe.",
            "            - \"* C(LOG) - Log the event in NSLOG or SYSLOG.\"",
            "            - >-",
            "                * C(DOWN) - Mark the service as being down, and then do not direct any traffic to the service until the",
            "                configured down time has expired. Persistent connections to the service are terminated as soon as the",
            "                service is marked as C(DOWN). Also, log the event in NSLOG or SYSLOG.",
            "",
            "    respcode:",
            "        description:",
            "            - >-",
            "                Response codes for which to mark the service as UP. For any other response code, the action performed",
            "                depends on the monitor type. C(HTTP) monitors and C(RADIUS) monitors mark the service as C(DOWN), while",
            "                C(HTTP-INLINE) monitors perform the action indicated by the Action parameter.",
            "",
            "    httprequest:",
            "        description:",
            "            - \"HTTP request to send to the server (for example, C(\\\\\"HEAD /file.html\\\\\")).\"",
            "",
            "    rtsprequest:",
            "        description:",
            "            - \"RTSP request to send to the server (for example, C(\\\\\"OPTIONS *\\\\\")).\"",
            "",
            "    customheaders:",
            "        description:",
            "            - \"Custom header string to include in the monitoring probes.\"",
            "",
            "    maxforwards:",
            "        description:",
            "            - >-",
            "                Maximum number of hops that the SIP request used for monitoring can traverse to reach the server.",
            "                Applicable only to monitors of type C(SIP-UDP).",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(255)\"",
            "",
            "    sipmethod:",
            "        choices:",
            "            - 'OPTIONS'",
            "            - 'INVITE'",
            "            - 'REGISTER'",
            "        description:",
            "            - \"SIP method to use for the query. Applicable only to monitors of type C(SIP-UDP).\"",
            "",
            "    sipuri:",
            "        description:",
            "            - >-",
            "                SIP URI string to send to the service (for example, C(sip:sip.test)). Applicable only to monitors of",
            "                type C(SIP-UDP).",
            "            - \"Minimum length = 1\"",
            "",
            "    sipreguri:",
            "        description:",
            "            - >-",
            "                SIP user to be registered. Applicable only if the monitor is of type C(SIP-UDP) and the SIP Method",
            "                parameter is set to C(REGISTER).",
            "            - \"Minimum length = 1\"",
            "",
            "    send:",
            "        description:",
            "            - \"String to send to the service. Applicable to C(TCP-ECV), C(HTTP-ECV), and C(UDP-ECV) monitors.\"",
            "",
            "    recv:",
            "        description:",
            "            - >-",
            "                String expected from the server for the service to be marked as UP. Applicable to C(TCP-ECV), C(HTTP-ECV),",
            "                and C(UDP-ECV) monitors.",
            "",
            "    query:",
            "        description:",
            "            - \"Domain name to resolve as part of monitoring the DNS service (for example, C(example.com)).\"",
            "",
            "    querytype:",
            "        choices:",
            "            - 'Address'",
            "            - 'Zone'",
            "            - 'AAAA'",
            "        description:",
            "            - >-",
            "                Type of DNS record for which to send monitoring queries. Set to C(Address) for querying A records, C(AAAA)",
            "                for querying AAAA records, and C(Zone) for querying the SOA record.",
            "",
            "    scriptname:",
            "        description:",
            "            - >-",
            "                Path and name of the script to execute. The script must be available on the NetScaler appliance, in",
            "                the /nsconfig/monitors/ directory.",
            "            - \"Minimum length = 1\"",
            "",
            "    scriptargs:",
            "        description:",
            "            - \"String of arguments for the script. The string is copied verbatim into the request.\"",
            "",
            "    dispatcherip:",
            "        description:",
            "            - \"IP address of the dispatcher to which to send the probe.\"",
            "",
            "    dispatcherport:",
            "        description:",
            "            - \"Port number on which the dispatcher listens for the monitoring probe.\"",
            "",
            "    username:",
            "        description:",
            "            - >-",
            "                User name with which to probe the C(RADIUS), C(NNTP), C(FTP), C(FTP-EXTENDED), C(MYSQL), C(MSSQL), C(POP3), C(CITRIX-AG),",
            "                C(CITRIX-XD-DDC), C(CITRIX-WI-EXTENDED), C(CITRIX-XNC) or C(CITRIX-XDM) server.",
            "            - \"Minimum length = 1\"",
            "",
            "    password:",
            "        description:",
            "            - >-",
            "                Password that is required for logging on to the C(RADIUS), C(NNTP), C(FTP), C(FTP-EXTENDED), C(MYSQL), C(MSSQL), C(POP3),",
            "                C(CITRIX-AG), C(CITRIX-XD-DDC), C(CITRIX-WI-EXTENDED), C(CITRIX-XNC-ECV) or C(CITRIX-XDM) server. Used in",
            "                conjunction with the user name specified for the C(username) parameter.",
            "            - \"Minimum length = 1\"",
            "",
            "    secondarypassword:",
            "        description:",
            "            - >-",
            "                Secondary password that users might have to provide to log on to the Access Gateway server.",
            "                Applicable to C(CITRIX-AG) monitors.",
            "",
            "    logonpointname:",
            "        description:",
            "            - >-",
            "                Name of the logon point that is configured for the Citrix Access Gateway Advanced Access Control",
            "                software. Required if you want to monitor the associated login page or Logon Agent. Applicable to",
            "                C(CITRIX-AAC-LAS) and C(CITRIX-AAC-LOGINPAGE) monitors.",
            "",
            "    lasversion:",
            "        description:",
            "            - >-",
            "                Version number of the Citrix Advanced Access Control Logon Agent. Required by the C(CITRIX-AAC-LAS)",
            "                monitor.",
            "",
            "    radkey:",
            "        description:",
            "            - >-",
            "                Authentication key (shared secret text string) for RADIUS clients and servers to exchange. Applicable",
            "                to monitors of type C(RADIUS) and C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    radnasid:",
            "        description:",
            "            - \"NAS-Identifier to send in the Access-Request packet. Applicable to monitors of type C(RADIUS).\"",
            "            - \"Minimum length = 1\"",
            "",
            "    radnasip:",
            "        description:",
            "            - >-",
            "                Network Access Server (NAS) IP address to use as the source IP address when monitoring a RADIUS",
            "                server. Applicable to monitors of type C(RADIUS) and C(RADIUS_ACCOUNTING).",
            "",
            "    radaccounttype:",
            "        description:",
            "            - \"Account Type to be used in Account Request Packet. Applicable to monitors of type C(RADIUS_ACCOUNTING).\"",
            "            - \"Minimum value = 0\"",
            "            - \"Maximum value = 15\"",
            "",
            "    radframedip:",
            "        description:",
            "            - \"Source ip with which the packet will go out . Applicable to monitors of type C(RADIUS_ACCOUNTING).\"",
            "",
            "    radapn:",
            "        description:",
            "            - >-",
            "                Called Station Id to be used in Account Request Packet. Applicable to monitors of type",
            "                C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    radmsisdn:",
            "        description:",
            "            - >-",
            "                Calling Stations Id to be used in Account Request Packet. Applicable to monitors of type",
            "                C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    radaccountsession:",
            "        description:",
            "            - >-",
            "                Account Session ID to be used in Account Request Packet. Applicable to monitors of type",
            "                C(RADIUS_ACCOUNTING).",
            "            - \"Minimum length = 1\"",
            "",
            "    lrtm:",
            "        choices:",
            "            - 'enabled'",
            "            - 'disabled'",
            "        description:",
            "            - >-",
            "                Calculate the least response times for bound services. If this parameter is not enabled, the",
            "                appliance does not learn the response times of the bound services. Also used for LRTM load balancing.",
            "",
            "    deviation:",
            "        description:",
            "            - >-",
            "                Time value added to the learned average response time in dynamic response time monitoring (DRTM).",
            "                When a deviation is specified, the appliance learns the average response time of bound services and",
            "                adds the deviation to the average. The final value is then continually adjusted to accommodate",
            "                response time variations over time. Specified in milliseconds, seconds, or minutes.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(20939)\"",
            "",
            "    units1:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"Unit of measurement for the Deviation parameter. Cannot be changed after the monitor is created.\"",
            "",
            "    interval:",
            "        description:",
            "            - \"Time interval between two successive probes. Must be greater than the value of Response Time-out.\"",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(20940)\"",
            "",
            "    units3:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"monitor interval units.\"",
            "",
            "    resptimeout:",
            "        description:",
            "            - >-",
            "                Amount of time for which the appliance must wait before it marks a probe as FAILED. Must be less than",
            "                the value specified for the Interval parameter.",
            "            - >-",
            "                Note: For C(UDP-ECV) monitors for which a receive string is not configured, response timeout does not",
            "                apply. For C(UDP-ECV) monitors with no receive string, probe failure is indicated by an ICMP port",
            "                unreachable error received from the service.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(20939)\"",
            "",
            "    units4:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"monitor response timeout units.\"",
            "",
            "    resptimeoutthresh:",
            "        description:",
            "            - >-",
            "                Response time threshold, specified as a percentage of the Response Time-out parameter. If the",
            "                response to a monitor probe has not arrived when the threshold is reached, the appliance generates an",
            "                SNMP trap called monRespTimeoutAboveThresh. After the response time returns to a value below the",
            "                threshold, the appliance generates a monRespTimeoutBelowThresh SNMP trap. For the traps to be",
            "                generated, the \"MONITOR-RTO-THRESHOLD\" alarm must also be enabled.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(100)\"",
            "",
            "    retries:",
            "        description:",
            "            - >-",
            "                Maximum number of probes to send to establish the state of a service for which a monitoring probe",
            "                failed.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(127)\"",
            "",
            "    failureretries:",
            "        description:",
            "            - >-",
            "                Number of retries that must fail, out of the number specified for the Retries parameter, for a",
            "                service to be marked as DOWN. For example, if the Retries parameter is set to 10 and the Failure",
            "                Retries parameter is set to 6, out of the ten probes sent, at least six probes must fail if the",
            "                service is to be marked as DOWN. The default value of 0 means that all the retries must fail if the",
            "                service is to be marked as DOWN.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(32)\"",
            "",
            "    alertretries:",
            "        description:",
            "            - >-",
            "                Number of consecutive probe failures after which the appliance generates an SNMP trap called",
            "                monProbeFailed.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(32)\"",
            "",
            "    successretries:",
            "        description:",
            "            - \"Number of consecutive successful probes required to transition a service's state from DOWN to UP.\"",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(32)\"",
            "",
            "    downtime:",
            "        description:",
            "            - >-",
            "                Time duration for which to wait before probing a service that has been marked as DOWN. Expressed in",
            "                milliseconds, seconds, or minutes.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(20939)\"",
            "",
            "    units2:",
            "        choices:",
            "            - 'SEC'",
            "            - 'MSEC'",
            "            - 'MIN'",
            "        description:",
            "            - \"Unit of measurement for the Down Time parameter. Cannot be changed after the monitor is created.\"",
            "",
            "    destip:",
            "        description:",
            "            - >-",
            "                IP address of the service to which to send probes. If the parameter is set to 0, the IP address of",
            "                the server to which the monitor is bound is considered the destination IP address.",
            "",
            "    destport:",
            "        description:",
            "            - >-",
            "                TCP or UDP port to which to send the probe. If the parameter is set to 0, the port number of the",
            "                service to which the monitor is bound is considered the destination port. For a monitor of type C(USER),",
            "                however, the destination port is the port number that is included in the HTTP request sent to the",
            "                dispatcher. Does not apply to monitors of type C(PING).",
            "",
            "    state:",
            "        choices:",
            "            - 'enabled'",
            "            - 'disabled'",
            "        description:",
            "            - >-",
            "                State of the monitor. The C(disabled) setting disables not only the monitor being configured, but all",
            "                monitors of the same type, until the parameter is set to C(enabled). If the monitor is bound to a",
            "                service, the state of the monitor is not taken into account when the state of the service is",
            "                determined.",
            "",
            "    reverse:",
            "        description:",
            "            - >-",
            "                Mark a service as DOWN, instead of UP, when probe criteria are satisfied, and as UP instead of DOWN",
            "                when probe criteria are not satisfied.",
            "        type: bool",
            "",
            "    transparent:",
            "        description:",
            "            - >-",
            "                The monitor is bound to a transparent device such as a firewall or router. The state of a transparent",
            "                device depends on the responsiveness of the services behind it. If a transparent device is being",
            "                monitored, a destination IP address must be specified. The probe is sent to the specified IP address",
            "                by using the MAC address of the transparent device.",
            "        type: bool",
            "",
            "    iptunnel:",
            "        description:",
            "            - >-",
            "                Send the monitoring probe to the service through an IP tunnel. A destination IP address must be",
            "                specified.",
            "        type: bool",
            "",
            "    tos:",
            "        description:",
            "            - \"Probe the service by encoding the destination IP address in the IP TOS (6) bits.\"",
            "        type: bool",
            "",
            "    tosid:",
            "        description:",
            "            - \"The TOS ID of the specified destination IP. Applicable only when the TOS parameter is set.\"",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(63)\"",
            "",
            "    secure:",
            "        description:",
            "            - >-",
            "                Use a secure SSL connection when monitoring a service. Applicable only to TCP based monitors. The",
            "                secure option cannot be used with a C(CITRIX-AG) monitor, because a CITRIX-AG monitor uses a secure",
            "                connection by default.",
            "        type: bool",
            "",
            "    validatecred:",
            "        description:",
            "            - >-",
            "                Validate the credentials of the Xen Desktop DDC server user. Applicable to monitors of type",
            "                C(CITRIX-XD-DDC).",
            "        type: bool",
            "",
            "    domain:",
            "        description:",
            "            - >-",
            "                Domain in which the XenDesktop Desktop Delivery Controller (DDC) servers or Web Interface servers are",
            "                present. Required by C(CITRIX-XD-DDC) and C(CITRIX-WI-EXTENDED) monitors for logging on to the DDC servers",
            "                and Web Interface servers, respectively.",
            "",
            "    ipaddress:",
            "        description:",
            "            - >-",
            "                Set of IP addresses expected in the monitoring response from the DNS server, if the record type is A",
            "                or AAAA. Applicable to C(DNS) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    group:",
            "        description:",
            "            - >-",
            "                Name of a newsgroup available on the NNTP service that is to be monitored. The appliance periodically",
            "                generates an NNTP query for the name of the newsgroup and evaluates the response. If the newsgroup is",
            "                found on the server, the service is marked as UP. If the newsgroup does not exist or if the search",
            "                fails, the service is marked as DOWN. Applicable to NNTP monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    filename:",
            "        description:",
            "            - >-",
            "                Name of a file on the FTP server. The appliance monitors the FTP service by periodically checking the",
            "                existence of the file on the server. Applicable to C(FTP-EXTENDED) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    basedn:",
            "        description:",
            "            - >-",
            "                The base distinguished name of the LDAP service, from where the LDAP server can begin the search for",
            "                the attributes in the monitoring query. Required for C(LDAP) service monitoring.",
            "            - \"Minimum length = 1\"",
            "",
            "    binddn:",
            "        description:",
            "            - >-",
            "                The distinguished name with which an LDAP monitor can perform the Bind operation on the LDAP server.",
            "                Optional. Applicable to C(LDAP) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    filter:",
            "        description:",
            "            - \"Filter criteria for the LDAP query. Optional.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    attribute:",
            "        description:",
            "            - >-",
            "                Attribute to evaluate when the LDAP server responds to the query. Success or failure of the",
            "                monitoring probe depends on whether the attribute exists in the response. Optional.",
            "            - \"Minimum length = 1\"",
            "",
            "    database:",
            "        description:",
            "            - \"Name of the database to connect to during authentication.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    oraclesid:",
            "        description:",
            "            - \"Name of the service identifier that is used to connect to the Oracle database during authentication.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    sqlquery:",
            "        description:",
            "            - >-",
            "                SQL query for a C(MYSQL-ECV) or C(MSSQL-ECV) monitor. Sent to the database server after the server",
            "                authenticates the connection.",
            "            - \"Minimum length = 1\"",
            "",
            "    evalrule:",
            "        description:",
            "            - >-",
            "                Default syntax expression that evaluates the database server's response to a MYSQL-ECV or MSSQL-ECV",
            "                monitoring query. Must produce a Boolean result. The result determines the state of the server. If",
            "                the expression returns TRUE, the probe succeeds.",
            "            - >-",
            "                For example, if you want the appliance to evaluate the error message to determine the state of the",
            "                server, use the rule C(MYSQL.RES.ROW(10) .TEXT_ELEM(2).EQ(\"MySQL\")).",
            "",
            "    mssqlprotocolversion:",
            "        choices:",
            "            - '70'",
            "            - '2000'",
            "            - '2000SP1'",
            "            - '2005'",
            "            - '2008'",
            "            - '2008R2'",
            "            - '2012'",
            "            - '2014'",
            "        description:",
            "            - \"Version of MSSQL server that is to be monitored.\"",
            "",
            "    Snmpoid:",
            "        description:",
            "            - \"SNMP OID for C(SNMP) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    snmpcommunity:",
            "        description:",
            "            - \"Community name for C(SNMP) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    snmpthreshold:",
            "        description:",
            "            - \"Threshold for C(SNMP) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    snmpversion:",
            "        choices:",
            "            - 'V1'",
            "            - 'V2'",
            "        description:",
            "            - \"SNMP version to be used for C(SNMP) monitors.\"",
            "",
            "    metrictable:",
            "        description:",
            "            - \"Metric table to which to bind metrics.\"",
            "            - \"Minimum length = 1\"",
            "            - \"Maximum length = 99\"",
            "",
            "    application:",
            "        description:",
            "            - >-",
            "                Name of the application used to determine the state of the service. Applicable to monitors of type",
            "                C(CITRIX-XML-SERVICE).",
            "            - \"Minimum length = 1\"",
            "",
            "    sitepath:",
            "        description:",
            "            - >-",
            "                URL of the logon page. For monitors of type C(CITRIX-WEB-INTERFACE), to monitor a dynamic page under the",
            "                site path, terminate the site path with a slash C(/). Applicable to C(CITRIX-WEB-INTERFACE),",
            "                C(CITRIX-WI-EXTENDED) and C(CITRIX-XDM) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    storename:",
            "        description:",
            "            - >-",
            "                Store Name. For monitors of type C(STOREFRONT), C(storename) is an optional argument defining storefront",
            "                service store name. Applicable to C(STOREFRONT) monitors.",
            "            - \"Minimum length = 1\"",
            "",
            "    storefrontacctservice:",
            "        description:",
            "            - >-",
            "                Enable/Disable probing for Account Service. Applicable only to Store Front monitors. For",
            "                multi-tenancy configuration users my skip account service.",
            "        type: bool",
            "",
            "    hostname:",
            "        description:",
            "            - \"Hostname in the FQDN format (Example: C(porche.cars.org)). Applicable to C(STOREFRONT) monitors.\"",
            "            - \"Minimum length = 1\"",
            "",
            "    netprofile:",
            "        description:",
            "            - \"Name of the network profile.\"",
            "            - \"Minimum length = 1\"",
            "            - \"Maximum length = 127\"",
            "",
            "    originhost:",
            "        description:",
            "            - >-",
            "                Origin-Host value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "            - \"Minimum length = 1\"",
            "",
            "    originrealm:",
            "        description:",
            "            - >-",
            "                Origin-Realm value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "            - \"Minimum length = 1\"",
            "",
            "    hostipaddress:",
            "        description:",
            "            - >-",
            "                Host-IP-Address value for the Capabilities-Exchange-Request (CER) message to use for monitoring",
            "                Diameter servers. If Host-IP-Address is not specified, the appliance inserts the mapped IP (MIP)",
            "                address or subnet IP (SNIP) address from which the CER request (the monitoring probe) is sent.",
            "            - \"Minimum length = 1\"",
            "",
            "    vendorid:",
            "        description:",
            "            - >-",
            "                Vendor-Id value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "",
            "    productname:",
            "        description:",
            "            - >-",
            "                Product-Name value for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "            - \"Minimum length = 1\"",
            "",
            "    firmwarerevision:",
            "        description:",
            "            - >-",
            "                Firmware-Revision value for the Capabilities-Exchange-Request (CER) message to use for monitoring",
            "                Diameter servers.",
            "",
            "    authapplicationid:",
            "        description:",
            "            - >-",
            "                List of Auth-Application-Id attribute value pairs (AVPs) for the Capabilities-Exchange-Request (CER)",
            "                message to use for monitoring Diameter servers. A maximum of eight of these AVPs are supported in a",
            "                monitoring CER message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    acctapplicationid:",
            "        description:",
            "            - >-",
            "                List of Acct-Application-Id attribute value pairs (AVPs) for the Capabilities-Exchange-Request (CER)",
            "                message to use for monitoring Diameter servers. A maximum of eight of these AVPs are supported in a",
            "                monitoring message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    inbandsecurityid:",
            "        choices:",
            "            - 'NO_INBAND_SECURITY'",
            "            - 'TLS'",
            "        description:",
            "            - >-",
            "                Inband-Security-Id for the Capabilities-Exchange-Request (CER) message to use for monitoring Diameter",
            "                servers.",
            "",
            "    supportedvendorids:",
            "        description:",
            "            - >-",
            "                List of Supported-Vendor-Id attribute value pairs (AVPs) for the Capabilities-Exchange-Request (CER)",
            "                message to use for monitoring Diameter servers. A maximum eight of these AVPs are supported in a",
            "                monitoring message.",
            "            - \"Minimum value = C(1)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    vendorspecificvendorid:",
            "        description:",
            "            - >-",
            "                Vendor-Id to use in the Vendor-Specific-Application-Id grouped attribute-value pair (AVP) in the",
            "                monitoring CER message. To specify Auth-Application-Id or Acct-Application-Id in",
            "                Vendor-Specific-Application-Id, use vendorSpecificAuthApplicationIds or",
            "                vendorSpecificAcctApplicationIds, respectively. Only one Vendor-Id is supported for all the",
            "                Vendor-Specific-Application-Id AVPs in a CER monitoring message.",
            "            - \"Minimum value = 1\"",
            "",
            "    vendorspecificauthapplicationids:",
            "        description:",
            "            - >-",
            "                List of Vendor-Specific-Auth-Application-Id attribute value pairs (AVPs) for the",
            "                Capabilities-Exchange-Request (CER) message to use for monitoring Diameter servers. A maximum of",
            "                eight of these AVPs are supported in a monitoring message. The specified value is combined with the",
            "                value of vendorSpecificVendorId to obtain the Vendor-Specific-Application-Id AVP in the CER",
            "                monitoring message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    vendorspecificacctapplicationids:",
            "        description:",
            "            - >-",
            "                List of Vendor-Specific-Acct-Application-Id attribute value pairs (AVPs) to use for monitoring",
            "                Diameter servers. A maximum of eight of these AVPs are supported in a monitoring message. The",
            "                specified value is combined with the value of vendorSpecificVendorId to obtain the",
            "                Vendor-Specific-Application-Id AVP in the CER monitoring message.",
            "            - \"Minimum value = C(0)\"",
            "            - \"Maximum value = C(4294967295)\"",
            "",
            "    kcdaccount:",
            "        description:",
            "            - \"KCD Account used by C(MSSQL) monitor.\"",
            "            - \"Minimum length = 1\"",
            "            - \"Maximum length = 32\"",
            "",
            "    storedb:",
            "        choices:",
            "            - 'enabled'",
            "            - 'disabled'",
            "        description:",
            "            - >-",
            "                Store the database list populated with the responses to monitor probes. Used in database specific",
            "                load balancing if C(MSSQL-ECV)/C(MYSQL-ECV) monitor is configured.",
            "",
            "    storefrontcheckbackendservices:",
            "        description:",
            "            - >-",
            "                This option will enable monitoring of services running on storefront server. Storefront services are",
            "                monitored by probing to a Windows service that runs on the Storefront server and exposes details of",
            "                which storefront services are running.",
            "        type: bool",
            "",
            "    trofscode:",
            "        description:",
            "            - \"Code expected when the server is under maintenance.\"",
            "",
            "    trofsstring:",
            "        description:",
            "            - >-",
            "                String expected from the server for the service to be marked as trofs. Applicable to HTTP-ECV/TCP-ECV",
            "                monitors.",
            "",
            "extends_documentation_fragment: netscaler",
            "requirements:",
            "    - nitro python sdk",
            "'''",
            "",
            "EXAMPLES = '''",
            "- name: Set lb monitor",
            "  local_action:",
            "    nsip: 172.18.0.2",
            "    nitro_user: nsroot",
            "    nitro_pass: nsroot",
            "    validate_certs: no",
            "",
            "",
            "    module: netscaler_lb_monitor",
            "    state: present",
            "",
            "    monitorname: monitor_1",
            "    type: HTTP-INLINE",
            "    action: DOWN",
            "    respcode: ['400']",
            "'''",
            "",
            "RETURN = '''",
            "loglines:",
            "    description: list of logged messages by the module",
            "    returned: always",
            "    type: list",
            "    sample: ['message 1', 'message 2']",
            "",
            "msg:",
            "    description: Message detailing the failure reason",
            "    returned: failure",
            "    type: str",
            "    sample: \"Action does not exist\"",
            "",
            "diff:",
            "    description: List of differences between the actual configured object and the configuration specified in the module",
            "    returned: failure",
            "    type: dict",
            "    sample: { 'targetlbvserver': 'difference. ours: (str) server1 other: (str) server2' }",
            "'''",
            "",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "from ansible.module_utils.network.netscaler.netscaler import (",
            "    ConfigProxy,",
            "    get_nitro_client,",
            "    netscaler_common_arguments,",
            "    log,",
            "    loglines,",
            "    ensure_feature_is_enabled,",
            "    get_immutables_intersection",
            ")",
            "",
            "try:",
            "    from nssrc.com.citrix.netscaler.nitro.resource.config.lb.lbmonitor import lbmonitor",
            "    from nssrc.com.citrix.netscaler.nitro.exception.nitro_exception import nitro_exception",
            "    PYTHON_SDK_IMPORTED = True",
            "except ImportError as e:",
            "    PYTHON_SDK_IMPORTED = False",
            "",
            "",
            "def lbmonitor_exists(client, module):",
            "    log('Checking if monitor exists')",
            "    if lbmonitor.count_filtered(client, 'monitorname:%s' % module.params['monitorname']) > 0:",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def lbmonitor_identical(client, module, lbmonitor_proxy):",
            "    log('Checking if monitor is identical')",
            "",
            "    count = lbmonitor.count_filtered(client, 'monitorname:%s' % module.params['monitorname'])",
            "    if count == 0:",
            "        return False",
            "",
            "    lbmonitor_list = lbmonitor.get_filtered(client, 'monitorname:%s' % module.params['monitorname'])",
            "    diff_dict = lbmonitor_proxy.diff_object(lbmonitor_list[0])",
            "",
            "    # Skipping hashed fields since the cannot be compared directly",
            "    hashed_fields = [",
            "        'password',",
            "        'secondarypassword',",
            "        'radkey',",
            "    ]",
            "    for key in hashed_fields:",
            "        if key in diff_dict:",
            "            del diff_dict[key]",
            "",
            "    if diff_dict == {}:",
            "        return True",
            "    else:",
            "        return False",
            "",
            "",
            "def diff_list(client, module, lbmonitor_proxy):",
            "    monitor_list = lbmonitor.get_filtered(client, 'monitorname:%s' % module.params['monitorname'])",
            "    return lbmonitor_proxy.diff_object(monitor_list[0])",
            "",
            "",
            "def main():",
            "",
            "    module_specific_arguments = dict(",
            "",
            "        monitorname=dict(type='str'),",
            "",
            "        type=dict(",
            "            type='str',",
            "            choices=[",
            "                'PING',",
            "                'TCP',",
            "                'HTTP',",
            "                'TCP-ECV',",
            "                'HTTP-ECV',",
            "                'UDP-ECV',",
            "                'DNS',",
            "                'FTP',",
            "                'LDNS-PING',",
            "                'LDNS-TCP',",
            "                'LDNS-DNS',",
            "                'RADIUS',",
            "                'USER',",
            "                'HTTP-INLINE',",
            "                'SIP-UDP',",
            "                'SIP-TCP',",
            "                'LOAD',",
            "                'FTP-EXTENDED',",
            "                'SMTP',",
            "                'SNMP',",
            "                'NNTP',",
            "                'MYSQL',",
            "                'MYSQL-ECV',",
            "                'MSSQL-ECV',",
            "                'ORACLE-ECV',",
            "                'LDAP',",
            "                'POP3',",
            "                'CITRIX-XML-SERVICE',",
            "                'CITRIX-WEB-INTERFACE',",
            "                'DNS-TCP',",
            "                'RTSP',",
            "                'ARP',",
            "                'CITRIX-AG',",
            "                'CITRIX-AAC-LOGINPAGE',",
            "                'CITRIX-AAC-LAS',",
            "                'CITRIX-XD-DDC',",
            "                'ND6',",
            "                'CITRIX-WI-EXTENDED',",
            "                'DIAMETER',",
            "                'RADIUS_ACCOUNTING',",
            "                'STOREFRONT',",
            "                'APPC',",
            "                'SMPP',",
            "                'CITRIX-XNC-ECV',",
            "                'CITRIX-XDM',",
            "                'CITRIX-STA-SERVICE',",
            "                'CITRIX-STA-SERVICE-NHOP',",
            "            ]",
            "        ),",
            "",
            "        action=dict(",
            "            type='str',",
            "            choices=[",
            "                'NONE',",
            "                'LOG',",
            "                'DOWN',",
            "            ]",
            "        ),",
            "        respcode=dict(type='list'),",
            "        httprequest=dict(type='str'),",
            "        rtsprequest=dict(type='str'),",
            "        customheaders=dict(type='str'),",
            "        maxforwards=dict(type='float'),",
            "        sipmethod=dict(",
            "            type='str',",
            "            choices=[",
            "                'OPTIONS',",
            "                'INVITE',",
            "                'REGISTER',",
            "            ]",
            "        ),",
            "        sipuri=dict(type='str'),",
            "        sipreguri=dict(type='str'),",
            "        send=dict(type='str'),",
            "        recv=dict(type='str'),",
            "        query=dict(type='str'),",
            "        querytype=dict(",
            "            type='str',",
            "            choices=[",
            "                'Address',",
            "                'Zone',",
            "                'AAAA',",
            "            ]",
            "        ),",
            "        scriptname=dict(type='str'),",
            "        scriptargs=dict(type='str'),",
            "        dispatcherip=dict(type='str'),",
            "        dispatcherport=dict(type='int'),",
            "        username=dict(type='str'),",
            "        password=dict(type='str'),",
            "        secondarypassword=dict(type='str'),",
            "        logonpointname=dict(type='str'),",
            "        lasversion=dict(type='str'),",
            "        radkey=dict(type='str', no_log=True),",
            "        radnasid=dict(type='str'),",
            "        radnasip=dict(type='str'),",
            "        radaccounttype=dict(type='float'),",
            "        radframedip=dict(type='str'),",
            "        radapn=dict(type='str'),",
            "        radmsisdn=dict(type='str'),",
            "        radaccountsession=dict(type='str'),",
            "        lrtm=dict(",
            "            type='str',",
            "            choices=[",
            "                'enabled',",
            "                'disabled',",
            "            ]",
            "        ),",
            "        deviation=dict(type='float'),",
            "        units1=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        interval=dict(type='int'),",
            "        units3=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        resptimeout=dict(type='int'),",
            "        units4=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        resptimeoutthresh=dict(type='float'),",
            "        retries=dict(type='int'),",
            "        failureretries=dict(type='int'),",
            "        alertretries=dict(type='int'),",
            "        successretries=dict(type='int'),",
            "        downtime=dict(type='int'),",
            "        units2=dict(",
            "            type='str',",
            "            choices=[",
            "                'SEC',",
            "                'MSEC',",
            "                'MIN',",
            "            ]",
            "        ),",
            "        destip=dict(type='str'),",
            "        destport=dict(type='int'),",
            "        reverse=dict(type='bool'),",
            "        transparent=dict(type='bool'),",
            "        iptunnel=dict(type='bool'),",
            "        tos=dict(type='bool'),",
            "        tosid=dict(type='float'),",
            "        secure=dict(type='bool'),",
            "        validatecred=dict(type='bool'),",
            "        domain=dict(type='str'),",
            "        ipaddress=dict(type='list'),",
            "        group=dict(type='str'),",
            "        filename=dict(type='str'),",
            "        basedn=dict(type='str'),",
            "        binddn=dict(type='str'),",
            "        filter=dict(type='str'),",
            "        attribute=dict(type='str'),",
            "        database=dict(type='str'),",
            "        oraclesid=dict(type='str'),",
            "        sqlquery=dict(type='str'),",
            "        evalrule=dict(type='str'),",
            "        mssqlprotocolversion=dict(",
            "            type='str',",
            "            choices=[",
            "                '70',",
            "                '2000',",
            "                '2000SP1',",
            "                '2005',",
            "                '2008',",
            "                '2008R2',",
            "                '2012',",
            "                '2014',",
            "            ]",
            "        ),",
            "        Snmpoid=dict(type='str'),",
            "        snmpcommunity=dict(type='str'),",
            "        snmpthreshold=dict(type='str'),",
            "        snmpversion=dict(",
            "            type='str',",
            "            choices=[",
            "                'V1',",
            "                'V2',",
            "            ]",
            "        ),",
            "        application=dict(type='str'),",
            "        sitepath=dict(type='str'),",
            "        storename=dict(type='str'),",
            "        storefrontacctservice=dict(type='bool'),",
            "        hostname=dict(type='str'),",
            "        netprofile=dict(type='str'),",
            "        originhost=dict(type='str'),",
            "        originrealm=dict(type='str'),",
            "        hostipaddress=dict(type='str'),",
            "        vendorid=dict(type='float'),",
            "        productname=dict(type='str'),",
            "        firmwarerevision=dict(type='float'),",
            "        authapplicationid=dict(type='list'),",
            "        acctapplicationid=dict(type='list'),",
            "        inbandsecurityid=dict(",
            "            type='str',",
            "            choices=[",
            "                'NO_INBAND_SECURITY',",
            "                'TLS',",
            "            ]",
            "        ),",
            "        supportedvendorids=dict(type='list'),",
            "        vendorspecificvendorid=dict(type='float'),",
            "        vendorspecificauthapplicationids=dict(type='list'),",
            "        vendorspecificacctapplicationids=dict(type='list'),",
            "        storedb=dict(",
            "            type='str',",
            "            choices=[",
            "                'enabled',",
            "                'disabled',",
            "            ]",
            "        ),",
            "        storefrontcheckbackendservices=dict(type='bool'),",
            "        trofscode=dict(type='float'),",
            "        trofsstring=dict(type='str'),",
            "    )",
            "",
            "    hand_inserted_arguments = dict()",
            "",
            "    argument_spec = dict()",
            "    argument_spec.update(module_specific_arguments)",
            "    argument_spec.update(netscaler_common_arguments)",
            "    argument_spec.update(hand_inserted_arguments)",
            "",
            "    module = AnsibleModule(",
            "        argument_spec=argument_spec,",
            "        supports_check_mode=True,",
            "    )",
            "",
            "    module_result = dict(",
            "        changed=False,",
            "        failed=False,",
            "        loglines=loglines,",
            "    )",
            "",
            "    # Fail the module if imports failed",
            "    if not PYTHON_SDK_IMPORTED:",
            "        module.fail_json(msg='Could not load nitro python sdk', **module_result)",
            "",
            "    # Fallthrough to rest of execution",
            "    client = get_nitro_client(module)",
            "",
            "    try:",
            "        client.login()",
            "    except nitro_exception as e:",
            "        msg = \"nitro exception during login. errorcode=%s, message=%s\" % (str(e.errorcode), e.message)",
            "        module.fail_json(msg=msg)",
            "    except Exception as e:",
            "        if str(type(e)) == \"<class 'requests.exceptions.ConnectionError'>\":",
            "            module.fail_json(msg='Connection error %s' % str(e))",
            "        elif str(type(e)) == \"<class 'requests.exceptions.SSLError'>\":",
            "            module.fail_json(msg='SSL Error %s' % str(e))",
            "        else:",
            "            module.fail_json(msg='Unexpected error during login %s' % str(e))",
            "",
            "    # Instantiate lb monitor object",
            "    readwrite_attrs = [",
            "        'monitorname',",
            "        'type',",
            "        'action',",
            "        'respcode',",
            "        'httprequest',",
            "        'rtsprequest',",
            "        'customheaders',",
            "        'maxforwards',",
            "        'sipmethod',",
            "        'sipuri',",
            "        'sipreguri',",
            "        'send',",
            "        'recv',",
            "        'query',",
            "        'querytype',",
            "        'scriptname',",
            "        'scriptargs',",
            "        'dispatcherip',",
            "        'dispatcherport',",
            "        'username',",
            "        'password',",
            "        'secondarypassword',",
            "        'logonpointname',",
            "        'lasversion',",
            "        'radkey',",
            "        'radnasid',",
            "        'radnasip',",
            "        'radaccounttype',",
            "        'radframedip',",
            "        'radapn',",
            "        'radmsisdn',",
            "        'radaccountsession',",
            "        'lrtm',",
            "        'deviation',",
            "        'units1',",
            "        'interval',",
            "        'units3',",
            "        'resptimeout',",
            "        'units4',",
            "        'resptimeoutthresh',",
            "        'retries',",
            "        'failureretries',",
            "        'alertretries',",
            "        'successretries',",
            "        'downtime',",
            "        'units2',",
            "        'destip',",
            "        'destport',",
            "        'reverse',",
            "        'transparent',",
            "        'iptunnel',",
            "        'tos',",
            "        'tosid',",
            "        'secure',",
            "        'validatecred',",
            "        'domain',",
            "        'ipaddress',",
            "        'group',",
            "        'filename',",
            "        'basedn',",
            "        'binddn',",
            "        'filter',",
            "        'attribute',",
            "        'database',",
            "        'oraclesid',",
            "        'sqlquery',",
            "        'evalrule',",
            "        'mssqlprotocolversion',",
            "        'Snmpoid',",
            "        'snmpcommunity',",
            "        'snmpthreshold',",
            "        'snmpversion',",
            "        'application',",
            "        'sitepath',",
            "        'storename',",
            "        'storefrontacctservice',",
            "        'netprofile',",
            "        'originhost',",
            "        'originrealm',",
            "        'hostipaddress',",
            "        'vendorid',",
            "        'productname',",
            "        'firmwarerevision',",
            "        'authapplicationid',",
            "        'acctapplicationid',",
            "        'inbandsecurityid',",
            "        'supportedvendorids',",
            "        'vendorspecificvendorid',",
            "        'vendorspecificauthapplicationids',",
            "        'vendorspecificacctapplicationids',",
            "        'storedb',",
            "        'storefrontcheckbackendservices',",
            "        'trofscode',",
            "        'trofsstring',",
            "    ]",
            "",
            "    readonly_attrs = [",
            "        'lrtmconf',",
            "        'lrtmconfstr',",
            "        'dynamicresponsetimeout',",
            "        'dynamicinterval',",
            "        'multimetrictable',",
            "        'dup_state',",
            "        'dup_weight',",
            "        'weight',",
            "    ]",
            "",
            "    immutable_attrs = [",
            "        'monitorname',",
            "        'type',",
            "        'units1',",
            "        'units3',",
            "        'units4',",
            "        'units2',",
            "        'Snmpoid',",
            "        'hostname',",
            "        'servicename',",
            "        'servicegroupname',",
            "    ]",
            "",
            "    transforms = {",
            "        'storefrontcheckbackendservices': ['bool_yes_no'],",
            "        'secure': ['bool_yes_no'],",
            "        'tos': ['bool_yes_no'],",
            "        'validatecred': ['bool_yes_no'],",
            "        'storefrontacctservice': ['bool_yes_no'],",
            "        'iptunnel': ['bool_yes_no'],",
            "        'transparent': ['bool_yes_no'],",
            "        'reverse': ['bool_yes_no'],",
            "        'lrtm': [lambda v: v.upper()],",
            "        'storedb': [lambda v: v.upper()],",
            "    }",
            "",
            "    lbmonitor_proxy = ConfigProxy(",
            "        actual=lbmonitor(),",
            "        client=client,",
            "        attribute_values_dict=module.params,",
            "        readwrite_attrs=readwrite_attrs,",
            "        readonly_attrs=readonly_attrs,",
            "        immutable_attrs=immutable_attrs,",
            "        transforms=transforms,",
            "    )",
            "",
            "    try:",
            "        ensure_feature_is_enabled(client, 'LB')",
            "",
            "        if module.params['state'] == 'present':",
            "            log('Applying actions for state present')",
            "            if not lbmonitor_exists(client, module):",
            "                if not module.check_mode:",
            "                    log('Adding monitor')",
            "                    lbmonitor_proxy.add()",
            "                    if module.params['save_config']:",
            "                        client.save_config()",
            "                module_result['changed'] = True",
            "            elif not lbmonitor_identical(client, module, lbmonitor_proxy):",
            "",
            "                # Check if we try to change value of immutable attributes",
            "                immutables_changed = get_immutables_intersection(lbmonitor_proxy, diff_list(client, module, lbmonitor_proxy).keys())",
            "                if immutables_changed != []:",
            "                    diff = diff_list(client, module, lbmonitor_proxy)",
            "                    msg = 'Cannot update immutable attributes %s' % (immutables_changed,)",
            "                    module.fail_json(msg=msg, diff=diff, **module_result)",
            "",
            "                if not module.check_mode:",
            "                    log('Updating monitor')",
            "                    lbmonitor_proxy.update()",
            "                    if module.params['save_config']:",
            "                        client.save_config()",
            "                module_result['changed'] = True",
            "            else:",
            "                log('Doing nothing for monitor')",
            "                module_result['changed'] = False",
            "",
            "            # Sanity check for result",
            "            log('Sanity checks for state present')",
            "            if not module.check_mode:",
            "                if not lbmonitor_exists(client, module):",
            "                    module.fail_json(msg='lb monitor does not exist', **module_result)",
            "                if not lbmonitor_identical(client, module, lbmonitor_proxy):",
            "                    module.fail_json(",
            "                        msg='lb monitor is not configured correctly',",
            "                        diff=diff_list(client, module, lbmonitor_proxy),",
            "                        **module_result",
            "                    )",
            "",
            "        elif module.params['state'] == 'absent':",
            "            log('Applying actions for state absent')",
            "            if lbmonitor_exists(client, module):",
            "                if not module.check_mode:",
            "                    lbmonitor_proxy.delete()",
            "                    if module.params['save_config']:",
            "                        client.save_config()",
            "                module_result['changed'] = True",
            "            else:",
            "                module_result['changed'] = False",
            "",
            "            # Sanity check for result",
            "            log('Sanity checks for state absent')",
            "            if not module.check_mode:",
            "                if lbmonitor_exists(client, module):",
            "                    module.fail_json(msg='lb monitor still exists', **module_result)",
            "",
            "        module_result['actual_attributes'] = lbmonitor_proxy.get_actual_rw_attributes(filter='monitorname')",
            "    except nitro_exception as e:",
            "        msg = \"nitro exception errorcode=%s, message=%s\" % (str(e.errorcode), e.message)",
            "        module.fail_json(msg=msg, **module_result)",
            "",
            "    client.logout()",
            "",
            "    module.exit_json(**module_result)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "989": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/network/nxos/nxos_aaa_server.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 234,
                "PatchRowcode": " def main():"
            },
            "1": {
                "beforePatchRowNumber": 235,
                "afterPatchRowNumber": 235,
                "PatchRowcode": "     argument_spec = dict("
            },
            "2": {
                "beforePatchRowNumber": 236,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         server_type=dict(type='str', choices=['radius', 'tacacs'], required=True),"
            },
            "3": {
                "beforePatchRowNumber": 237,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        global_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 237,
                "PatchRowcode": "+        global_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 238,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "         encrypt_type=dict(type='str', choices=['0', '7']),"
            },
            "6": {
                "beforePatchRowNumber": 239,
                "afterPatchRowNumber": 239,
                "PatchRowcode": "         deadtime=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 240,
                "afterPatchRowNumber": 240,
                "PatchRowcode": "         server_timeout=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "#",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'network'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "",
            "module: nxos_aaa_server",
            "extends_documentation_fragment: nxos",
            "version_added: \"2.2\"",
            "short_description: Manages AAA server global configuration.",
            "description:",
            "    - Manages AAA server global configuration",
            "author:",
            "    - Jason Edelman (@jedelman8)",
            "notes:",
            "    - Tested against NXOSv 7.3.(0)D1(1) on VIRL",
            "    - The server_type parameter is always required.",
            "    - If encrypt_type is not supplied, the global AAA server key will be",
            "      stored as encrypted (type 7).",
            "    - Changes to the global AAA server key with encrypt_type=0",
            "      are not idempotent.",
            "    - state=default will set the supplied parameters to their default values.",
            "      The parameters that you want to default must also be set to default.",
            "      If global_key=default, the global key will be removed.",
            "options:",
            "    server_type:",
            "        description:",
            "            - The server type is either radius or tacacs.",
            "        required: true",
            "        choices: ['radius', 'tacacs']",
            "    global_key:",
            "        description:",
            "            - Global AAA shared secret or keyword 'default'.",
            "    encrypt_type:",
            "        description:",
            "            - The state of encryption applied to the entered global key.",
            "              O clear text, 7 encrypted. Type-6 encryption is not supported.",
            "        choices: ['0', '7']",
            "    deadtime:",
            "        description:",
            "            - Duration for which a non-reachable AAA server is skipped,",
            "              in minutes or keyword 'default.",
            "              Range is 1-1440. Device default is 0.",
            "    server_timeout:",
            "        description:",
            "            - Global AAA server timeout period, in seconds or keyword 'default.",
            "              Range is 1-60. Device default is 5.",
            "    directed_request:",
            "        description:",
            "            - Enables direct authentication requests to AAA server or keyword 'default'",
            "              Device default is disabled.",
            "        choices: ['enabled', 'disabled']",
            "    state:",
            "        description:",
            "            - Manage the state of the resource.",
            "        default: present",
            "        choices: ['present','default']",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Radius Server Basic settings",
            "  - name: \"Radius Server Basic settings\"",
            "    nxos_aaa_server:",
            "        server_type: radius",
            "        server_timeout: 9",
            "        deadtime: 20",
            "        directed_request: enabled",
            "",
            "# Tacacs Server Basic settings",
            "  - name: \"Tacacs Server Basic settings\"",
            "    nxos_aaa_server:",
            "        server_type: tacacs",
            "        server_timeout: 8",
            "        deadtime: 19",
            "        directed_request: disabled",
            "",
            "# Setting Global Key",
            "  - name: \"AAA Server Global Key\"",
            "    nxos_aaa_server:",
            "        server_type: radius",
            "        global_key: test_key",
            "'''",
            "",
            "RETURN = '''",
            "commands:",
            "    description: command sent to the device",
            "    returned: always",
            "    type: list",
            "    sample: [\"radius-server deadtime 22\", \"radius-server timeout 11\",",
            "             \"radius-server directed-request\"]",
            "'''",
            "import re",
            "",
            "from ansible.module_utils.network.nxos.nxos import load_config, run_commands",
            "from ansible.module_utils.network.nxos.nxos import nxos_argument_spec, check_args",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "",
            "PARAM_TO_DEFAULT_KEYMAP = {",
            "    'server_timeout': '5',",
            "    'deadtime': '0',",
            "    'directed_request': 'disabled',",
            "}",
            "",
            "",
            "def execute_show_command(command, module):",
            "    command = {",
            "        'command': command,",
            "        'output': 'text',",
            "    }",
            "",
            "    return run_commands(module, command)",
            "",
            "",
            "def flatten_list(command_lists):",
            "    flat_command_list = []",
            "    for command in command_lists:",
            "        if isinstance(command, list):",
            "            flat_command_list.extend(command)",
            "        else:",
            "            flat_command_list.append(command)",
            "    return flat_command_list",
            "",
            "",
            "def get_aaa_server_info(server_type, module):",
            "    aaa_server_info = {}",
            "    server_command = 'show {0}-server'.format(server_type)",
            "    request_command = 'show {0}-server directed-request'.format(server_type)",
            "    global_key_command = 'show run | sec {0}'.format(server_type)",
            "    aaa_regex = r'.*{0}-server\\skey\\s\\d\\s+(?P<key>\\S+).*'.format(server_type)",
            "",
            "    server_body = execute_show_command(server_command, module)[0]",
            "",
            "    split_server = server_body.splitlines()",
            "",
            "    for line in split_server:",
            "        if line.startswith('timeout'):",
            "            aaa_server_info['server_timeout'] = line.split(':')[1]",
            "",
            "        elif line.startswith('deadtime'):",
            "            aaa_server_info['deadtime'] = line.split(':')[1]",
            "",
            "    request_body = execute_show_command(request_command, module)[0]",
            "",
            "    if bool(request_body):",
            "        aaa_server_info['directed_request'] = request_body.replace('\\n', '')",
            "    else:",
            "        aaa_server_info['directed_request'] = 'disabled'",
            "",
            "    key_body = execute_show_command(global_key_command, module)[0]",
            "",
            "    try:",
            "        match_global_key = re.match(aaa_regex, key_body, re.DOTALL)",
            "        group_key = match_global_key.groupdict()",
            "        aaa_server_info['global_key'] = group_key[\"key\"].replace('\\\"', '')",
            "    except (AttributeError, TypeError):",
            "        aaa_server_info['global_key'] = None",
            "",
            "    return aaa_server_info",
            "",
            "",
            "def config_aaa_server(params, server_type):",
            "    cmds = []",
            "",
            "    deadtime = params.get('deadtime')",
            "    server_timeout = params.get('server_timeout')",
            "    directed_request = params.get('directed_request')",
            "    encrypt_type = params.get('encrypt_type', '7')",
            "    global_key = params.get('global_key')",
            "",
            "    if deadtime is not None:",
            "        cmds.append('{0}-server deadtime {1}'.format(server_type, deadtime))",
            "",
            "    if server_timeout is not None:",
            "        cmds.append('{0}-server timeout {1}'.format(server_type, server_timeout))",
            "",
            "    if directed_request is not None:",
            "        if directed_request == 'enabled':",
            "            cmds.append('{0}-server directed-request'.format(server_type))",
            "        elif directed_request == 'disabled':",
            "            cmds.append('no {0}-server directed-request'.format(server_type))",
            "",
            "    if global_key is not None:",
            "        cmds.append('{0}-server key {1} {2}'.format(server_type, encrypt_type,",
            "                                                    global_key))",
            "",
            "    return cmds",
            "",
            "",
            "def default_aaa_server(existing, params, server_type):",
            "    cmds = []",
            "",
            "    deadtime = params.get('deadtime')",
            "    server_timeout = params.get('server_timeout')",
            "    directed_request = params.get('directed_request')",
            "    global_key = params.get('global_key')",
            "    existing_key = existing.get('global_key')",
            "",
            "    if deadtime is not None and existing.get('deadtime') != PARAM_TO_DEFAULT_KEYMAP['deadtime']:",
            "        cmds.append('no {0}-server deadtime 1'.format(server_type))",
            "",
            "    if server_timeout is not None and existing.get('server_timeout') != PARAM_TO_DEFAULT_KEYMAP['server_timeout']:",
            "        cmds.append('no {0}-server timeout 1'.format(server_type))",
            "",
            "    if directed_request is not None and existing.get('directed_request') != PARAM_TO_DEFAULT_KEYMAP['directed_request']:",
            "        cmds.append('no {0}-server directed-request'.format(server_type))",
            "",
            "    if global_key is not None and existing_key is not None:",
            "        cmds.append('no {0}-server key 7 {1}'.format(server_type, existing_key))",
            "",
            "    return cmds",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        server_type=dict(type='str', choices=['radius', 'tacacs'], required=True),",
            "        global_key=dict(type='str'),",
            "        encrypt_type=dict(type='str', choices=['0', '7']),",
            "        deadtime=dict(type='str'),",
            "        server_timeout=dict(type='str'),",
            "        directed_request=dict(type='str', choices=['enabled', 'disabled', 'default']),",
            "        state=dict(choices=['default', 'present'], default='present'),",
            "    )",
            "",
            "    argument_spec.update(nxos_argument_spec)",
            "",
            "    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)",
            "",
            "    warnings = list()",
            "    check_args(module, warnings)",
            "    results = {'changed': False, 'commands': [], 'warnings': warnings}",
            "",
            "    server_type = module.params['server_type']",
            "    global_key = module.params['global_key']",
            "    encrypt_type = module.params['encrypt_type']",
            "    deadtime = module.params['deadtime']",
            "    server_timeout = module.params['server_timeout']",
            "    directed_request = module.params['directed_request']",
            "    state = module.params['state']",
            "",
            "    if encrypt_type and not global_key:",
            "        module.fail_json(msg='encrypt_type must be used with global_key.')",
            "",
            "    args = dict(server_type=server_type, global_key=global_key,",
            "                encrypt_type=encrypt_type, deadtime=deadtime,",
            "                server_timeout=server_timeout, directed_request=directed_request)",
            "",
            "    proposed = dict((k, v) for k, v in args.items() if v is not None)",
            "",
            "    existing = get_aaa_server_info(server_type, module)",
            "",
            "    commands = []",
            "    if state == 'present':",
            "        if deadtime:",
            "            try:",
            "                if int(deadtime) < 0 or int(deadtime) > 1440:",
            "                    raise ValueError",
            "            except ValueError:",
            "                module.fail_json(",
            "                    msg='deadtime must be an integer between 0 and 1440')",
            "",
            "        if server_timeout:",
            "            try:",
            "                if int(server_timeout) < 1 or int(server_timeout) > 60:",
            "                    raise ValueError",
            "            except ValueError:",
            "                module.fail_json(",
            "                    msg='server_timeout must be an integer between 1 and 60')",
            "",
            "        delta = dict(set(proposed.items()).difference(",
            "            existing.items()))",
            "        if delta:",
            "            command = config_aaa_server(delta, server_type)",
            "            if command:",
            "                commands.append(command)",
            "",
            "    elif state == 'default':",
            "        for key, value in proposed.items():",
            "            if key != 'server_type' and value != 'default':",
            "                module.fail_json(",
            "                    msg='Parameters must be set to \"default\"'",
            "                        'when state=default')",
            "        command = default_aaa_server(existing, proposed, server_type)",
            "        if command:",
            "            commands.append(command)",
            "",
            "    cmds = flatten_list(commands)",
            "    if cmds:",
            "        results['changed'] = True",
            "        if not module.check_mode:",
            "            load_config(module, cmds)",
            "        if 'configure' in cmds:",
            "            cmds.pop(0)",
            "        results['commands'] = cmds",
            "",
            "    module.exit_json(**results)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "#",
            "# This file is part of Ansible",
            "#",
            "# Ansible is free software: you can redistribute it and/or modify",
            "# it under the terms of the GNU General Public License as published by",
            "# the Free Software Foundation, either version 3 of the License, or",
            "# (at your option) any later version.",
            "#",
            "# Ansible is distributed in the hope that it will be useful,",
            "# but WITHOUT ANY WARRANTY; without even the implied warranty of",
            "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the",
            "# GNU General Public License for more details.",
            "#",
            "# You should have received a copy of the GNU General Public License",
            "# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.",
            "#",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'network'}",
            "",
            "",
            "DOCUMENTATION = '''",
            "---",
            "",
            "module: nxos_aaa_server",
            "extends_documentation_fragment: nxos",
            "version_added: \"2.2\"",
            "short_description: Manages AAA server global configuration.",
            "description:",
            "    - Manages AAA server global configuration",
            "author:",
            "    - Jason Edelman (@jedelman8)",
            "notes:",
            "    - Tested against NXOSv 7.3.(0)D1(1) on VIRL",
            "    - The server_type parameter is always required.",
            "    - If encrypt_type is not supplied, the global AAA server key will be",
            "      stored as encrypted (type 7).",
            "    - Changes to the global AAA server key with encrypt_type=0",
            "      are not idempotent.",
            "    - state=default will set the supplied parameters to their default values.",
            "      The parameters that you want to default must also be set to default.",
            "      If global_key=default, the global key will be removed.",
            "options:",
            "    server_type:",
            "        description:",
            "            - The server type is either radius or tacacs.",
            "        required: true",
            "        choices: ['radius', 'tacacs']",
            "    global_key:",
            "        description:",
            "            - Global AAA shared secret or keyword 'default'.",
            "    encrypt_type:",
            "        description:",
            "            - The state of encryption applied to the entered global key.",
            "              O clear text, 7 encrypted. Type-6 encryption is not supported.",
            "        choices: ['0', '7']",
            "    deadtime:",
            "        description:",
            "            - Duration for which a non-reachable AAA server is skipped,",
            "              in minutes or keyword 'default.",
            "              Range is 1-1440. Device default is 0.",
            "    server_timeout:",
            "        description:",
            "            - Global AAA server timeout period, in seconds or keyword 'default.",
            "              Range is 1-60. Device default is 5.",
            "    directed_request:",
            "        description:",
            "            - Enables direct authentication requests to AAA server or keyword 'default'",
            "              Device default is disabled.",
            "        choices: ['enabled', 'disabled']",
            "    state:",
            "        description:",
            "            - Manage the state of the resource.",
            "        default: present",
            "        choices: ['present','default']",
            "'''",
            "",
            "EXAMPLES = '''",
            "# Radius Server Basic settings",
            "  - name: \"Radius Server Basic settings\"",
            "    nxos_aaa_server:",
            "        server_type: radius",
            "        server_timeout: 9",
            "        deadtime: 20",
            "        directed_request: enabled",
            "",
            "# Tacacs Server Basic settings",
            "  - name: \"Tacacs Server Basic settings\"",
            "    nxos_aaa_server:",
            "        server_type: tacacs",
            "        server_timeout: 8",
            "        deadtime: 19",
            "        directed_request: disabled",
            "",
            "# Setting Global Key",
            "  - name: \"AAA Server Global Key\"",
            "    nxos_aaa_server:",
            "        server_type: radius",
            "        global_key: test_key",
            "'''",
            "",
            "RETURN = '''",
            "commands:",
            "    description: command sent to the device",
            "    returned: always",
            "    type: list",
            "    sample: [\"radius-server deadtime 22\", \"radius-server timeout 11\",",
            "             \"radius-server directed-request\"]",
            "'''",
            "import re",
            "",
            "from ansible.module_utils.network.nxos.nxos import load_config, run_commands",
            "from ansible.module_utils.network.nxos.nxos import nxos_argument_spec, check_args",
            "from ansible.module_utils.basic import AnsibleModule",
            "",
            "",
            "PARAM_TO_DEFAULT_KEYMAP = {",
            "    'server_timeout': '5',",
            "    'deadtime': '0',",
            "    'directed_request': 'disabled',",
            "}",
            "",
            "",
            "def execute_show_command(command, module):",
            "    command = {",
            "        'command': command,",
            "        'output': 'text',",
            "    }",
            "",
            "    return run_commands(module, command)",
            "",
            "",
            "def flatten_list(command_lists):",
            "    flat_command_list = []",
            "    for command in command_lists:",
            "        if isinstance(command, list):",
            "            flat_command_list.extend(command)",
            "        else:",
            "            flat_command_list.append(command)",
            "    return flat_command_list",
            "",
            "",
            "def get_aaa_server_info(server_type, module):",
            "    aaa_server_info = {}",
            "    server_command = 'show {0}-server'.format(server_type)",
            "    request_command = 'show {0}-server directed-request'.format(server_type)",
            "    global_key_command = 'show run | sec {0}'.format(server_type)",
            "    aaa_regex = r'.*{0}-server\\skey\\s\\d\\s+(?P<key>\\S+).*'.format(server_type)",
            "",
            "    server_body = execute_show_command(server_command, module)[0]",
            "",
            "    split_server = server_body.splitlines()",
            "",
            "    for line in split_server:",
            "        if line.startswith('timeout'):",
            "            aaa_server_info['server_timeout'] = line.split(':')[1]",
            "",
            "        elif line.startswith('deadtime'):",
            "            aaa_server_info['deadtime'] = line.split(':')[1]",
            "",
            "    request_body = execute_show_command(request_command, module)[0]",
            "",
            "    if bool(request_body):",
            "        aaa_server_info['directed_request'] = request_body.replace('\\n', '')",
            "    else:",
            "        aaa_server_info['directed_request'] = 'disabled'",
            "",
            "    key_body = execute_show_command(global_key_command, module)[0]",
            "",
            "    try:",
            "        match_global_key = re.match(aaa_regex, key_body, re.DOTALL)",
            "        group_key = match_global_key.groupdict()",
            "        aaa_server_info['global_key'] = group_key[\"key\"].replace('\\\"', '')",
            "    except (AttributeError, TypeError):",
            "        aaa_server_info['global_key'] = None",
            "",
            "    return aaa_server_info",
            "",
            "",
            "def config_aaa_server(params, server_type):",
            "    cmds = []",
            "",
            "    deadtime = params.get('deadtime')",
            "    server_timeout = params.get('server_timeout')",
            "    directed_request = params.get('directed_request')",
            "    encrypt_type = params.get('encrypt_type', '7')",
            "    global_key = params.get('global_key')",
            "",
            "    if deadtime is not None:",
            "        cmds.append('{0}-server deadtime {1}'.format(server_type, deadtime))",
            "",
            "    if server_timeout is not None:",
            "        cmds.append('{0}-server timeout {1}'.format(server_type, server_timeout))",
            "",
            "    if directed_request is not None:",
            "        if directed_request == 'enabled':",
            "            cmds.append('{0}-server directed-request'.format(server_type))",
            "        elif directed_request == 'disabled':",
            "            cmds.append('no {0}-server directed-request'.format(server_type))",
            "",
            "    if global_key is not None:",
            "        cmds.append('{0}-server key {1} {2}'.format(server_type, encrypt_type,",
            "                                                    global_key))",
            "",
            "    return cmds",
            "",
            "",
            "def default_aaa_server(existing, params, server_type):",
            "    cmds = []",
            "",
            "    deadtime = params.get('deadtime')",
            "    server_timeout = params.get('server_timeout')",
            "    directed_request = params.get('directed_request')",
            "    global_key = params.get('global_key')",
            "    existing_key = existing.get('global_key')",
            "",
            "    if deadtime is not None and existing.get('deadtime') != PARAM_TO_DEFAULT_KEYMAP['deadtime']:",
            "        cmds.append('no {0}-server deadtime 1'.format(server_type))",
            "",
            "    if server_timeout is not None and existing.get('server_timeout') != PARAM_TO_DEFAULT_KEYMAP['server_timeout']:",
            "        cmds.append('no {0}-server timeout 1'.format(server_type))",
            "",
            "    if directed_request is not None and existing.get('directed_request') != PARAM_TO_DEFAULT_KEYMAP['directed_request']:",
            "        cmds.append('no {0}-server directed-request'.format(server_type))",
            "",
            "    if global_key is not None and existing_key is not None:",
            "        cmds.append('no {0}-server key 7 {1}'.format(server_type, existing_key))",
            "",
            "    return cmds",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        server_type=dict(type='str', choices=['radius', 'tacacs'], required=True),",
            "        global_key=dict(type='str', no_log=True),",
            "        encrypt_type=dict(type='str', choices=['0', '7']),",
            "        deadtime=dict(type='str'),",
            "        server_timeout=dict(type='str'),",
            "        directed_request=dict(type='str', choices=['enabled', 'disabled', 'default']),",
            "        state=dict(choices=['default', 'present'], default='present'),",
            "    )",
            "",
            "    argument_spec.update(nxos_argument_spec)",
            "",
            "    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)",
            "",
            "    warnings = list()",
            "    check_args(module, warnings)",
            "    results = {'changed': False, 'commands': [], 'warnings': warnings}",
            "",
            "    server_type = module.params['server_type']",
            "    global_key = module.params['global_key']",
            "    encrypt_type = module.params['encrypt_type']",
            "    deadtime = module.params['deadtime']",
            "    server_timeout = module.params['server_timeout']",
            "    directed_request = module.params['directed_request']",
            "    state = module.params['state']",
            "",
            "    if encrypt_type and not global_key:",
            "        module.fail_json(msg='encrypt_type must be used with global_key.')",
            "",
            "    args = dict(server_type=server_type, global_key=global_key,",
            "                encrypt_type=encrypt_type, deadtime=deadtime,",
            "                server_timeout=server_timeout, directed_request=directed_request)",
            "",
            "    proposed = dict((k, v) for k, v in args.items() if v is not None)",
            "",
            "    existing = get_aaa_server_info(server_type, module)",
            "",
            "    commands = []",
            "    if state == 'present':",
            "        if deadtime:",
            "            try:",
            "                if int(deadtime) < 0 or int(deadtime) > 1440:",
            "                    raise ValueError",
            "            except ValueError:",
            "                module.fail_json(",
            "                    msg='deadtime must be an integer between 0 and 1440')",
            "",
            "        if server_timeout:",
            "            try:",
            "                if int(server_timeout) < 1 or int(server_timeout) > 60:",
            "                    raise ValueError",
            "            except ValueError:",
            "                module.fail_json(",
            "                    msg='server_timeout must be an integer between 1 and 60')",
            "",
            "        delta = dict(set(proposed.items()).difference(",
            "            existing.items()))",
            "        if delta:",
            "            command = config_aaa_server(delta, server_type)",
            "            if command:",
            "                commands.append(command)",
            "",
            "    elif state == 'default':",
            "        for key, value in proposed.items():",
            "            if key != 'server_type' and value != 'default':",
            "                module.fail_json(",
            "                    msg='Parameters must be set to \"default\"'",
            "                        'when state=default')",
            "        command = default_aaa_server(existing, proposed, server_type)",
            "        if command:",
            "            commands.append(command)",
            "",
            "    cmds = flatten_list(commands)",
            "    if cmds:",
            "        results['changed'] = True",
            "        if not module.check_mode:",
            "            load_config(module, cmds)",
            "        if 'configure' in cmds:",
            "            cmds.pop(0)",
            "        results['commands'] = cmds",
            "",
            "    module.exit_json(**results)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "237": [
                "main"
            ]
        },
        "addLocation": []
    },
    "lib/ansible/modules/network/nxos/nxos_pim_interface.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 435,
                "afterPatchRowNumber": 435,
                "PatchRowcode": "         interface=dict(type='str', required=True),"
            },
            "1": {
                "beforePatchRowNumber": 436,
                "afterPatchRowNumber": 436,
                "PatchRowcode": "         sparse=dict(type='bool', default=False),"
            },
            "2": {
                "beforePatchRowNumber": 437,
                "afterPatchRowNumber": 437,
                "PatchRowcode": "         dr_prio=dict(type='str'),"
            },
            "3": {
                "beforePatchRowNumber": 438,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        hello_auth_key=dict(type='str'),"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 438,
                "PatchRowcode": "+        hello_auth_key=dict(type='str', no_log=True),"
            },
            "5": {
                "beforePatchRowNumber": 439,
                "afterPatchRowNumber": 439,
                "PatchRowcode": "         hello_interval=dict(type='int'),"
            },
            "6": {
                "beforePatchRowNumber": 440,
                "afterPatchRowNumber": 440,
                "PatchRowcode": "         jp_policy_out=dict(type='str'),"
            },
            "7": {
                "beforePatchRowNumber": 441,
                "afterPatchRowNumber": 441,
                "PatchRowcode": "         jp_policy_in=dict(type='str'),"
            }
        },
        "frontPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'network'}",
            "",
            "DOCUMENTATION = r'''",
            "---",
            "module: nxos_pim_interface",
            "extends_documentation_fragment: nxos",
            "version_added: \"2.2\"",
            "short_description: Manages PIM interface configuration.",
            "description:",
            "  - Manages PIM interface configuration settings.",
            "author:",
            "  - Jason Edelman (@jedelman8)",
            "notes:",
            "  - Tested against NXOSv 7.3.(0)D1(1) on VIRL",
            "  - When C(state=default), supported params will be reset to a default state.",
            "    These include C(dr_prio), C(hello_auth_key), C(hello_interval), C(jp_policy_out),",
            "    C(jp_policy_in), C(jp_type_in), C(jp_type_out), C(border), C(neighbor_policy),",
            "    C(neighbor_type).",
            "  - The C(hello_auth_key) param is not idempotent.",
            "  - C(hello_auth_key) only supports clear text passwords.",
            "  - When C(state=absent), pim interface configuration will be set to defaults and pim-sm",
            "    will be disabled on the interface.",
            "  - PIM must be enabled on the device to use this module.",
            "  - This module is for Layer 3 interfaces.",
            "options:",
            "  interface:",
            "    description:",
            "      - Full name of the interface such as Ethernet1/33.",
            "    type: str",
            "    required: true",
            "  sparse:",
            "    description:",
            "      - Enable/disable sparse-mode on the interface.",
            "    type: bool",
            "    default: no",
            "  dr_prio:",
            "    description:",
            "      - Configures priority for PIM DR election on interface.",
            "    type: str",
            "  hello_auth_key:",
            "    description:",
            "      - Authentication for hellos on this interface.",
            "    type: str",
            "  hello_interval:",
            "    description:",
            "      - Hello interval in milliseconds for this interface.",
            "    type: int",
            "  jp_policy_out:",
            "    description:",
            "      - Policy for join-prune messages (outbound).",
            "    type: str",
            "  jp_policy_in:",
            "    description:",
            "      - Policy for join-prune messages (inbound).",
            "    type: str",
            "  jp_type_out:",
            "    description:",
            "      - Type of policy mapped to C(jp_policy_out).",
            "    type: str",
            "    choices: [ prefix, routemap ]",
            "  jp_type_in:",
            "    description:",
            "      - Type of policy mapped to C(jp_policy_in).",
            "    type: str",
            "    choices: [ prefix, routemap ]",
            "  border:",
            "    description:",
            "      - Configures interface to be a boundary of a PIM domain.",
            "    type: bool",
            "    default: no",
            "  neighbor_policy:",
            "    description:",
            "      - Configures a neighbor policy for filtering adjacencies.",
            "    type: str",
            "  neighbor_type:",
            "    description:",
            "      - Type of policy mapped to neighbor_policy.",
            "    type: str",
            "    choices: [ prefix, routemap ]",
            "  state:",
            "    description:",
            "      - Manages desired state of the resource.",
            "    type: str",
            "    choices: [ present, default ]",
            "    default: present",
            "'''",
            "EXAMPLES = r'''",
            "- name: Ensure PIM is not running on the interface",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    state: absent",
            "",
            "- name: Ensure the interface has pim-sm enabled with the appropriate priority and hello interval",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    dr_prio: 10",
            "    hello_interval: 40",
            "    state: present",
            "",
            "- name: Ensure join-prune policies exist",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    jp_policy_in: JPIN",
            "    jp_policy_out: JPOUT",
            "    jp_type_in: routemap",
            "    jp_type_out: routemap",
            "",
            "- name: Ensure defaults are in place",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    state: default",
            "'''",
            "",
            "RETURN = r'''",
            "commands:",
            "    description: command sent to the device",
            "    returned: always",
            "    type: list",
            "    sample: [\"interface eth1/33\", \"ip pim neighbor-policy test\",",
            "            \"ip pim neighbor-policy test\"]",
            "'''",
            "",
            "import re",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.network.nxos.nxos import get_config, load_config, run_commands",
            "from ansible.module_utils.network.nxos.nxos import nxos_argument_spec, check_args",
            "from ansible.module_utils.network.nxos.nxos import get_interface_type",
            "from ansible.module_utils.six import string_types",
            "",
            "",
            "PARAM_TO_COMMAND_KEYMAP = {",
            "    'interface': '',",
            "    'sparse': 'ip pim sparse-mode',",
            "    'dr_prio': 'ip pim dr-priority {0}',",
            "    'hello_interval': 'ip pim hello-interval {0}',",
            "    'hello_auth_key': 'ip pim hello-authentication ah-md5 {0}',",
            "    'border': 'ip pim border',",
            "    'jp_policy_out': 'ip pim jp-policy prefix-list {0} out',",
            "    'jp_policy_in': 'ip pim jp-policy prefix-list {0} in',",
            "    'jp_type_in': '',",
            "    'jp_type_out': '',",
            "    'neighbor_policy': 'ip pim neighbor-policy prefix-list {0}',",
            "    'neighbor_type': '',",
            "}",
            "",
            "PARAM_TO_DEFAULT_KEYMAP = {",
            "    'dr_prio': '1',",
            "    'hello_interval': '30000',",
            "    'sparse': False,",
            "    'border': False,",
            "    'hello_auth_key': False,",
            "}",
            "",
            "",
            "def execute_show_command(command, module, text=False):",
            "    if text:",
            "        cmds = [{",
            "            'command': command,",
            "            'output': 'text'",
            "        }]",
            "    else:",
            "        cmds = [{",
            "            'command': command,",
            "            'output': 'json'",
            "        }]",
            "",
            "    return run_commands(module, cmds)",
            "",
            "",
            "def flatten_list(command_lists):",
            "    flat_command_list = []",
            "    for command in command_lists:",
            "        if isinstance(command, list):",
            "            flat_command_list.extend(command)",
            "        else:",
            "            flat_command_list.append(command)",
            "    return flat_command_list",
            "",
            "",
            "def local_existing(gexisting):",
            "    jp_bidir = False",
            "    isauth = False",
            "    if gexisting:",
            "        jp_bidir = gexisting.get('jp_bidir')",
            "        isauth = gexisting.get('isauth')",
            "        if jp_bidir and isauth:",
            "            gexisting.pop('jp_bidir')",
            "            gexisting.pop('isauth')",
            "",
            "    return gexisting, jp_bidir, isauth",
            "",
            "",
            "def get_interface_mode(interface, intf_type, module):",
            "    mode = 'unknown'",
            "    command = 'show interface {0}'.format(interface)",
            "    body = execute_show_command(command, module)",
            "",
            "    try:",
            "        interface_table = body[0]['TABLE_interface']['ROW_interface']",
            "    except (KeyError, AttributeError, IndexError):",
            "        return mode",
            "",
            "    if intf_type in ['ethernet', 'portchannel']:",
            "        mode = str(interface_table.get('eth_mode', 'layer3'))",
            "        if mode in ['access', 'trunk']:",
            "            mode = 'layer2'",
            "        elif mode == 'routed':",
            "            mode = 'layer3'",
            "    elif intf_type in ['loopback', 'svi']:",
            "        mode = 'layer3'",
            "    return mode",
            "",
            "",
            "def get_pim_interface(module, interface):",
            "    pim_interface = {}",
            "    body = get_config(module, flags=['interface {0}'.format(interface)])",
            "",
            "    pim_interface['neighbor_type'] = None",
            "    pim_interface['neighbor_policy'] = None",
            "    pim_interface['jp_policy_in'] = None",
            "    pim_interface['jp_policy_out'] = None",
            "    pim_interface['jp_type_in'] = None",
            "    pim_interface['jp_type_out'] = None",
            "    pim_interface['jp_bidir'] = False",
            "    pim_interface['isauth'] = False",
            "",
            "    if body:",
            "        all_lines = body.splitlines()",
            "",
            "        for each in all_lines:",
            "            if 'jp-policy' in each:",
            "                policy_name = \\",
            "                    re.search(r'ip pim jp-policy(?: prefix-list)? (\\S+)(?: \\S+)?', each).group(1)",
            "                if 'prefix-list' in each:",
            "                    ptype = 'prefix'",
            "                else:",
            "                    ptype = 'routemap'",
            "                if 'out' in each:",
            "                    pim_interface['jp_policy_out'] = policy_name",
            "                    pim_interface['jp_type_out'] = ptype",
            "                elif 'in' in each:",
            "                    pim_interface['jp_policy_in'] = policy_name",
            "                    pim_interface['jp_type_in'] = ptype",
            "                else:",
            "                    pim_interface['jp_policy_in'] = policy_name",
            "                    pim_interface['jp_policy_out'] = policy_name",
            "                    pim_interface['jp_bidir'] = True",
            "            elif 'neighbor-policy' in each:",
            "                pim_interface['neighbor_policy'] = \\",
            "                    re.search(r'ip pim neighbor-policy(?: prefix-list)? (\\S+)', each).group(1)",
            "                if 'prefix-list' in each:",
            "                    pim_interface['neighbor_type'] = 'prefix'",
            "                else:",
            "                    pim_interface['neighbor_type'] = 'routemap'",
            "            elif 'ah-md5' in each:",
            "                pim_interface['isauth'] = True",
            "            elif 'sparse-mode' in each:",
            "                pim_interface['sparse'] = True",
            "            elif 'border' in each:",
            "                pim_interface['border'] = True",
            "            elif 'hello-interval' in each:",
            "                pim_interface['hello_interval'] = \\",
            "                    re.search(r'ip pim hello-interval (\\d+)', body).group(1)",
            "            elif 'dr-priority' in each:",
            "                pim_interface['dr_prio'] = \\",
            "                    re.search(r'ip pim dr-priority (\\d+)', body).group(1)",
            "",
            "    return pim_interface",
            "",
            "",
            "def fix_delta(delta, existing):",
            "    for key in list(delta):",
            "        if key in ['dr_prio', 'hello_interval', 'sparse', 'border']:",
            "            if delta.get(key) == PARAM_TO_DEFAULT_KEYMAP.get(key) and existing.get(key) is None:",
            "                delta.pop(key)",
            "    return delta",
            "",
            "",
            "def config_pim_interface(delta, existing, jp_bidir, isauth):",
            "    command = None",
            "    commands = []",
            "",
            "    delta = fix_delta(delta, existing)",
            "",
            "    if jp_bidir:",
            "        if delta.get('jp_policy_in') or delta.get('jp_policy_out'):",
            "            if existing.get('jp_type_in') == 'prefix':",
            "                command = 'no ip pim jp-policy prefix-list {0}'.format(existing.get('jp_policy_in'))",
            "            else:",
            "                command = 'no ip pim jp-policy {0}'.format(existing.get('jp_policy_in'))",
            "            if command:",
            "                commands.append(command)",
            "",
            "    for k, v in delta.items():",
            "        if k in ['dr_prio', 'hello_interval', 'hello_auth_key', 'border',",
            "                 'sparse']:",
            "            if v:",
            "                command = PARAM_TO_COMMAND_KEYMAP.get(k).format(v)",
            "            elif k == 'hello_auth_key':",
            "                if isauth:",
            "                    command = 'no ip pim hello-authentication ah-md5'",
            "            else:",
            "                command = 'no ' + PARAM_TO_COMMAND_KEYMAP.get(k).format(v)",
            "",
            "            if command:",
            "                commands.append(command)",
            "        elif k in ['neighbor_policy', 'jp_policy_in', 'jp_policy_out',",
            "                   'neighbor_type']:",
            "            if k in ['neighbor_policy', 'neighbor_type']:",
            "                temp = delta.get('neighbor_policy') or existing.get(",
            "                    'neighbor_policy')",
            "                if delta.get('neighbor_type') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif delta.get('neighbor_type') == 'routemap':",
            "                    command = 'ip pim neighbor-policy {0}'.format(temp)",
            "                elif existing.get('neighbor_type') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif existing.get('neighbor_type') == 'routemap':",
            "                    command = 'ip pim neighbor-policy {0}'.format(temp)",
            "            elif k in ['jp_policy_in', 'jp_type_in']:",
            "                temp = delta.get('jp_policy_in') or existing.get(",
            "                    'jp_policy_in')",
            "                if delta.get('jp_type_in') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif delta.get('jp_type_in') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} in'.format(temp)",
            "                elif existing.get('jp_type_in') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif existing.get('jp_type_in') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} in'.format(temp)",
            "            elif k in ['jp_policy_out', 'jp_type_out']:",
            "                temp = delta.get('jp_policy_out') or existing.get(",
            "                    'jp_policy_out')",
            "                if delta.get('jp_type_out') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif delta.get('jp_type_out') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} out'.format(temp)",
            "                elif existing.get('jp_type_out') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif existing.get('jp_type_out') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} out'.format(temp)",
            "            if command:",
            "                commands.append(command)",
            "        command = None",
            "",
            "    return commands",
            "",
            "",
            "def get_pim_interface_defaults():",
            "",
            "    args = dict(dr_prio=PARAM_TO_DEFAULT_KEYMAP.get('dr_prio'),",
            "                border=PARAM_TO_DEFAULT_KEYMAP.get('border'),",
            "                sparse=PARAM_TO_DEFAULT_KEYMAP.get('sparse'),",
            "                hello_interval=PARAM_TO_DEFAULT_KEYMAP.get('hello_interval'),",
            "                hello_auth_key=PARAM_TO_DEFAULT_KEYMAP.get('hello_auth_key'))",
            "",
            "    default = dict((param, value) for (param, value) in args.items()",
            "                   if value is not None)",
            "",
            "    return default",
            "",
            "",
            "def default_pim_interface_policies(existing, jp_bidir):",
            "    commands = []",
            "",
            "    if jp_bidir:",
            "        if existing.get('jp_policy_in') or existing.get('jp_policy_out'):",
            "            if existing.get('jp_type_in') == 'prefix':",
            "                command = 'no ip pim jp-policy prefix-list {0}'.format(existing.get('jp_policy_in'))",
            "        if command:",
            "            commands.append(command)",
            "",
            "    elif not jp_bidir:",
            "        command = None",
            "        for k in existing:",
            "            if k == 'jp_policy_in':",
            "                if existing.get('jp_policy_in'):",
            "                    if existing.get('jp_type_in') == 'prefix':",
            "                        command = 'no ip pim jp-policy prefix-list {0} in'.format(",
            "                            existing.get('jp_policy_in')",
            "                        )",
            "                    else:",
            "                        command = 'no ip pim jp-policy {0} in'.format(",
            "                            existing.get('jp_policy_in')",
            "                        )",
            "            elif k == 'jp_policy_out':",
            "                if existing.get('jp_policy_out'):",
            "                    if existing.get('jp_type_out') == 'prefix':",
            "                        command = 'no ip pim jp-policy prefix-list {0} out'.format(",
            "                            existing.get('jp_policy_out')",
            "                        )",
            "                    else:",
            "                        command = 'no ip pim jp-policy {0} out'.format(",
            "                            existing.get('jp_policy_out')",
            "                        )",
            "            if command:",
            "                commands.append(command)",
            "            command = None",
            "",
            "    if existing.get('neighbor_policy'):",
            "        command = 'no ip pim neighbor-policy'",
            "        commands.append(command)",
            "",
            "    return commands",
            "",
            "",
            "def config_pim_interface_defaults(existing, jp_bidir, isauth):",
            "    command = []",
            "",
            "    # returns a dict",
            "    defaults = get_pim_interface_defaults()",
            "    delta = dict(set(defaults.items()).difference(",
            "        existing.items()))",
            "    if delta:",
            "        # returns a list",
            "        command = config_pim_interface(delta, existing,",
            "                                       jp_bidir, isauth)",
            "    comm = default_pim_interface_policies(existing, jp_bidir)",
            "    if comm:",
            "        for each in comm:",
            "            command.append(each)",
            "",
            "    return command",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        interface=dict(type='str', required=True),",
            "        sparse=dict(type='bool', default=False),",
            "        dr_prio=dict(type='str'),",
            "        hello_auth_key=dict(type='str'),",
            "        hello_interval=dict(type='int'),",
            "        jp_policy_out=dict(type='str'),",
            "        jp_policy_in=dict(type='str'),",
            "        jp_type_out=dict(type='str', choices=['prefix', 'routemap']),",
            "        jp_type_in=dict(type='str', choices=['prefix', 'routemap']),",
            "        border=dict(type='bool', default=False),",
            "        neighbor_policy=dict(type='str'),",
            "        neighbor_type=dict(type='str', choices=['prefix', 'routemap']),",
            "        state=dict(type='str', default='present', choices=['absent', 'default', 'present']),",
            "    )",
            "    argument_spec.update(nxos_argument_spec)",
            "",
            "    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)",
            "",
            "    warnings = list()",
            "    check_args(module, warnings)",
            "    results = {'changed': False, 'commands': [], 'warnings': warnings}",
            "",
            "    state = module.params['state']",
            "    interface = module.params['interface']",
            "    jp_type_in = module.params['jp_type_in']",
            "    jp_type_out = module.params['jp_type_out']",
            "    jp_policy_in = module.params['jp_policy_in']",
            "    jp_policy_out = module.params['jp_policy_out']",
            "    neighbor_policy = module.params['neighbor_policy']",
            "    neighbor_type = module.params['neighbor_type']",
            "    hello_interval = module.params['hello_interval']",
            "",
            "    intf_type = get_interface_type(interface)",
            "    if get_interface_mode(interface, intf_type, module) == 'layer2':",
            "        module.fail_json(msg='this module only works on Layer 3 interfaces.')",
            "",
            "    if jp_policy_in:",
            "        if not jp_type_in:",
            "            module.fail_json(msg='jp_type_in required when using jp_policy_in.')",
            "    if jp_policy_out:",
            "        if not jp_type_out:",
            "            module.fail_json(msg='jp_type_out required when using jp_policy_out.')",
            "    if neighbor_policy:",
            "        if not neighbor_type:",
            "            module.fail_json(msg='neighbor_type required when using neighbor_policy.')",
            "",
            "    get_existing = get_pim_interface(module, interface)",
            "    existing, jp_bidir, isauth = local_existing(get_existing)",
            "",
            "    args = PARAM_TO_COMMAND_KEYMAP.keys()",
            "    proposed = dict((k, v) for k, v in module.params.items()",
            "                    if v is not None and k in args)",
            "",
            "    if hello_interval:",
            "        proposed['hello_interval'] = str(proposed['hello_interval'] * 1000)",
            "",
            "    delta = dict(set(proposed.items()).difference(existing.items()))",
            "",
            "    commands = []",
            "    if state == 'present':",
            "        if delta:",
            "            command = config_pim_interface(delta, existing, jp_bidir, isauth)",
            "            if command:",
            "                commands.append(command)",
            "    elif state == 'default' or state == 'absent':",
            "        defaults = config_pim_interface_defaults(existing, jp_bidir, isauth)",
            "        if defaults:",
            "            commands.append(defaults)",
            "",
            "    if commands:",
            "        commands.insert(0, ['interface {0}'.format(interface)])",
            "",
            "    cmds = flatten_list(commands)",
            "    if cmds:",
            "        results['changed'] = True",
            "        if not module.check_mode:",
            "            load_config(module, cmds)",
            "        if 'configure' in cmds:",
            "            cmds.pop(0)",
            "",
            "    results['commands'] = cmds",
            "",
            "    module.exit_json(**results)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "afterPatchFile": [
            "#!/usr/bin/python",
            "# -*- coding: utf-8 -*-",
            "",
            "# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)",
            "",
            "ANSIBLE_METADATA = {'metadata_version': '1.1',",
            "                    'status': ['preview'],",
            "                    'supported_by': 'network'}",
            "",
            "DOCUMENTATION = r'''",
            "---",
            "module: nxos_pim_interface",
            "extends_documentation_fragment: nxos",
            "version_added: \"2.2\"",
            "short_description: Manages PIM interface configuration.",
            "description:",
            "  - Manages PIM interface configuration settings.",
            "author:",
            "  - Jason Edelman (@jedelman8)",
            "notes:",
            "  - Tested against NXOSv 7.3.(0)D1(1) on VIRL",
            "  - When C(state=default), supported params will be reset to a default state.",
            "    These include C(dr_prio), C(hello_auth_key), C(hello_interval), C(jp_policy_out),",
            "    C(jp_policy_in), C(jp_type_in), C(jp_type_out), C(border), C(neighbor_policy),",
            "    C(neighbor_type).",
            "  - The C(hello_auth_key) param is not idempotent.",
            "  - C(hello_auth_key) only supports clear text passwords.",
            "  - When C(state=absent), pim interface configuration will be set to defaults and pim-sm",
            "    will be disabled on the interface.",
            "  - PIM must be enabled on the device to use this module.",
            "  - This module is for Layer 3 interfaces.",
            "options:",
            "  interface:",
            "    description:",
            "      - Full name of the interface such as Ethernet1/33.",
            "    type: str",
            "    required: true",
            "  sparse:",
            "    description:",
            "      - Enable/disable sparse-mode on the interface.",
            "    type: bool",
            "    default: no",
            "  dr_prio:",
            "    description:",
            "      - Configures priority for PIM DR election on interface.",
            "    type: str",
            "  hello_auth_key:",
            "    description:",
            "      - Authentication for hellos on this interface.",
            "    type: str",
            "  hello_interval:",
            "    description:",
            "      - Hello interval in milliseconds for this interface.",
            "    type: int",
            "  jp_policy_out:",
            "    description:",
            "      - Policy for join-prune messages (outbound).",
            "    type: str",
            "  jp_policy_in:",
            "    description:",
            "      - Policy for join-prune messages (inbound).",
            "    type: str",
            "  jp_type_out:",
            "    description:",
            "      - Type of policy mapped to C(jp_policy_out).",
            "    type: str",
            "    choices: [ prefix, routemap ]",
            "  jp_type_in:",
            "    description:",
            "      - Type of policy mapped to C(jp_policy_in).",
            "    type: str",
            "    choices: [ prefix, routemap ]",
            "  border:",
            "    description:",
            "      - Configures interface to be a boundary of a PIM domain.",
            "    type: bool",
            "    default: no",
            "  neighbor_policy:",
            "    description:",
            "      - Configures a neighbor policy for filtering adjacencies.",
            "    type: str",
            "  neighbor_type:",
            "    description:",
            "      - Type of policy mapped to neighbor_policy.",
            "    type: str",
            "    choices: [ prefix, routemap ]",
            "  state:",
            "    description:",
            "      - Manages desired state of the resource.",
            "    type: str",
            "    choices: [ present, default ]",
            "    default: present",
            "'''",
            "EXAMPLES = r'''",
            "- name: Ensure PIM is not running on the interface",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    state: absent",
            "",
            "- name: Ensure the interface has pim-sm enabled with the appropriate priority and hello interval",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    dr_prio: 10",
            "    hello_interval: 40",
            "    state: present",
            "",
            "- name: Ensure join-prune policies exist",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    jp_policy_in: JPIN",
            "    jp_policy_out: JPOUT",
            "    jp_type_in: routemap",
            "    jp_type_out: routemap",
            "",
            "- name: Ensure defaults are in place",
            "  nxos_pim_interface:",
            "    interface: eth1/33",
            "    state: default",
            "'''",
            "",
            "RETURN = r'''",
            "commands:",
            "    description: command sent to the device",
            "    returned: always",
            "    type: list",
            "    sample: [\"interface eth1/33\", \"ip pim neighbor-policy test\",",
            "            \"ip pim neighbor-policy test\"]",
            "'''",
            "",
            "import re",
            "from ansible.module_utils.basic import AnsibleModule",
            "from ansible.module_utils.network.nxos.nxos import get_config, load_config, run_commands",
            "from ansible.module_utils.network.nxos.nxos import nxos_argument_spec, check_args",
            "from ansible.module_utils.network.nxos.nxos import get_interface_type",
            "from ansible.module_utils.six import string_types",
            "",
            "",
            "PARAM_TO_COMMAND_KEYMAP = {",
            "    'interface': '',",
            "    'sparse': 'ip pim sparse-mode',",
            "    'dr_prio': 'ip pim dr-priority {0}',",
            "    'hello_interval': 'ip pim hello-interval {0}',",
            "    'hello_auth_key': 'ip pim hello-authentication ah-md5 {0}',",
            "    'border': 'ip pim border',",
            "    'jp_policy_out': 'ip pim jp-policy prefix-list {0} out',",
            "    'jp_policy_in': 'ip pim jp-policy prefix-list {0} in',",
            "    'jp_type_in': '',",
            "    'jp_type_out': '',",
            "    'neighbor_policy': 'ip pim neighbor-policy prefix-list {0}',",
            "    'neighbor_type': '',",
            "}",
            "",
            "PARAM_TO_DEFAULT_KEYMAP = {",
            "    'dr_prio': '1',",
            "    'hello_interval': '30000',",
            "    'sparse': False,",
            "    'border': False,",
            "    'hello_auth_key': False,",
            "}",
            "",
            "",
            "def execute_show_command(command, module, text=False):",
            "    if text:",
            "        cmds = [{",
            "            'command': command,",
            "            'output': 'text'",
            "        }]",
            "    else:",
            "        cmds = [{",
            "            'command': command,",
            "            'output': 'json'",
            "        }]",
            "",
            "    return run_commands(module, cmds)",
            "",
            "",
            "def flatten_list(command_lists):",
            "    flat_command_list = []",
            "    for command in command_lists:",
            "        if isinstance(command, list):",
            "            flat_command_list.extend(command)",
            "        else:",
            "            flat_command_list.append(command)",
            "    return flat_command_list",
            "",
            "",
            "def local_existing(gexisting):",
            "    jp_bidir = False",
            "    isauth = False",
            "    if gexisting:",
            "        jp_bidir = gexisting.get('jp_bidir')",
            "        isauth = gexisting.get('isauth')",
            "        if jp_bidir and isauth:",
            "            gexisting.pop('jp_bidir')",
            "            gexisting.pop('isauth')",
            "",
            "    return gexisting, jp_bidir, isauth",
            "",
            "",
            "def get_interface_mode(interface, intf_type, module):",
            "    mode = 'unknown'",
            "    command = 'show interface {0}'.format(interface)",
            "    body = execute_show_command(command, module)",
            "",
            "    try:",
            "        interface_table = body[0]['TABLE_interface']['ROW_interface']",
            "    except (KeyError, AttributeError, IndexError):",
            "        return mode",
            "",
            "    if intf_type in ['ethernet', 'portchannel']:",
            "        mode = str(interface_table.get('eth_mode', 'layer3'))",
            "        if mode in ['access', 'trunk']:",
            "            mode = 'layer2'",
            "        elif mode == 'routed':",
            "            mode = 'layer3'",
            "    elif intf_type in ['loopback', 'svi']:",
            "        mode = 'layer3'",
            "    return mode",
            "",
            "",
            "def get_pim_interface(module, interface):",
            "    pim_interface = {}",
            "    body = get_config(module, flags=['interface {0}'.format(interface)])",
            "",
            "    pim_interface['neighbor_type'] = None",
            "    pim_interface['neighbor_policy'] = None",
            "    pim_interface['jp_policy_in'] = None",
            "    pim_interface['jp_policy_out'] = None",
            "    pim_interface['jp_type_in'] = None",
            "    pim_interface['jp_type_out'] = None",
            "    pim_interface['jp_bidir'] = False",
            "    pim_interface['isauth'] = False",
            "",
            "    if body:",
            "        all_lines = body.splitlines()",
            "",
            "        for each in all_lines:",
            "            if 'jp-policy' in each:",
            "                policy_name = \\",
            "                    re.search(r'ip pim jp-policy(?: prefix-list)? (\\S+)(?: \\S+)?', each).group(1)",
            "                if 'prefix-list' in each:",
            "                    ptype = 'prefix'",
            "                else:",
            "                    ptype = 'routemap'",
            "                if 'out' in each:",
            "                    pim_interface['jp_policy_out'] = policy_name",
            "                    pim_interface['jp_type_out'] = ptype",
            "                elif 'in' in each:",
            "                    pim_interface['jp_policy_in'] = policy_name",
            "                    pim_interface['jp_type_in'] = ptype",
            "                else:",
            "                    pim_interface['jp_policy_in'] = policy_name",
            "                    pim_interface['jp_policy_out'] = policy_name",
            "                    pim_interface['jp_bidir'] = True",
            "            elif 'neighbor-policy' in each:",
            "                pim_interface['neighbor_policy'] = \\",
            "                    re.search(r'ip pim neighbor-policy(?: prefix-list)? (\\S+)', each).group(1)",
            "                if 'prefix-list' in each:",
            "                    pim_interface['neighbor_type'] = 'prefix'",
            "                else:",
            "                    pim_interface['neighbor_type'] = 'routemap'",
            "            elif 'ah-md5' in each:",
            "                pim_interface['isauth'] = True",
            "            elif 'sparse-mode' in each:",
            "                pim_interface['sparse'] = True",
            "            elif 'border' in each:",
            "                pim_interface['border'] = True",
            "            elif 'hello-interval' in each:",
            "                pim_interface['hello_interval'] = \\",
            "                    re.search(r'ip pim hello-interval (\\d+)', body).group(1)",
            "            elif 'dr-priority' in each:",
            "                pim_interface['dr_prio'] = \\",
            "                    re.search(r'ip pim dr-priority (\\d+)', body).group(1)",
            "",
            "    return pim_interface",
            "",
            "",
            "def fix_delta(delta, existing):",
            "    for key in list(delta):",
            "        if key in ['dr_prio', 'hello_interval', 'sparse', 'border']:",
            "            if delta.get(key) == PARAM_TO_DEFAULT_KEYMAP.get(key) and existing.get(key) is None:",
            "                delta.pop(key)",
            "    return delta",
            "",
            "",
            "def config_pim_interface(delta, existing, jp_bidir, isauth):",
            "    command = None",
            "    commands = []",
            "",
            "    delta = fix_delta(delta, existing)",
            "",
            "    if jp_bidir:",
            "        if delta.get('jp_policy_in') or delta.get('jp_policy_out'):",
            "            if existing.get('jp_type_in') == 'prefix':",
            "                command = 'no ip pim jp-policy prefix-list {0}'.format(existing.get('jp_policy_in'))",
            "            else:",
            "                command = 'no ip pim jp-policy {0}'.format(existing.get('jp_policy_in'))",
            "            if command:",
            "                commands.append(command)",
            "",
            "    for k, v in delta.items():",
            "        if k in ['dr_prio', 'hello_interval', 'hello_auth_key', 'border',",
            "                 'sparse']:",
            "            if v:",
            "                command = PARAM_TO_COMMAND_KEYMAP.get(k).format(v)",
            "            elif k == 'hello_auth_key':",
            "                if isauth:",
            "                    command = 'no ip pim hello-authentication ah-md5'",
            "            else:",
            "                command = 'no ' + PARAM_TO_COMMAND_KEYMAP.get(k).format(v)",
            "",
            "            if command:",
            "                commands.append(command)",
            "        elif k in ['neighbor_policy', 'jp_policy_in', 'jp_policy_out',",
            "                   'neighbor_type']:",
            "            if k in ['neighbor_policy', 'neighbor_type']:",
            "                temp = delta.get('neighbor_policy') or existing.get(",
            "                    'neighbor_policy')",
            "                if delta.get('neighbor_type') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif delta.get('neighbor_type') == 'routemap':",
            "                    command = 'ip pim neighbor-policy {0}'.format(temp)",
            "                elif existing.get('neighbor_type') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif existing.get('neighbor_type') == 'routemap':",
            "                    command = 'ip pim neighbor-policy {0}'.format(temp)",
            "            elif k in ['jp_policy_in', 'jp_type_in']:",
            "                temp = delta.get('jp_policy_in') or existing.get(",
            "                    'jp_policy_in')",
            "                if delta.get('jp_type_in') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif delta.get('jp_type_in') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} in'.format(temp)",
            "                elif existing.get('jp_type_in') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif existing.get('jp_type_in') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} in'.format(temp)",
            "            elif k in ['jp_policy_out', 'jp_type_out']:",
            "                temp = delta.get('jp_policy_out') or existing.get(",
            "                    'jp_policy_out')",
            "                if delta.get('jp_type_out') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif delta.get('jp_type_out') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} out'.format(temp)",
            "                elif existing.get('jp_type_out') == 'prefix':",
            "                    command = PARAM_TO_COMMAND_KEYMAP.get(k).format(temp)",
            "                elif existing.get('jp_type_out') == 'routemap':",
            "                    command = 'ip pim jp-policy {0} out'.format(temp)",
            "            if command:",
            "                commands.append(command)",
            "        command = None",
            "",
            "    return commands",
            "",
            "",
            "def get_pim_interface_defaults():",
            "",
            "    args = dict(dr_prio=PARAM_TO_DEFAULT_KEYMAP.get('dr_prio'),",
            "                border=PARAM_TO_DEFAULT_KEYMAP.get('border'),",
            "                sparse=PARAM_TO_DEFAULT_KEYMAP.get('sparse'),",
            "                hello_interval=PARAM_TO_DEFAULT_KEYMAP.get('hello_interval'),",
            "                hello_auth_key=PARAM_TO_DEFAULT_KEYMAP.get('hello_auth_key'))",
            "",
            "    default = dict((param, value) for (param, value) in args.items()",
            "                   if value is not None)",
            "",
            "    return default",
            "",
            "",
            "def default_pim_interface_policies(existing, jp_bidir):",
            "    commands = []",
            "",
            "    if jp_bidir:",
            "        if existing.get('jp_policy_in') or existing.get('jp_policy_out'):",
            "            if existing.get('jp_type_in') == 'prefix':",
            "                command = 'no ip pim jp-policy prefix-list {0}'.format(existing.get('jp_policy_in'))",
            "        if command:",
            "            commands.append(command)",
            "",
            "    elif not jp_bidir:",
            "        command = None",
            "        for k in existing:",
            "            if k == 'jp_policy_in':",
            "                if existing.get('jp_policy_in'):",
            "                    if existing.get('jp_type_in') == 'prefix':",
            "                        command = 'no ip pim jp-policy prefix-list {0} in'.format(",
            "                            existing.get('jp_policy_in')",
            "                        )",
            "                    else:",
            "                        command = 'no ip pim jp-policy {0} in'.format(",
            "                            existing.get('jp_policy_in')",
            "                        )",
            "            elif k == 'jp_policy_out':",
            "                if existing.get('jp_policy_out'):",
            "                    if existing.get('jp_type_out') == 'prefix':",
            "                        command = 'no ip pim jp-policy prefix-list {0} out'.format(",
            "                            existing.get('jp_policy_out')",
            "                        )",
            "                    else:",
            "                        command = 'no ip pim jp-policy {0} out'.format(",
            "                            existing.get('jp_policy_out')",
            "                        )",
            "            if command:",
            "                commands.append(command)",
            "            command = None",
            "",
            "    if existing.get('neighbor_policy'):",
            "        command = 'no ip pim neighbor-policy'",
            "        commands.append(command)",
            "",
            "    return commands",
            "",
            "",
            "def config_pim_interface_defaults(existing, jp_bidir, isauth):",
            "    command = []",
            "",
            "    # returns a dict",
            "    defaults = get_pim_interface_defaults()",
            "    delta = dict(set(defaults.items()).difference(",
            "        existing.items()))",
            "    if delta:",
            "        # returns a list",
            "        command = config_pim_interface(delta, existing,",
            "                                       jp_bidir, isauth)",
            "    comm = default_pim_interface_policies(existing, jp_bidir)",
            "    if comm:",
            "        for each in comm:",
            "            command.append(each)",
            "",
            "    return command",
            "",
            "",
            "def main():",
            "    argument_spec = dict(",
            "        interface=dict(type='str', required=True),",
            "        sparse=dict(type='bool', default=False),",
            "        dr_prio=dict(type='str'),",
            "        hello_auth_key=dict(type='str', no_log=True),",
            "        hello_interval=dict(type='int'),",
            "        jp_policy_out=dict(type='str'),",
            "        jp_policy_in=dict(type='str'),",
            "        jp_type_out=dict(type='str', choices=['prefix', 'routemap']),",
            "        jp_type_in=dict(type='str', choices=['prefix', 'routemap']),",
            "        border=dict(type='bool', default=False),",
            "        neighbor_policy=dict(type='str'),",
            "        neighbor_type=dict(type='str', choices=['prefix', 'routemap']),",
            "        state=dict(type='str', default='present', choices=['absent', 'default', 'present']),",
            "    )",
            "    argument_spec.update(nxos_argument_spec)",
            "",
            "    module = AnsibleModule(argument_spec=argument_spec, supports_check_mode=True)",
            "",
            "    warnings = list()",
            "    check_args(module, warnings)",
            "    results = {'changed': False, 'commands': [], 'warnings': warnings}",
            "",
            "    state = module.params['state']",
            "    interface = module.params['interface']",
            "    jp_type_in = module.params['jp_type_in']",
            "    jp_type_out = module.params['jp_type_out']",
            "    jp_policy_in = module.params['jp_policy_in']",
            "    jp_policy_out = module.params['jp_policy_out']",
            "    neighbor_policy = module.params['neighbor_policy']",
            "    neighbor_type = module.params['neighbor_type']",
            "    hello_interval = module.params['hello_interval']",
            "",
            "    intf_type = get_interface_type(interface)",
            "    if get_interface_mode(interface, intf_type, module) == 'layer2':",
            "        module.fail_json(msg='this module only works on Layer 3 interfaces.')",
            "",
            "    if jp_policy_in:",
            "        if not jp_type_in:",
            "            module.fail_json(msg='jp_type_in required when using jp_policy_in.')",
            "    if jp_policy_out:",
            "        if not jp_type_out:",
            "            module.fail_json(msg='jp_type_out required when using jp_policy_out.')",
            "    if neighbor_policy:",
            "        if not neighbor_type:",
            "            module.fail_json(msg='neighbor_type required when using neighbor_policy.')",
            "",
            "    get_existing = get_pim_interface(module, interface)",
            "    existing, jp_bidir, isauth = local_existing(get_existing)",
            "",
            "    args = PARAM_TO_COMMAND_KEYMAP.keys()",
            "    proposed = dict((k, v) for k, v in module.params.items()",
            "                    if v is not None and k in args)",
            "",
            "    if hello_interval:",
            "        proposed['hello_interval'] = str(proposed['hello_interval'] * 1000)",
            "",
            "    delta = dict(set(proposed.items()).difference(existing.items()))",
            "",
            "    commands = []",
            "    if state == 'present':",
            "        if delta:",
            "            command = config_pim_interface(delta, existing, jp_bidir, isauth)",
            "            if command:",
            "                commands.append(command)",
            "    elif state == 'default' or state == 'absent':",
            "        defaults = config_pim_interface_defaults(existing, jp_bidir, isauth)",
            "        if defaults:",
            "            commands.append(defaults)",
            "",
            "    if commands:",
            "        commands.insert(0, ['interface {0}'.format(interface)])",
            "",
            "    cmds = flatten_list(commands)",
            "    if cmds:",
            "        results['changed'] = True",
            "        if not module.check_mode:",
            "            load_config(module, cmds)",
            "        if 'configure' in cmds:",
            "            cmds.pop(0)",
            "",
            "    results['commands'] = cmds",
            "",
            "    module.exit_json(**results)",
            "",
            "",
            "if __name__ == '__main__':",
            "    main()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "438": [
                "main"
            ]
        },
        "addLocation": []
    }
}