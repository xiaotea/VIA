{
    "src/libre_chat/router.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from dataclasses import dataclass"
            },
            "1": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " from typing import Any, Dict, List, Optional, Union"
            },
            "2": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 6,
                "PatchRowcode": "+import werkzeug"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " from fastapi import APIRouter, Body, File, HTTPException, Request, UploadFile, WebSocket"
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from fastapi.responses import JSONResponse"
            },
            "6": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 9,
                "PatchRowcode": " from langchain.callbacks.base import AsyncCallbackHandler"
            },
            "7": {
                "beforePatchRowNumber": 123,
                "afterPatchRowNumber": 124,
                "PatchRowcode": "                 )"
            },
            "8": {
                "beforePatchRowNumber": 124,
                "afterPatchRowNumber": 125,
                "PatchRowcode": "             for uploaded in files:"
            },
            "9": {
                "beforePatchRowNumber": 125,
                "afterPatchRowNumber": 126,
                "PatchRowcode": "                 if uploaded.filename:  # no cov"
            },
            "10": {
                "beforePatchRowNumber": 126,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    file_path = os.path.join(self.conf.vector.documents_path, uploaded.filename)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 127,
                "PatchRowcode": "+                    file_path = werkzeug.utils.safe_join(self.conf.vector.documents_path, uploaded.filename)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 128,
                "PatchRowcode": "+                    if file_path is None:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 129,
                "PatchRowcode": "+                        raise HTTPException("
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 130,
                "PatchRowcode": "+                            status_code=403,"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 131,
                "PatchRowcode": "+                            detail=f\"Invalid file name: {uploaded.filename}\","
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 132,
                "PatchRowcode": "+                        )"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 133,
                "PatchRowcode": "+"
            },
            "18": {
                "beforePatchRowNumber": 127,
                "afterPatchRowNumber": 134,
                "PatchRowcode": "                     with open(file_path, \"wb\") as file:"
            },
            "19": {
                "beforePatchRowNumber": 128,
                "afterPatchRowNumber": 135,
                "PatchRowcode": "                         file.write(uploaded.file.read())"
            },
            "20": {
                "beforePatchRowNumber": 129,
                "afterPatchRowNumber": 136,
                "PatchRowcode": "                     # Check if the uploaded file is a zip file"
            }
        },
        "frontPatchFile": [
            "import os",
            "import zipfile",
            "from dataclasses import dataclass",
            "from typing import Any, Dict, List, Optional, Union",
            "",
            "from fastapi import APIRouter, Body, File, HTTPException, Request, UploadFile, WebSocket",
            "from fastapi.responses import JSONResponse",
            "from langchain.callbacks.base import AsyncCallbackHandler",
            "from langchain.memory import ConversationBufferMemory",
            "",
            "from libre_chat.conf import ChatConf, default_conf",
            "from libre_chat.utils import ChatResponse, Prompt, log",
            "",
            "__all__ = [",
            "    \"ChatRouter\",",
            "]",
            "",
            "api_responses: Optional[Dict[Union[int, str], Dict[str, Any]]] = {",
            "    200: {",
            "        \"description\": \"Chat response\",",
            "        \"content\": {",
            "            \"application/json\": {",
            "                \"result\": \"\",",
            "                \"source_docs\": [],",
            "            },",
            "        },",
            "    },",
            "    400: {\"description\": \"Bad Request\"},",
            "    422: {\"description\": \"Unprocessable Entity\"},",
            "}",
            "",
            "",
            "@dataclass",
            "class PromptResponse:",
            "    result: str",
            "    source_documents: Optional[List[Any]] = None",
            "",
            "",
            "class ChatRouter(APIRouter):",
            "    \"\"\"",
            "    Class to deploy a LLM router with FastAPI.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        *args: Any,",
            "        llm: Any,",
            "        path: str = \"/prompt\",",
            "        conf: Optional[ChatConf] = None,",
            "        examples: Optional[List[str]] = None,",
            "        **kwargs: Any,",
            "    ) -> None:",
            "        \"\"\"",
            "        Constructor of the LLM API router with the actual calls",
            "        \"\"\"",
            "        self.path = path",
            "        self.llm = llm",
            "        self.conf = conf if conf else default_conf",
            "        self.title = self.conf.info.title",
            "        self.description = self.conf.info.description",
            "        self.version = self.conf.info.version",
            "        self.examples = examples if examples else self.conf.info.examples",
            "        example_post = {\"prompt\": self.examples[0]}",
            "",
            "        # Instantiate APIRouter",
            "        super().__init__(",
            "            *args,",
            "            responses=api_responses,",
            "            **kwargs,",
            "        )",
            "        # Create a list to store all connected WebSocket clients",
            "        self.connected_clients: List[WebSocket] = []",
            "",
            "        @self.get(",
            "            self.path,",
            "            name=\"Prompt the LLM\",",
            "            description=self.description,",
            "            response_model=PromptResponse,",
            "        )",
            "        def get_prompt(request: Request, prompt: str = self.examples[0]) -> JSONResponse:",
            "            \"\"\"Send a prompt to the chatbot through HTTP GET operation.",
            "",
            "            :param request: The HTTP GET request with a .body()",
            "            :param prompt: Prompt to send to the LLM",
            "            \"\"\"",
            "            return JSONResponse(self.llm.query(prompt))",
            "",
            "        @self.post(",
            "            self.path,",
            "            name=\"Prompt the LLM\",",
            "            description=self.description,",
            "            response_description=\"Prompt response\",",
            "            response_model=PromptResponse,",
            "        )",
            "        def post_prompt(",
            "            request: Request,",
            "            prompt: Prompt = Body(..., example=example_post),",
            "        ) -> JSONResponse:",
            "            \"\"\"Send a prompt to the chatbot through HTTP POST operation.",
            "",
            "            :param request: The HTTP POST request with a .body()",
            "            :param prompt: Prompt to send to the LLM.",
            "            \"\"\"",
            "            return JSONResponse(self.llm.query(prompt.prompt))",
            "",
            "        @self.post(",
            "            \"/documents\",",
            "            description=\"\"\"Upload documents to be added to the vectorstore, you can provide a zip file that will be automatically unzipped.\"\"\",",
            "            response_description=\"Operation result\",",
            "            response_model={},",
            "            tags=[\"vectorstore\"],",
            "        )",
            "        def upload_documents(",
            "            files: List[UploadFile] = File(...),",
            "            admin_pass: Optional[str] = None,",
            "            # current_user: User = Depends(get_current_user),",
            "        ) -> JSONResponse:",
            "            os.makedirs(self.conf.vector.documents_path, exist_ok=True)",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            for uploaded in files:",
            "                if uploaded.filename:  # no cov",
            "                    file_path = os.path.join(self.conf.vector.documents_path, uploaded.filename)",
            "                    with open(file_path, \"wb\") as file:",
            "                        file.write(uploaded.file.read())",
            "                    # Check if the uploaded file is a zip file",
            "                    if uploaded.filename.endswith(\".zip\"):",
            "                        log.info(f\"\ud83e\udd10 Unzipping {file_path}\")",
            "                        with zipfile.ZipFile(file_path, \"r\") as zip_ref:",
            "                            zip_ref.extractall(self.conf.vector.documents_path)",
            "                        os.remove(file_path)",
            "            # TODO: add just the uploaded files instead of rebuilding the triplestore",
            "            self.llm.build_vectorstore()",
            "            self.llm.setup_dbqa()",
            "            return JSONResponse(",
            "                {",
            "                    \"message\": f\"Documents uploaded in {self.conf.vector.documents_path}, vectorstore rebuilt.\"",
            "                }",
            "            )",
            "",
            "        @self.get(",
            "            \"/documents\",",
            "            description=\"\"\"List documents uploaded to the server.\"\"\",",
            "            response_description=\"List of files\",",
            "            response_model={},",
            "            tags=[\"vectorstore\"],",
            "        )",
            "        def list_documents(",
            "            admin_pass: Optional[str] = None,",
            "            # Depends(get_current_user)",
            "        ) -> JSONResponse:",
            "            \"\"\"List all documents in the documents folder.\"\"\"",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            file_list = os.listdir(self.conf.vector.documents_path)",
            "            return JSONResponse({\"count\": len(file_list), \"files\": file_list})",
            "",
            "        @self.get(",
            "            \"/config\",",
            "            name=\"Get Chat configuration\",",
            "            description=\"\"\"Get the Chat web service configuration.\"\"\",",
            "            response_description=\"Chat configuration\",",
            "            response_model=ChatConf,",
            "            tags=[\"configuration\"],",
            "        )",
            "        def get_config(",
            "            admin_pass: Optional[str] = None,",
            "        ) -> JSONResponse:",
            "            \"\"\"Get the Chat web service configuration.\"\"\"",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            return JSONResponse(self.conf.dict())",
            "",
            "        @self.post(",
            "            \"/config\",",
            "            name=\"Edit Chat configuration\",",
            "            description=\"\"\"Edit the Chat web service configuration.\"\"\",",
            "            response_description=\"Chat configuration\",",
            "            response_model=ChatConf,",
            "            tags=[\"configuration\"],",
            "        )",
            "        def post_config(",
            "            request: Request,",
            "            config: ChatConf = Body(..., example=self.conf),",
            "            admin_pass: Optional[str] = None,",
            "        ) -> JSONResponse:",
            "            \"\"\"Edit the Chat web service configuration.\"\"\"",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            self.conf = config",
            "            # TODO: save new config to disk, and make sure all workers reload the new config",
            "            return JSONResponse(self.conf.dict())",
            "",
            "        @self.websocket(\"/chat\")",
            "        async def websocket_endpoint(websocket: WebSocket) -> None:",
            "            await websocket.accept()",
            "            self.connected_clients.append(websocket)",
            "            log.info(",
            "                f\"\ud83d\udd0c New websocket connection: {len(self.connected_clients)} clients are connected\"",
            "            )",
            "            memory = ConversationBufferMemory(ai_prefix=\"AI Assistant\")",
            "            try:",
            "                # Loop to receive messages from the WebSocket client",
            "                while True:",
            "                    data = await websocket.receive_json()",
            "",
            "                    start_resp = ChatResponse(sender=\"bot\", message=\"\", type=\"start\")",
            "                    await websocket.send_json(start_resp.dict())",
            "",
            "                    resp = await self.llm.aquery(",
            "                        data[\"prompt\"],",
            "                        memory=memory,",
            "                        callbacks=[StreamWebsocketCallback(websocket)],",
            "                    )",
            "                    # chat_history.append((question, resp[\"result\"]))",
            "                    # log.warning(\"RESULTS!\")",
            "                    # log.warning(resp[\"result\"])",
            "",
            "                    end_resp = ChatResponse(",
            "                        sender=\"bot\",",
            "                        message=resp[\"result\"],",
            "                        type=\"end\",",
            "                        sources=resp[\"source_documents\"] if \"source_documents\" in resp else None,",
            "                    )",
            "                    await websocket.send_json(end_resp.model_dump())",
            "            except Exception as e:",
            "                log.error(f\"WebSocket error: {e}\")",
            "            finally:",
            "                self.connected_clients.remove(websocket)",
            "",
            "",
            "# https://github.com/langchain-ai/chat-langchain/blob/master/main.py",
            "# class StreamingWebsocketCallbackHandler(AsyncCallbackHandler):",
            "class StreamWebsocketCallback(AsyncCallbackHandler):",
            "    \"\"\"Callback handler for streaming to websocket.",
            "    Only works with LLMs that support streaming.\"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        websocket: WebSocket,",
            "    ) -> None:",
            "        \"\"\"Initialize callback handler.\"\"\"",
            "        super().__init__()",
            "        self.websocket = websocket",
            "",
            "    async def on_llm_new_token(self, token: str, **kwargs: Any) -> None:",
            "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"",
            "        resp = ChatResponse(message=token, sender=\"bot\", type=\"stream\")",
            "        await self.websocket.send_json(resp.model_dump())"
        ],
        "afterPatchFile": [
            "import os",
            "import zipfile",
            "from dataclasses import dataclass",
            "from typing import Any, Dict, List, Optional, Union",
            "",
            "import werkzeug",
            "from fastapi import APIRouter, Body, File, HTTPException, Request, UploadFile, WebSocket",
            "from fastapi.responses import JSONResponse",
            "from langchain.callbacks.base import AsyncCallbackHandler",
            "from langchain.memory import ConversationBufferMemory",
            "",
            "from libre_chat.conf import ChatConf, default_conf",
            "from libre_chat.utils import ChatResponse, Prompt, log",
            "",
            "__all__ = [",
            "    \"ChatRouter\",",
            "]",
            "",
            "api_responses: Optional[Dict[Union[int, str], Dict[str, Any]]] = {",
            "    200: {",
            "        \"description\": \"Chat response\",",
            "        \"content\": {",
            "            \"application/json\": {",
            "                \"result\": \"\",",
            "                \"source_docs\": [],",
            "            },",
            "        },",
            "    },",
            "    400: {\"description\": \"Bad Request\"},",
            "    422: {\"description\": \"Unprocessable Entity\"},",
            "}",
            "",
            "",
            "@dataclass",
            "class PromptResponse:",
            "    result: str",
            "    source_documents: Optional[List[Any]] = None",
            "",
            "",
            "class ChatRouter(APIRouter):",
            "    \"\"\"",
            "    Class to deploy a LLM router with FastAPI.",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        *args: Any,",
            "        llm: Any,",
            "        path: str = \"/prompt\",",
            "        conf: Optional[ChatConf] = None,",
            "        examples: Optional[List[str]] = None,",
            "        **kwargs: Any,",
            "    ) -> None:",
            "        \"\"\"",
            "        Constructor of the LLM API router with the actual calls",
            "        \"\"\"",
            "        self.path = path",
            "        self.llm = llm",
            "        self.conf = conf if conf else default_conf",
            "        self.title = self.conf.info.title",
            "        self.description = self.conf.info.description",
            "        self.version = self.conf.info.version",
            "        self.examples = examples if examples else self.conf.info.examples",
            "        example_post = {\"prompt\": self.examples[0]}",
            "",
            "        # Instantiate APIRouter",
            "        super().__init__(",
            "            *args,",
            "            responses=api_responses,",
            "            **kwargs,",
            "        )",
            "        # Create a list to store all connected WebSocket clients",
            "        self.connected_clients: List[WebSocket] = []",
            "",
            "        @self.get(",
            "            self.path,",
            "            name=\"Prompt the LLM\",",
            "            description=self.description,",
            "            response_model=PromptResponse,",
            "        )",
            "        def get_prompt(request: Request, prompt: str = self.examples[0]) -> JSONResponse:",
            "            \"\"\"Send a prompt to the chatbot through HTTP GET operation.",
            "",
            "            :param request: The HTTP GET request with a .body()",
            "            :param prompt: Prompt to send to the LLM",
            "            \"\"\"",
            "            return JSONResponse(self.llm.query(prompt))",
            "",
            "        @self.post(",
            "            self.path,",
            "            name=\"Prompt the LLM\",",
            "            description=self.description,",
            "            response_description=\"Prompt response\",",
            "            response_model=PromptResponse,",
            "        )",
            "        def post_prompt(",
            "            request: Request,",
            "            prompt: Prompt = Body(..., example=example_post),",
            "        ) -> JSONResponse:",
            "            \"\"\"Send a prompt to the chatbot through HTTP POST operation.",
            "",
            "            :param request: The HTTP POST request with a .body()",
            "            :param prompt: Prompt to send to the LLM.",
            "            \"\"\"",
            "            return JSONResponse(self.llm.query(prompt.prompt))",
            "",
            "        @self.post(",
            "            \"/documents\",",
            "            description=\"\"\"Upload documents to be added to the vectorstore, you can provide a zip file that will be automatically unzipped.\"\"\",",
            "            response_description=\"Operation result\",",
            "            response_model={},",
            "            tags=[\"vectorstore\"],",
            "        )",
            "        def upload_documents(",
            "            files: List[UploadFile] = File(...),",
            "            admin_pass: Optional[str] = None,",
            "            # current_user: User = Depends(get_current_user),",
            "        ) -> JSONResponse:",
            "            os.makedirs(self.conf.vector.documents_path, exist_ok=True)",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            for uploaded in files:",
            "                if uploaded.filename:  # no cov",
            "                    file_path = werkzeug.utils.safe_join(self.conf.vector.documents_path, uploaded.filename)",
            "                    if file_path is None:",
            "                        raise HTTPException(",
            "                            status_code=403,",
            "                            detail=f\"Invalid file name: {uploaded.filename}\",",
            "                        )",
            "",
            "                    with open(file_path, \"wb\") as file:",
            "                        file.write(uploaded.file.read())",
            "                    # Check if the uploaded file is a zip file",
            "                    if uploaded.filename.endswith(\".zip\"):",
            "                        log.info(f\"\ud83e\udd10 Unzipping {file_path}\")",
            "                        with zipfile.ZipFile(file_path, \"r\") as zip_ref:",
            "                            zip_ref.extractall(self.conf.vector.documents_path)",
            "                        os.remove(file_path)",
            "            # TODO: add just the uploaded files instead of rebuilding the triplestore",
            "            self.llm.build_vectorstore()",
            "            self.llm.setup_dbqa()",
            "            return JSONResponse(",
            "                {",
            "                    \"message\": f\"Documents uploaded in {self.conf.vector.documents_path}, vectorstore rebuilt.\"",
            "                }",
            "            )",
            "",
            "        @self.get(",
            "            \"/documents\",",
            "            description=\"\"\"List documents uploaded to the server.\"\"\",",
            "            response_description=\"List of files\",",
            "            response_model={},",
            "            tags=[\"vectorstore\"],",
            "        )",
            "        def list_documents(",
            "            admin_pass: Optional[str] = None,",
            "            # Depends(get_current_user)",
            "        ) -> JSONResponse:",
            "            \"\"\"List all documents in the documents folder.\"\"\"",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            file_list = os.listdir(self.conf.vector.documents_path)",
            "            return JSONResponse({\"count\": len(file_list), \"files\": file_list})",
            "",
            "        @self.get(",
            "            \"/config\",",
            "            name=\"Get Chat configuration\",",
            "            description=\"\"\"Get the Chat web service configuration.\"\"\",",
            "            response_description=\"Chat configuration\",",
            "            response_model=ChatConf,",
            "            tags=[\"configuration\"],",
            "        )",
            "        def get_config(",
            "            admin_pass: Optional[str] = None,",
            "        ) -> JSONResponse:",
            "            \"\"\"Get the Chat web service configuration.\"\"\"",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            return JSONResponse(self.conf.dict())",
            "",
            "        @self.post(",
            "            \"/config\",",
            "            name=\"Edit Chat configuration\",",
            "            description=\"\"\"Edit the Chat web service configuration.\"\"\",",
            "            response_description=\"Chat configuration\",",
            "            response_model=ChatConf,",
            "            tags=[\"configuration\"],",
            "        )",
            "        def post_config(",
            "            request: Request,",
            "            config: ChatConf = Body(..., example=self.conf),",
            "            admin_pass: Optional[str] = None,",
            "        ) -> JSONResponse:",
            "            \"\"\"Edit the Chat web service configuration.\"\"\"",
            "            if self.conf.auth.admin_pass and admin_pass != self.conf.auth.admin_pass:",
            "                raise HTTPException(",
            "                    status_code=403,",
            "                    detail=\"The admin pass key provided was wrong\",",
            "                )",
            "            self.conf = config",
            "            # TODO: save new config to disk, and make sure all workers reload the new config",
            "            return JSONResponse(self.conf.dict())",
            "",
            "        @self.websocket(\"/chat\")",
            "        async def websocket_endpoint(websocket: WebSocket) -> None:",
            "            await websocket.accept()",
            "            self.connected_clients.append(websocket)",
            "            log.info(",
            "                f\"\ud83d\udd0c New websocket connection: {len(self.connected_clients)} clients are connected\"",
            "            )",
            "            memory = ConversationBufferMemory(ai_prefix=\"AI Assistant\")",
            "            try:",
            "                # Loop to receive messages from the WebSocket client",
            "                while True:",
            "                    data = await websocket.receive_json()",
            "",
            "                    start_resp = ChatResponse(sender=\"bot\", message=\"\", type=\"start\")",
            "                    await websocket.send_json(start_resp.dict())",
            "",
            "                    resp = await self.llm.aquery(",
            "                        data[\"prompt\"],",
            "                        memory=memory,",
            "                        callbacks=[StreamWebsocketCallback(websocket)],",
            "                    )",
            "                    # chat_history.append((question, resp[\"result\"]))",
            "                    # log.warning(\"RESULTS!\")",
            "                    # log.warning(resp[\"result\"])",
            "",
            "                    end_resp = ChatResponse(",
            "                        sender=\"bot\",",
            "                        message=resp[\"result\"],",
            "                        type=\"end\",",
            "                        sources=resp[\"source_documents\"] if \"source_documents\" in resp else None,",
            "                    )",
            "                    await websocket.send_json(end_resp.model_dump())",
            "            except Exception as e:",
            "                log.error(f\"WebSocket error: {e}\")",
            "            finally:",
            "                self.connected_clients.remove(websocket)",
            "",
            "",
            "# https://github.com/langchain-ai/chat-langchain/blob/master/main.py",
            "# class StreamingWebsocketCallbackHandler(AsyncCallbackHandler):",
            "class StreamWebsocketCallback(AsyncCallbackHandler):",
            "    \"\"\"Callback handler for streaming to websocket.",
            "    Only works with LLMs that support streaming.\"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        websocket: WebSocket,",
            "    ) -> None:",
            "        \"\"\"Initialize callback handler.\"\"\"",
            "        super().__init__()",
            "        self.websocket = websocket",
            "",
            "    async def on_llm_new_token(self, token: str, **kwargs: Any) -> None:",
            "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"",
            "        resp = ChatResponse(message=token, sender=\"bot\", type=\"stream\")",
            "        await self.websocket.send_json(resp.model_dump())"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "126": [
                "ChatRouter",
                "__init__",
                "upload_documents"
            ]
        },
        "addLocation": []
    }
}