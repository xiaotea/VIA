{
    "src/promptflow-core/promptflow/core/_utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " from typing import Dict, Optional, Tuple, Union"
            },
            "1": {
                "beforePatchRowNumber": 11,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 12,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " from jinja2 import Template"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 13,
                "PatchRowcode": "+from jinja2.sandbox import SandboxedEnvironment"
            },
            "4": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 14,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " from promptflow._constants import AZURE_WORKSPACE_REGEX_FORMAT"
            },
            "6": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " from promptflow._utils.flow_utils import is_flex_flow, is_prompty_flow, resolve_flow_path"
            },
            "7": {
                "beforePatchRowNumber": 23,
                "afterPatchRowNumber": 24,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 24,
                "afterPatchRowNumber": 25,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 25,
                "afterPatchRowNumber": 26,
                "PatchRowcode": " def render_jinja_template_content(template_content, *, trim_blocks=True, keep_trailing_newline=True, **kwargs):"
            },
            "10": {
                "beforePatchRowNumber": 26,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    template = Template(template_content, trim_blocks=trim_blocks, keep_trailing_newline=keep_trailing_newline)"
            },
            "11": {
                "beforePatchRowNumber": 27,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return template.render(**kwargs)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+    use_sandbox_env = os.environ.get(\"PF_USE_SANDBOX_FOR_JINJA\", \"true\")"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+    if use_sandbox_env.lower() == \"false\":"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+        template = Template(template_content, trim_blocks=trim_blocks, keep_trailing_newline=keep_trailing_newline)"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+        return template.render(**kwargs)"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+    else:"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+        sandbox_env = SandboxedEnvironment(trim_blocks=trim_blocks, keep_trailing_newline=keep_trailing_newline)"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+        sanitized_template = sandbox_env.from_string(template_content)"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+        return sanitized_template.render(**kwargs)"
            },
            "20": {
                "beforePatchRowNumber": 28,
                "afterPatchRowNumber": 35,
                "PatchRowcode": " "
            },
            "21": {
                "beforePatchRowNumber": 29,
                "afterPatchRowNumber": 36,
                "PatchRowcode": " "
            },
            "22": {
                "beforePatchRowNumber": 30,
                "afterPatchRowNumber": 37,
                "PatchRowcode": " def init_executable(*, flow_data: dict = None, flow_path: Path = None, working_dir: Path = None):"
            }
        },
        "frontPatchFile": [
            "# ---------------------------------------------------------",
            "# Copyright (c) Microsoft Corporation. All rights reserved.",
            "# ---------------------------------------------------------",
            "import json",
            "import os",
            "import re",
            "from configparser import ConfigParser",
            "from os import PathLike",
            "from pathlib import Path",
            "from typing import Dict, Optional, Tuple, Union",
            "",
            "from jinja2 import Template",
            "",
            "from promptflow._constants import AZURE_WORKSPACE_REGEX_FORMAT",
            "from promptflow._utils.flow_utils import is_flex_flow, is_prompty_flow, resolve_flow_path",
            "from promptflow._utils.logger_utils import LoggerFactory",
            "from promptflow._utils.utils import _match_reference",
            "from promptflow._utils.yaml_utils import load_yaml",
            "from promptflow.core._errors import InvalidSampleError, MalformedConnectionProviderConfig, MissingRequiredPackage",
            "from promptflow.exceptions import UserErrorException",
            "",
            "logger = LoggerFactory.get_logger(name=__name__)",
            "",
            "",
            "def render_jinja_template_content(template_content, *, trim_blocks=True, keep_trailing_newline=True, **kwargs):",
            "    template = Template(template_content, trim_blocks=trim_blocks, keep_trailing_newline=keep_trailing_newline)",
            "    return template.render(**kwargs)",
            "",
            "",
            "def init_executable(*, flow_data: dict = None, flow_path: Path = None, working_dir: Path = None):",
            "    if flow_data and flow_path:",
            "        raise ValueError(\"flow_dag and flow_path cannot be both provided.\")",
            "    if not flow_data and not flow_path:",
            "        raise ValueError(\"flow_dag or flow_path must be provided.\")",
            "    if flow_data and not working_dir:",
            "        raise ValueError(\"working_dir must be provided when flow_dag is provided.\")",
            "",
            "    if flow_path:",
            "        if is_prompty_flow(file_path=flow_path):",
            "            from promptflow.contracts.flow import PromptyFlow as ExecutablePromptyFlow",
            "            from promptflow.core._flow import Prompty",
            "",
            "            configs, _ = Prompty._parse_prompty(flow_path)",
            "            return ExecutablePromptyFlow._from_dict(flow_data=configs, working_dir=working_dir or flow_path.parent)",
            "",
            "        flow_dir, flow_filename = resolve_flow_path(flow_path)",
            "        flow_data = load_yaml(flow_dir / flow_filename)",
            "",
            "        # priority: code in yaml > working_dir > flow_dir",
            "        if \"code\" not in flow_data:",
            "            working_dir = working_dir or flow_dir",
            "        elif os.path.isabs(flow_data[\"code\"]):",
            "            working_dir = Path(flow_data[\"code\"])",
            "        else:",
            "            working_dir = flow_dir / Path(flow_data[\"code\"])",
            "",
            "    from promptflow.contracts.flow import FlexFlow as ExecutableEagerFlow",
            "    from promptflow.contracts.flow import Flow as ExecutableFlow",
            "",
            "    if is_flex_flow(yaml_dict=flow_data):",
            "        return ExecutableEagerFlow._from_dict(flow_data=flow_data, working_dir=working_dir)",
            "",
            "    # for DAG flow, use data to init executable to improve performance",
            "    return ExecutableFlow._from_dict(flow_data=flow_data, working_dir=working_dir)",
            "",
            "",
            "# !!! Attention!!!: Please make sure you have contact with PRS team before changing the interface.",
            "# They are using FlowExecutor.update_environment_variables_with_connections(connections)",
            "def update_environment_variables_with_connections(built_connections):",
            "    \"\"\"The function will result env var value ${my_connection.key} to the real connection keys.\"\"\"",
            "    return update_dict_value_with_connections(built_connections, os.environ)",
            "",
            "",
            "def override_connection_config_with_environment_variable(connections: Dict[str, dict]):",
            "    \"\"\"",
            "    The function will use relevant environment variable to override connection configurations. For instance, if there",
            "    is a custom connection named 'custom_connection' with a configuration key called 'chat_deployment_name,' the",
            "    function will attempt to retrieve 'chat_deployment_name' from the environment variable",
            "    'CUSTOM_CONNECTION_CHAT_DEPLOYMENT_NAME' by default. If the environment variable is not set, it will use the",
            "    original value as a fallback.",
            "    \"\"\"",
            "    for connection_name, connection in connections.items():",
            "        values = connection.get(\"value\", {})",
            "        for key, val in values.items():",
            "            connection_name = connection_name.replace(\" \", \"_\")",
            "            env_name = f\"{connection_name}_{key}\".upper()",
            "            if env_name not in os.environ:",
            "                continue",
            "            values[key] = os.environ[env_name]",
            "            logger.info(f\"Connection {connection_name}'s {key} is overridden with environment variable {env_name}\")",
            "    return connections",
            "",
            "",
            "def resolve_connections_environment_variable_reference(connections: Dict[str, dict]):",
            "    \"\"\"The function will resolve connection secrets env var reference like api_key: ${env:KEY}\"\"\"",
            "    for connection in connections.values():",
            "        values = connection.get(\"value\", {})",
            "        for key, val in values.items():",
            "            if not _match_env_reference(val):",
            "                continue",
            "            env_name = _match_env_reference(val)",
            "            if env_name not in os.environ:",
            "                raise UserErrorException(f\"Environment variable {env_name} is not found.\")",
            "            values[key] = os.environ[env_name]",
            "    return connections",
            "",
            "",
            "def _match_env_reference(val: str):",
            "    try:",
            "        val = val.strip()",
            "        m = re.match(r\"^\\$\\{env:(.+)}$\", val)",
            "        if not m:",
            "            return None",
            "        name = m.groups()[0]",
            "        return name",
            "    except Exception:",
            "        # for exceptions when val is not a string, return",
            "        return None",
            "",
            "",
            "def get_used_connection_names_from_environment_variables():",
            "    \"\"\"The function will get all potential related connection names from current environment variables.",
            "    for example, if part of env var is",
            "    {",
            "      \"ENV_VAR_1\": \"${my_connection.key}\",",
            "      \"ENV_VAR_2\": \"${my_connection.key2}\",",
            "      \"ENV_VAR_3\": \"${my_connection2.key}\",",
            "    }",
            "    The function will return {\"my_connection\", \"my_connection2\"}.",
            "    \"\"\"",
            "    return get_used_connection_names_from_dict(os.environ)",
            "",
            "",
            "def update_dict_value_with_connections(built_connections, connection_dict: dict):",
            "    for key, val in connection_dict.items():",
            "        connection_name, connection_key = _match_reference(val)",
            "        if connection_name is None:",
            "            continue",
            "        if connection_name not in built_connections:",
            "            continue",
            "        if connection_key not in built_connections[connection_name][\"value\"]:",
            "            continue",
            "        connection_dict[key] = built_connections[connection_name][\"value\"][connection_key]",
            "",
            "",
            "def get_used_connection_names_from_dict(connection_dict: dict):",
            "    connection_names = set()",
            "    for key, val in connection_dict.items():",
            "        connection_name, _ = _match_reference(val)",
            "        if connection_name:",
            "            connection_names.add(connection_name)",
            "",
            "    return connection_names",
            "",
            "",
            "def extract_workspace(provider_config) -> Tuple[str, str, str]:",
            "    match = re.match(AZURE_WORKSPACE_REGEX_FORMAT, provider_config)",
            "    if not match or len(match.groups()) != 5:",
            "        raise MalformedConnectionProviderConfig(provider_config=provider_config)",
            "    subscription_id = match.group(1)",
            "    resource_group = match.group(3)",
            "    workspace_name = match.group(5)",
            "    return subscription_id, resource_group, workspace_name",
            "",
            "",
            "def get_workspace_from_resource_id(resource_id: str, credential, pkg_name: Optional[str] = None):",
            "    # check azure extension first",
            "    try:",
            "        from azure.ai.ml import MLClient",
            "    except ImportError as e:",
            "        if pkg_name is not None:",
            "            error_msg = f\"Please install '{pkg_name}' to use Azure related features.\"",
            "        else:",
            "            error_msg = (",
            "                \"Please install Azure extension (e.g. `pip install promptflow-azure`) to use Azure related features.\"",
            "            )",
            "        raise MissingRequiredPackage(message=error_msg) from e",
            "    # extract workspace triad and get from Azure",
            "    subscription_id, resource_group_name, workspace_name = extract_workspace(resource_id)",
            "    ml_client = MLClient(",
            "        credential=credential,",
            "        subscription_id=subscription_id,",
            "        resource_group_name=resource_group_name,",
            "        workspace_name=workspace_name,",
            "    )",
            "    return ml_client.workspaces.get(name=workspace_name)",
            "",
            "",
            "def load_inputs_from_sample(sample: Union[dict, str, PathLike]):",
            "    if not sample:",
            "        return {}",
            "    elif isinstance(sample, dict):",
            "        return sample",
            "    elif isinstance(sample, (str, Path)) and str(sample).endswith(\".json\"):",
            "        if str(sample).startswith(\"file:\"):",
            "            sample = sample[len(\"file:\") :]",
            "        if not Path(sample).exists():",
            "            raise InvalidSampleError(f\"Cannot find sample file {sample}.\")",
            "        with open(sample, \"r\") as f:",
            "            return json.load(f)",
            "    else:",
            "        raise InvalidSampleError(\"Only dict and json file are supported as sample in prompty.\")",
            "",
            "",
            "def get_workspace_triad_from_local() -> tuple:",
            "    subscription_id = None",
            "    resource_group_name = None",
            "    workspace_name = None",
            "    azure_config_path = Path.home() / \".azure\"",
            "    config_parser = ConfigParser()",
            "    # subscription id",
            "    try:",
            "        config_parser.read_file(open(azure_config_path / \"clouds.config\"))",
            "        subscription_id = config_parser[\"AzureCloud\"][\"subscription\"]",
            "    except Exception:  # pylint: disable=broad-except",
            "        pass",
            "    # resource group name & workspace name",
            "    try:",
            "        config_parser.read_file(open(azure_config_path / \"config\"))",
            "        resource_group_name = config_parser[\"defaults\"][\"group\"]",
            "        workspace_name = config_parser[\"defaults\"][\"workspace\"]",
            "    except Exception:  # pylint: disable=broad-except",
            "        pass",
            "    return subscription_id, resource_group_name, workspace_name"
        ],
        "afterPatchFile": [
            "# ---------------------------------------------------------",
            "# Copyright (c) Microsoft Corporation. All rights reserved.",
            "# ---------------------------------------------------------",
            "import json",
            "import os",
            "import re",
            "from configparser import ConfigParser",
            "from os import PathLike",
            "from pathlib import Path",
            "from typing import Dict, Optional, Tuple, Union",
            "",
            "from jinja2 import Template",
            "from jinja2.sandbox import SandboxedEnvironment",
            "",
            "from promptflow._constants import AZURE_WORKSPACE_REGEX_FORMAT",
            "from promptflow._utils.flow_utils import is_flex_flow, is_prompty_flow, resolve_flow_path",
            "from promptflow._utils.logger_utils import LoggerFactory",
            "from promptflow._utils.utils import _match_reference",
            "from promptflow._utils.yaml_utils import load_yaml",
            "from promptflow.core._errors import InvalidSampleError, MalformedConnectionProviderConfig, MissingRequiredPackage",
            "from promptflow.exceptions import UserErrorException",
            "",
            "logger = LoggerFactory.get_logger(name=__name__)",
            "",
            "",
            "def render_jinja_template_content(template_content, *, trim_blocks=True, keep_trailing_newline=True, **kwargs):",
            "    use_sandbox_env = os.environ.get(\"PF_USE_SANDBOX_FOR_JINJA\", \"true\")",
            "    if use_sandbox_env.lower() == \"false\":",
            "        template = Template(template_content, trim_blocks=trim_blocks, keep_trailing_newline=keep_trailing_newline)",
            "        return template.render(**kwargs)",
            "    else:",
            "        sandbox_env = SandboxedEnvironment(trim_blocks=trim_blocks, keep_trailing_newline=keep_trailing_newline)",
            "        sanitized_template = sandbox_env.from_string(template_content)",
            "        return sanitized_template.render(**kwargs)",
            "",
            "",
            "def init_executable(*, flow_data: dict = None, flow_path: Path = None, working_dir: Path = None):",
            "    if flow_data and flow_path:",
            "        raise ValueError(\"flow_dag and flow_path cannot be both provided.\")",
            "    if not flow_data and not flow_path:",
            "        raise ValueError(\"flow_dag or flow_path must be provided.\")",
            "    if flow_data and not working_dir:",
            "        raise ValueError(\"working_dir must be provided when flow_dag is provided.\")",
            "",
            "    if flow_path:",
            "        if is_prompty_flow(file_path=flow_path):",
            "            from promptflow.contracts.flow import PromptyFlow as ExecutablePromptyFlow",
            "            from promptflow.core._flow import Prompty",
            "",
            "            configs, _ = Prompty._parse_prompty(flow_path)",
            "            return ExecutablePromptyFlow._from_dict(flow_data=configs, working_dir=working_dir or flow_path.parent)",
            "",
            "        flow_dir, flow_filename = resolve_flow_path(flow_path)",
            "        flow_data = load_yaml(flow_dir / flow_filename)",
            "",
            "        # priority: code in yaml > working_dir > flow_dir",
            "        if \"code\" not in flow_data:",
            "            working_dir = working_dir or flow_dir",
            "        elif os.path.isabs(flow_data[\"code\"]):",
            "            working_dir = Path(flow_data[\"code\"])",
            "        else:",
            "            working_dir = flow_dir / Path(flow_data[\"code\"])",
            "",
            "    from promptflow.contracts.flow import FlexFlow as ExecutableEagerFlow",
            "    from promptflow.contracts.flow import Flow as ExecutableFlow",
            "",
            "    if is_flex_flow(yaml_dict=flow_data):",
            "        return ExecutableEagerFlow._from_dict(flow_data=flow_data, working_dir=working_dir)",
            "",
            "    # for DAG flow, use data to init executable to improve performance",
            "    return ExecutableFlow._from_dict(flow_data=flow_data, working_dir=working_dir)",
            "",
            "",
            "# !!! Attention!!!: Please make sure you have contact with PRS team before changing the interface.",
            "# They are using FlowExecutor.update_environment_variables_with_connections(connections)",
            "def update_environment_variables_with_connections(built_connections):",
            "    \"\"\"The function will result env var value ${my_connection.key} to the real connection keys.\"\"\"",
            "    return update_dict_value_with_connections(built_connections, os.environ)",
            "",
            "",
            "def override_connection_config_with_environment_variable(connections: Dict[str, dict]):",
            "    \"\"\"",
            "    The function will use relevant environment variable to override connection configurations. For instance, if there",
            "    is a custom connection named 'custom_connection' with a configuration key called 'chat_deployment_name,' the",
            "    function will attempt to retrieve 'chat_deployment_name' from the environment variable",
            "    'CUSTOM_CONNECTION_CHAT_DEPLOYMENT_NAME' by default. If the environment variable is not set, it will use the",
            "    original value as a fallback.",
            "    \"\"\"",
            "    for connection_name, connection in connections.items():",
            "        values = connection.get(\"value\", {})",
            "        for key, val in values.items():",
            "            connection_name = connection_name.replace(\" \", \"_\")",
            "            env_name = f\"{connection_name}_{key}\".upper()",
            "            if env_name not in os.environ:",
            "                continue",
            "            values[key] = os.environ[env_name]",
            "            logger.info(f\"Connection {connection_name}'s {key} is overridden with environment variable {env_name}\")",
            "    return connections",
            "",
            "",
            "def resolve_connections_environment_variable_reference(connections: Dict[str, dict]):",
            "    \"\"\"The function will resolve connection secrets env var reference like api_key: ${env:KEY}\"\"\"",
            "    for connection in connections.values():",
            "        values = connection.get(\"value\", {})",
            "        for key, val in values.items():",
            "            if not _match_env_reference(val):",
            "                continue",
            "            env_name = _match_env_reference(val)",
            "            if env_name not in os.environ:",
            "                raise UserErrorException(f\"Environment variable {env_name} is not found.\")",
            "            values[key] = os.environ[env_name]",
            "    return connections",
            "",
            "",
            "def _match_env_reference(val: str):",
            "    try:",
            "        val = val.strip()",
            "        m = re.match(r\"^\\$\\{env:(.+)}$\", val)",
            "        if not m:",
            "            return None",
            "        name = m.groups()[0]",
            "        return name",
            "    except Exception:",
            "        # for exceptions when val is not a string, return",
            "        return None",
            "",
            "",
            "def get_used_connection_names_from_environment_variables():",
            "    \"\"\"The function will get all potential related connection names from current environment variables.",
            "    for example, if part of env var is",
            "    {",
            "      \"ENV_VAR_1\": \"${my_connection.key}\",",
            "      \"ENV_VAR_2\": \"${my_connection.key2}\",",
            "      \"ENV_VAR_3\": \"${my_connection2.key}\",",
            "    }",
            "    The function will return {\"my_connection\", \"my_connection2\"}.",
            "    \"\"\"",
            "    return get_used_connection_names_from_dict(os.environ)",
            "",
            "",
            "def update_dict_value_with_connections(built_connections, connection_dict: dict):",
            "    for key, val in connection_dict.items():",
            "        connection_name, connection_key = _match_reference(val)",
            "        if connection_name is None:",
            "            continue",
            "        if connection_name not in built_connections:",
            "            continue",
            "        if connection_key not in built_connections[connection_name][\"value\"]:",
            "            continue",
            "        connection_dict[key] = built_connections[connection_name][\"value\"][connection_key]",
            "",
            "",
            "def get_used_connection_names_from_dict(connection_dict: dict):",
            "    connection_names = set()",
            "    for key, val in connection_dict.items():",
            "        connection_name, _ = _match_reference(val)",
            "        if connection_name:",
            "            connection_names.add(connection_name)",
            "",
            "    return connection_names",
            "",
            "",
            "def extract_workspace(provider_config) -> Tuple[str, str, str]:",
            "    match = re.match(AZURE_WORKSPACE_REGEX_FORMAT, provider_config)",
            "    if not match or len(match.groups()) != 5:",
            "        raise MalformedConnectionProviderConfig(provider_config=provider_config)",
            "    subscription_id = match.group(1)",
            "    resource_group = match.group(3)",
            "    workspace_name = match.group(5)",
            "    return subscription_id, resource_group, workspace_name",
            "",
            "",
            "def get_workspace_from_resource_id(resource_id: str, credential, pkg_name: Optional[str] = None):",
            "    # check azure extension first",
            "    try:",
            "        from azure.ai.ml import MLClient",
            "    except ImportError as e:",
            "        if pkg_name is not None:",
            "            error_msg = f\"Please install '{pkg_name}' to use Azure related features.\"",
            "        else:",
            "            error_msg = (",
            "                \"Please install Azure extension (e.g. `pip install promptflow-azure`) to use Azure related features.\"",
            "            )",
            "        raise MissingRequiredPackage(message=error_msg) from e",
            "    # extract workspace triad and get from Azure",
            "    subscription_id, resource_group_name, workspace_name = extract_workspace(resource_id)",
            "    ml_client = MLClient(",
            "        credential=credential,",
            "        subscription_id=subscription_id,",
            "        resource_group_name=resource_group_name,",
            "        workspace_name=workspace_name,",
            "    )",
            "    return ml_client.workspaces.get(name=workspace_name)",
            "",
            "",
            "def load_inputs_from_sample(sample: Union[dict, str, PathLike]):",
            "    if not sample:",
            "        return {}",
            "    elif isinstance(sample, dict):",
            "        return sample",
            "    elif isinstance(sample, (str, Path)) and str(sample).endswith(\".json\"):",
            "        if str(sample).startswith(\"file:\"):",
            "            sample = sample[len(\"file:\") :]",
            "        if not Path(sample).exists():",
            "            raise InvalidSampleError(f\"Cannot find sample file {sample}.\")",
            "        with open(sample, \"r\") as f:",
            "            return json.load(f)",
            "    else:",
            "        raise InvalidSampleError(\"Only dict and json file are supported as sample in prompty.\")",
            "",
            "",
            "def get_workspace_triad_from_local() -> tuple:",
            "    subscription_id = None",
            "    resource_group_name = None",
            "    workspace_name = None",
            "    azure_config_path = Path.home() / \".azure\"",
            "    config_parser = ConfigParser()",
            "    # subscription id",
            "    try:",
            "        config_parser.read_file(open(azure_config_path / \"clouds.config\"))",
            "        subscription_id = config_parser[\"AzureCloud\"][\"subscription\"]",
            "    except Exception:  # pylint: disable=broad-except",
            "        pass",
            "    # resource group name & workspace name",
            "    try:",
            "        config_parser.read_file(open(azure_config_path / \"config\"))",
            "        resource_group_name = config_parser[\"defaults\"][\"group\"]",
            "        workspace_name = config_parser[\"defaults\"][\"workspace\"]",
            "    except Exception:  # pylint: disable=broad-except",
            "        pass",
            "    return subscription_id, resource_group_name, workspace_name"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "26": [
                "render_jinja_template_content"
            ],
            "27": [
                "render_jinja_template_content"
            ]
        },
        "addLocation": []
    },
    "src/promptflow/tests/executor/unittests/_utils/test_utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 3,
                "afterPatchRowNumber": 3,
                "PatchRowcode": " from unittest.mock import patch"
            },
            "1": {
                "beforePatchRowNumber": 4,
                "afterPatchRowNumber": 4,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 5,
                "afterPatchRowNumber": 5,
                "PatchRowcode": " import pytest"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 6,
                "PatchRowcode": "+from jinja2.exceptions import SecurityError"
            },
            "4": {
                "beforePatchRowNumber": 6,
                "afterPatchRowNumber": 7,
                "PatchRowcode": " "
            },
            "5": {
                "beforePatchRowNumber": 7,
                "afterPatchRowNumber": 8,
                "PatchRowcode": " from promptflow._utils.utils import get_int_env_var, is_json_serializable, log_progress"
            },
            "6": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 9,
                "PatchRowcode": "+from promptflow.core._utils import render_jinja_template_content"
            },
            "7": {
                "beforePatchRowNumber": 8,
                "afterPatchRowNumber": 10,
                "PatchRowcode": " "
            },
            "8": {
                "beforePatchRowNumber": 9,
                "afterPatchRowNumber": 11,
                "PatchRowcode": " "
            },
            "9": {
                "beforePatchRowNumber": 10,
                "afterPatchRowNumber": 12,
                "PatchRowcode": " class MyObj:"
            },
            "10": {
                "beforePatchRowNumber": 13,
                "afterPatchRowNumber": 15,
                "PatchRowcode": " "
            },
            "11": {
                "beforePatchRowNumber": 14,
                "afterPatchRowNumber": 16,
                "PatchRowcode": " @pytest.mark.unittest"
            },
            "12": {
                "beforePatchRowNumber": 15,
                "afterPatchRowNumber": 17,
                "PatchRowcode": " class TestUtils:"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 18,
                "PatchRowcode": "+    jinja_payload = \"\"\""
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 19,
                "PatchRowcode": "+            # system:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 20,
                "PatchRowcode": "+            You are a helpful assistant."
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 21,
                "PatchRowcode": "+"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 22,
                "PatchRowcode": "+            {% for item in chat_history %}"
            },
            "18": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 23,
                "PatchRowcode": "+            # user:"
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 24,
                "PatchRowcode": "+            {{item.inputs.question}}"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 25,
                "PatchRowcode": "+            # assistant:"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 26,
                "PatchRowcode": "+            {{item.outputs.answer}}"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 27,
                "PatchRowcode": "+            {% endfor %}"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 28,
                "PatchRowcode": "+"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 29,
                "PatchRowcode": "+            # user:"
            },
            "25": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 30,
                "PatchRowcode": "+            {{question}}"
            },
            "26": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 31,
                "PatchRowcode": "+        \"\"\""
            },
            "27": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 32,
                "PatchRowcode": "+    jinja_payload_injected_code = \"\"\""
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 33,
                "PatchRowcode": "+            {% for x in ().__class__.__base__.__subclasses__() %}"
            },
            "29": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 34,
                "PatchRowcode": "+                {% if \"catch_warnings\" in x.__name__.lower() %}"
            },
            "30": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 35,
                "PatchRowcode": "+                    {{ x().__enter__.__globals__['__builtins__']['__import__']('os')."
            },
            "31": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+                    popen('<html><body>GodServer</body></html>').read() }}"
            },
            "32": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 37,
                "PatchRowcode": "+                {% endif %}"
            },
            "33": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 38,
                "PatchRowcode": "+            {% endfor %}"
            },
            "34": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 39,
                "PatchRowcode": "+        \"\"\""
            },
            "35": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 40,
                "PatchRowcode": "+"
            },
            "36": {
                "beforePatchRowNumber": 16,
                "afterPatchRowNumber": 41,
                "PatchRowcode": "     @pytest.mark.parametrize(\"value, expected_res\", [(None, True), (1, True), (\"\", True), (MyObj(), False)])"
            },
            "37": {
                "beforePatchRowNumber": 17,
                "afterPatchRowNumber": 42,
                "PatchRowcode": "     def test_is_json_serializable(self, value, expected_res):"
            },
            "38": {
                "beforePatchRowNumber": 18,
                "afterPatchRowNumber": 43,
                "PatchRowcode": "         assert is_json_serializable(value) == expected_res"
            },
            "39": {
                "beforePatchRowNumber": 31,
                "afterPatchRowNumber": 56,
                "PatchRowcode": "         with patch.dict(os.environ, {env_var: env_value} if env_value is not None else {}):"
            },
            "40": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 57,
                "PatchRowcode": "             assert get_int_env_var(env_var, default_value) == expected_result"
            },
            "41": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 58,
                "PatchRowcode": " "
            },
            "42": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 59,
                "PatchRowcode": "+    @pytest.mark.parametrize("
            },
            "43": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 60,
                "PatchRowcode": "+        \"template_payload,use_sandbox_env,should_raise_error\","
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 61,
                "PatchRowcode": "+        ["
            },
            "45": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 62,
                "PatchRowcode": "+            # default - PF_USE_SANDBOX_FOR_JINJA = true"
            },
            "46": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 63,
                "PatchRowcode": "+            (jinja_payload, True, False),"
            },
            "47": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 64,
                "PatchRowcode": "+            (jinja_payload_injected_code, True, True),"
            },
            "48": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 65,
                "PatchRowcode": "+            # default - when PF_USE_SANDBOX_FOR_JINJA was not set"
            },
            "49": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 66,
                "PatchRowcode": "+            (jinja_payload, \"\", False),"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 67,
                "PatchRowcode": "+            (jinja_payload_injected_code, \"\", True),"
            },
            "51": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 68,
                "PatchRowcode": "+            # when PF_USE_SANDBOX_FOR_JINJA = False"
            },
            "52": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 69,
                "PatchRowcode": "+            (jinja_payload, False, False),"
            },
            "53": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 70,
                "PatchRowcode": "+            (jinja_payload_injected_code, False, False),"
            },
            "54": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 71,
                "PatchRowcode": "+        ],"
            },
            "55": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 72,
                "PatchRowcode": "+    )"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 73,
                "PatchRowcode": "+    def test_render_template(self, template_payload, use_sandbox_env, should_raise_error):"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 74,
                "PatchRowcode": "+        os.environ[\"PF_USE_SANDBOX_FOR_JINJA\"] = str(use_sandbox_env)"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 75,
                "PatchRowcode": "+"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 76,
                "PatchRowcode": "+        if should_raise_error:"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 77,
                "PatchRowcode": "+            with pytest.raises(SecurityError):"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 78,
                "PatchRowcode": "+                template = render_jinja_template_content(template_payload)"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 79,
                "PatchRowcode": "+        else:"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 80,
                "PatchRowcode": "+            template = render_jinja_template_content(template_payload)"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 81,
                "PatchRowcode": "+            assert template is not None"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 82,
                "PatchRowcode": "+"
            },
            "66": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 83,
                "PatchRowcode": "     @pytest.mark.parametrize("
            },
            "67": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 84,
                "PatchRowcode": "         \"env_var, env_value, expected_result\","
            },
            "68": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": 85,
                "PatchRowcode": "         ["
            }
        },
        "frontPatchFile": [
            "import os",
            "from datetime import datetime",
            "from unittest.mock import patch",
            "",
            "import pytest",
            "",
            "from promptflow._utils.utils import get_int_env_var, is_json_serializable, log_progress",
            "",
            "",
            "class MyObj:",
            "    pass",
            "",
            "",
            "@pytest.mark.unittest",
            "class TestUtils:",
            "    @pytest.mark.parametrize(\"value, expected_res\", [(None, True), (1, True), (\"\", True), (MyObj(), False)])",
            "    def test_is_json_serializable(self, value, expected_res):",
            "        assert is_json_serializable(value) == expected_res",
            "",
            "    @pytest.mark.parametrize(",
            "        \"env_var, env_value, default_value, expected_result\",",
            "        [",
            "            (\"TEST_VAR\", \"10\", None, 10),  # Valid integer string",
            "            (\"TEST_VAR\", \"invalid\", None, None),  # Invalid integer strings",
            "            (\"TEST_VAR\", None, 5, 5),  # Environment variable does not exist",
            "            (\"TEST_VAR\", \"10\", 5, 10),  # Valid integer string with a default value",
            "            (\"TEST_VAR\", \"invalid\", 5, 5),  # Invalid integer string with a default value",
            "        ],",
            "    )",
            "    def test_get_int_env_var(self, env_var, env_value, default_value, expected_result):",
            "        with patch.dict(os.environ, {env_var: env_value} if env_value is not None else {}):",
            "            assert get_int_env_var(env_var, default_value) == expected_result",
            "",
            "    @pytest.mark.parametrize(",
            "        \"env_var, env_value, expected_result\",",
            "        [",
            "            (\"TEST_VAR\", \"10\", 10),  # Valid integer string",
            "            (\"TEST_VAR\", \"invalid\", None),  # Invalid integer strings",
            "            (\"TEST_VAR\", None, None),  # Environment variable does not exist",
            "        ],",
            "    )",
            "    def test_get_int_env_var_without_default_vaue(self, env_var, env_value, expected_result):",
            "        with patch.dict(os.environ, {env_var: env_value} if env_value is not None else {}):",
            "            assert get_int_env_var(env_var) == expected_result",
            "",
            "    @patch(\"promptflow.executor._line_execution_process_pool.bulk_logger\", autospec=True)",
            "    def test_log_progress(self, mock_logger):",
            "        run_start_time = datetime.utcnow()",
            "        # Tests do not log when not specified at specified intervals (interval = 2)",
            "        total_count = 20",
            "        current_count = 3",
            "        last_log_count = 2",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_not_called()",
            "",
            "        # Test logging at specified intervals (interval = 2)",
            "        current_count = 8",
            "        last_log_count = 7",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_any_call(\"Finished 8 / 20 lines.\")",
            "",
            "        mock_logger.reset_mock()",
            "",
            "        # Test logging using last_log_count parameter (conut - last_log_count >= interval(2))",
            "        current_count = 9",
            "        last_log_count = 7",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_any_call(\"Finished 9 / 20 lines.\")",
            "",
            "        mock_logger.reset_mock()",
            "",
            "        # Test don't log using last_log_count parameter ((conut - last_log_count < interval(2))",
            "        current_count = 9",
            "        last_log_count = 8",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_not_called()"
        ],
        "afterPatchFile": [
            "import os",
            "from datetime import datetime",
            "from unittest.mock import patch",
            "",
            "import pytest",
            "from jinja2.exceptions import SecurityError",
            "",
            "from promptflow._utils.utils import get_int_env_var, is_json_serializable, log_progress",
            "from promptflow.core._utils import render_jinja_template_content",
            "",
            "",
            "class MyObj:",
            "    pass",
            "",
            "",
            "@pytest.mark.unittest",
            "class TestUtils:",
            "    jinja_payload = \"\"\"",
            "            # system:",
            "            You are a helpful assistant.",
            "",
            "            {% for item in chat_history %}",
            "            # user:",
            "            {{item.inputs.question}}",
            "            # assistant:",
            "            {{item.outputs.answer}}",
            "            {% endfor %}",
            "",
            "            # user:",
            "            {{question}}",
            "        \"\"\"",
            "    jinja_payload_injected_code = \"\"\"",
            "            {% for x in ().__class__.__base__.__subclasses__() %}",
            "                {% if \"catch_warnings\" in x.__name__.lower() %}",
            "                    {{ x().__enter__.__globals__['__builtins__']['__import__']('os').",
            "                    popen('<html><body>GodServer</body></html>').read() }}",
            "                {% endif %}",
            "            {% endfor %}",
            "        \"\"\"",
            "",
            "    @pytest.mark.parametrize(\"value, expected_res\", [(None, True), (1, True), (\"\", True), (MyObj(), False)])",
            "    def test_is_json_serializable(self, value, expected_res):",
            "        assert is_json_serializable(value) == expected_res",
            "",
            "    @pytest.mark.parametrize(",
            "        \"env_var, env_value, default_value, expected_result\",",
            "        [",
            "            (\"TEST_VAR\", \"10\", None, 10),  # Valid integer string",
            "            (\"TEST_VAR\", \"invalid\", None, None),  # Invalid integer strings",
            "            (\"TEST_VAR\", None, 5, 5),  # Environment variable does not exist",
            "            (\"TEST_VAR\", \"10\", 5, 10),  # Valid integer string with a default value",
            "            (\"TEST_VAR\", \"invalid\", 5, 5),  # Invalid integer string with a default value",
            "        ],",
            "    )",
            "    def test_get_int_env_var(self, env_var, env_value, default_value, expected_result):",
            "        with patch.dict(os.environ, {env_var: env_value} if env_value is not None else {}):",
            "            assert get_int_env_var(env_var, default_value) == expected_result",
            "",
            "    @pytest.mark.parametrize(",
            "        \"template_payload,use_sandbox_env,should_raise_error\",",
            "        [",
            "            # default - PF_USE_SANDBOX_FOR_JINJA = true",
            "            (jinja_payload, True, False),",
            "            (jinja_payload_injected_code, True, True),",
            "            # default - when PF_USE_SANDBOX_FOR_JINJA was not set",
            "            (jinja_payload, \"\", False),",
            "            (jinja_payload_injected_code, \"\", True),",
            "            # when PF_USE_SANDBOX_FOR_JINJA = False",
            "            (jinja_payload, False, False),",
            "            (jinja_payload_injected_code, False, False),",
            "        ],",
            "    )",
            "    def test_render_template(self, template_payload, use_sandbox_env, should_raise_error):",
            "        os.environ[\"PF_USE_SANDBOX_FOR_JINJA\"] = str(use_sandbox_env)",
            "",
            "        if should_raise_error:",
            "            with pytest.raises(SecurityError):",
            "                template = render_jinja_template_content(template_payload)",
            "        else:",
            "            template = render_jinja_template_content(template_payload)",
            "            assert template is not None",
            "",
            "    @pytest.mark.parametrize(",
            "        \"env_var, env_value, expected_result\",",
            "        [",
            "            (\"TEST_VAR\", \"10\", 10),  # Valid integer string",
            "            (\"TEST_VAR\", \"invalid\", None),  # Invalid integer strings",
            "            (\"TEST_VAR\", None, None),  # Environment variable does not exist",
            "        ],",
            "    )",
            "    def test_get_int_env_var_without_default_vaue(self, env_var, env_value, expected_result):",
            "        with patch.dict(os.environ, {env_var: env_value} if env_value is not None else {}):",
            "            assert get_int_env_var(env_var) == expected_result",
            "",
            "    @patch(\"promptflow.executor._line_execution_process_pool.bulk_logger\", autospec=True)",
            "    def test_log_progress(self, mock_logger):",
            "        run_start_time = datetime.utcnow()",
            "        # Tests do not log when not specified at specified intervals (interval = 2)",
            "        total_count = 20",
            "        current_count = 3",
            "        last_log_count = 2",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_not_called()",
            "",
            "        # Test logging at specified intervals (interval = 2)",
            "        current_count = 8",
            "        last_log_count = 7",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_any_call(\"Finished 8 / 20 lines.\")",
            "",
            "        mock_logger.reset_mock()",
            "",
            "        # Test logging using last_log_count parameter (conut - last_log_count >= interval(2))",
            "        current_count = 9",
            "        last_log_count = 7",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_any_call(\"Finished 9 / 20 lines.\")",
            "",
            "        mock_logger.reset_mock()",
            "",
            "        # Test don't log using last_log_count parameter ((conut - last_log_count < interval(2))",
            "        current_count = 9",
            "        last_log_count = 8",
            "        log_progress(run_start_time, total_count, current_count, last_log_count, mock_logger)",
            "        mock_logger.info.assert_not_called()"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "-1",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {},
        "addLocation": [
            "src.promptflow.tests.executor.unittests._utils.test_utils.TestUtils.self"
        ]
    }
}