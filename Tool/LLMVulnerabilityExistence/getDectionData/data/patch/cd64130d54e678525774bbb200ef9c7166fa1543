{
    "gradio/routes.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": 327,
                "PatchRowcode": "                 return RedirectResponse("
            },
            "1": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 328,
                "PatchRowcode": "                     url=path_or_url, status_code=status.HTTP_302_FOUND"
            },
            "2": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 329,
                "PatchRowcode": "                 )"
            },
            "3": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 330,
                "PatchRowcode": "+"
            },
            "4": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 331,
                "PatchRowcode": "             abs_path = utils.abspath(path_or_url)"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+"
            },
            "6": {
                "beforePatchRowNumber": 331,
                "afterPatchRowNumber": 333,
                "PatchRowcode": "             in_blocklist = any("
            },
            "7": {
                "beforePatchRowNumber": 332,
                "afterPatchRowNumber": 334,
                "PatchRowcode": "                 utils.is_in_or_equal(abs_path, blocked_path)"
            },
            "8": {
                "beforePatchRowNumber": 333,
                "afterPatchRowNumber": 335,
                "PatchRowcode": "                 for blocked_path in blocks.blocked_paths"
            },
            "9": {
                "beforePatchRowNumber": 334,
                "afterPatchRowNumber": 336,
                "PatchRowcode": "             )"
            },
            "10": {
                "beforePatchRowNumber": 335,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if in_blocklist or any(part.startswith(\".\") for part in abs_path.parts):"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 337,
                "PatchRowcode": "+            is_dotfile = any(part.startswith(\".\") for part in abs_path.parts)"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 338,
                "PatchRowcode": "+            is_dir = abs_path.is_dir()"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 339,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 340,
                "PatchRowcode": "+            if in_blocklist or is_dotfile or is_dir:"
            },
            "15": {
                "beforePatchRowNumber": 336,
                "afterPatchRowNumber": 341,
                "PatchRowcode": "                 raise HTTPException(403, f\"File not allowed: {path_or_url}.\")"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 342,
                "PatchRowcode": "+            if not abs_path.exists():"
            },
            "17": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 343,
                "PatchRowcode": "+                raise HTTPException(404, f\"File not found: {path_or_url}.\")"
            },
            "18": {
                "beforePatchRowNumber": 337,
                "afterPatchRowNumber": 344,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 338,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            in_app_dir = utils.abspath(app.cwd) in abs_path.parents"
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 345,
                "PatchRowcode": "+            in_app_dir = utils.is_in_or_equal(abs_path, app.cwd)"
            },
            "21": {
                "beforePatchRowNumber": 339,
                "afterPatchRowNumber": 346,
                "PatchRowcode": "             created_by_app = str(abs_path) in set().union(*blocks.temp_file_sets)"
            },
            "22": {
                "beforePatchRowNumber": 340,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            in_file_dir = any("
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 347,
                "PatchRowcode": "+            in_allowlist = any("
            },
            "24": {
                "beforePatchRowNumber": 341,
                "afterPatchRowNumber": 348,
                "PatchRowcode": "                 utils.is_in_or_equal(abs_path, allowed_path)"
            },
            "25": {
                "beforePatchRowNumber": 342,
                "afterPatchRowNumber": 349,
                "PatchRowcode": "                 for allowed_path in blocks.allowed_paths"
            },
            "26": {
                "beforePatchRowNumber": 343,
                "afterPatchRowNumber": 350,
                "PatchRowcode": "             )"
            },
            "27": {
                "beforePatchRowNumber": 344,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            was_uploaded = utils.abspath(app.uploaded_file_dir) in abs_path.parents"
            },
            "28": {
                "beforePatchRowNumber": 345,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "29": {
                "beforePatchRowNumber": 346,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            if in_app_dir or created_by_app or in_file_dir or was_uploaded:"
            },
            "30": {
                "beforePatchRowNumber": 347,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if not abs_path.exists():"
            },
            "31": {
                "beforePatchRowNumber": 348,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    raise HTTPException(404, \"File not found\")"
            },
            "32": {
                "beforePatchRowNumber": 349,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if abs_path.is_dir():"
            },
            "33": {
                "beforePatchRowNumber": 350,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    raise HTTPException(403)"
            },
            "34": {
                "beforePatchRowNumber": 351,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "35": {
                "beforePatchRowNumber": 352,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                range_val = request.headers.get(\"Range\", \"\").strip()"
            },
            "36": {
                "beforePatchRowNumber": 353,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                if range_val.startswith(\"bytes=\") and \"-\" in range_val:"
            },
            "37": {
                "beforePatchRowNumber": 354,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    range_val = range_val[6:]"
            },
            "38": {
                "beforePatchRowNumber": 355,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    start, end = range_val.split(\"-\")"
            },
            "39": {
                "beforePatchRowNumber": 356,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    if start.isnumeric() and end.isnumeric():"
            },
            "40": {
                "beforePatchRowNumber": 357,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        start = int(start)"
            },
            "41": {
                "beforePatchRowNumber": 358,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        end = int(end)"
            },
            "42": {
                "beforePatchRowNumber": 359,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        response = ranged_response.RangedFileResponse("
            },
            "43": {
                "beforePatchRowNumber": 360,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            abs_path,"
            },
            "44": {
                "beforePatchRowNumber": 361,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            ranged_response.OpenRange(start, end),"
            },
            "45": {
                "beforePatchRowNumber": 362,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            dict(request.headers),"
            },
            "46": {
                "beforePatchRowNumber": 363,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                            stat_result=os.stat(abs_path),"
            },
            "47": {
                "beforePatchRowNumber": 364,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        )"
            },
            "48": {
                "beforePatchRowNumber": 365,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                        return response"
            },
            "49": {
                "beforePatchRowNumber": 366,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                return FileResponse(abs_path, headers={\"Accept-Ranges\": \"bytes\"})"
            },
            "50": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 351,
                "PatchRowcode": "+            was_uploaded = utils.is_in_or_equal(abs_path, app.uploaded_file_dir)"
            },
            "51": {
                "beforePatchRowNumber": 367,
                "afterPatchRowNumber": 352,
                "PatchRowcode": " "
            },
            "52": {
                "beforePatchRowNumber": 368,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            else:"
            },
            "53": {
                "beforePatchRowNumber": 369,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                raise HTTPException("
            },
            "54": {
                "beforePatchRowNumber": 370,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    403,"
            },
            "55": {
                "beforePatchRowNumber": 371,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                    f\"File cannot be fetched: {path_or_url}. All files must contained within the Gradio python app working directory, or be a temp file created by the Gradio python app.\","
            },
            "56": {
                "beforePatchRowNumber": 372,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                )"
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 353,
                "PatchRowcode": "+            if not (in_app_dir or created_by_app or in_allowlist or was_uploaded):"
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 354,
                "PatchRowcode": "+                raise HTTPException(403, f\"File not allowed: {path_or_url}.\")"
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 355,
                "PatchRowcode": "+"
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 356,
                "PatchRowcode": "+            range_val = request.headers.get(\"Range\", \"\").strip()"
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 357,
                "PatchRowcode": "+            if range_val.startswith(\"bytes=\") and \"-\" in range_val:"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 358,
                "PatchRowcode": "+                range_val = range_val[6:]"
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 359,
                "PatchRowcode": "+                start, end = range_val.split(\"-\")"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 360,
                "PatchRowcode": "+                if start.isnumeric() and end.isnumeric():"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 361,
                "PatchRowcode": "+                    start = int(start)"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 362,
                "PatchRowcode": "+                    end = int(end)"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 363,
                "PatchRowcode": "+                    response = ranged_response.RangedFileResponse("
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 364,
                "PatchRowcode": "+                        abs_path,"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 365,
                "PatchRowcode": "+                        ranged_response.OpenRange(start, end),"
            },
            "70": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 366,
                "PatchRowcode": "+                        dict(request.headers),"
            },
            "71": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 367,
                "PatchRowcode": "+                        stat_result=os.stat(abs_path),"
            },
            "72": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 368,
                "PatchRowcode": "+                    )"
            },
            "73": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 369,
                "PatchRowcode": "+                    return response"
            },
            "74": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 370,
                "PatchRowcode": "+            return FileResponse(abs_path, headers={\"Accept-Ranges\": \"bytes\"})"
            },
            "75": {
                "beforePatchRowNumber": 373,
                "afterPatchRowNumber": 371,
                "PatchRowcode": " "
            },
            "76": {
                "beforePatchRowNumber": 374,
                "afterPatchRowNumber": 372,
                "PatchRowcode": "         @app.get(\"/file/{path:path}\", dependencies=[Depends(login_check)])"
            },
            "77": {
                "beforePatchRowNumber": 375,
                "afterPatchRowNumber": 373,
                "PatchRowcode": "         async def file_deprecated(path: str, request: fastapi.Request):"
            }
        },
        "frontPatchFile": [
            "\"\"\"Implements a FastAPI server to run the gradio interface. Note that some types in this",
            "module use the Optional/Union notation so that they work correctly with pydantic.\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import asyncio",
            "import inspect",
            "import json",
            "import mimetypes",
            "import os",
            "import secrets",
            "import tempfile",
            "import traceback",
            "from asyncio import TimeoutError as AsyncTimeOutError",
            "from collections import defaultdict",
            "from copy import deepcopy",
            "from pathlib import Path",
            "from typing import Any, Dict, List, Optional, Type",
            "from urllib.parse import urlparse",
            "",
            "import fastapi",
            "import httpx",
            "import markupsafe",
            "import orjson",
            "import pkg_resources",
            "from fastapi import Depends, FastAPI, File, HTTPException, UploadFile, WebSocket, status",
            "from fastapi.middleware.cors import CORSMiddleware",
            "from fastapi.responses import (",
            "    FileResponse,",
            "    HTMLResponse,",
            "    JSONResponse,",
            "    PlainTextResponse,",
            ")",
            "from fastapi.security import OAuth2PasswordRequestForm",
            "from fastapi.templating import Jinja2Templates",
            "from gradio_client.documentation import document, set_documentation_group",
            "from jinja2.exceptions import TemplateNotFound",
            "from starlette.background import BackgroundTask",
            "from starlette.responses import RedirectResponse, StreamingResponse",
            "from starlette.websockets import WebSocketState",
            "",
            "import gradio",
            "import gradio.ranged_response as ranged_response",
            "from gradio import utils",
            "from gradio.context import Context",
            "from gradio.data_classes import PredictBody, ResetBody",
            "from gradio.exceptions import Error",
            "from gradio.helpers import EventData",
            "from gradio.queueing import Estimation, Event",
            "from gradio.utils import cancel_tasks, run_coro_in_background, set_task_name",
            "",
            "mimetypes.init()",
            "",
            "STATIC_TEMPLATE_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/\")",
            "STATIC_PATH_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/frontend/static\")",
            "BUILD_PATH_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/frontend/assets\")",
            "VERSION_FILE = pkg_resources.resource_filename(\"gradio\", \"version.txt\")",
            "with open(VERSION_FILE) as version_file:",
            "    VERSION = version_file.read()",
            "",
            "",
            "class ORJSONResponse(JSONResponse):",
            "    media_type = \"application/json\"",
            "",
            "    @staticmethod",
            "    def _render(content: Any) -> bytes:",
            "        return orjson.dumps(",
            "            content,",
            "            option=orjson.OPT_SERIALIZE_NUMPY | orjson.OPT_PASSTHROUGH_DATETIME,",
            "            default=str,",
            "        )",
            "",
            "    def render(self, content: Any) -> bytes:",
            "        return ORJSONResponse._render(content)",
            "",
            "    @staticmethod",
            "    def _render_str(content: Any) -> str:",
            "        return ORJSONResponse._render(content).decode(\"utf-8\")",
            "",
            "",
            "def toorjson(value):",
            "    return markupsafe.Markup(",
            "        ORJSONResponse._render_str(value)",
            "        .replace(\"<\", \"\\\\u003c\")",
            "        .replace(\">\", \"\\\\u003e\")",
            "        .replace(\"&\", \"\\\\u0026\")",
            "        .replace(\"'\", \"\\\\u0027\")",
            "    )",
            "",
            "",
            "templates = Jinja2Templates(directory=STATIC_TEMPLATE_LIB)",
            "templates.env.filters[\"toorjson\"] = toorjson",
            "",
            "client = httpx.AsyncClient()",
            "",
            "###########",
            "# Auth",
            "###########",
            "",
            "",
            "class App(FastAPI):",
            "    \"\"\"",
            "    FastAPI App Wrapper",
            "    \"\"\"",
            "",
            "    def __init__(self, **kwargs):",
            "        self.tokens = {}",
            "        self.auth = None",
            "        self.blocks: gradio.Blocks | None = None",
            "        self.state_holder = {}",
            "        self.iterators = defaultdict(dict)",
            "        self.lock = asyncio.Lock()",
            "        self.queue_token = secrets.token_urlsafe(32)",
            "        self.startup_events_triggered = False",
            "        self.uploaded_file_dir = os.environ.get(\"GRADIO_TEMP_DIR\") or str(",
            "            Path(tempfile.gettempdir()) / \"gradio\"",
            "        )",
            "        # Allow user to manually set `docs_url` and `redoc_url`",
            "        # when instantiating an App; when they're not set, disable docs and redoc.",
            "        kwargs.setdefault(\"docs_url\", None)",
            "        kwargs.setdefault(\"redoc_url\", None)",
            "        super().__init__(**kwargs)",
            "",
            "    def configure_app(self, blocks: gradio.Blocks) -> None:",
            "        auth = blocks.auth",
            "        if auth is not None:",
            "            if not callable(auth):",
            "                self.auth = {account[0]: account[1] for account in auth}",
            "            else:",
            "                self.auth = auth",
            "        else:",
            "            self.auth = None",
            "",
            "        self.blocks = blocks",
            "        if hasattr(self.blocks, \"_queue\"):",
            "            self.blocks._queue.set_access_token(self.queue_token)",
            "        self.cwd = os.getcwd()",
            "        self.favicon_path = blocks.favicon_path",
            "        self.tokens = {}",
            "        self.root_path = blocks.root_path",
            "",
            "    def get_blocks(self) -> gradio.Blocks:",
            "        if self.blocks is None:",
            "            raise ValueError(\"No Blocks has been configured for this app.\")",
            "        return self.blocks",
            "",
            "    @staticmethod",
            "    def build_proxy_request(url_path):",
            "        url = httpx.URL(url_path)",
            "        is_hf_url = url.host.endswith(\".hf.space\")",
            "        headers = {}",
            "        if Context.hf_token is not None and is_hf_url:",
            "            headers[\"Authorization\"] = f\"Bearer {Context.hf_token}\"",
            "        rp_req = client.build_request(\"GET\", url, headers=headers)",
            "        return rp_req",
            "",
            "    @staticmethod",
            "    def create_app(",
            "        blocks: gradio.Blocks, app_kwargs: Dict[str, Any] | None = None",
            "    ) -> App:",
            "        app_kwargs = app_kwargs or {}",
            "        app_kwargs.setdefault(\"default_response_class\", ORJSONResponse)",
            "        app = App(**app_kwargs)",
            "        app.configure_app(blocks)",
            "",
            "        app.add_middleware(",
            "            CORSMiddleware,",
            "            allow_origins=[\"*\"],",
            "            allow_methods=[\"*\"],",
            "            allow_headers=[\"*\"],",
            "        )",
            "",
            "        @app.get(\"/user\")",
            "        @app.get(\"/user/\")",
            "        def get_current_user(request: fastapi.Request) -> Optional[str]:",
            "            token = request.cookies.get(\"access-token\") or request.cookies.get(",
            "                \"access-token-unsecure\"",
            "            )",
            "            return app.tokens.get(token)",
            "",
            "        @app.get(\"/login_check\")",
            "        @app.get(\"/login_check/\")",
            "        def login_check(user: str = Depends(get_current_user)):",
            "            if app.auth is None or user is not None:",
            "                return",
            "            raise HTTPException(",
            "                status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Not authenticated\"",
            "            )",
            "",
            "        async def ws_login_check(websocket: WebSocket) -> Optional[str]:",
            "            token = websocket.cookies.get(\"access-token\") or websocket.cookies.get(",
            "                \"access-token-unsecure\"",
            "            )",
            "            return token  # token is returned to allow request in queue",
            "",
            "        @app.get(\"/token\")",
            "        @app.get(\"/token/\")",
            "        def get_token(request: fastapi.Request) -> dict:",
            "            token = request.cookies.get(\"access-token\")",
            "            return {\"token\": token, \"user\": app.tokens.get(token)}",
            "",
            "        @app.get(\"/app_id\")",
            "        @app.get(\"/app_id/\")",
            "        def app_id(request: fastapi.Request) -> dict:",
            "            return {\"app_id\": app.get_blocks().app_id}",
            "",
            "        @app.post(\"/login\")",
            "        @app.post(\"/login/\")",
            "        def login(form_data: OAuth2PasswordRequestForm = Depends()):",
            "            username, password = form_data.username, form_data.password",
            "            if app.auth is None:",
            "                return RedirectResponse(url=\"/\", status_code=status.HTTP_302_FOUND)",
            "            if (",
            "                not callable(app.auth)",
            "                and username in app.auth",
            "                and app.auth[username] == password",
            "            ) or (callable(app.auth) and app.auth.__call__(username, password)):",
            "                token = secrets.token_urlsafe(16)",
            "                app.tokens[token] = username",
            "                response = JSONResponse(content={\"success\": True})",
            "                response.set_cookie(",
            "                    key=\"access-token\",",
            "                    value=token,",
            "                    httponly=True,",
            "                    samesite=\"none\",",
            "                    secure=True,",
            "                )",
            "                response.set_cookie(",
            "                    key=\"access-token-unsecure\", value=token, httponly=True",
            "                )",
            "                return response",
            "            else:",
            "                raise HTTPException(status_code=400, detail=\"Incorrect credentials.\")",
            "",
            "        ###############",
            "        # Main Routes",
            "        ###############",
            "",
            "        @app.head(\"/\", response_class=HTMLResponse)",
            "        @app.get(\"/\", response_class=HTMLResponse)",
            "        def main(request: fastapi.Request, user: str = Depends(get_current_user)):",
            "            mimetypes.add_type(\"application/javascript\", \".js\")",
            "            blocks = app.get_blocks()",
            "            root_path = request.scope.get(\"root_path\", \"\")",
            "",
            "            if app.auth is None or user is not None:",
            "                config = app.get_blocks().config",
            "                config[\"root\"] = root_path",
            "            else:",
            "                config = {",
            "                    \"auth_required\": True,",
            "                    \"auth_message\": blocks.auth_message,",
            "                    \"is_space\": app.get_blocks().is_space,",
            "                    \"root\": root_path,",
            "                }",
            "",
            "            try:",
            "                template = (",
            "                    \"frontend/share.html\" if blocks.share else \"frontend/index.html\"",
            "                )",
            "                return templates.TemplateResponse(",
            "                    template,",
            "                    {\"request\": request, \"config\": config},",
            "                )",
            "            except TemplateNotFound as err:",
            "                if blocks.share:",
            "                    raise ValueError(",
            "                        \"Did you install Gradio from source files? Share mode only \"",
            "                        \"works when Gradio is installed through the pip package.\"",
            "                    ) from err",
            "                else:",
            "                    raise ValueError(",
            "                        \"Did you install Gradio from source files? You need to build \"",
            "                        \"the frontend by running /scripts/build_frontend.sh\"",
            "                    ) from err",
            "",
            "        @app.get(\"/info/\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/info\", dependencies=[Depends(login_check)])",
            "        def api_info(serialize: bool = True):",
            "            config = app.get_blocks().config",
            "            return gradio.blocks.get_api_info(config, serialize)  # type: ignore",
            "",
            "        @app.get(\"/config/\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/config\", dependencies=[Depends(login_check)])",
            "        def get_config(request: fastapi.Request):",
            "            root_path = request.scope.get(\"root_path\", \"\")",
            "            config = app.get_blocks().config",
            "            config[\"root\"] = root_path",
            "            return config",
            "",
            "        @app.get(\"/static/{path:path}\")",
            "        def static_resource(path: str):",
            "            static_file = safe_join(STATIC_PATH_LIB, path)",
            "            return FileResponse(static_file)",
            "",
            "        @app.get(\"/assets/{path:path}\")",
            "        def build_resource(path: str):",
            "            build_file = safe_join(BUILD_PATH_LIB, path)",
            "            return FileResponse(build_file)",
            "",
            "        @app.get(\"/favicon.ico\")",
            "        async def favicon():",
            "            blocks = app.get_blocks()",
            "            if blocks.favicon_path is None:",
            "                return static_resource(\"img/logo.svg\")",
            "            else:",
            "                return FileResponse(blocks.favicon_path)",
            "",
            "        @app.head(\"/proxy={url_path:path}\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/proxy={url_path:path}\", dependencies=[Depends(login_check)])",
            "        async def reverse_proxy(url_path: str):",
            "            # Adapted from: https://github.com/tiangolo/fastapi/issues/1788",
            "            rp_req = app.build_proxy_request(url_path)",
            "            rp_resp = await client.send(rp_req, stream=True)",
            "            return StreamingResponse(",
            "                rp_resp.aiter_raw(),",
            "                status_code=rp_resp.status_code,",
            "                headers=rp_resp.headers,  # type: ignore",
            "                background=BackgroundTask(rp_resp.aclose),",
            "            )",
            "",
            "        @app.head(\"/file={path_or_url:path}\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/file={path_or_url:path}\", dependencies=[Depends(login_check)])",
            "        async def file(path_or_url: str, request: fastapi.Request):",
            "            blocks = app.get_blocks()",
            "            if utils.validate_url(path_or_url):",
            "                return RedirectResponse(",
            "                    url=path_or_url, status_code=status.HTTP_302_FOUND",
            "                )",
            "            abs_path = utils.abspath(path_or_url)",
            "            in_blocklist = any(",
            "                utils.is_in_or_equal(abs_path, blocked_path)",
            "                for blocked_path in blocks.blocked_paths",
            "            )",
            "            if in_blocklist or any(part.startswith(\".\") for part in abs_path.parts):",
            "                raise HTTPException(403, f\"File not allowed: {path_or_url}.\")",
            "",
            "            in_app_dir = utils.abspath(app.cwd) in abs_path.parents",
            "            created_by_app = str(abs_path) in set().union(*blocks.temp_file_sets)",
            "            in_file_dir = any(",
            "                utils.is_in_or_equal(abs_path, allowed_path)",
            "                for allowed_path in blocks.allowed_paths",
            "            )",
            "            was_uploaded = utils.abspath(app.uploaded_file_dir) in abs_path.parents",
            "",
            "            if in_app_dir or created_by_app or in_file_dir or was_uploaded:",
            "                if not abs_path.exists():",
            "                    raise HTTPException(404, \"File not found\")",
            "                if abs_path.is_dir():",
            "                    raise HTTPException(403)",
            "",
            "                range_val = request.headers.get(\"Range\", \"\").strip()",
            "                if range_val.startswith(\"bytes=\") and \"-\" in range_val:",
            "                    range_val = range_val[6:]",
            "                    start, end = range_val.split(\"-\")",
            "                    if start.isnumeric() and end.isnumeric():",
            "                        start = int(start)",
            "                        end = int(end)",
            "                        response = ranged_response.RangedFileResponse(",
            "                            abs_path,",
            "                            ranged_response.OpenRange(start, end),",
            "                            dict(request.headers),",
            "                            stat_result=os.stat(abs_path),",
            "                        )",
            "                        return response",
            "                return FileResponse(abs_path, headers={\"Accept-Ranges\": \"bytes\"})",
            "",
            "            else:",
            "                raise HTTPException(",
            "                    403,",
            "                    f\"File cannot be fetched: {path_or_url}. All files must contained within the Gradio python app working directory, or be a temp file created by the Gradio python app.\",",
            "                )",
            "",
            "        @app.get(\"/file/{path:path}\", dependencies=[Depends(login_check)])",
            "        async def file_deprecated(path: str, request: fastapi.Request):",
            "            return await file(path, request)",
            "",
            "        @app.post(\"/reset/\")",
            "        @app.post(\"/reset\")",
            "        async def reset_iterator(body: ResetBody):",
            "            if body.session_hash not in app.iterators:",
            "                return {\"success\": False}",
            "            async with app.lock:",
            "                app.iterators[body.session_hash][body.fn_index] = None",
            "                app.iterators[body.session_hash][\"should_reset\"].add(body.fn_index)",
            "            return {\"success\": True}",
            "",
            "        async def run_predict(",
            "            body: PredictBody,",
            "            request: Request | List[Request],",
            "            fn_index_inferred: int,",
            "        ):",
            "            if hasattr(body, \"session_hash\"):",
            "                if body.session_hash not in app.state_holder:",
            "                    app.state_holder[body.session_hash] = {",
            "                        _id: deepcopy(getattr(block, \"value\", None))",
            "                        for _id, block in app.get_blocks().blocks.items()",
            "                        if getattr(block, \"stateful\", False)",
            "                    }",
            "                session_state = app.state_holder[body.session_hash]",
            "                iterators = app.iterators[body.session_hash]",
            "                # The should_reset set keeps track of the fn_indices",
            "                # that have been cancelled. When a job is cancelled,",
            "                # the /reset route will mark the jobs as having been reset.",
            "                # That way if the cancel job finishes BEFORE the job being cancelled",
            "                # the job being cancelled will not overwrite the state of the iterator.",
            "                # In all cases, should_reset will be the empty set the next time",
            "                # the fn_index is run.",
            "                app.iterators[body.session_hash][\"should_reset\"] = set()",
            "            else:",
            "                session_state = {}",
            "                iterators = {}",
            "            event_id = getattr(body, \"event_id\", None)",
            "            raw_input = body.data",
            "            fn_index = body.fn_index",
            "",
            "            dependency = app.get_blocks().dependencies[fn_index_inferred]",
            "            target = dependency[\"targets\"][0] if len(dependency[\"targets\"]) else None",
            "            event_data = EventData(",
            "                app.get_blocks().blocks.get(target) if target else None,",
            "                body.event_data,",
            "            )",
            "            batch = dependency[\"batch\"]",
            "            if not (body.batched) and batch:",
            "                raw_input = [raw_input]",
            "            try:",
            "                with utils.MatplotlibBackendMananger():",
            "                    output = await app.get_blocks().process_api(",
            "                        fn_index=fn_index_inferred,",
            "                        inputs=raw_input,",
            "                        request=request,",
            "                        state=session_state,",
            "                        iterators=iterators,",
            "                        event_id=event_id,",
            "                        event_data=event_data,",
            "                    )",
            "                iterator = output.pop(\"iterator\", None)",
            "                if hasattr(body, \"session_hash\"):",
            "                    if fn_index in app.iterators[body.session_hash][\"should_reset\"]:",
            "                        app.iterators[body.session_hash][fn_index] = None",
            "                    else:",
            "                        app.iterators[body.session_hash][fn_index] = iterator",
            "                if isinstance(output, Error):",
            "                    raise output",
            "            except BaseException as error:",
            "                show_error = app.get_blocks().show_error or isinstance(error, Error)",
            "                traceback.print_exc()",
            "                return JSONResponse(",
            "                    content={\"error\": str(error) if show_error else None},",
            "                    status_code=500,",
            "                )",
            "",
            "            if not (body.batched) and batch:",
            "                output[\"data\"] = output[\"data\"][0]",
            "            return output",
            "",
            "        # had to use '/run' endpoint for Colab compatibility, '/api' supported for backwards compatibility",
            "        @app.post(\"/run/{api_name}\", dependencies=[Depends(login_check)])",
            "        @app.post(\"/run/{api_name}/\", dependencies=[Depends(login_check)])",
            "        @app.post(\"/api/{api_name}\", dependencies=[Depends(login_check)])",
            "        @app.post(\"/api/{api_name}/\", dependencies=[Depends(login_check)])",
            "        async def predict(",
            "            api_name: str,",
            "            body: PredictBody,",
            "            request: fastapi.Request,",
            "            username: str = Depends(get_current_user),",
            "        ):",
            "            fn_index_inferred = None",
            "            if body.fn_index is None:",
            "                for i, fn in enumerate(app.get_blocks().dependencies):",
            "                    if fn[\"api_name\"] == api_name:",
            "                        fn_index_inferred = i",
            "                        break",
            "                if fn_index_inferred is None:",
            "                    return JSONResponse(",
            "                        content={",
            "                            \"error\": f\"This app has no endpoint /api/{api_name}/.\"",
            "                        },",
            "                        status_code=500,",
            "                    )",
            "            else:",
            "                fn_index_inferred = body.fn_index",
            "            if (",
            "                not app.get_blocks().api_open",
            "                and app.get_blocks().queue_enabled_for_fn(fn_index_inferred)",
            "                and f\"Bearer {app.queue_token}\" != request.headers.get(\"Authorization\")",
            "            ):",
            "                raise HTTPException(",
            "                    status_code=status.HTTP_401_UNAUTHORIZED,",
            "                    detail=\"Not authorized to skip the queue\",",
            "                )",
            "",
            "            # If this fn_index cancels jobs, then the only input we need is the",
            "            # current session hash",
            "            if app.get_blocks().dependencies[fn_index_inferred][\"cancels\"]:",
            "                body.data = [body.session_hash]",
            "            if body.request:",
            "                if body.batched:",
            "                    gr_request = [",
            "                        Request(username=username, **req) for req in body.request",
            "                    ]",
            "                else:",
            "                    assert isinstance(body.request, dict)",
            "                    gr_request = Request(username=username, **body.request)",
            "            else:",
            "                gr_request = Request(username=username, request=request)",
            "            result = await run_predict(",
            "                body=body,",
            "                fn_index_inferred=fn_index_inferred,",
            "                request=gr_request,",
            "            )",
            "            return result",
            "",
            "        @app.websocket(\"/queue/join\")",
            "        async def join_queue(",
            "            websocket: WebSocket,",
            "            token: Optional[str] = Depends(ws_login_check),",
            "        ):",
            "            blocks = app.get_blocks()",
            "            if app.auth is not None and token is None:",
            "                await websocket.close(code=status.WS_1008_POLICY_VIOLATION)",
            "                return",
            "            if blocks._queue.server_path is None:",
            "                app_url = get_server_url_from_ws_url(str(websocket.url))",
            "                blocks._queue.set_url(app_url)",
            "            await websocket.accept()",
            "            # In order to cancel jobs, we need the session_hash and fn_index",
            "            # to create a unique id for each job",
            "            try:",
            "                await asyncio.wait_for(",
            "                    websocket.send_json({\"msg\": \"send_hash\"}), timeout=5",
            "                )",
            "            except AsyncTimeOutError:",
            "                return",
            "",
            "            try:",
            "                session_info = await asyncio.wait_for(",
            "                    websocket.receive_json(), timeout=5",
            "                )",
            "            except AsyncTimeOutError:",
            "                return",
            "",
            "            event = Event(",
            "                websocket, session_info[\"session_hash\"], session_info[\"fn_index\"]",
            "            )",
            "            # set the token into Event to allow using the same token for call_prediction",
            "            event.token = token",
            "            event.session_hash = session_info[\"session_hash\"]",
            "",
            "            # Continuous events are not put in the queue  so that they do not",
            "            # occupy the queue's resource as they are expected to run forever",
            "            if blocks.dependencies[event.fn_index].get(\"every\", 0):",
            "                await cancel_tasks({f\"{event.session_hash}_{event.fn_index}\"})",
            "                await blocks._queue.reset_iterators(event.session_hash, event.fn_index)",
            "                task = run_coro_in_background(",
            "                    blocks._queue.process_events, [event], False",
            "                )",
            "                set_task_name(task, event.session_hash, event.fn_index, batch=False)",
            "            else:",
            "                rank = blocks._queue.push(event)",
            "",
            "                if rank is None:",
            "                    await blocks._queue.send_message(event, {\"msg\": \"queue_full\"})",
            "                    await event.disconnect()",
            "                    return",
            "                estimation = blocks._queue.get_estimation()",
            "                await blocks._queue.send_estimation(event, estimation, rank)",
            "            while True:",
            "                await asyncio.sleep(1)",
            "                if websocket.application_state == WebSocketState.DISCONNECTED:",
            "                    return",
            "",
            "        @app.get(",
            "            \"/queue/status\",",
            "            dependencies=[Depends(login_check)],",
            "            response_model=Estimation,",
            "        )",
            "        async def get_queue_status():",
            "            return app.get_blocks()._queue.get_estimation()",
            "",
            "        @app.post(\"/upload\", dependencies=[Depends(login_check)])",
            "        async def upload_file(",
            "            files: List[UploadFile] = File(...),",
            "        ):",
            "            output_files = []",
            "            file_manager = gradio.File()",
            "            for input_file in files:",
            "                output_files.append(",
            "                    await file_manager.save_uploaded_file(",
            "                        input_file, app.uploaded_file_dir",
            "                    )",
            "                )",
            "            return output_files",
            "",
            "        @app.on_event(\"startup\")",
            "        @app.get(\"/startup-events\")",
            "        async def startup_events():",
            "            if not app.startup_events_triggered:",
            "                app.get_blocks().startup_events()",
            "                app.startup_events_triggered = True",
            "                return True",
            "            return False",
            "",
            "        @app.get(\"/theme.css\", response_class=PlainTextResponse)",
            "        def theme_css():",
            "            return PlainTextResponse(app.get_blocks().theme_css, media_type=\"text/css\")",
            "",
            "        @app.get(\"/robots.txt\", response_class=PlainTextResponse)",
            "        def robots_txt():",
            "            if app.get_blocks().share:",
            "                return \"User-agent: *\\nDisallow: /\"",
            "            else:",
            "                return \"User-agent: *\\nDisallow: \"",
            "",
            "        return app",
            "",
            "",
            "########",
            "# Helper functions",
            "########",
            "",
            "",
            "def safe_join(directory: str, path: str) -> str:",
            "    \"\"\"Safely path to a base directory to avoid escaping the base directory.",
            "    Borrowed from: werkzeug.security.safe_join\"\"\"",
            "    _os_alt_seps: List[str] = [",
            "        sep for sep in [os.path.sep, os.path.altsep] if sep is not None and sep != \"/\"",
            "    ]",
            "",
            "    if path == \"\":",
            "        raise HTTPException(400)",
            "",
            "    filename = os.path.normpath(path)",
            "    fullpath = os.path.join(directory, filename)",
            "    if (",
            "        any(sep in filename for sep in _os_alt_seps)",
            "        or os.path.isabs(filename)",
            "        or filename == \"..\"",
            "        or filename.startswith(\"../\")",
            "        or os.path.isdir(fullpath)",
            "    ):",
            "        raise HTTPException(403)",
            "",
            "    if not os.path.exists(fullpath):",
            "        raise HTTPException(404, \"File not found\")",
            "",
            "    return fullpath",
            "",
            "",
            "def get_types(cls_set: List[Type]):",
            "    docset = []",
            "    types = []",
            "    for cls in cls_set:",
            "        doc = inspect.getdoc(cls) or \"\"",
            "        doc_lines = doc.split(\"\\n\")",
            "        for line in doc_lines:",
            "            if \"value (\" in line:",
            "                types.append(line.split(\"value (\")[1].split(\")\")[0])",
            "        docset.append(doc_lines[1].split(\":\")[-1])",
            "    return docset, types",
            "",
            "",
            "def get_server_url_from_ws_url(ws_url: str):",
            "    ws_url_parsed = urlparse(ws_url)",
            "    scheme = \"http\" if ws_url_parsed.scheme == \"ws\" else \"https\"",
            "    port = f\":{ws_url_parsed.port}\" if ws_url_parsed.port else \"\"",
            "    return f\"{scheme}://{ws_url_parsed.hostname}{port}{ws_url_parsed.path.replace('queue/join', '')}\"",
            "",
            "",
            "set_documentation_group(\"routes\")",
            "",
            "",
            "class Obj:",
            "    \"\"\"",
            "    Using a class to convert dictionaries into objects. Used by the `Request` class.",
            "    Credit: https://www.geeksforgeeks.org/convert-nested-python-dictionary-to-object/",
            "    \"\"\"",
            "",
            "    def __init__(self, dict_):",
            "        self.__dict__.update(dict_)",
            "        for key, value in dict_.items():",
            "            if isinstance(value, (dict, list)):",
            "                value = Obj(value)",
            "            setattr(self, key, value)",
            "",
            "    def __getitem__(self, item):",
            "        return self.__dict__[item]",
            "",
            "    def __setitem__(self, item, value):",
            "        self.__dict__[item] = value",
            "",
            "    def __iter__(self):",
            "        for key, value in self.__dict__.items():",
            "            if isinstance(value, Obj):",
            "                yield (key, dict(value))",
            "            else:",
            "                yield (key, value)",
            "",
            "    def __contains__(self, item) -> bool:",
            "        if item in self.__dict__:",
            "            return True",
            "        for value in self.__dict__.values():",
            "            if isinstance(value, Obj) and item in value:",
            "                return True",
            "        return False",
            "",
            "    def keys(self):",
            "        return self.__dict__.keys()",
            "",
            "    def values(self):",
            "        return self.__dict__.values()",
            "",
            "    def items(self):",
            "        return self.__dict__.items()",
            "",
            "    def __str__(self) -> str:",
            "        return str(self.__dict__)",
            "",
            "    def __repr__(self) -> str:",
            "        return str(self.__dict__)",
            "",
            "",
            "@document()",
            "class Request:",
            "    \"\"\"",
            "    A Gradio request object that can be used to access the request headers, cookies,",
            "    query parameters and other information about the request from within the prediction",
            "    function. The class is a thin wrapper around the fastapi.Request class. Attributes",
            "    of this class include: `headers`, `client`, `query_params`, and `path_params`. If",
            "    auth is enabled, the `username` attribute can be used to get the logged in user.",
            "    Example:",
            "        import gradio as gr",
            "        def echo(name, request: gr.Request):",
            "            print(\"Request headers dictionary:\", request.headers)",
            "            print(\"IP address:\", request.client.host)",
            "            return name",
            "        io = gr.Interface(echo, \"textbox\", \"textbox\").launch()",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        request: fastapi.Request | None = None,",
            "        username: str | None = None,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"",
            "        Can be instantiated with either a fastapi.Request or by manually passing in",
            "        attributes (needed for websocket-based queueing).",
            "        Parameters:",
            "            request: A fastapi.Request",
            "        \"\"\"",
            "        self.request = request",
            "        self.username = username",
            "        self.kwargs: Dict = kwargs",
            "",
            "    def dict_to_obj(self, d):",
            "        if isinstance(d, dict):",
            "            return json.loads(json.dumps(d), object_hook=Obj)",
            "        else:",
            "            return d",
            "",
            "    def __getattr__(self, name):",
            "        if self.request:",
            "            return self.dict_to_obj(getattr(self.request, name))",
            "        else:",
            "            try:",
            "                obj = self.kwargs[name]",
            "            except KeyError as ke:",
            "                raise AttributeError(",
            "                    f\"'Request' object has no attribute '{name}'\"",
            "                ) from ke",
            "            return self.dict_to_obj(obj)",
            "",
            "",
            "@document()",
            "def mount_gradio_app(",
            "    app: fastapi.FastAPI,",
            "    blocks: gradio.Blocks,",
            "    path: str,",
            "    gradio_api_url: str | None = None,",
            ") -> fastapi.FastAPI:",
            "    \"\"\"Mount a gradio.Blocks to an existing FastAPI application.",
            "",
            "    Parameters:",
            "        app: The parent FastAPI application.",
            "        blocks: The blocks object we want to mount to the parent app.",
            "        path: The path at which the gradio application will be mounted.",
            "        gradio_api_url: The full url at which the gradio app will run. This is only needed if deploying to Huggingface spaces of if the websocket endpoints of your deployed app are on a different network location than the gradio app. If deploying to spaces, set gradio_api_url to 'http://localhost:7860/'",
            "    Example:",
            "        from fastapi import FastAPI",
            "        import gradio as gr",
            "        app = FastAPI()",
            "        @app.get(\"/\")",
            "        def read_main():",
            "            return {\"message\": \"This is your main app\"}",
            "        io = gr.Interface(lambda x: \"Hello, \" + x + \"!\", \"textbox\", \"textbox\")",
            "        app = gr.mount_gradio_app(app, io, path=\"/gradio\")",
            "        # Then run `uvicorn run:app` from the terminal and navigate to http://localhost:8000/gradio.",
            "    \"\"\"",
            "    blocks.dev_mode = False",
            "    blocks.config = blocks.get_config_file()",
            "    blocks.validate_queue_settings()",
            "    gradio_app = App.create_app(blocks)",
            "",
            "    @app.on_event(\"startup\")",
            "    async def start_queue():",
            "        if gradio_app.get_blocks().enable_queue:",
            "            if gradio_api_url:",
            "                gradio_app.get_blocks()._queue.set_url(gradio_api_url)",
            "            gradio_app.get_blocks().startup_events()",
            "",
            "    app.mount(path, gradio_app)",
            "    return app"
        ],
        "afterPatchFile": [
            "\"\"\"Implements a FastAPI server to run the gradio interface. Note that some types in this",
            "module use the Optional/Union notation so that they work correctly with pydantic.\"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import asyncio",
            "import inspect",
            "import json",
            "import mimetypes",
            "import os",
            "import secrets",
            "import tempfile",
            "import traceback",
            "from asyncio import TimeoutError as AsyncTimeOutError",
            "from collections import defaultdict",
            "from copy import deepcopy",
            "from pathlib import Path",
            "from typing import Any, Dict, List, Optional, Type",
            "from urllib.parse import urlparse",
            "",
            "import fastapi",
            "import httpx",
            "import markupsafe",
            "import orjson",
            "import pkg_resources",
            "from fastapi import Depends, FastAPI, File, HTTPException, UploadFile, WebSocket, status",
            "from fastapi.middleware.cors import CORSMiddleware",
            "from fastapi.responses import (",
            "    FileResponse,",
            "    HTMLResponse,",
            "    JSONResponse,",
            "    PlainTextResponse,",
            ")",
            "from fastapi.security import OAuth2PasswordRequestForm",
            "from fastapi.templating import Jinja2Templates",
            "from gradio_client.documentation import document, set_documentation_group",
            "from jinja2.exceptions import TemplateNotFound",
            "from starlette.background import BackgroundTask",
            "from starlette.responses import RedirectResponse, StreamingResponse",
            "from starlette.websockets import WebSocketState",
            "",
            "import gradio",
            "import gradio.ranged_response as ranged_response",
            "from gradio import utils",
            "from gradio.context import Context",
            "from gradio.data_classes import PredictBody, ResetBody",
            "from gradio.exceptions import Error",
            "from gradio.helpers import EventData",
            "from gradio.queueing import Estimation, Event",
            "from gradio.utils import cancel_tasks, run_coro_in_background, set_task_name",
            "",
            "mimetypes.init()",
            "",
            "STATIC_TEMPLATE_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/\")",
            "STATIC_PATH_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/frontend/static\")",
            "BUILD_PATH_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/frontend/assets\")",
            "VERSION_FILE = pkg_resources.resource_filename(\"gradio\", \"version.txt\")",
            "with open(VERSION_FILE) as version_file:",
            "    VERSION = version_file.read()",
            "",
            "",
            "class ORJSONResponse(JSONResponse):",
            "    media_type = \"application/json\"",
            "",
            "    @staticmethod",
            "    def _render(content: Any) -> bytes:",
            "        return orjson.dumps(",
            "            content,",
            "            option=orjson.OPT_SERIALIZE_NUMPY | orjson.OPT_PASSTHROUGH_DATETIME,",
            "            default=str,",
            "        )",
            "",
            "    def render(self, content: Any) -> bytes:",
            "        return ORJSONResponse._render(content)",
            "",
            "    @staticmethod",
            "    def _render_str(content: Any) -> str:",
            "        return ORJSONResponse._render(content).decode(\"utf-8\")",
            "",
            "",
            "def toorjson(value):",
            "    return markupsafe.Markup(",
            "        ORJSONResponse._render_str(value)",
            "        .replace(\"<\", \"\\\\u003c\")",
            "        .replace(\">\", \"\\\\u003e\")",
            "        .replace(\"&\", \"\\\\u0026\")",
            "        .replace(\"'\", \"\\\\u0027\")",
            "    )",
            "",
            "",
            "templates = Jinja2Templates(directory=STATIC_TEMPLATE_LIB)",
            "templates.env.filters[\"toorjson\"] = toorjson",
            "",
            "client = httpx.AsyncClient()",
            "",
            "###########",
            "# Auth",
            "###########",
            "",
            "",
            "class App(FastAPI):",
            "    \"\"\"",
            "    FastAPI App Wrapper",
            "    \"\"\"",
            "",
            "    def __init__(self, **kwargs):",
            "        self.tokens = {}",
            "        self.auth = None",
            "        self.blocks: gradio.Blocks | None = None",
            "        self.state_holder = {}",
            "        self.iterators = defaultdict(dict)",
            "        self.lock = asyncio.Lock()",
            "        self.queue_token = secrets.token_urlsafe(32)",
            "        self.startup_events_triggered = False",
            "        self.uploaded_file_dir = os.environ.get(\"GRADIO_TEMP_DIR\") or str(",
            "            Path(tempfile.gettempdir()) / \"gradio\"",
            "        )",
            "        # Allow user to manually set `docs_url` and `redoc_url`",
            "        # when instantiating an App; when they're not set, disable docs and redoc.",
            "        kwargs.setdefault(\"docs_url\", None)",
            "        kwargs.setdefault(\"redoc_url\", None)",
            "        super().__init__(**kwargs)",
            "",
            "    def configure_app(self, blocks: gradio.Blocks) -> None:",
            "        auth = blocks.auth",
            "        if auth is not None:",
            "            if not callable(auth):",
            "                self.auth = {account[0]: account[1] for account in auth}",
            "            else:",
            "                self.auth = auth",
            "        else:",
            "            self.auth = None",
            "",
            "        self.blocks = blocks",
            "        if hasattr(self.blocks, \"_queue\"):",
            "            self.blocks._queue.set_access_token(self.queue_token)",
            "        self.cwd = os.getcwd()",
            "        self.favicon_path = blocks.favicon_path",
            "        self.tokens = {}",
            "        self.root_path = blocks.root_path",
            "",
            "    def get_blocks(self) -> gradio.Blocks:",
            "        if self.blocks is None:",
            "            raise ValueError(\"No Blocks has been configured for this app.\")",
            "        return self.blocks",
            "",
            "    @staticmethod",
            "    def build_proxy_request(url_path):",
            "        url = httpx.URL(url_path)",
            "        is_hf_url = url.host.endswith(\".hf.space\")",
            "        headers = {}",
            "        if Context.hf_token is not None and is_hf_url:",
            "            headers[\"Authorization\"] = f\"Bearer {Context.hf_token}\"",
            "        rp_req = client.build_request(\"GET\", url, headers=headers)",
            "        return rp_req",
            "",
            "    @staticmethod",
            "    def create_app(",
            "        blocks: gradio.Blocks, app_kwargs: Dict[str, Any] | None = None",
            "    ) -> App:",
            "        app_kwargs = app_kwargs or {}",
            "        app_kwargs.setdefault(\"default_response_class\", ORJSONResponse)",
            "        app = App(**app_kwargs)",
            "        app.configure_app(blocks)",
            "",
            "        app.add_middleware(",
            "            CORSMiddleware,",
            "            allow_origins=[\"*\"],",
            "            allow_methods=[\"*\"],",
            "            allow_headers=[\"*\"],",
            "        )",
            "",
            "        @app.get(\"/user\")",
            "        @app.get(\"/user/\")",
            "        def get_current_user(request: fastapi.Request) -> Optional[str]:",
            "            token = request.cookies.get(\"access-token\") or request.cookies.get(",
            "                \"access-token-unsecure\"",
            "            )",
            "            return app.tokens.get(token)",
            "",
            "        @app.get(\"/login_check\")",
            "        @app.get(\"/login_check/\")",
            "        def login_check(user: str = Depends(get_current_user)):",
            "            if app.auth is None or user is not None:",
            "                return",
            "            raise HTTPException(",
            "                status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Not authenticated\"",
            "            )",
            "",
            "        async def ws_login_check(websocket: WebSocket) -> Optional[str]:",
            "            token = websocket.cookies.get(\"access-token\") or websocket.cookies.get(",
            "                \"access-token-unsecure\"",
            "            )",
            "            return token  # token is returned to allow request in queue",
            "",
            "        @app.get(\"/token\")",
            "        @app.get(\"/token/\")",
            "        def get_token(request: fastapi.Request) -> dict:",
            "            token = request.cookies.get(\"access-token\")",
            "            return {\"token\": token, \"user\": app.tokens.get(token)}",
            "",
            "        @app.get(\"/app_id\")",
            "        @app.get(\"/app_id/\")",
            "        def app_id(request: fastapi.Request) -> dict:",
            "            return {\"app_id\": app.get_blocks().app_id}",
            "",
            "        @app.post(\"/login\")",
            "        @app.post(\"/login/\")",
            "        def login(form_data: OAuth2PasswordRequestForm = Depends()):",
            "            username, password = form_data.username, form_data.password",
            "            if app.auth is None:",
            "                return RedirectResponse(url=\"/\", status_code=status.HTTP_302_FOUND)",
            "            if (",
            "                not callable(app.auth)",
            "                and username in app.auth",
            "                and app.auth[username] == password",
            "            ) or (callable(app.auth) and app.auth.__call__(username, password)):",
            "                token = secrets.token_urlsafe(16)",
            "                app.tokens[token] = username",
            "                response = JSONResponse(content={\"success\": True})",
            "                response.set_cookie(",
            "                    key=\"access-token\",",
            "                    value=token,",
            "                    httponly=True,",
            "                    samesite=\"none\",",
            "                    secure=True,",
            "                )",
            "                response.set_cookie(",
            "                    key=\"access-token-unsecure\", value=token, httponly=True",
            "                )",
            "                return response",
            "            else:",
            "                raise HTTPException(status_code=400, detail=\"Incorrect credentials.\")",
            "",
            "        ###############",
            "        # Main Routes",
            "        ###############",
            "",
            "        @app.head(\"/\", response_class=HTMLResponse)",
            "        @app.get(\"/\", response_class=HTMLResponse)",
            "        def main(request: fastapi.Request, user: str = Depends(get_current_user)):",
            "            mimetypes.add_type(\"application/javascript\", \".js\")",
            "            blocks = app.get_blocks()",
            "            root_path = request.scope.get(\"root_path\", \"\")",
            "",
            "            if app.auth is None or user is not None:",
            "                config = app.get_blocks().config",
            "                config[\"root\"] = root_path",
            "            else:",
            "                config = {",
            "                    \"auth_required\": True,",
            "                    \"auth_message\": blocks.auth_message,",
            "                    \"is_space\": app.get_blocks().is_space,",
            "                    \"root\": root_path,",
            "                }",
            "",
            "            try:",
            "                template = (",
            "                    \"frontend/share.html\" if blocks.share else \"frontend/index.html\"",
            "                )",
            "                return templates.TemplateResponse(",
            "                    template,",
            "                    {\"request\": request, \"config\": config},",
            "                )",
            "            except TemplateNotFound as err:",
            "                if blocks.share:",
            "                    raise ValueError(",
            "                        \"Did you install Gradio from source files? Share mode only \"",
            "                        \"works when Gradio is installed through the pip package.\"",
            "                    ) from err",
            "                else:",
            "                    raise ValueError(",
            "                        \"Did you install Gradio from source files? You need to build \"",
            "                        \"the frontend by running /scripts/build_frontend.sh\"",
            "                    ) from err",
            "",
            "        @app.get(\"/info/\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/info\", dependencies=[Depends(login_check)])",
            "        def api_info(serialize: bool = True):",
            "            config = app.get_blocks().config",
            "            return gradio.blocks.get_api_info(config, serialize)  # type: ignore",
            "",
            "        @app.get(\"/config/\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/config\", dependencies=[Depends(login_check)])",
            "        def get_config(request: fastapi.Request):",
            "            root_path = request.scope.get(\"root_path\", \"\")",
            "            config = app.get_blocks().config",
            "            config[\"root\"] = root_path",
            "            return config",
            "",
            "        @app.get(\"/static/{path:path}\")",
            "        def static_resource(path: str):",
            "            static_file = safe_join(STATIC_PATH_LIB, path)",
            "            return FileResponse(static_file)",
            "",
            "        @app.get(\"/assets/{path:path}\")",
            "        def build_resource(path: str):",
            "            build_file = safe_join(BUILD_PATH_LIB, path)",
            "            return FileResponse(build_file)",
            "",
            "        @app.get(\"/favicon.ico\")",
            "        async def favicon():",
            "            blocks = app.get_blocks()",
            "            if blocks.favicon_path is None:",
            "                return static_resource(\"img/logo.svg\")",
            "            else:",
            "                return FileResponse(blocks.favicon_path)",
            "",
            "        @app.head(\"/proxy={url_path:path}\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/proxy={url_path:path}\", dependencies=[Depends(login_check)])",
            "        async def reverse_proxy(url_path: str):",
            "            # Adapted from: https://github.com/tiangolo/fastapi/issues/1788",
            "            rp_req = app.build_proxy_request(url_path)",
            "            rp_resp = await client.send(rp_req, stream=True)",
            "            return StreamingResponse(",
            "                rp_resp.aiter_raw(),",
            "                status_code=rp_resp.status_code,",
            "                headers=rp_resp.headers,  # type: ignore",
            "                background=BackgroundTask(rp_resp.aclose),",
            "            )",
            "",
            "        @app.head(\"/file={path_or_url:path}\", dependencies=[Depends(login_check)])",
            "        @app.get(\"/file={path_or_url:path}\", dependencies=[Depends(login_check)])",
            "        async def file(path_or_url: str, request: fastapi.Request):",
            "            blocks = app.get_blocks()",
            "            if utils.validate_url(path_or_url):",
            "                return RedirectResponse(",
            "                    url=path_or_url, status_code=status.HTTP_302_FOUND",
            "                )",
            "",
            "            abs_path = utils.abspath(path_or_url)",
            "",
            "            in_blocklist = any(",
            "                utils.is_in_or_equal(abs_path, blocked_path)",
            "                for blocked_path in blocks.blocked_paths",
            "            )",
            "            is_dotfile = any(part.startswith(\".\") for part in abs_path.parts)",
            "            is_dir = abs_path.is_dir()",
            "",
            "            if in_blocklist or is_dotfile or is_dir:",
            "                raise HTTPException(403, f\"File not allowed: {path_or_url}.\")",
            "            if not abs_path.exists():",
            "                raise HTTPException(404, f\"File not found: {path_or_url}.\")",
            "",
            "            in_app_dir = utils.is_in_or_equal(abs_path, app.cwd)",
            "            created_by_app = str(abs_path) in set().union(*blocks.temp_file_sets)",
            "            in_allowlist = any(",
            "                utils.is_in_or_equal(abs_path, allowed_path)",
            "                for allowed_path in blocks.allowed_paths",
            "            )",
            "            was_uploaded = utils.is_in_or_equal(abs_path, app.uploaded_file_dir)",
            "",
            "            if not (in_app_dir or created_by_app or in_allowlist or was_uploaded):",
            "                raise HTTPException(403, f\"File not allowed: {path_or_url}.\")",
            "",
            "            range_val = request.headers.get(\"Range\", \"\").strip()",
            "            if range_val.startswith(\"bytes=\") and \"-\" in range_val:",
            "                range_val = range_val[6:]",
            "                start, end = range_val.split(\"-\")",
            "                if start.isnumeric() and end.isnumeric():",
            "                    start = int(start)",
            "                    end = int(end)",
            "                    response = ranged_response.RangedFileResponse(",
            "                        abs_path,",
            "                        ranged_response.OpenRange(start, end),",
            "                        dict(request.headers),",
            "                        stat_result=os.stat(abs_path),",
            "                    )",
            "                    return response",
            "            return FileResponse(abs_path, headers={\"Accept-Ranges\": \"bytes\"})",
            "",
            "        @app.get(\"/file/{path:path}\", dependencies=[Depends(login_check)])",
            "        async def file_deprecated(path: str, request: fastapi.Request):",
            "            return await file(path, request)",
            "",
            "        @app.post(\"/reset/\")",
            "        @app.post(\"/reset\")",
            "        async def reset_iterator(body: ResetBody):",
            "            if body.session_hash not in app.iterators:",
            "                return {\"success\": False}",
            "            async with app.lock:",
            "                app.iterators[body.session_hash][body.fn_index] = None",
            "                app.iterators[body.session_hash][\"should_reset\"].add(body.fn_index)",
            "            return {\"success\": True}",
            "",
            "        async def run_predict(",
            "            body: PredictBody,",
            "            request: Request | List[Request],",
            "            fn_index_inferred: int,",
            "        ):",
            "            if hasattr(body, \"session_hash\"):",
            "                if body.session_hash not in app.state_holder:",
            "                    app.state_holder[body.session_hash] = {",
            "                        _id: deepcopy(getattr(block, \"value\", None))",
            "                        for _id, block in app.get_blocks().blocks.items()",
            "                        if getattr(block, \"stateful\", False)",
            "                    }",
            "                session_state = app.state_holder[body.session_hash]",
            "                iterators = app.iterators[body.session_hash]",
            "                # The should_reset set keeps track of the fn_indices",
            "                # that have been cancelled. When a job is cancelled,",
            "                # the /reset route will mark the jobs as having been reset.",
            "                # That way if the cancel job finishes BEFORE the job being cancelled",
            "                # the job being cancelled will not overwrite the state of the iterator.",
            "                # In all cases, should_reset will be the empty set the next time",
            "                # the fn_index is run.",
            "                app.iterators[body.session_hash][\"should_reset\"] = set()",
            "            else:",
            "                session_state = {}",
            "                iterators = {}",
            "            event_id = getattr(body, \"event_id\", None)",
            "            raw_input = body.data",
            "            fn_index = body.fn_index",
            "",
            "            dependency = app.get_blocks().dependencies[fn_index_inferred]",
            "            target = dependency[\"targets\"][0] if len(dependency[\"targets\"]) else None",
            "            event_data = EventData(",
            "                app.get_blocks().blocks.get(target) if target else None,",
            "                body.event_data,",
            "            )",
            "            batch = dependency[\"batch\"]",
            "            if not (body.batched) and batch:",
            "                raw_input = [raw_input]",
            "            try:",
            "                with utils.MatplotlibBackendMananger():",
            "                    output = await app.get_blocks().process_api(",
            "                        fn_index=fn_index_inferred,",
            "                        inputs=raw_input,",
            "                        request=request,",
            "                        state=session_state,",
            "                        iterators=iterators,",
            "                        event_id=event_id,",
            "                        event_data=event_data,",
            "                    )",
            "                iterator = output.pop(\"iterator\", None)",
            "                if hasattr(body, \"session_hash\"):",
            "                    if fn_index in app.iterators[body.session_hash][\"should_reset\"]:",
            "                        app.iterators[body.session_hash][fn_index] = None",
            "                    else:",
            "                        app.iterators[body.session_hash][fn_index] = iterator",
            "                if isinstance(output, Error):",
            "                    raise output",
            "            except BaseException as error:",
            "                show_error = app.get_blocks().show_error or isinstance(error, Error)",
            "                traceback.print_exc()",
            "                return JSONResponse(",
            "                    content={\"error\": str(error) if show_error else None},",
            "                    status_code=500,",
            "                )",
            "",
            "            if not (body.batched) and batch:",
            "                output[\"data\"] = output[\"data\"][0]",
            "            return output",
            "",
            "        # had to use '/run' endpoint for Colab compatibility, '/api' supported for backwards compatibility",
            "        @app.post(\"/run/{api_name}\", dependencies=[Depends(login_check)])",
            "        @app.post(\"/run/{api_name}/\", dependencies=[Depends(login_check)])",
            "        @app.post(\"/api/{api_name}\", dependencies=[Depends(login_check)])",
            "        @app.post(\"/api/{api_name}/\", dependencies=[Depends(login_check)])",
            "        async def predict(",
            "            api_name: str,",
            "            body: PredictBody,",
            "            request: fastapi.Request,",
            "            username: str = Depends(get_current_user),",
            "        ):",
            "            fn_index_inferred = None",
            "            if body.fn_index is None:",
            "                for i, fn in enumerate(app.get_blocks().dependencies):",
            "                    if fn[\"api_name\"] == api_name:",
            "                        fn_index_inferred = i",
            "                        break",
            "                if fn_index_inferred is None:",
            "                    return JSONResponse(",
            "                        content={",
            "                            \"error\": f\"This app has no endpoint /api/{api_name}/.\"",
            "                        },",
            "                        status_code=500,",
            "                    )",
            "            else:",
            "                fn_index_inferred = body.fn_index",
            "            if (",
            "                not app.get_blocks().api_open",
            "                and app.get_blocks().queue_enabled_for_fn(fn_index_inferred)",
            "                and f\"Bearer {app.queue_token}\" != request.headers.get(\"Authorization\")",
            "            ):",
            "                raise HTTPException(",
            "                    status_code=status.HTTP_401_UNAUTHORIZED,",
            "                    detail=\"Not authorized to skip the queue\",",
            "                )",
            "",
            "            # If this fn_index cancels jobs, then the only input we need is the",
            "            # current session hash",
            "            if app.get_blocks().dependencies[fn_index_inferred][\"cancels\"]:",
            "                body.data = [body.session_hash]",
            "            if body.request:",
            "                if body.batched:",
            "                    gr_request = [",
            "                        Request(username=username, **req) for req in body.request",
            "                    ]",
            "                else:",
            "                    assert isinstance(body.request, dict)",
            "                    gr_request = Request(username=username, **body.request)",
            "            else:",
            "                gr_request = Request(username=username, request=request)",
            "            result = await run_predict(",
            "                body=body,",
            "                fn_index_inferred=fn_index_inferred,",
            "                request=gr_request,",
            "            )",
            "            return result",
            "",
            "        @app.websocket(\"/queue/join\")",
            "        async def join_queue(",
            "            websocket: WebSocket,",
            "            token: Optional[str] = Depends(ws_login_check),",
            "        ):",
            "            blocks = app.get_blocks()",
            "            if app.auth is not None and token is None:",
            "                await websocket.close(code=status.WS_1008_POLICY_VIOLATION)",
            "                return",
            "            if blocks._queue.server_path is None:",
            "                app_url = get_server_url_from_ws_url(str(websocket.url))",
            "                blocks._queue.set_url(app_url)",
            "            await websocket.accept()",
            "            # In order to cancel jobs, we need the session_hash and fn_index",
            "            # to create a unique id for each job",
            "            try:",
            "                await asyncio.wait_for(",
            "                    websocket.send_json({\"msg\": \"send_hash\"}), timeout=5",
            "                )",
            "            except AsyncTimeOutError:",
            "                return",
            "",
            "            try:",
            "                session_info = await asyncio.wait_for(",
            "                    websocket.receive_json(), timeout=5",
            "                )",
            "            except AsyncTimeOutError:",
            "                return",
            "",
            "            event = Event(",
            "                websocket, session_info[\"session_hash\"], session_info[\"fn_index\"]",
            "            )",
            "            # set the token into Event to allow using the same token for call_prediction",
            "            event.token = token",
            "            event.session_hash = session_info[\"session_hash\"]",
            "",
            "            # Continuous events are not put in the queue  so that they do not",
            "            # occupy the queue's resource as they are expected to run forever",
            "            if blocks.dependencies[event.fn_index].get(\"every\", 0):",
            "                await cancel_tasks({f\"{event.session_hash}_{event.fn_index}\"})",
            "                await blocks._queue.reset_iterators(event.session_hash, event.fn_index)",
            "                task = run_coro_in_background(",
            "                    blocks._queue.process_events, [event], False",
            "                )",
            "                set_task_name(task, event.session_hash, event.fn_index, batch=False)",
            "            else:",
            "                rank = blocks._queue.push(event)",
            "",
            "                if rank is None:",
            "                    await blocks._queue.send_message(event, {\"msg\": \"queue_full\"})",
            "                    await event.disconnect()",
            "                    return",
            "                estimation = blocks._queue.get_estimation()",
            "                await blocks._queue.send_estimation(event, estimation, rank)",
            "            while True:",
            "                await asyncio.sleep(1)",
            "                if websocket.application_state == WebSocketState.DISCONNECTED:",
            "                    return",
            "",
            "        @app.get(",
            "            \"/queue/status\",",
            "            dependencies=[Depends(login_check)],",
            "            response_model=Estimation,",
            "        )",
            "        async def get_queue_status():",
            "            return app.get_blocks()._queue.get_estimation()",
            "",
            "        @app.post(\"/upload\", dependencies=[Depends(login_check)])",
            "        async def upload_file(",
            "            files: List[UploadFile] = File(...),",
            "        ):",
            "            output_files = []",
            "            file_manager = gradio.File()",
            "            for input_file in files:",
            "                output_files.append(",
            "                    await file_manager.save_uploaded_file(",
            "                        input_file, app.uploaded_file_dir",
            "                    )",
            "                )",
            "            return output_files",
            "",
            "        @app.on_event(\"startup\")",
            "        @app.get(\"/startup-events\")",
            "        async def startup_events():",
            "            if not app.startup_events_triggered:",
            "                app.get_blocks().startup_events()",
            "                app.startup_events_triggered = True",
            "                return True",
            "            return False",
            "",
            "        @app.get(\"/theme.css\", response_class=PlainTextResponse)",
            "        def theme_css():",
            "            return PlainTextResponse(app.get_blocks().theme_css, media_type=\"text/css\")",
            "",
            "        @app.get(\"/robots.txt\", response_class=PlainTextResponse)",
            "        def robots_txt():",
            "            if app.get_blocks().share:",
            "                return \"User-agent: *\\nDisallow: /\"",
            "            else:",
            "                return \"User-agent: *\\nDisallow: \"",
            "",
            "        return app",
            "",
            "",
            "########",
            "# Helper functions",
            "########",
            "",
            "",
            "def safe_join(directory: str, path: str) -> str:",
            "    \"\"\"Safely path to a base directory to avoid escaping the base directory.",
            "    Borrowed from: werkzeug.security.safe_join\"\"\"",
            "    _os_alt_seps: List[str] = [",
            "        sep for sep in [os.path.sep, os.path.altsep] if sep is not None and sep != \"/\"",
            "    ]",
            "",
            "    if path == \"\":",
            "        raise HTTPException(400)",
            "",
            "    filename = os.path.normpath(path)",
            "    fullpath = os.path.join(directory, filename)",
            "    if (",
            "        any(sep in filename for sep in _os_alt_seps)",
            "        or os.path.isabs(filename)",
            "        or filename == \"..\"",
            "        or filename.startswith(\"../\")",
            "        or os.path.isdir(fullpath)",
            "    ):",
            "        raise HTTPException(403)",
            "",
            "    if not os.path.exists(fullpath):",
            "        raise HTTPException(404, \"File not found\")",
            "",
            "    return fullpath",
            "",
            "",
            "def get_types(cls_set: List[Type]):",
            "    docset = []",
            "    types = []",
            "    for cls in cls_set:",
            "        doc = inspect.getdoc(cls) or \"\"",
            "        doc_lines = doc.split(\"\\n\")",
            "        for line in doc_lines:",
            "            if \"value (\" in line:",
            "                types.append(line.split(\"value (\")[1].split(\")\")[0])",
            "        docset.append(doc_lines[1].split(\":\")[-1])",
            "    return docset, types",
            "",
            "",
            "def get_server_url_from_ws_url(ws_url: str):",
            "    ws_url_parsed = urlparse(ws_url)",
            "    scheme = \"http\" if ws_url_parsed.scheme == \"ws\" else \"https\"",
            "    port = f\":{ws_url_parsed.port}\" if ws_url_parsed.port else \"\"",
            "    return f\"{scheme}://{ws_url_parsed.hostname}{port}{ws_url_parsed.path.replace('queue/join', '')}\"",
            "",
            "",
            "set_documentation_group(\"routes\")",
            "",
            "",
            "class Obj:",
            "    \"\"\"",
            "    Using a class to convert dictionaries into objects. Used by the `Request` class.",
            "    Credit: https://www.geeksforgeeks.org/convert-nested-python-dictionary-to-object/",
            "    \"\"\"",
            "",
            "    def __init__(self, dict_):",
            "        self.__dict__.update(dict_)",
            "        for key, value in dict_.items():",
            "            if isinstance(value, (dict, list)):",
            "                value = Obj(value)",
            "            setattr(self, key, value)",
            "",
            "    def __getitem__(self, item):",
            "        return self.__dict__[item]",
            "",
            "    def __setitem__(self, item, value):",
            "        self.__dict__[item] = value",
            "",
            "    def __iter__(self):",
            "        for key, value in self.__dict__.items():",
            "            if isinstance(value, Obj):",
            "                yield (key, dict(value))",
            "            else:",
            "                yield (key, value)",
            "",
            "    def __contains__(self, item) -> bool:",
            "        if item in self.__dict__:",
            "            return True",
            "        for value in self.__dict__.values():",
            "            if isinstance(value, Obj) and item in value:",
            "                return True",
            "        return False",
            "",
            "    def keys(self):",
            "        return self.__dict__.keys()",
            "",
            "    def values(self):",
            "        return self.__dict__.values()",
            "",
            "    def items(self):",
            "        return self.__dict__.items()",
            "",
            "    def __str__(self) -> str:",
            "        return str(self.__dict__)",
            "",
            "    def __repr__(self) -> str:",
            "        return str(self.__dict__)",
            "",
            "",
            "@document()",
            "class Request:",
            "    \"\"\"",
            "    A Gradio request object that can be used to access the request headers, cookies,",
            "    query parameters and other information about the request from within the prediction",
            "    function. The class is a thin wrapper around the fastapi.Request class. Attributes",
            "    of this class include: `headers`, `client`, `query_params`, and `path_params`. If",
            "    auth is enabled, the `username` attribute can be used to get the logged in user.",
            "    Example:",
            "        import gradio as gr",
            "        def echo(name, request: gr.Request):",
            "            print(\"Request headers dictionary:\", request.headers)",
            "            print(\"IP address:\", request.client.host)",
            "            return name",
            "        io = gr.Interface(echo, \"textbox\", \"textbox\").launch()",
            "    \"\"\"",
            "",
            "    def __init__(",
            "        self,",
            "        request: fastapi.Request | None = None,",
            "        username: str | None = None,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"",
            "        Can be instantiated with either a fastapi.Request or by manually passing in",
            "        attributes (needed for websocket-based queueing).",
            "        Parameters:",
            "            request: A fastapi.Request",
            "        \"\"\"",
            "        self.request = request",
            "        self.username = username",
            "        self.kwargs: Dict = kwargs",
            "",
            "    def dict_to_obj(self, d):",
            "        if isinstance(d, dict):",
            "            return json.loads(json.dumps(d), object_hook=Obj)",
            "        else:",
            "            return d",
            "",
            "    def __getattr__(self, name):",
            "        if self.request:",
            "            return self.dict_to_obj(getattr(self.request, name))",
            "        else:",
            "            try:",
            "                obj = self.kwargs[name]",
            "            except KeyError as ke:",
            "                raise AttributeError(",
            "                    f\"'Request' object has no attribute '{name}'\"",
            "                ) from ke",
            "            return self.dict_to_obj(obj)",
            "",
            "",
            "@document()",
            "def mount_gradio_app(",
            "    app: fastapi.FastAPI,",
            "    blocks: gradio.Blocks,",
            "    path: str,",
            "    gradio_api_url: str | None = None,",
            ") -> fastapi.FastAPI:",
            "    \"\"\"Mount a gradio.Blocks to an existing FastAPI application.",
            "",
            "    Parameters:",
            "        app: The parent FastAPI application.",
            "        blocks: The blocks object we want to mount to the parent app.",
            "        path: The path at which the gradio application will be mounted.",
            "        gradio_api_url: The full url at which the gradio app will run. This is only needed if deploying to Huggingface spaces of if the websocket endpoints of your deployed app are on a different network location than the gradio app. If deploying to spaces, set gradio_api_url to 'http://localhost:7860/'",
            "    Example:",
            "        from fastapi import FastAPI",
            "        import gradio as gr",
            "        app = FastAPI()",
            "        @app.get(\"/\")",
            "        def read_main():",
            "            return {\"message\": \"This is your main app\"}",
            "        io = gr.Interface(lambda x: \"Hello, \" + x + \"!\", \"textbox\", \"textbox\")",
            "        app = gr.mount_gradio_app(app, io, path=\"/gradio\")",
            "        # Then run `uvicorn run:app` from the terminal and navigate to http://localhost:8000/gradio.",
            "    \"\"\"",
            "    blocks.dev_mode = False",
            "    blocks.config = blocks.get_config_file()",
            "    blocks.validate_queue_settings()",
            "    gradio_app = App.create_app(blocks)",
            "",
            "    @app.on_event(\"startup\")",
            "    async def start_queue():",
            "        if gradio_app.get_blocks().enable_queue:",
            "            if gradio_api_url:",
            "                gradio_app.get_blocks()._queue.set_url(gradio_api_url)",
            "            gradio_app.get_blocks().startup_events()",
            "",
            "    app.mount(path, gradio_app)",
            "    return app"
        ],
        "action": [
            "0",
            "0",
            "0",
            "-1",
            "0",
            "-1",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "335": [
                "App",
                "create_app"
            ],
            "338": [
                "App",
                "create_app"
            ],
            "340": [
                "App",
                "create_app"
            ],
            "344": [
                "App",
                "create_app"
            ],
            "345": [
                "App",
                "create_app"
            ],
            "346": [
                "App",
                "create_app"
            ],
            "347": [
                "App",
                "create_app"
            ],
            "348": [
                "App",
                "create_app"
            ],
            "349": [
                "App",
                "create_app"
            ],
            "350": [
                "App",
                "create_app"
            ],
            "351": [
                "App",
                "create_app"
            ],
            "352": [
                "App",
                "create_app"
            ],
            "353": [
                "App",
                "create_app"
            ],
            "354": [
                "App",
                "create_app"
            ],
            "355": [
                "App",
                "create_app"
            ],
            "356": [
                "App",
                "create_app"
            ],
            "357": [
                "App",
                "create_app"
            ],
            "358": [
                "App",
                "create_app"
            ],
            "359": [
                "App",
                "create_app"
            ],
            "360": [
                "App",
                "create_app"
            ],
            "361": [
                "App",
                "create_app"
            ],
            "362": [
                "App",
                "create_app"
            ],
            "363": [
                "App",
                "create_app"
            ],
            "364": [
                "App",
                "create_app"
            ],
            "365": [
                "App",
                "create_app"
            ],
            "366": [
                "App",
                "create_app"
            ],
            "368": [
                "App",
                "create_app"
            ],
            "369": [
                "App",
                "create_app"
            ],
            "370": [
                "App",
                "create_app"
            ],
            "371": [
                "App",
                "create_app"
            ],
            "372": [
                "App",
                "create_app"
            ]
        },
        "addLocation": [
            "gradio.routes.mount_gradio_app",
            "saleor.graphql.core.tests.test_view"
        ]
    },
    "gradio/utils.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 844,
                "afterPatchRowNumber": 844,
                "PatchRowcode": "     True if path_1 is a descendant (i.e. located within) path_2 or if the paths are the"
            },
            "1": {
                "beforePatchRowNumber": 845,
                "afterPatchRowNumber": 845,
                "PatchRowcode": "     same, returns False otherwise."
            },
            "2": {
                "beforePatchRowNumber": 846,
                "afterPatchRowNumber": 846,
                "PatchRowcode": "     Parameters:"
            },
            "3": {
                "beforePatchRowNumber": 847,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path_1: str or Path (can be a file or directory)"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 847,
                "PatchRowcode": "+        path_1: str or Path (should be a file)"
            },
            "5": {
                "beforePatchRowNumber": 848,
                "afterPatchRowNumber": 848,
                "PatchRowcode": "         path_2: str or Path (can be a file or directory)"
            },
            "6": {
                "beforePatchRowNumber": 849,
                "afterPatchRowNumber": 849,
                "PatchRowcode": "     \"\"\""
            },
            "7": {
                "beforePatchRowNumber": 850,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    return (abspath(path_2) in abspath(path_1).parents) or abspath(path_1) == abspath("
            },
            "8": {
                "beforePatchRowNumber": 851,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        path_2"
            },
            "9": {
                "beforePatchRowNumber": 852,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    )"
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 850,
                "PatchRowcode": "+    path_1, path_2 = abspath(path_1), abspath(path_2)"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 851,
                "PatchRowcode": "+    try:"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 852,
                "PatchRowcode": "+        if str(path_1.relative_to(path_2)).startswith(\"..\"):  # prevent path traversal"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 853,
                "PatchRowcode": "+            return False"
            },
            "14": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 854,
                "PatchRowcode": "+    except ValueError:"
            },
            "15": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 855,
                "PatchRowcode": "+        return False"
            },
            "16": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 856,
                "PatchRowcode": "+    return True"
            },
            "17": {
                "beforePatchRowNumber": 853,
                "afterPatchRowNumber": 857,
                "PatchRowcode": " "
            },
            "18": {
                "beforePatchRowNumber": 854,
                "afterPatchRowNumber": 858,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": 855,
                "afterPatchRowNumber": 859,
                "PatchRowcode": " def get_serializer_name(block: Block) -> str | None:"
            }
        },
        "frontPatchFile": [
            "\"\"\" Handy utility functions. \"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import asyncio",
            "import copy",
            "import functools",
            "import inspect",
            "import json",
            "import json.decoder",
            "import os",
            "import pkgutil",
            "import random",
            "import re",
            "import sys",
            "import time",
            "import typing",
            "import warnings",
            "from contextlib import contextmanager",
            "from enum import Enum",
            "from io import BytesIO",
            "from numbers import Number",
            "from pathlib import Path",
            "from typing import (",
            "    TYPE_CHECKING,",
            "    Any,",
            "    Callable,",
            "    Generator,",
            "    TypeVar,",
            "    Union,",
            ")",
            "",
            "import anyio",
            "import httpx",
            "import matplotlib",
            "import requests",
            "from gradio_client.serializing import Serializable",
            "from markdown_it import MarkdownIt",
            "from mdit_py_plugins.dollarmath.index import dollarmath_plugin",
            "from mdit_py_plugins.footnote.index import footnote_plugin",
            "from pydantic import BaseModel, parse_obj_as",
            "",
            "import gradio",
            "from gradio.context import Context",
            "from gradio.strings import en",
            "",
            "if TYPE_CHECKING:  # Only import for type checking (is False at runtime).",
            "    from gradio.blocks import Block, BlockContext",
            "    from gradio.components import Component",
            "",
            "JSON_PATH = os.path.join(os.path.dirname(gradio.__file__), \"launches.json\")",
            "GRADIO_VERSION = (",
            "    (pkgutil.get_data(__name__, \"version.txt\") or b\"\").decode(\"ascii\").strip()",
            ")",
            "",
            "T = TypeVar(\"T\")",
            "",
            "",
            "def colab_check() -> bool:",
            "    \"\"\"",
            "    Check if interface is launching from Google Colab",
            "    :return is_colab (bool): True or False",
            "    \"\"\"",
            "    is_colab = False",
            "    try:  # Check if running interactively using ipython.",
            "        from IPython import get_ipython",
            "",
            "        from_ipynb = get_ipython()",
            "        if \"google.colab\" in str(from_ipynb):",
            "            is_colab = True",
            "    except (ImportError, NameError):",
            "        pass",
            "    return is_colab",
            "",
            "",
            "def kaggle_check() -> bool:",
            "    return bool(",
            "        os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") or os.environ.get(\"GFOOTBALL_DATA_DIR\")",
            "    )",
            "",
            "",
            "def sagemaker_check() -> bool:",
            "    try:",
            "        import boto3  # type: ignore",
            "",
            "        client = boto3.client(\"sts\")",
            "        response = client.get_caller_identity()",
            "        return \"sagemaker\" in response[\"Arn\"].lower()",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def ipython_check() -> bool:",
            "    \"\"\"",
            "    Check if interface is launching from iPython (not colab)",
            "    :return is_ipython (bool): True or False",
            "    \"\"\"",
            "    is_ipython = False",
            "    try:  # Check if running interactively using ipython.",
            "        from IPython import get_ipython",
            "",
            "        if get_ipython() is not None:",
            "            is_ipython = True",
            "    except (ImportError, NameError):",
            "        pass",
            "    return is_ipython",
            "",
            "",
            "def readme_to_html(article: str) -> str:",
            "    try:",
            "        response = requests.get(article, timeout=3)",
            "        if response.status_code == requests.codes.ok:  # pylint: disable=no-member",
            "            article = response.text",
            "    except requests.exceptions.RequestException:",
            "        pass",
            "    return article",
            "",
            "",
            "def show_tip(interface: gradio.Blocks) -> None:",
            "    if interface.show_tips and random.random() < 1.5:",
            "        tip: str = random.choice(en[\"TIPS\"])",
            "        print(f\"Tip: {tip}\")",
            "",
            "",
            "def launch_counter() -> None:",
            "    try:",
            "        if not os.path.exists(JSON_PATH):",
            "            launches = {\"launches\": 1}",
            "            with open(JSON_PATH, \"w+\") as j:",
            "                json.dump(launches, j)",
            "        else:",
            "            with open(JSON_PATH) as j:",
            "                launches = json.load(j)",
            "            launches[\"launches\"] += 1",
            "            if launches[\"launches\"] in [25, 50, 150, 500, 1000]:",
            "                print(en[\"BETA_INVITE\"])",
            "            with open(JSON_PATH, \"w\") as j:",
            "                j.write(json.dumps(launches))",
            "    except Exception:",
            "        pass",
            "",
            "",
            "def get_default_args(func: Callable) -> list[Any]:",
            "    signature = inspect.signature(func)",
            "    return [",
            "        v.default if v.default is not inspect.Parameter.empty else None",
            "        for v in signature.parameters.values()",
            "    ]",
            "",
            "",
            "def assert_configs_are_equivalent_besides_ids(",
            "    config1: dict, config2: dict, root_keys: tuple = (\"mode\",)",
            "):",
            "    \"\"\"Allows you to test if two different Blocks configs produce the same demo.",
            "",
            "    Parameters:",
            "    config1 (dict): nested dict with config from the first Blocks instance",
            "    config2 (dict): nested dict with config from the second Blocks instance",
            "    root_keys (Tuple): an interable consisting of which keys to test for equivalence at",
            "        the root level of the config. By default, only \"mode\" is tested,",
            "        so keys like \"version\" are ignored.",
            "    \"\"\"",
            "    config1 = copy.deepcopy(config1)",
            "    config2 = copy.deepcopy(config2)",
            "",
            "    for key in root_keys:",
            "        assert config1[key] == config2[key], f\"Configs have different: {key}\"",
            "",
            "    assert len(config1[\"components\"]) == len(",
            "        config2[\"components\"]",
            "    ), \"# of components are different\"",
            "",
            "    def assert_same_components(config1_id, config2_id):",
            "        c1 = list(filter(lambda c: c[\"id\"] == config1_id, config1[\"components\"]))[0]",
            "        c2 = list(filter(lambda c: c[\"id\"] == config2_id, config2[\"components\"]))[0]",
            "        c1 = copy.deepcopy(c1)",
            "        c1.pop(\"id\")",
            "        c2 = copy.deepcopy(c2)",
            "        c2.pop(\"id\")",
            "        assert c1 == c2, f\"{c1} does not match {c2}\"",
            "",
            "    def same_children_recursive(children1, chidren2):",
            "        for child1, child2 in zip(children1, chidren2):",
            "            assert_same_components(child1[\"id\"], child2[\"id\"])",
            "            if \"children\" in child1 or \"children\" in child2:",
            "                same_children_recursive(child1[\"children\"], child2[\"children\"])",
            "",
            "    children1 = config1[\"layout\"][\"children\"]",
            "    children2 = config2[\"layout\"][\"children\"]",
            "    same_children_recursive(children1, children2)",
            "",
            "    for d1, d2 in zip(config1[\"dependencies\"], config2[\"dependencies\"]):",
            "        for t1, t2 in zip(d1.pop(\"targets\"), d2.pop(\"targets\")):",
            "            assert_same_components(t1, t2)",
            "        for i1, i2 in zip(d1.pop(\"inputs\"), d2.pop(\"inputs\")):",
            "            assert_same_components(i1, i2)",
            "        for o1, o2 in zip(d1.pop(\"outputs\"), d2.pop(\"outputs\")):",
            "            assert_same_components(o1, o2)",
            "",
            "        assert d1 == d2, f\"{d1} does not match {d2}\"",
            "",
            "    return True",
            "",
            "",
            "def format_ner_list(input_string: str, ner_groups: list[dict[str, str | int]]):",
            "    if len(ner_groups) == 0:",
            "        return [(input_string, None)]",
            "",
            "    output = []",
            "    end = 0",
            "    prev_end = 0",
            "",
            "    for group in ner_groups:",
            "        entity, start, end = group[\"entity_group\"], group[\"start\"], group[\"end\"]",
            "        output.append((input_string[prev_end:start], None))",
            "        output.append((input_string[start:end], entity))",
            "        prev_end = end",
            "",
            "    output.append((input_string[end:], None))",
            "    return output",
            "",
            "",
            "def delete_none(_dict: dict, skip_value: bool = False) -> dict:",
            "    \"\"\"",
            "    Delete keys whose values are None from a dictionary",
            "    \"\"\"",
            "    for key, value in list(_dict.items()):",
            "        if skip_value and key == \"value\":",
            "            continue",
            "        elif value is None:",
            "            del _dict[key]",
            "    return _dict",
            "",
            "",
            "def resolve_singleton(_list: list[Any] | Any) -> Any:",
            "    if len(_list) == 1:",
            "        return _list[0]",
            "    else:",
            "        return _list",
            "",
            "",
            "def component_or_layout_class(cls_name: str) -> type[Component] | type[BlockContext]:",
            "    \"\"\"",
            "    Returns the component, template, or layout class with the given class name, or",
            "    raises a ValueError if not found.",
            "",
            "    Parameters:",
            "    cls_name (str): lower-case string class name of a component",
            "    Returns:",
            "    cls: the component class",
            "    \"\"\"",
            "    import gradio.blocks",
            "    import gradio.components",
            "    import gradio.layouts",
            "    import gradio.templates",
            "",
            "    components = [",
            "        (name, cls)",
            "        for name, cls in gradio.components.__dict__.items()",
            "        if isinstance(cls, type)",
            "    ]",
            "    templates = [",
            "        (name, cls)",
            "        for name, cls in gradio.templates.__dict__.items()",
            "        if isinstance(cls, type)",
            "    ]",
            "    layouts = [",
            "        (name, cls)",
            "        for name, cls in gradio.layouts.__dict__.items()",
            "        if isinstance(cls, type)",
            "    ]",
            "    for name, cls in components + templates + layouts:",
            "        if name.lower() == cls_name.replace(\"_\", \"\") and (",
            "            issubclass(cls, gradio.components.Component)",
            "            or issubclass(cls, gradio.blocks.BlockContext)",
            "        ):",
            "            return cls",
            "    raise ValueError(f\"No such component or layout: {cls_name}\")",
            "",
            "",
            "def run_coro_in_background(func: Callable, *args, **kwargs):",
            "    \"\"\"",
            "    Runs coroutines in background.",
            "",
            "    Warning, be careful to not use this function in other than FastAPI scope, because the event_loop has not started yet.",
            "    You can use it in any scope reached by FastAPI app.",
            "",
            "    correct scope examples: endpoints in routes, Blocks.process_api",
            "    incorrect scope examples: Blocks.launch",
            "",
            "    Use startup_events in routes.py if you need to run a coro in background in Blocks.launch().",
            "",
            "",
            "    Example:",
            "        utils.run_coro_in_background(fn, *args, **kwargs)",
            "",
            "    Args:",
            "        func:",
            "        *args:",
            "        **kwargs:",
            "",
            "    Returns:",
            "",
            "    \"\"\"",
            "    event_loop = asyncio.get_event_loop()",
            "    return event_loop.create_task(func(*args, **kwargs))",
            "",
            "",
            "def run_sync_iterator_async(iterator):",
            "    \"\"\"Helper for yielding StopAsyncIteration from sync iterators.\"\"\"",
            "    try:",
            "        return next(iterator)",
            "    except StopIteration:",
            "        # raise a ValueError here because co-routines can't raise StopIteration themselves",
            "        raise StopAsyncIteration() from None",
            "",
            "",
            "class SyncToAsyncIterator:",
            "    \"\"\"Treat a synchronous iterator as async one.\"\"\"",
            "",
            "    def __init__(self, iterator, limiter) -> None:",
            "        self.iterator = iterator",
            "        self.limiter = limiter",
            "",
            "    def __aiter__(self):",
            "        return self",
            "",
            "    async def __anext__(self):",
            "        return await anyio.to_thread.run_sync(",
            "            run_sync_iterator_async, self.iterator, limiter=self.limiter",
            "        )",
            "",
            "",
            "async def async_iteration(iterator):",
            "    # anext not introduced until 3.10 :(",
            "    return await iterator.__anext__()",
            "",
            "",
            "class AsyncRequest:",
            "    \"\"\"",
            "    The AsyncRequest class is a low-level API that allow you to create asynchronous HTTP requests without a context manager.",
            "    Compared to making calls by using httpx directly, AsyncRequest offers several advantages:",
            "        (1) Includes response validation functionality both using validation models and functions.",
            "        (2) Exceptions are handled silently during the request call, which provides the ability to inspect each one",
            "        request call individually in the case where there are multiple asynchronous request calls and some of them fail.",
            "        (3) Provides HTTP request types with AsyncRequest.Method Enum class for ease of usage",
            "",
            "    AsyncRequest also offers some util functions such as has_exception, is_valid and status to inspect get detailed",
            "    information about executed request call.",
            "",
            "    The basic usage of AsyncRequest is as follows: create a AsyncRequest object with inputs(method, url etc.). Then use it",
            "    with the \"await\" statement, and then you can use util functions to do some post request checks depending on your use-case.",
            "    Finally, call the get_validated_data function to get the response data.",
            "",
            "    You can see example usages in test_utils.py.",
            "    \"\"\"",
            "",
            "    client = httpx.AsyncClient()",
            "",
            "    class Method(str, Enum):",
            "        \"\"\"",
            "        Method is an enumeration class that contains possible types of HTTP request methods.",
            "        \"\"\"",
            "",
            "        ANY = \"*\"",
            "        CONNECT = \"CONNECT\"",
            "        HEAD = \"HEAD\"",
            "        GET = \"GET\"",
            "        DELETE = \"DELETE\"",
            "        OPTIONS = \"OPTIONS\"",
            "        PATCH = \"PATCH\"",
            "        POST = \"POST\"",
            "        PUT = \"PUT\"",
            "        TRACE = \"TRACE\"",
            "",
            "    def __init__(",
            "        self,",
            "        method: Method,",
            "        url: str,",
            "        *,",
            "        validation_model: type[BaseModel] | None = None,",
            "        validation_function: Union[Callable, None] = None,",
            "        exception_type: type[Exception] = Exception,",
            "        raise_for_status: bool = False,",
            "        client: httpx.AsyncClient | None = None,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"",
            "        Initialize the Request instance.",
            "        Args:",
            "            method(Request.Method) : method of the request",
            "            url(str): url of the request",
            "            *",
            "            validation_model(Type[BaseModel]): a pydantic validation class type to use in validation of the response",
            "            validation_function(Callable): a callable instance to use in validation of the response",
            "            exception_class(Type[Exception]): a exception type to throw with its type",
            "            raise_for_status(bool): a flag that determines to raise httpx.Request.raise_for_status() exceptions.",
            "        \"\"\"",
            "        self._exception: Union[Exception, None] = None",
            "        self._status = None",
            "        self._raise_for_status = raise_for_status",
            "        self._validation_model = validation_model",
            "        self._validation_function = validation_function",
            "        self._exception_type = exception_type",
            "        self._validated_data = None",
            "        # Create request",
            "        self._request = self._create_request(method, url, **kwargs)",
            "        self.client_ = client or self.client",
            "",
            "    def __await__(self) -> Generator[None, Any, AsyncRequest]:",
            "        \"\"\"",
            "        Wrap Request's __await__ magic function to create request calls which are executed in one line.",
            "        \"\"\"",
            "        return self.__run().__await__()",
            "",
            "    async def __run(self) -> AsyncRequest:",
            "        \"\"\"",
            "        Manage the request call lifecycle.",
            "        Execute the request by sending it through the client, then check its status.",
            "        Then parse the request into Json format. And then validate it using the provided validation methods.",
            "        If a problem occurs in this sequential process,",
            "        an exception will be raised within the corresponding method, and allowed to be examined.",
            "        Manage the request call lifecycle.",
            "",
            "        Returns:",
            "            Request",
            "        \"\"\"",
            "        try:",
            "            # Send the request and get the response.",
            "            self._response: httpx.Response = await self.client_.send(self._request)",
            "            # Raise for _status",
            "            self._status = self._response.status_code",
            "            if self._raise_for_status:",
            "                self._response.raise_for_status()",
            "            # Parse client response data to JSON",
            "            self._json_response_data = self._response.json()",
            "            # Validate response data",
            "            self._validated_data = self._validate_response_data(",
            "                self._json_response_data",
            "            )",
            "        except Exception as exception:",
            "            # If there is an exception, store it to do further inspections.",
            "            self._exception = self._exception_type(exception)",
            "        return self",
            "",
            "    @staticmethod",
            "    def _create_request(method: Method, url: str, **kwargs) -> httpx.Request:",
            "        \"\"\"",
            "        Create a request. This is a httpx request wrapper function.",
            "        Args:",
            "            method(Request.Method): request method type",
            "            url(str): target url of the request",
            "            **kwargs",
            "        Returns:",
            "            Request",
            "        \"\"\"",
            "        request = httpx.Request(method, url, **kwargs)",
            "        return request",
            "",
            "    def _validate_response_data(self, response):",
            "        \"\"\"",
            "        Validate response using given validation methods. If there is a validation method and response is not valid,",
            "        validation functions will raise an exception for them.",
            "        Args:",
            "            response(ResponseJson): response object",
            "        Returns:",
            "            ResponseJson: Validated Json object.",
            "        \"\"\"",
            "",
            "        # We use raw response as a default value if there is no validation method or response is not valid.",
            "        validated_response = response",
            "",
            "        try:",
            "            # If a validation model is provided, validate response using the validation model.",
            "            if self._validation_model:",
            "                validated_response = self._validate_response_by_model(response)",
            "            # Then, If a validation function is provided, validate response using the validation function.",
            "            if self._validation_function:",
            "                validated_response = self._validate_response_by_validation_function(",
            "                    response",
            "                )",
            "        except Exception as exception:",
            "            # If one of the validation methods does not confirm, raised exception will be silently handled.",
            "            # We assign this exception to classes instance to do further inspections via is_valid function.",
            "            self._exception = exception",
            "",
            "        return validated_response",
            "",
            "    def _validate_response_by_model(self, response) -> BaseModel:",
            "        \"\"\"",
            "        Validate response json using the validation model.",
            "        Args:",
            "            response(ResponseJson): response object",
            "        Returns:",
            "            ResponseJson: Validated Json object.",
            "        \"\"\"",
            "        validated_data = BaseModel()",
            "        if self._validation_model:",
            "            validated_data = parse_obj_as(self._validation_model, response)",
            "        return validated_data",
            "",
            "    def _validate_response_by_validation_function(self, response):",
            "        \"\"\"",
            "        Validate response json using the validation function.",
            "        Args:",
            "            response(ResponseJson): response object",
            "        Returns:",
            "            ResponseJson: Validated Json object.",
            "        \"\"\"",
            "        validated_data = None",
            "",
            "        if self._validation_function:",
            "            validated_data = self._validation_function(response)",
            "",
            "        return validated_data",
            "",
            "    def is_valid(self, raise_exceptions: bool = False) -> bool:",
            "        \"\"\"",
            "        Check response object's validity+. Raise exceptions if raise_exceptions flag is True.",
            "        Args:",
            "            raise_exceptions(bool) : a flag to raise exceptions in this check",
            "        Returns:",
            "            bool: validity of the data",
            "        \"\"\"",
            "        if self.has_exception and self._exception:",
            "            if raise_exceptions:",
            "                raise self._exception",
            "            return False",
            "        else:",
            "            # If there is no exception, that means there is no validation error.",
            "            return True",
            "",
            "    def get_validated_data(self):",
            "        return self._validated_data",
            "",
            "    @property",
            "    def json(self):",
            "        return self._json_response_data",
            "",
            "    @property",
            "    def exception(self):",
            "        return self._exception",
            "",
            "    @property",
            "    def has_exception(self):",
            "        return self.exception is not None",
            "",
            "    @property",
            "    def raise_exceptions(self):",
            "        if self.has_exception and self._exception:",
            "            raise self._exception",
            "",
            "    @property",
            "    def status(self):",
            "        return self._status",
            "",
            "",
            "@contextmanager",
            "def set_directory(path: Path | str):",
            "    \"\"\"Context manager that sets the working directory to the given path.\"\"\"",
            "    origin = Path().absolute()",
            "    try:",
            "        os.chdir(path)",
            "        yield",
            "    finally:",
            "        os.chdir(origin)",
            "",
            "",
            "def sanitize_value_for_csv(value: str | Number) -> str | Number:",
            "    \"\"\"",
            "    Sanitizes a value that is being written to a CSV file to prevent CSV injection attacks.",
            "    Reference: https://owasp.org/www-community/attacks/CSV_Injection",
            "    \"\"\"",
            "    if isinstance(value, Number):",
            "        return value",
            "    unsafe_prefixes = [\"=\", \"+\", \"-\", \"@\", \"\\t\", \"\\n\"]",
            "    unsafe_sequences = [\",=\", \",+\", \",-\", \",@\", \",\\t\", \",\\n\"]",
            "    if any(value.startswith(prefix) for prefix in unsafe_prefixes) or any(",
            "        sequence in value for sequence in unsafe_sequences",
            "    ):",
            "        value = f\"'{value}\"",
            "    return value",
            "",
            "",
            "def sanitize_list_for_csv(values: list[Any]) -> list[Any]:",
            "    \"\"\"",
            "    Sanitizes a list of values (or a list of list of values) that is being written to a",
            "    CSV file to prevent CSV injection attacks.",
            "    \"\"\"",
            "    sanitized_values = []",
            "    for value in values:",
            "        if isinstance(value, list):",
            "            sanitized_value = [sanitize_value_for_csv(v) for v in value]",
            "            sanitized_values.append(sanitized_value)",
            "        else:",
            "            sanitized_value = sanitize_value_for_csv(value)",
            "            sanitized_values.append(sanitized_value)",
            "    return sanitized_values",
            "",
            "",
            "def append_unique_suffix(name: str, list_of_names: list[str]):",
            "    \"\"\"Appends a numerical suffix to `name` so that it does not appear in `list_of_names`.\"\"\"",
            "    set_of_names: set[str] = set(list_of_names)  # for O(1) lookup",
            "    if name not in set_of_names:",
            "        return name",
            "    else:",
            "        suffix_counter = 1",
            "        new_name = f\"{name}_{suffix_counter}\"",
            "        while new_name in set_of_names:",
            "            suffix_counter += 1",
            "            new_name = f\"{name}_{suffix_counter}\"",
            "        return new_name",
            "",
            "",
            "def validate_url(possible_url: str) -> bool:",
            "    headers = {\"User-Agent\": \"gradio (https://gradio.app/; team@gradio.app)\"}",
            "    try:",
            "        head_request = requests.head(possible_url, headers=headers)",
            "        if head_request.status_code == 405:",
            "            return requests.get(possible_url, headers=headers).ok",
            "        return head_request.ok",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_update(val):",
            "    return isinstance(val, dict) and \"update\" in val.get(\"__type__\", \"\")",
            "",
            "",
            "def get_continuous_fn(fn: Callable, every: float) -> Callable:",
            "    def continuous_fn(*args):",
            "        while True:",
            "            output = fn(*args)",
            "            yield output",
            "            time.sleep(every)",
            "",
            "    return continuous_fn",
            "",
            "",
            "async def cancel_tasks(task_ids: set[str]):",
            "    if sys.version_info < (3, 8):",
            "        return None",
            "",
            "    matching_tasks = [",
            "        task for task in asyncio.all_tasks() if task.get_name() in task_ids",
            "    ]",
            "    for task in matching_tasks:",
            "        task.cancel()",
            "    await asyncio.gather(*matching_tasks, return_exceptions=True)",
            "",
            "",
            "def set_task_name(task, session_hash: str, fn_index: int, batch: bool):",
            "    if sys.version_info >= (3, 8) and not (",
            "        batch",
            "    ):  # You shouldn't be able to cancel a task if it's part of a batch",
            "        task.set_name(f\"{session_hash}_{fn_index}\")",
            "",
            "",
            "def get_cancel_function(",
            "    dependencies: list[dict[str, Any]]",
            ") -> tuple[Callable, list[int]]:",
            "    fn_to_comp = {}",
            "    for dep in dependencies:",
            "        if Context.root_block:",
            "            fn_index = next(",
            "                i for i, d in enumerate(Context.root_block.dependencies) if d == dep",
            "            )",
            "            fn_to_comp[fn_index] = [",
            "                Context.root_block.blocks[o] for o in dep[\"outputs\"]",
            "            ]",
            "",
            "    async def cancel(session_hash: str) -> None:",
            "        task_ids = {f\"{session_hash}_{fn}\" for fn in fn_to_comp}",
            "        await cancel_tasks(task_ids)",
            "",
            "    return (",
            "        cancel,",
            "        list(fn_to_comp.keys()),",
            "    )",
            "",
            "",
            "def get_type_hints(fn):",
            "    # Importing gradio with the canonical abbreviation. Used in typing._eval_type.",
            "    import gradio as gr  # noqa: F401",
            "    from gradio import Request  # noqa: F401",
            "",
            "    if inspect.isfunction(fn) or inspect.ismethod(fn):",
            "        pass",
            "    elif callable(fn):",
            "        fn = fn.__call__",
            "    else:",
            "        return {}",
            "",
            "    try:",
            "        return typing.get_type_hints(fn)",
            "    except TypeError:",
            "        # On Python 3.9 or earlier, get_type_hints throws a TypeError if the function",
            "        # has a type annotation that include \"|\". We resort to parsing the signature",
            "        # manually using inspect.signature.",
            "        type_hints = {}",
            "        sig = inspect.signature(fn)",
            "        for name, param in sig.parameters.items():",
            "            if param.annotation is inspect.Parameter.empty:",
            "                continue",
            "            if \"|\" in str(param.annotation):",
            "                continue",
            "            # To convert the string annotation to a class, we use the",
            "            # internal typing._eval_type function. This is not ideal, but",
            "            # it's the only way to do it without eval-ing the string.",
            "            # Since the API is internal, it may change in the future.",
            "            try:",
            "                type_hints[name] = typing._eval_type(  # type: ignore",
            "                    typing.ForwardRef(param.annotation), globals(), locals()",
            "                )",
            "            except (NameError, TypeError):",
            "                pass",
            "        return type_hints",
            "",
            "",
            "def is_special_typed_parameter(name, parameter_types):",
            "    from gradio.helpers import EventData",
            "    from gradio.routes import Request",
            "",
            "    \"\"\"Checks if parameter has a type hint designating it as a gr.Request or gr.EventData\"\"\"",
            "    hint = parameter_types.get(name)",
            "    if not hint:",
            "        return False",
            "    is_request = hint == Request",
            "    is_event_data = inspect.isclass(hint) and issubclass(hint, EventData)",
            "    return is_request or is_event_data",
            "",
            "",
            "def check_function_inputs_match(fn: Callable, inputs: list, inputs_as_dict: bool):",
            "    \"\"\"",
            "    Checks if the input component set matches the function",
            "    Returns: None if valid, a string error message if mismatch",
            "    \"\"\"",
            "",
            "    signature = inspect.signature(fn)",
            "    parameter_types = get_type_hints(fn)",
            "    min_args = 0",
            "    max_args = 0",
            "    infinity = -1",
            "    for name, param in signature.parameters.items():",
            "        has_default = param.default != param.empty",
            "        if param.kind in [param.POSITIONAL_ONLY, param.POSITIONAL_OR_KEYWORD]:",
            "            if not is_special_typed_parameter(name, parameter_types):",
            "                if not has_default:",
            "                    min_args += 1",
            "                max_args += 1",
            "        elif param.kind == param.VAR_POSITIONAL:",
            "            max_args = infinity",
            "        elif param.kind == param.KEYWORD_ONLY and not has_default:",
            "            return f\"Keyword-only args must have default values for function {fn}\"",
            "    arg_count = 1 if inputs_as_dict else len(inputs)",
            "    if min_args == max_args and max_args != arg_count:",
            "        warnings.warn(",
            "            f\"Expected {max_args} arguments for function {fn}, received {arg_count}.\"",
            "        )",
            "    if arg_count < min_args:",
            "        warnings.warn(",
            "            f\"Expected at least {min_args} arguments for function {fn}, received {arg_count}.\"",
            "        )",
            "    if max_args != infinity and arg_count > max_args:",
            "        warnings.warn(",
            "            f\"Expected maximum {max_args} arguments for function {fn}, received {arg_count}.\"",
            "        )",
            "",
            "",
            "class TupleNoPrint(tuple):",
            "    # To remove printing function return in notebook",
            "    def __repr__(self):",
            "        return \"\"",
            "",
            "    def __str__(self):",
            "        return \"\"",
            "",
            "",
            "class MatplotlibBackendMananger:",
            "    def __enter__(self):",
            "        self._original_backend = matplotlib.get_backend()",
            "        matplotlib.use(\"agg\")",
            "",
            "    def __exit__(self, exc_type, exc_val, exc_tb):",
            "        matplotlib.use(self._original_backend)",
            "",
            "",
            "def tex2svg(formula, *args):",
            "    with MatplotlibBackendMananger():",
            "        import matplotlib.pyplot as plt",
            "",
            "        fontsize = 20",
            "        dpi = 300",
            "        plt.rc(\"mathtext\", fontset=\"cm\")",
            "        fig = plt.figure(figsize=(0.01, 0.01))",
            "        fig.text(0, 0, rf\"${formula}$\", fontsize=fontsize)",
            "        output = BytesIO()",
            "        fig.savefig(",
            "            output,",
            "            dpi=dpi,",
            "            transparent=True,",
            "            format=\"svg\",",
            "            bbox_inches=\"tight\",",
            "            pad_inches=0.0,",
            "        )",
            "        plt.close(fig)",
            "        output.seek(0)",
            "        xml_code = output.read().decode(\"utf-8\")",
            "        svg_start = xml_code.index(\"<svg \")",
            "        svg_code = xml_code[svg_start:]",
            "        svg_code = re.sub(r\"<metadata>.*<\\/metadata>\", \"\", svg_code, flags=re.DOTALL)",
            "        svg_code = re.sub(r' width=\"[^\"]+\"', \"\", svg_code)",
            "        height_match = re.search(r'height=\"([\\d.]+)pt\"', svg_code)",
            "        if height_match:",
            "            height = float(height_match.group(1))",
            "            new_height = height / fontsize  # conversion from pt to em",
            "            svg_code = re.sub(",
            "                r'height=\"[\\d.]+pt\"', f'height=\"{new_height}em\"', svg_code",
            "            )",
            "        copy_code = f\"<span style='font-size: 0px'>{formula}</span>\"",
            "    return f\"{copy_code}{svg_code}\"",
            "",
            "",
            "def abspath(path: str | Path) -> Path:",
            "    \"\"\"Returns absolute path of a str or Path path, but does not resolve symlinks.\"\"\"",
            "    path = Path(path)",
            "",
            "    if path.is_absolute():",
            "        return path",
            "",
            "    # recursively check if there is a symlink within the path",
            "    is_symlink = path.is_symlink() or any(",
            "        parent.is_symlink() for parent in path.parents",
            "    )",
            "",
            "    if is_symlink or path == path.resolve():  # in case path couldn't be resolved",
            "        return Path.cwd() / path",
            "    else:",
            "        return path.resolve()",
            "",
            "",
            "def is_in_or_equal(path_1: str | Path, path_2: str | Path):",
            "    \"\"\"",
            "    True if path_1 is a descendant (i.e. located within) path_2 or if the paths are the",
            "    same, returns False otherwise.",
            "    Parameters:",
            "        path_1: str or Path (can be a file or directory)",
            "        path_2: str or Path (can be a file or directory)",
            "    \"\"\"",
            "    return (abspath(path_2) in abspath(path_1).parents) or abspath(path_1) == abspath(",
            "        path_2",
            "    )",
            "",
            "",
            "def get_serializer_name(block: Block) -> str | None:",
            "    if not hasattr(block, \"serialize\"):",
            "        return None",
            "",
            "    def get_class_that_defined_method(meth: Callable):",
            "        # Adapted from: https://stackoverflow.com/a/25959545/5209347",
            "        if isinstance(meth, functools.partial):",
            "            return get_class_that_defined_method(meth.func)",
            "        if inspect.ismethod(meth) or (",
            "            inspect.isbuiltin(meth)",
            "            and getattr(meth, \"__self__\", None) is not None",
            "            and getattr(meth.__self__, \"__class__\", None)",
            "        ):",
            "            for cls in inspect.getmro(meth.__self__.__class__):",
            "                # Find the first serializer defined in gradio_client that",
            "                if issubclass(cls, Serializable) and \"gradio_client\" in cls.__module__:",
            "                    return cls",
            "                if meth.__name__ in cls.__dict__:",
            "                    return cls",
            "            meth = getattr(meth, \"__func__\", meth)  # fallback to __qualname__ parsing",
            "        if inspect.isfunction(meth):",
            "            cls = getattr(",
            "                inspect.getmodule(meth),",
            "                meth.__qualname__.split(\".<locals>\", 1)[0].rsplit(\".\", 1)[0],",
            "                None,",
            "            )",
            "            if isinstance(cls, type):",
            "                return cls",
            "        return getattr(meth, \"__objclass__\", None)",
            "",
            "    cls = get_class_that_defined_method(block.serialize)  # type: ignore",
            "    if cls:",
            "        return cls.__name__",
            "",
            "",
            "def get_markdown_parser() -> MarkdownIt:",
            "    md = (",
            "        MarkdownIt(",
            "            \"js-default\",",
            "            {",
            "                \"linkify\": True,",
            "                \"typographer\": True,",
            "                \"html\": True,",
            "            },",
            "        )",
            "        .use(dollarmath_plugin, renderer=tex2svg, allow_digits=False)",
            "        .use(footnote_plugin)",
            "        .enable(\"table\")",
            "    )",
            "",
            "    # Add target=\"_blank\" to all links. Taken from MarkdownIt docs: https://github.com/executablebooks/markdown-it-py/blob/master/docs/architecture.md",
            "    def render_blank_link(self, tokens, idx, options, env):",
            "        tokens[idx].attrSet(\"target\", \"_blank\")",
            "        return self.renderToken(tokens, idx, options, env)",
            "",
            "    md.add_render_rule(\"link_open\", render_blank_link)",
            "",
            "    return md",
            "",
            "",
            "HTML_TAG_RE = re.compile(\"<.*?>\")",
            "",
            "",
            "def remove_html_tags(raw_html: str | None) -> str:",
            "    return re.sub(HTML_TAG_RE, \"\", raw_html or \"\")"
        ],
        "afterPatchFile": [
            "\"\"\" Handy utility functions. \"\"\"",
            "",
            "from __future__ import annotations",
            "",
            "import asyncio",
            "import copy",
            "import functools",
            "import inspect",
            "import json",
            "import json.decoder",
            "import os",
            "import pkgutil",
            "import random",
            "import re",
            "import sys",
            "import time",
            "import typing",
            "import warnings",
            "from contextlib import contextmanager",
            "from enum import Enum",
            "from io import BytesIO",
            "from numbers import Number",
            "from pathlib import Path",
            "from typing import (",
            "    TYPE_CHECKING,",
            "    Any,",
            "    Callable,",
            "    Generator,",
            "    TypeVar,",
            "    Union,",
            ")",
            "",
            "import anyio",
            "import httpx",
            "import matplotlib",
            "import requests",
            "from gradio_client.serializing import Serializable",
            "from markdown_it import MarkdownIt",
            "from mdit_py_plugins.dollarmath.index import dollarmath_plugin",
            "from mdit_py_plugins.footnote.index import footnote_plugin",
            "from pydantic import BaseModel, parse_obj_as",
            "",
            "import gradio",
            "from gradio.context import Context",
            "from gradio.strings import en",
            "",
            "if TYPE_CHECKING:  # Only import for type checking (is False at runtime).",
            "    from gradio.blocks import Block, BlockContext",
            "    from gradio.components import Component",
            "",
            "JSON_PATH = os.path.join(os.path.dirname(gradio.__file__), \"launches.json\")",
            "GRADIO_VERSION = (",
            "    (pkgutil.get_data(__name__, \"version.txt\") or b\"\").decode(\"ascii\").strip()",
            ")",
            "",
            "T = TypeVar(\"T\")",
            "",
            "",
            "def colab_check() -> bool:",
            "    \"\"\"",
            "    Check if interface is launching from Google Colab",
            "    :return is_colab (bool): True or False",
            "    \"\"\"",
            "    is_colab = False",
            "    try:  # Check if running interactively using ipython.",
            "        from IPython import get_ipython",
            "",
            "        from_ipynb = get_ipython()",
            "        if \"google.colab\" in str(from_ipynb):",
            "            is_colab = True",
            "    except (ImportError, NameError):",
            "        pass",
            "    return is_colab",
            "",
            "",
            "def kaggle_check() -> bool:",
            "    return bool(",
            "        os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") or os.environ.get(\"GFOOTBALL_DATA_DIR\")",
            "    )",
            "",
            "",
            "def sagemaker_check() -> bool:",
            "    try:",
            "        import boto3  # type: ignore",
            "",
            "        client = boto3.client(\"sts\")",
            "        response = client.get_caller_identity()",
            "        return \"sagemaker\" in response[\"Arn\"].lower()",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def ipython_check() -> bool:",
            "    \"\"\"",
            "    Check if interface is launching from iPython (not colab)",
            "    :return is_ipython (bool): True or False",
            "    \"\"\"",
            "    is_ipython = False",
            "    try:  # Check if running interactively using ipython.",
            "        from IPython import get_ipython",
            "",
            "        if get_ipython() is not None:",
            "            is_ipython = True",
            "    except (ImportError, NameError):",
            "        pass",
            "    return is_ipython",
            "",
            "",
            "def readme_to_html(article: str) -> str:",
            "    try:",
            "        response = requests.get(article, timeout=3)",
            "        if response.status_code == requests.codes.ok:  # pylint: disable=no-member",
            "            article = response.text",
            "    except requests.exceptions.RequestException:",
            "        pass",
            "    return article",
            "",
            "",
            "def show_tip(interface: gradio.Blocks) -> None:",
            "    if interface.show_tips and random.random() < 1.5:",
            "        tip: str = random.choice(en[\"TIPS\"])",
            "        print(f\"Tip: {tip}\")",
            "",
            "",
            "def launch_counter() -> None:",
            "    try:",
            "        if not os.path.exists(JSON_PATH):",
            "            launches = {\"launches\": 1}",
            "            with open(JSON_PATH, \"w+\") as j:",
            "                json.dump(launches, j)",
            "        else:",
            "            with open(JSON_PATH) as j:",
            "                launches = json.load(j)",
            "            launches[\"launches\"] += 1",
            "            if launches[\"launches\"] in [25, 50, 150, 500, 1000]:",
            "                print(en[\"BETA_INVITE\"])",
            "            with open(JSON_PATH, \"w\") as j:",
            "                j.write(json.dumps(launches))",
            "    except Exception:",
            "        pass",
            "",
            "",
            "def get_default_args(func: Callable) -> list[Any]:",
            "    signature = inspect.signature(func)",
            "    return [",
            "        v.default if v.default is not inspect.Parameter.empty else None",
            "        for v in signature.parameters.values()",
            "    ]",
            "",
            "",
            "def assert_configs_are_equivalent_besides_ids(",
            "    config1: dict, config2: dict, root_keys: tuple = (\"mode\",)",
            "):",
            "    \"\"\"Allows you to test if two different Blocks configs produce the same demo.",
            "",
            "    Parameters:",
            "    config1 (dict): nested dict with config from the first Blocks instance",
            "    config2 (dict): nested dict with config from the second Blocks instance",
            "    root_keys (Tuple): an interable consisting of which keys to test for equivalence at",
            "        the root level of the config. By default, only \"mode\" is tested,",
            "        so keys like \"version\" are ignored.",
            "    \"\"\"",
            "    config1 = copy.deepcopy(config1)",
            "    config2 = copy.deepcopy(config2)",
            "",
            "    for key in root_keys:",
            "        assert config1[key] == config2[key], f\"Configs have different: {key}\"",
            "",
            "    assert len(config1[\"components\"]) == len(",
            "        config2[\"components\"]",
            "    ), \"# of components are different\"",
            "",
            "    def assert_same_components(config1_id, config2_id):",
            "        c1 = list(filter(lambda c: c[\"id\"] == config1_id, config1[\"components\"]))[0]",
            "        c2 = list(filter(lambda c: c[\"id\"] == config2_id, config2[\"components\"]))[0]",
            "        c1 = copy.deepcopy(c1)",
            "        c1.pop(\"id\")",
            "        c2 = copy.deepcopy(c2)",
            "        c2.pop(\"id\")",
            "        assert c1 == c2, f\"{c1} does not match {c2}\"",
            "",
            "    def same_children_recursive(children1, chidren2):",
            "        for child1, child2 in zip(children1, chidren2):",
            "            assert_same_components(child1[\"id\"], child2[\"id\"])",
            "            if \"children\" in child1 or \"children\" in child2:",
            "                same_children_recursive(child1[\"children\"], child2[\"children\"])",
            "",
            "    children1 = config1[\"layout\"][\"children\"]",
            "    children2 = config2[\"layout\"][\"children\"]",
            "    same_children_recursive(children1, children2)",
            "",
            "    for d1, d2 in zip(config1[\"dependencies\"], config2[\"dependencies\"]):",
            "        for t1, t2 in zip(d1.pop(\"targets\"), d2.pop(\"targets\")):",
            "            assert_same_components(t1, t2)",
            "        for i1, i2 in zip(d1.pop(\"inputs\"), d2.pop(\"inputs\")):",
            "            assert_same_components(i1, i2)",
            "        for o1, o2 in zip(d1.pop(\"outputs\"), d2.pop(\"outputs\")):",
            "            assert_same_components(o1, o2)",
            "",
            "        assert d1 == d2, f\"{d1} does not match {d2}\"",
            "",
            "    return True",
            "",
            "",
            "def format_ner_list(input_string: str, ner_groups: list[dict[str, str | int]]):",
            "    if len(ner_groups) == 0:",
            "        return [(input_string, None)]",
            "",
            "    output = []",
            "    end = 0",
            "    prev_end = 0",
            "",
            "    for group in ner_groups:",
            "        entity, start, end = group[\"entity_group\"], group[\"start\"], group[\"end\"]",
            "        output.append((input_string[prev_end:start], None))",
            "        output.append((input_string[start:end], entity))",
            "        prev_end = end",
            "",
            "    output.append((input_string[end:], None))",
            "    return output",
            "",
            "",
            "def delete_none(_dict: dict, skip_value: bool = False) -> dict:",
            "    \"\"\"",
            "    Delete keys whose values are None from a dictionary",
            "    \"\"\"",
            "    for key, value in list(_dict.items()):",
            "        if skip_value and key == \"value\":",
            "            continue",
            "        elif value is None:",
            "            del _dict[key]",
            "    return _dict",
            "",
            "",
            "def resolve_singleton(_list: list[Any] | Any) -> Any:",
            "    if len(_list) == 1:",
            "        return _list[0]",
            "    else:",
            "        return _list",
            "",
            "",
            "def component_or_layout_class(cls_name: str) -> type[Component] | type[BlockContext]:",
            "    \"\"\"",
            "    Returns the component, template, or layout class with the given class name, or",
            "    raises a ValueError if not found.",
            "",
            "    Parameters:",
            "    cls_name (str): lower-case string class name of a component",
            "    Returns:",
            "    cls: the component class",
            "    \"\"\"",
            "    import gradio.blocks",
            "    import gradio.components",
            "    import gradio.layouts",
            "    import gradio.templates",
            "",
            "    components = [",
            "        (name, cls)",
            "        for name, cls in gradio.components.__dict__.items()",
            "        if isinstance(cls, type)",
            "    ]",
            "    templates = [",
            "        (name, cls)",
            "        for name, cls in gradio.templates.__dict__.items()",
            "        if isinstance(cls, type)",
            "    ]",
            "    layouts = [",
            "        (name, cls)",
            "        for name, cls in gradio.layouts.__dict__.items()",
            "        if isinstance(cls, type)",
            "    ]",
            "    for name, cls in components + templates + layouts:",
            "        if name.lower() == cls_name.replace(\"_\", \"\") and (",
            "            issubclass(cls, gradio.components.Component)",
            "            or issubclass(cls, gradio.blocks.BlockContext)",
            "        ):",
            "            return cls",
            "    raise ValueError(f\"No such component or layout: {cls_name}\")",
            "",
            "",
            "def run_coro_in_background(func: Callable, *args, **kwargs):",
            "    \"\"\"",
            "    Runs coroutines in background.",
            "",
            "    Warning, be careful to not use this function in other than FastAPI scope, because the event_loop has not started yet.",
            "    You can use it in any scope reached by FastAPI app.",
            "",
            "    correct scope examples: endpoints in routes, Blocks.process_api",
            "    incorrect scope examples: Blocks.launch",
            "",
            "    Use startup_events in routes.py if you need to run a coro in background in Blocks.launch().",
            "",
            "",
            "    Example:",
            "        utils.run_coro_in_background(fn, *args, **kwargs)",
            "",
            "    Args:",
            "        func:",
            "        *args:",
            "        **kwargs:",
            "",
            "    Returns:",
            "",
            "    \"\"\"",
            "    event_loop = asyncio.get_event_loop()",
            "    return event_loop.create_task(func(*args, **kwargs))",
            "",
            "",
            "def run_sync_iterator_async(iterator):",
            "    \"\"\"Helper for yielding StopAsyncIteration from sync iterators.\"\"\"",
            "    try:",
            "        return next(iterator)",
            "    except StopIteration:",
            "        # raise a ValueError here because co-routines can't raise StopIteration themselves",
            "        raise StopAsyncIteration() from None",
            "",
            "",
            "class SyncToAsyncIterator:",
            "    \"\"\"Treat a synchronous iterator as async one.\"\"\"",
            "",
            "    def __init__(self, iterator, limiter) -> None:",
            "        self.iterator = iterator",
            "        self.limiter = limiter",
            "",
            "    def __aiter__(self):",
            "        return self",
            "",
            "    async def __anext__(self):",
            "        return await anyio.to_thread.run_sync(",
            "            run_sync_iterator_async, self.iterator, limiter=self.limiter",
            "        )",
            "",
            "",
            "async def async_iteration(iterator):",
            "    # anext not introduced until 3.10 :(",
            "    return await iterator.__anext__()",
            "",
            "",
            "class AsyncRequest:",
            "    \"\"\"",
            "    The AsyncRequest class is a low-level API that allow you to create asynchronous HTTP requests without a context manager.",
            "    Compared to making calls by using httpx directly, AsyncRequest offers several advantages:",
            "        (1) Includes response validation functionality both using validation models and functions.",
            "        (2) Exceptions are handled silently during the request call, which provides the ability to inspect each one",
            "        request call individually in the case where there are multiple asynchronous request calls and some of them fail.",
            "        (3) Provides HTTP request types with AsyncRequest.Method Enum class for ease of usage",
            "",
            "    AsyncRequest also offers some util functions such as has_exception, is_valid and status to inspect get detailed",
            "    information about executed request call.",
            "",
            "    The basic usage of AsyncRequest is as follows: create a AsyncRequest object with inputs(method, url etc.). Then use it",
            "    with the \"await\" statement, and then you can use util functions to do some post request checks depending on your use-case.",
            "    Finally, call the get_validated_data function to get the response data.",
            "",
            "    You can see example usages in test_utils.py.",
            "    \"\"\"",
            "",
            "    client = httpx.AsyncClient()",
            "",
            "    class Method(str, Enum):",
            "        \"\"\"",
            "        Method is an enumeration class that contains possible types of HTTP request methods.",
            "        \"\"\"",
            "",
            "        ANY = \"*\"",
            "        CONNECT = \"CONNECT\"",
            "        HEAD = \"HEAD\"",
            "        GET = \"GET\"",
            "        DELETE = \"DELETE\"",
            "        OPTIONS = \"OPTIONS\"",
            "        PATCH = \"PATCH\"",
            "        POST = \"POST\"",
            "        PUT = \"PUT\"",
            "        TRACE = \"TRACE\"",
            "",
            "    def __init__(",
            "        self,",
            "        method: Method,",
            "        url: str,",
            "        *,",
            "        validation_model: type[BaseModel] | None = None,",
            "        validation_function: Union[Callable, None] = None,",
            "        exception_type: type[Exception] = Exception,",
            "        raise_for_status: bool = False,",
            "        client: httpx.AsyncClient | None = None,",
            "        **kwargs,",
            "    ):",
            "        \"\"\"",
            "        Initialize the Request instance.",
            "        Args:",
            "            method(Request.Method) : method of the request",
            "            url(str): url of the request",
            "            *",
            "            validation_model(Type[BaseModel]): a pydantic validation class type to use in validation of the response",
            "            validation_function(Callable): a callable instance to use in validation of the response",
            "            exception_class(Type[Exception]): a exception type to throw with its type",
            "            raise_for_status(bool): a flag that determines to raise httpx.Request.raise_for_status() exceptions.",
            "        \"\"\"",
            "        self._exception: Union[Exception, None] = None",
            "        self._status = None",
            "        self._raise_for_status = raise_for_status",
            "        self._validation_model = validation_model",
            "        self._validation_function = validation_function",
            "        self._exception_type = exception_type",
            "        self._validated_data = None",
            "        # Create request",
            "        self._request = self._create_request(method, url, **kwargs)",
            "        self.client_ = client or self.client",
            "",
            "    def __await__(self) -> Generator[None, Any, AsyncRequest]:",
            "        \"\"\"",
            "        Wrap Request's __await__ magic function to create request calls which are executed in one line.",
            "        \"\"\"",
            "        return self.__run().__await__()",
            "",
            "    async def __run(self) -> AsyncRequest:",
            "        \"\"\"",
            "        Manage the request call lifecycle.",
            "        Execute the request by sending it through the client, then check its status.",
            "        Then parse the request into Json format. And then validate it using the provided validation methods.",
            "        If a problem occurs in this sequential process,",
            "        an exception will be raised within the corresponding method, and allowed to be examined.",
            "        Manage the request call lifecycle.",
            "",
            "        Returns:",
            "            Request",
            "        \"\"\"",
            "        try:",
            "            # Send the request and get the response.",
            "            self._response: httpx.Response = await self.client_.send(self._request)",
            "            # Raise for _status",
            "            self._status = self._response.status_code",
            "            if self._raise_for_status:",
            "                self._response.raise_for_status()",
            "            # Parse client response data to JSON",
            "            self._json_response_data = self._response.json()",
            "            # Validate response data",
            "            self._validated_data = self._validate_response_data(",
            "                self._json_response_data",
            "            )",
            "        except Exception as exception:",
            "            # If there is an exception, store it to do further inspections.",
            "            self._exception = self._exception_type(exception)",
            "        return self",
            "",
            "    @staticmethod",
            "    def _create_request(method: Method, url: str, **kwargs) -> httpx.Request:",
            "        \"\"\"",
            "        Create a request. This is a httpx request wrapper function.",
            "        Args:",
            "            method(Request.Method): request method type",
            "            url(str): target url of the request",
            "            **kwargs",
            "        Returns:",
            "            Request",
            "        \"\"\"",
            "        request = httpx.Request(method, url, **kwargs)",
            "        return request",
            "",
            "    def _validate_response_data(self, response):",
            "        \"\"\"",
            "        Validate response using given validation methods. If there is a validation method and response is not valid,",
            "        validation functions will raise an exception for them.",
            "        Args:",
            "            response(ResponseJson): response object",
            "        Returns:",
            "            ResponseJson: Validated Json object.",
            "        \"\"\"",
            "",
            "        # We use raw response as a default value if there is no validation method or response is not valid.",
            "        validated_response = response",
            "",
            "        try:",
            "            # If a validation model is provided, validate response using the validation model.",
            "            if self._validation_model:",
            "                validated_response = self._validate_response_by_model(response)",
            "            # Then, If a validation function is provided, validate response using the validation function.",
            "            if self._validation_function:",
            "                validated_response = self._validate_response_by_validation_function(",
            "                    response",
            "                )",
            "        except Exception as exception:",
            "            # If one of the validation methods does not confirm, raised exception will be silently handled.",
            "            # We assign this exception to classes instance to do further inspections via is_valid function.",
            "            self._exception = exception",
            "",
            "        return validated_response",
            "",
            "    def _validate_response_by_model(self, response) -> BaseModel:",
            "        \"\"\"",
            "        Validate response json using the validation model.",
            "        Args:",
            "            response(ResponseJson): response object",
            "        Returns:",
            "            ResponseJson: Validated Json object.",
            "        \"\"\"",
            "        validated_data = BaseModel()",
            "        if self._validation_model:",
            "            validated_data = parse_obj_as(self._validation_model, response)",
            "        return validated_data",
            "",
            "    def _validate_response_by_validation_function(self, response):",
            "        \"\"\"",
            "        Validate response json using the validation function.",
            "        Args:",
            "            response(ResponseJson): response object",
            "        Returns:",
            "            ResponseJson: Validated Json object.",
            "        \"\"\"",
            "        validated_data = None",
            "",
            "        if self._validation_function:",
            "            validated_data = self._validation_function(response)",
            "",
            "        return validated_data",
            "",
            "    def is_valid(self, raise_exceptions: bool = False) -> bool:",
            "        \"\"\"",
            "        Check response object's validity+. Raise exceptions if raise_exceptions flag is True.",
            "        Args:",
            "            raise_exceptions(bool) : a flag to raise exceptions in this check",
            "        Returns:",
            "            bool: validity of the data",
            "        \"\"\"",
            "        if self.has_exception and self._exception:",
            "            if raise_exceptions:",
            "                raise self._exception",
            "            return False",
            "        else:",
            "            # If there is no exception, that means there is no validation error.",
            "            return True",
            "",
            "    def get_validated_data(self):",
            "        return self._validated_data",
            "",
            "    @property",
            "    def json(self):",
            "        return self._json_response_data",
            "",
            "    @property",
            "    def exception(self):",
            "        return self._exception",
            "",
            "    @property",
            "    def has_exception(self):",
            "        return self.exception is not None",
            "",
            "    @property",
            "    def raise_exceptions(self):",
            "        if self.has_exception and self._exception:",
            "            raise self._exception",
            "",
            "    @property",
            "    def status(self):",
            "        return self._status",
            "",
            "",
            "@contextmanager",
            "def set_directory(path: Path | str):",
            "    \"\"\"Context manager that sets the working directory to the given path.\"\"\"",
            "    origin = Path().absolute()",
            "    try:",
            "        os.chdir(path)",
            "        yield",
            "    finally:",
            "        os.chdir(origin)",
            "",
            "",
            "def sanitize_value_for_csv(value: str | Number) -> str | Number:",
            "    \"\"\"",
            "    Sanitizes a value that is being written to a CSV file to prevent CSV injection attacks.",
            "    Reference: https://owasp.org/www-community/attacks/CSV_Injection",
            "    \"\"\"",
            "    if isinstance(value, Number):",
            "        return value",
            "    unsafe_prefixes = [\"=\", \"+\", \"-\", \"@\", \"\\t\", \"\\n\"]",
            "    unsafe_sequences = [\",=\", \",+\", \",-\", \",@\", \",\\t\", \",\\n\"]",
            "    if any(value.startswith(prefix) for prefix in unsafe_prefixes) or any(",
            "        sequence in value for sequence in unsafe_sequences",
            "    ):",
            "        value = f\"'{value}\"",
            "    return value",
            "",
            "",
            "def sanitize_list_for_csv(values: list[Any]) -> list[Any]:",
            "    \"\"\"",
            "    Sanitizes a list of values (or a list of list of values) that is being written to a",
            "    CSV file to prevent CSV injection attacks.",
            "    \"\"\"",
            "    sanitized_values = []",
            "    for value in values:",
            "        if isinstance(value, list):",
            "            sanitized_value = [sanitize_value_for_csv(v) for v in value]",
            "            sanitized_values.append(sanitized_value)",
            "        else:",
            "            sanitized_value = sanitize_value_for_csv(value)",
            "            sanitized_values.append(sanitized_value)",
            "    return sanitized_values",
            "",
            "",
            "def append_unique_suffix(name: str, list_of_names: list[str]):",
            "    \"\"\"Appends a numerical suffix to `name` so that it does not appear in `list_of_names`.\"\"\"",
            "    set_of_names: set[str] = set(list_of_names)  # for O(1) lookup",
            "    if name not in set_of_names:",
            "        return name",
            "    else:",
            "        suffix_counter = 1",
            "        new_name = f\"{name}_{suffix_counter}\"",
            "        while new_name in set_of_names:",
            "            suffix_counter += 1",
            "            new_name = f\"{name}_{suffix_counter}\"",
            "        return new_name",
            "",
            "",
            "def validate_url(possible_url: str) -> bool:",
            "    headers = {\"User-Agent\": \"gradio (https://gradio.app/; team@gradio.app)\"}",
            "    try:",
            "        head_request = requests.head(possible_url, headers=headers)",
            "        if head_request.status_code == 405:",
            "            return requests.get(possible_url, headers=headers).ok",
            "        return head_request.ok",
            "    except Exception:",
            "        return False",
            "",
            "",
            "def is_update(val):",
            "    return isinstance(val, dict) and \"update\" in val.get(\"__type__\", \"\")",
            "",
            "",
            "def get_continuous_fn(fn: Callable, every: float) -> Callable:",
            "    def continuous_fn(*args):",
            "        while True:",
            "            output = fn(*args)",
            "            yield output",
            "            time.sleep(every)",
            "",
            "    return continuous_fn",
            "",
            "",
            "async def cancel_tasks(task_ids: set[str]):",
            "    if sys.version_info < (3, 8):",
            "        return None",
            "",
            "    matching_tasks = [",
            "        task for task in asyncio.all_tasks() if task.get_name() in task_ids",
            "    ]",
            "    for task in matching_tasks:",
            "        task.cancel()",
            "    await asyncio.gather(*matching_tasks, return_exceptions=True)",
            "",
            "",
            "def set_task_name(task, session_hash: str, fn_index: int, batch: bool):",
            "    if sys.version_info >= (3, 8) and not (",
            "        batch",
            "    ):  # You shouldn't be able to cancel a task if it's part of a batch",
            "        task.set_name(f\"{session_hash}_{fn_index}\")",
            "",
            "",
            "def get_cancel_function(",
            "    dependencies: list[dict[str, Any]]",
            ") -> tuple[Callable, list[int]]:",
            "    fn_to_comp = {}",
            "    for dep in dependencies:",
            "        if Context.root_block:",
            "            fn_index = next(",
            "                i for i, d in enumerate(Context.root_block.dependencies) if d == dep",
            "            )",
            "            fn_to_comp[fn_index] = [",
            "                Context.root_block.blocks[o] for o in dep[\"outputs\"]",
            "            ]",
            "",
            "    async def cancel(session_hash: str) -> None:",
            "        task_ids = {f\"{session_hash}_{fn}\" for fn in fn_to_comp}",
            "        await cancel_tasks(task_ids)",
            "",
            "    return (",
            "        cancel,",
            "        list(fn_to_comp.keys()),",
            "    )",
            "",
            "",
            "def get_type_hints(fn):",
            "    # Importing gradio with the canonical abbreviation. Used in typing._eval_type.",
            "    import gradio as gr  # noqa: F401",
            "    from gradio import Request  # noqa: F401",
            "",
            "    if inspect.isfunction(fn) or inspect.ismethod(fn):",
            "        pass",
            "    elif callable(fn):",
            "        fn = fn.__call__",
            "    else:",
            "        return {}",
            "",
            "    try:",
            "        return typing.get_type_hints(fn)",
            "    except TypeError:",
            "        # On Python 3.9 or earlier, get_type_hints throws a TypeError if the function",
            "        # has a type annotation that include \"|\". We resort to parsing the signature",
            "        # manually using inspect.signature.",
            "        type_hints = {}",
            "        sig = inspect.signature(fn)",
            "        for name, param in sig.parameters.items():",
            "            if param.annotation is inspect.Parameter.empty:",
            "                continue",
            "            if \"|\" in str(param.annotation):",
            "                continue",
            "            # To convert the string annotation to a class, we use the",
            "            # internal typing._eval_type function. This is not ideal, but",
            "            # it's the only way to do it without eval-ing the string.",
            "            # Since the API is internal, it may change in the future.",
            "            try:",
            "                type_hints[name] = typing._eval_type(  # type: ignore",
            "                    typing.ForwardRef(param.annotation), globals(), locals()",
            "                )",
            "            except (NameError, TypeError):",
            "                pass",
            "        return type_hints",
            "",
            "",
            "def is_special_typed_parameter(name, parameter_types):",
            "    from gradio.helpers import EventData",
            "    from gradio.routes import Request",
            "",
            "    \"\"\"Checks if parameter has a type hint designating it as a gr.Request or gr.EventData\"\"\"",
            "    hint = parameter_types.get(name)",
            "    if not hint:",
            "        return False",
            "    is_request = hint == Request",
            "    is_event_data = inspect.isclass(hint) and issubclass(hint, EventData)",
            "    return is_request or is_event_data",
            "",
            "",
            "def check_function_inputs_match(fn: Callable, inputs: list, inputs_as_dict: bool):",
            "    \"\"\"",
            "    Checks if the input component set matches the function",
            "    Returns: None if valid, a string error message if mismatch",
            "    \"\"\"",
            "",
            "    signature = inspect.signature(fn)",
            "    parameter_types = get_type_hints(fn)",
            "    min_args = 0",
            "    max_args = 0",
            "    infinity = -1",
            "    for name, param in signature.parameters.items():",
            "        has_default = param.default != param.empty",
            "        if param.kind in [param.POSITIONAL_ONLY, param.POSITIONAL_OR_KEYWORD]:",
            "            if not is_special_typed_parameter(name, parameter_types):",
            "                if not has_default:",
            "                    min_args += 1",
            "                max_args += 1",
            "        elif param.kind == param.VAR_POSITIONAL:",
            "            max_args = infinity",
            "        elif param.kind == param.KEYWORD_ONLY and not has_default:",
            "            return f\"Keyword-only args must have default values for function {fn}\"",
            "    arg_count = 1 if inputs_as_dict else len(inputs)",
            "    if min_args == max_args and max_args != arg_count:",
            "        warnings.warn(",
            "            f\"Expected {max_args} arguments for function {fn}, received {arg_count}.\"",
            "        )",
            "    if arg_count < min_args:",
            "        warnings.warn(",
            "            f\"Expected at least {min_args} arguments for function {fn}, received {arg_count}.\"",
            "        )",
            "    if max_args != infinity and arg_count > max_args:",
            "        warnings.warn(",
            "            f\"Expected maximum {max_args} arguments for function {fn}, received {arg_count}.\"",
            "        )",
            "",
            "",
            "class TupleNoPrint(tuple):",
            "    # To remove printing function return in notebook",
            "    def __repr__(self):",
            "        return \"\"",
            "",
            "    def __str__(self):",
            "        return \"\"",
            "",
            "",
            "class MatplotlibBackendMananger:",
            "    def __enter__(self):",
            "        self._original_backend = matplotlib.get_backend()",
            "        matplotlib.use(\"agg\")",
            "",
            "    def __exit__(self, exc_type, exc_val, exc_tb):",
            "        matplotlib.use(self._original_backend)",
            "",
            "",
            "def tex2svg(formula, *args):",
            "    with MatplotlibBackendMananger():",
            "        import matplotlib.pyplot as plt",
            "",
            "        fontsize = 20",
            "        dpi = 300",
            "        plt.rc(\"mathtext\", fontset=\"cm\")",
            "        fig = plt.figure(figsize=(0.01, 0.01))",
            "        fig.text(0, 0, rf\"${formula}$\", fontsize=fontsize)",
            "        output = BytesIO()",
            "        fig.savefig(",
            "            output,",
            "            dpi=dpi,",
            "            transparent=True,",
            "            format=\"svg\",",
            "            bbox_inches=\"tight\",",
            "            pad_inches=0.0,",
            "        )",
            "        plt.close(fig)",
            "        output.seek(0)",
            "        xml_code = output.read().decode(\"utf-8\")",
            "        svg_start = xml_code.index(\"<svg \")",
            "        svg_code = xml_code[svg_start:]",
            "        svg_code = re.sub(r\"<metadata>.*<\\/metadata>\", \"\", svg_code, flags=re.DOTALL)",
            "        svg_code = re.sub(r' width=\"[^\"]+\"', \"\", svg_code)",
            "        height_match = re.search(r'height=\"([\\d.]+)pt\"', svg_code)",
            "        if height_match:",
            "            height = float(height_match.group(1))",
            "            new_height = height / fontsize  # conversion from pt to em",
            "            svg_code = re.sub(",
            "                r'height=\"[\\d.]+pt\"', f'height=\"{new_height}em\"', svg_code",
            "            )",
            "        copy_code = f\"<span style='font-size: 0px'>{formula}</span>\"",
            "    return f\"{copy_code}{svg_code}\"",
            "",
            "",
            "def abspath(path: str | Path) -> Path:",
            "    \"\"\"Returns absolute path of a str or Path path, but does not resolve symlinks.\"\"\"",
            "    path = Path(path)",
            "",
            "    if path.is_absolute():",
            "        return path",
            "",
            "    # recursively check if there is a symlink within the path",
            "    is_symlink = path.is_symlink() or any(",
            "        parent.is_symlink() for parent in path.parents",
            "    )",
            "",
            "    if is_symlink or path == path.resolve():  # in case path couldn't be resolved",
            "        return Path.cwd() / path",
            "    else:",
            "        return path.resolve()",
            "",
            "",
            "def is_in_or_equal(path_1: str | Path, path_2: str | Path):",
            "    \"\"\"",
            "    True if path_1 is a descendant (i.e. located within) path_2 or if the paths are the",
            "    same, returns False otherwise.",
            "    Parameters:",
            "        path_1: str or Path (should be a file)",
            "        path_2: str or Path (can be a file or directory)",
            "    \"\"\"",
            "    path_1, path_2 = abspath(path_1), abspath(path_2)",
            "    try:",
            "        if str(path_1.relative_to(path_2)).startswith(\"..\"):  # prevent path traversal",
            "            return False",
            "    except ValueError:",
            "        return False",
            "    return True",
            "",
            "",
            "def get_serializer_name(block: Block) -> str | None:",
            "    if not hasattr(block, \"serialize\"):",
            "        return None",
            "",
            "    def get_class_that_defined_method(meth: Callable):",
            "        # Adapted from: https://stackoverflow.com/a/25959545/5209347",
            "        if isinstance(meth, functools.partial):",
            "            return get_class_that_defined_method(meth.func)",
            "        if inspect.ismethod(meth) or (",
            "            inspect.isbuiltin(meth)",
            "            and getattr(meth, \"__self__\", None) is not None",
            "            and getattr(meth.__self__, \"__class__\", None)",
            "        ):",
            "            for cls in inspect.getmro(meth.__self__.__class__):",
            "                # Find the first serializer defined in gradio_client that",
            "                if issubclass(cls, Serializable) and \"gradio_client\" in cls.__module__:",
            "                    return cls",
            "                if meth.__name__ in cls.__dict__:",
            "                    return cls",
            "            meth = getattr(meth, \"__func__\", meth)  # fallback to __qualname__ parsing",
            "        if inspect.isfunction(meth):",
            "            cls = getattr(",
            "                inspect.getmodule(meth),",
            "                meth.__qualname__.split(\".<locals>\", 1)[0].rsplit(\".\", 1)[0],",
            "                None,",
            "            )",
            "            if isinstance(cls, type):",
            "                return cls",
            "        return getattr(meth, \"__objclass__\", None)",
            "",
            "    cls = get_class_that_defined_method(block.serialize)  # type: ignore",
            "    if cls:",
            "        return cls.__name__",
            "",
            "",
            "def get_markdown_parser() -> MarkdownIt:",
            "    md = (",
            "        MarkdownIt(",
            "            \"js-default\",",
            "            {",
            "                \"linkify\": True,",
            "                \"typographer\": True,",
            "                \"html\": True,",
            "            },",
            "        )",
            "        .use(dollarmath_plugin, renderer=tex2svg, allow_digits=False)",
            "        .use(footnote_plugin)",
            "        .enable(\"table\")",
            "    )",
            "",
            "    # Add target=\"_blank\" to all links. Taken from MarkdownIt docs: https://github.com/executablebooks/markdown-it-py/blob/master/docs/architecture.md",
            "    def render_blank_link(self, tokens, idx, options, env):",
            "        tokens[idx].attrSet(\"target\", \"_blank\")",
            "        return self.renderToken(tokens, idx, options, env)",
            "",
            "    md.add_render_rule(\"link_open\", render_blank_link)",
            "",
            "    return md",
            "",
            "",
            "HTML_TAG_RE = re.compile(\"<.*?>\")",
            "",
            "",
            "def remove_html_tags(raw_html: str | None) -> str:",
            "    return re.sub(HTML_TAG_RE, \"\", raw_html or \"\")"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "847": [
                "is_in_or_equal"
            ],
            "850": [
                "is_in_or_equal"
            ],
            "851": [
                "is_in_or_equal"
            ],
            "852": [
                "is_in_or_equal"
            ]
        },
        "addLocation": []
    }
}