{
    "aim/ext/transport/client.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 32,
                "afterPatchRowNumber": 32,
                "PatchRowcode": " class Client:"
            },
            "1": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "     _thread_local = threading.local()"
            },
            "2": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " "
            },
            "3": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    _queue = RequestQueue("
            },
            "4": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        'remote_tracker',"
            },
            "5": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        max_queue_memory=os.getenv(AIM_CLIENT_QUEUE_MAX_MEMORY, 1024 * 1024 * 1024),"
            },
            "6": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        retry_count=DEFAULT_RETRY_COUNT,"
            },
            "7": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        retry_interval=DEFAULT_RETRY_INTERVAL"
            },
            "8": {
                "beforePatchRowNumber": 40,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    )"
            },
            "9": {
                "beforePatchRowNumber": 41,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "10": {
                "beforePatchRowNumber": 42,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "     def __init__(self, remote_path: str):"
            },
            "11": {
                "beforePatchRowNumber": 43,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        # temporary workaround for M1 build"
            },
            "12": {
                "beforePatchRowNumber": 44,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-"
            },
            "13": {
                "beforePatchRowNumber": 45,
                "afterPatchRowNumber": 36,
                "PatchRowcode": "         self._id = str(uuid.uuid4())"
            },
            "14": {
                "beforePatchRowNumber": 46,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "         if remote_path.endswith('/'):"
            },
            "15": {
                "beforePatchRowNumber": 47,
                "afterPatchRowNumber": 38,
                "PatchRowcode": "             remote_path = remote_path[:-1]"
            },
            "16": {
                "beforePatchRowNumber": 58,
                "afterPatchRowNumber": 49,
                "PatchRowcode": "         self._tracking_endpoint = f'{self.remote_path}/tracking'"
            },
            "17": {
                "beforePatchRowNumber": 59,
                "afterPatchRowNumber": 50,
                "PatchRowcode": "         self.connect()"
            },
            "18": {
                "beforePatchRowNumber": 60,
                "afterPatchRowNumber": 51,
                "PatchRowcode": " "
            },
            "19": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 52,
                "PatchRowcode": "+        self._queue = RequestQueue("
            },
            "20": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 53,
                "PatchRowcode": "+            f'remote_tracker_{self._id}',"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 54,
                "PatchRowcode": "+            max_queue_memory=os.getenv(AIM_CLIENT_QUEUE_MAX_MEMORY, 1024 * 1024 * 1024),"
            },
            "22": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 55,
                "PatchRowcode": "+            retry_count=DEFAULT_RETRY_COUNT,"
            },
            "23": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 56,
                "PatchRowcode": "+            retry_interval=DEFAULT_RETRY_INTERVAL"
            },
            "24": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 57,
                "PatchRowcode": "+        )"
            },
            "25": {
                "beforePatchRowNumber": 61,
                "afterPatchRowNumber": 58,
                "PatchRowcode": "         self._heartbeat_sender = HeartbeatSender(self)"
            },
            "26": {
                "beforePatchRowNumber": 62,
                "afterPatchRowNumber": 59,
                "PatchRowcode": "         self._heartbeat_sender.start()"
            },
            "27": {
                "beforePatchRowNumber": 63,
                "afterPatchRowNumber": 60,
                "PatchRowcode": "         self._thread_local.atomic_instructions = {}"
            }
        },
        "frontPatchFile": [
            "import requests",
            "import base64",
            "import logging",
            "import os",
            "import threading",
            "import uuid",
            "import weakref",
            "",
            "from copy import deepcopy",
            "from typing import Tuple",
            "from websockets.sync.client import connect",
            "",
            "from aim.ext.transport.utils import handle_exception",
            "from aim.ext.transport.message_utils import (",
            "    raise_exception,",
            "    pack_args,",
            "    unpack_stream,",
            "    unpack_args,",
            "    encode_tree,",
            "    decode_tree",
            ")",
            "from aim.ext.transport.request_queue import RequestQueue",
            "from aim.ext.transport.heartbeat import HeartbeatSender",
            "",
            "AIM_CLIENT_QUEUE_MAX_MEMORY = '__AIM_CLIENT_QUEUE_MAX_MEMORY__'",
            "DEFAULT_RETRY_INTERVAL = 0.1  # 100 ms",
            "DEFAULT_RETRY_COUNT = 2",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class Client:",
            "    _thread_local = threading.local()",
            "",
            "    _queue = RequestQueue(",
            "        'remote_tracker',",
            "        max_queue_memory=os.getenv(AIM_CLIENT_QUEUE_MAX_MEMORY, 1024 * 1024 * 1024),",
            "        retry_count=DEFAULT_RETRY_COUNT,",
            "        retry_interval=DEFAULT_RETRY_INTERVAL",
            "    )",
            "",
            "    def __init__(self, remote_path: str):",
            "        # temporary workaround for M1 build",
            "",
            "        self._id = str(uuid.uuid4())",
            "        if remote_path.endswith('/'):",
            "            remote_path = remote_path[:-1]",
            "        self._remote_path = remote_path",
            "",
            "        self._http_protocol = 'http://'",
            "        self._ws_protocol = 'ws://'",
            "        self.request_headers = {}",
            "        self.protocol_probe()",
            "",
            "        self._resource_pool = weakref.WeakValueDictionary()",
            "",
            "        self._client_endpoint = f'{self.remote_path}/client'",
            "        self._tracking_endpoint = f'{self.remote_path}/tracking'",
            "        self.connect()",
            "",
            "        self._heartbeat_sender = HeartbeatSender(self)",
            "        self._heartbeat_sender.start()",
            "        self._thread_local.atomic_instructions = {}",
            "        self._ws = None",
            "",
            "    def protocol_probe(self):",
            "        endpoint = f'http://{self.remote_path}/status/'",
            "        try:",
            "            response = requests.get(endpoint, headers=self.request_headers)",
            "            if response.status_code == 200:",
            "                if response.url.startswith('https://'):",
            "                    self._http_protocol = 'https://'",
            "                    self._ws_protocol = 'wss://'",
            "                    return",
            "        except Exception:",
            "            pass",
            "",
            "        endpoint = f'https://{self.remote_path}/status/'",
            "        try:",
            "            response = requests.get(endpoint, headers=self.request_headers)",
            "            if response.status_code == 200:",
            "                self._http_protocol = 'https://'",
            "                self._ws_protocol = 'wss://'",
            "        except Exception:",
            "            pass",
            "",
            "    def reinitialize_resource(self, handler):",
            "        # write some request to get a resource on server side with an already given handler",
            "        resource = self._resource_pool[handler]",
            "        self.get_resource_handler(resource, resource.resource_type, handler, resource.init_args)",
            "",
            "    def _reinitialize_all_resources(self):",
            "        handlers_list = list(self._resource_pool.keys())",
            "        for handler in handlers_list:",
            "            self.reinitialize_resource(handler)",
            "",
            "    @handle_exception(requests.ConnectionError,",
            "                      error_message='Failed to connect to Aim Server. Have you forgot to run `aim server` command?')",
            "    def _check_remote_version_compatibility(self):",
            "        from aim.__version__ import __version__ as client_version",
            "",
            "        error_message_template = 'The Aim Remote tracking server version ({}) '\\",
            "                                 'is not compatible with the Aim client version ({}).'\\",
            "                                 'Please upgrade either the Aim Client or the Aim Remote.'",
            "",
            "        warning_message_template = 'The Aim Remote tracking server version ({}) ' \\",
            "                                   'and the Aim client version ({}) do not match.' \\",
            "                                   'Consider upgrading either the client or remote tracking server.'",
            "",
            "        remote_version = self.get_version()",
            "",
            "        # server doesn't yet have the `get_version()` method implemented",
            "        if remote_version == '<3.19.0':",
            "            RuntimeError(error_message_template.format(remote_version, client_version))",
            "",
            "        # compare versions",
            "        if client_version == remote_version:",
            "            return",
            "",
            "        # if the server has a newer version always force to upgrade the client",
            "        if client_version < remote_version:",
            "            raise RuntimeError(error_message_template.format(remote_version, client_version))",
            "",
            "        # for other mismatching versions throw a warning for now",
            "        logger.warning(warning_message_template.format(remote_version, client_version))",
            "        # further incompatibility list will be added manually",
            "",
            "    def client_heartbeat(self):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/heartbeat/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        return response",
            "",
            "    @handle_exception(requests.ConnectionError,",
            "                      error_message='Failed to connect to Aim Server. Have you forgot to run `aim server` command?')",
            "    def connect(self):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/connect/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        return response",
            "",
            "    def reconnect(self):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/reconnect/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        self.refresh_ws()",
            "        self._reinitialize_all_resources()",
            "",
            "        return response",
            "",
            "    def disconnect(self):",
            "        self._heartbeat_sender.stop()",
            "        if self._ws:",
            "            self._ws.close()",
            "",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/disconnect/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        return response",
            "",
            "    def get_version(self,):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/get-version/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code == 404:",
            "            return '<3.19.0'",
            "        if response.status_code == 400:",
            "            raise_exception(response_json.get('exception'))",
            "        return response_json.get('version')",
            "",
            "    def get_resource_handler(self, resource, resource_type, handler='', args=()):",
            "        endpoint = f'{self._http_protocol}{self._tracking_endpoint}/{self.uri}/get-resource/'",
            "",
            "        request_data = {",
            "            'resource_handler': handler,",
            "            'resource_type': resource_type,",
            "            'args': base64.b64encode(args).decode()",
            "        }",
            "",
            "        response = requests.post(endpoint, json=request_data, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code == 400:",
            "            raise_exception(response_json.get('exception'))",
            "        elif response.status_code != 200:",
            "            raise (Exception(response_json))",
            "",
            "        handler = response_json.get('handler')",
            "        self._resource_pool[handler] = resource",
            "",
            "        return handler",
            "",
            "    def release_resource(self, queue_id, resource_handler):",
            "        endpoint = f'{self._http_protocol}{self._tracking_endpoint}/{self.uri}/release-resource/{resource_handler}/'",
            "        if queue_id != -1:",
            "            self.get_queue().wait_for_finish()",
            "",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code == 400:",
            "            raise_exception(response_json.get('exception'))",
            "",
            "        del self._resource_pool[resource_handler]",
            "",
            "    def run_instruction(self, queue_id, resource, method, args=(), is_write_only=False):",
            "        args = deepcopy(args)",
            "",
            "        # self._thread_local can be empty in the 'clean up' phase.",
            "",
            "        if is_write_only:",
            "            assert queue_id != -1",
            "            if getattr(self._thread_local, 'atomic_instructions', None) is not None and \\",
            "                    self._thread_local.atomic_instructions.get(queue_id, None) is not None:",
            "                self._thread_local.atomic_instructions[queue_id].append((resource, method, args))",
            "                return",
            "",
            "            self.get_queue().register_task(",
            "                self,",
            "                self._run_write_instructions, list(encode_tree([(resource, method, args)], strict=False)))",
            "            return",
            "",
            "        return self._run_read_instructions(queue_id, resource, method, args)",
            "",
            "    def _run_read_instructions(self, queue_id, resource, method, args):",
            "        endpoint = f'{self._http_protocol}{self._tracking_endpoint}/{self.uri}/read-instruction/'",
            "",
            "        request_data = {",
            "            'resource_handler': resource,",
            "            'method_name': method,",
            "            'args': base64.b64encode(pack_args(encode_tree(args))).decode()",
            "        }",
            "",
            "        if queue_id != -1:",
            "            self.get_queue().wait_for_finish()",
            "",
            "        response = requests.post(endpoint, json=request_data, stream=True, headers=self.request_headers)",
            "",
            "        if response.status_code == 400:",
            "            raise_exception(response.json().get('exception'))",
            "        return decode_tree(unpack_stream(response.iter_content(chunk_size=None)))",
            "",
            "    def _run_write_instructions(self, instructions: [Tuple[bytes, bytes]]):",
            "        msg = pack_args(iter(instructions))",
            "",
            "        self.ws.send(msg)",
            "",
            "        response = self.ws.recv()",
            "        if response == b'OK':",
            "            return",
            "",
            "        response_json = decode_tree(unpack_args(response))",
            "        raise_exception(response_json)",
            "",
            "    def start_instructions_batch(self, hash_):",
            "        if getattr(self._thread_local, 'atomic_instructions', None) is None:",
            "            self._thread_local.atomic_instructions = {}",
            "        self._thread_local.atomic_instructions[hash_] = []",
            "",
            "    def flush_instructions_batch(self, hash_):",
            "        if self._thread_local.atomic_instructions.get(hash_) is None:",
            "            return",
            "",
            "        self.get_queue().register_task(",
            "            self,",
            "            self._run_write_instructions, list(encode_tree(self._thread_local.atomic_instructions[hash_])))",
            "        del self._thread_local.atomic_instructions[hash_]",
            "",
            "    def refresh_ws(self):",
            "        self._ws = connect(f'{self._ws_protocol}{self._tracking_endpoint}/{self.uri}/write-instruction/')",
            "",
            "    @property",
            "    def ws(self):",
            "        if self._ws is None:",
            "            self._ws = connect(f'{self._ws_protocol}{self._tracking_endpoint}/{self.uri}/write-instruction/',",
            "                               additional_headers=self.request_headers)",
            "",
            "        return self._ws",
            "",
            "    @property",
            "    def uri(self):",
            "        return self._id",
            "",
            "    @property",
            "    def remote_path(self):",
            "        return self._remote_path",
            "",
            "    def get_queue(self):",
            "        return self._queue"
        ],
        "afterPatchFile": [
            "import requests",
            "import base64",
            "import logging",
            "import os",
            "import threading",
            "import uuid",
            "import weakref",
            "",
            "from copy import deepcopy",
            "from typing import Tuple",
            "from websockets.sync.client import connect",
            "",
            "from aim.ext.transport.utils import handle_exception",
            "from aim.ext.transport.message_utils import (",
            "    raise_exception,",
            "    pack_args,",
            "    unpack_stream,",
            "    unpack_args,",
            "    encode_tree,",
            "    decode_tree",
            ")",
            "from aim.ext.transport.request_queue import RequestQueue",
            "from aim.ext.transport.heartbeat import HeartbeatSender",
            "",
            "AIM_CLIENT_QUEUE_MAX_MEMORY = '__AIM_CLIENT_QUEUE_MAX_MEMORY__'",
            "DEFAULT_RETRY_INTERVAL = 0.1  # 100 ms",
            "DEFAULT_RETRY_COUNT = 2",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class Client:",
            "    _thread_local = threading.local()",
            "",
            "    def __init__(self, remote_path: str):",
            "        self._id = str(uuid.uuid4())",
            "        if remote_path.endswith('/'):",
            "            remote_path = remote_path[:-1]",
            "        self._remote_path = remote_path",
            "",
            "        self._http_protocol = 'http://'",
            "        self._ws_protocol = 'ws://'",
            "        self.request_headers = {}",
            "        self.protocol_probe()",
            "",
            "        self._resource_pool = weakref.WeakValueDictionary()",
            "",
            "        self._client_endpoint = f'{self.remote_path}/client'",
            "        self._tracking_endpoint = f'{self.remote_path}/tracking'",
            "        self.connect()",
            "",
            "        self._queue = RequestQueue(",
            "            f'remote_tracker_{self._id}',",
            "            max_queue_memory=os.getenv(AIM_CLIENT_QUEUE_MAX_MEMORY, 1024 * 1024 * 1024),",
            "            retry_count=DEFAULT_RETRY_COUNT,",
            "            retry_interval=DEFAULT_RETRY_INTERVAL",
            "        )",
            "        self._heartbeat_sender = HeartbeatSender(self)",
            "        self._heartbeat_sender.start()",
            "        self._thread_local.atomic_instructions = {}",
            "        self._ws = None",
            "",
            "    def protocol_probe(self):",
            "        endpoint = f'http://{self.remote_path}/status/'",
            "        try:",
            "            response = requests.get(endpoint, headers=self.request_headers)",
            "            if response.status_code == 200:",
            "                if response.url.startswith('https://'):",
            "                    self._http_protocol = 'https://'",
            "                    self._ws_protocol = 'wss://'",
            "                    return",
            "        except Exception:",
            "            pass",
            "",
            "        endpoint = f'https://{self.remote_path}/status/'",
            "        try:",
            "            response = requests.get(endpoint, headers=self.request_headers)",
            "            if response.status_code == 200:",
            "                self._http_protocol = 'https://'",
            "                self._ws_protocol = 'wss://'",
            "        except Exception:",
            "            pass",
            "",
            "    def reinitialize_resource(self, handler):",
            "        # write some request to get a resource on server side with an already given handler",
            "        resource = self._resource_pool[handler]",
            "        self.get_resource_handler(resource, resource.resource_type, handler, resource.init_args)",
            "",
            "    def _reinitialize_all_resources(self):",
            "        handlers_list = list(self._resource_pool.keys())",
            "        for handler in handlers_list:",
            "            self.reinitialize_resource(handler)",
            "",
            "    @handle_exception(requests.ConnectionError,",
            "                      error_message='Failed to connect to Aim Server. Have you forgot to run `aim server` command?')",
            "    def _check_remote_version_compatibility(self):",
            "        from aim.__version__ import __version__ as client_version",
            "",
            "        error_message_template = 'The Aim Remote tracking server version ({}) '\\",
            "                                 'is not compatible with the Aim client version ({}).'\\",
            "                                 'Please upgrade either the Aim Client or the Aim Remote.'",
            "",
            "        warning_message_template = 'The Aim Remote tracking server version ({}) ' \\",
            "                                   'and the Aim client version ({}) do not match.' \\",
            "                                   'Consider upgrading either the client or remote tracking server.'",
            "",
            "        remote_version = self.get_version()",
            "",
            "        # server doesn't yet have the `get_version()` method implemented",
            "        if remote_version == '<3.19.0':",
            "            RuntimeError(error_message_template.format(remote_version, client_version))",
            "",
            "        # compare versions",
            "        if client_version == remote_version:",
            "            return",
            "",
            "        # if the server has a newer version always force to upgrade the client",
            "        if client_version < remote_version:",
            "            raise RuntimeError(error_message_template.format(remote_version, client_version))",
            "",
            "        # for other mismatching versions throw a warning for now",
            "        logger.warning(warning_message_template.format(remote_version, client_version))",
            "        # further incompatibility list will be added manually",
            "",
            "    def client_heartbeat(self):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/heartbeat/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        return response",
            "",
            "    @handle_exception(requests.ConnectionError,",
            "                      error_message='Failed to connect to Aim Server. Have you forgot to run `aim server` command?')",
            "    def connect(self):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/connect/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        return response",
            "",
            "    def reconnect(self):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/reconnect/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        self.refresh_ws()",
            "        self._reinitialize_all_resources()",
            "",
            "        return response",
            "",
            "    def disconnect(self):",
            "        self._heartbeat_sender.stop()",
            "        if self._ws:",
            "            self._ws.close()",
            "",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/disconnect/{self.uri}/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code != 200:",
            "            raise_exception(response_json.get('message'))",
            "",
            "        return response",
            "",
            "    def get_version(self,):",
            "        endpoint = f'{self._http_protocol}{self._client_endpoint}/get-version/'",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code == 404:",
            "            return '<3.19.0'",
            "        if response.status_code == 400:",
            "            raise_exception(response_json.get('exception'))",
            "        return response_json.get('version')",
            "",
            "    def get_resource_handler(self, resource, resource_type, handler='', args=()):",
            "        endpoint = f'{self._http_protocol}{self._tracking_endpoint}/{self.uri}/get-resource/'",
            "",
            "        request_data = {",
            "            'resource_handler': handler,",
            "            'resource_type': resource_type,",
            "            'args': base64.b64encode(args).decode()",
            "        }",
            "",
            "        response = requests.post(endpoint, json=request_data, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code == 400:",
            "            raise_exception(response_json.get('exception'))",
            "        elif response.status_code != 200:",
            "            raise (Exception(response_json))",
            "",
            "        handler = response_json.get('handler')",
            "        self._resource_pool[handler] = resource",
            "",
            "        return handler",
            "",
            "    def release_resource(self, queue_id, resource_handler):",
            "        endpoint = f'{self._http_protocol}{self._tracking_endpoint}/{self.uri}/release-resource/{resource_handler}/'",
            "        if queue_id != -1:",
            "            self.get_queue().wait_for_finish()",
            "",
            "        response = requests.get(endpoint, headers=self.request_headers)",
            "        response_json = response.json()",
            "        if response.status_code == 400:",
            "            raise_exception(response_json.get('exception'))",
            "",
            "        del self._resource_pool[resource_handler]",
            "",
            "    def run_instruction(self, queue_id, resource, method, args=(), is_write_only=False):",
            "        args = deepcopy(args)",
            "",
            "        # self._thread_local can be empty in the 'clean up' phase.",
            "",
            "        if is_write_only:",
            "            assert queue_id != -1",
            "            if getattr(self._thread_local, 'atomic_instructions', None) is not None and \\",
            "                    self._thread_local.atomic_instructions.get(queue_id, None) is not None:",
            "                self._thread_local.atomic_instructions[queue_id].append((resource, method, args))",
            "                return",
            "",
            "            self.get_queue().register_task(",
            "                self,",
            "                self._run_write_instructions, list(encode_tree([(resource, method, args)], strict=False)))",
            "            return",
            "",
            "        return self._run_read_instructions(queue_id, resource, method, args)",
            "",
            "    def _run_read_instructions(self, queue_id, resource, method, args):",
            "        endpoint = f'{self._http_protocol}{self._tracking_endpoint}/{self.uri}/read-instruction/'",
            "",
            "        request_data = {",
            "            'resource_handler': resource,",
            "            'method_name': method,",
            "            'args': base64.b64encode(pack_args(encode_tree(args))).decode()",
            "        }",
            "",
            "        if queue_id != -1:",
            "            self.get_queue().wait_for_finish()",
            "",
            "        response = requests.post(endpoint, json=request_data, stream=True, headers=self.request_headers)",
            "",
            "        if response.status_code == 400:",
            "            raise_exception(response.json().get('exception'))",
            "        return decode_tree(unpack_stream(response.iter_content(chunk_size=None)))",
            "",
            "    def _run_write_instructions(self, instructions: [Tuple[bytes, bytes]]):",
            "        msg = pack_args(iter(instructions))",
            "",
            "        self.ws.send(msg)",
            "",
            "        response = self.ws.recv()",
            "        if response == b'OK':",
            "            return",
            "",
            "        response_json = decode_tree(unpack_args(response))",
            "        raise_exception(response_json)",
            "",
            "    def start_instructions_batch(self, hash_):",
            "        if getattr(self._thread_local, 'atomic_instructions', None) is None:",
            "            self._thread_local.atomic_instructions = {}",
            "        self._thread_local.atomic_instructions[hash_] = []",
            "",
            "    def flush_instructions_batch(self, hash_):",
            "        if self._thread_local.atomic_instructions.get(hash_) is None:",
            "            return",
            "",
            "        self.get_queue().register_task(",
            "            self,",
            "            self._run_write_instructions, list(encode_tree(self._thread_local.atomic_instructions[hash_])))",
            "        del self._thread_local.atomic_instructions[hash_]",
            "",
            "    def refresh_ws(self):",
            "        self._ws = connect(f'{self._ws_protocol}{self._tracking_endpoint}/{self.uri}/write-instruction/')",
            "",
            "    @property",
            "    def ws(self):",
            "        if self._ws is None:",
            "            self._ws = connect(f'{self._ws_protocol}{self._tracking_endpoint}/{self.uri}/write-instruction/',",
            "                               additional_headers=self.request_headers)",
            "",
            "        return self._ws",
            "",
            "    @property",
            "    def uri(self):",
            "        return self._id",
            "",
            "    @property",
            "    def remote_path(self):",
            "        return self._remote_path",
            "",
            "    def get_queue(self):",
            "        return self._queue"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "1",
            "0",
            "1",
            "1",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "35": [
                "Client"
            ],
            "36": [
                "Client"
            ],
            "37": [
                "Client"
            ],
            "38": [
                "Client"
            ],
            "39": [
                "Client"
            ],
            "40": [
                "Client"
            ],
            "41": [
                "Client"
            ],
            "43": [
                "Client",
                "__init__"
            ],
            "44": [
                "Client",
                "__init__"
            ]
        },
        "addLocation": []
    },
    "aim/ext/transport/request_queue.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 33,
                "afterPatchRowNumber": 33,
                "PatchRowcode": "             self._client = weakref.ref(client)"
            },
            "1": {
                "beforePatchRowNumber": 34,
                "afterPatchRowNumber": 34,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 35,
                "afterPatchRowNumber": 35,
                "PatchRowcode": "         if self._shutdown:"
            },
            "3": {
                "beforePatchRowNumber": 36,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            logger.debug('Cannot register task: rpc task queue is stopped.')"
            },
            "4": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 36,
                "PatchRowcode": "+            logger.debug('Cannot register task: task queue is stopped.')"
            },
            "5": {
                "beforePatchRowNumber": 37,
                "afterPatchRowNumber": 37,
                "PatchRowcode": "             return"
            },
            "6": {
                "beforePatchRowNumber": 38,
                "afterPatchRowNumber": 38,
                "PatchRowcode": " "
            },
            "7": {
                "beforePatchRowNumber": 39,
                "afterPatchRowNumber": 39,
                "PatchRowcode": "         arg_size = self._calculate_size(args)"
            },
            "8": {
                "beforePatchRowNumber": 100,
                "afterPatchRowNumber": 100,
                "PatchRowcode": "     def stop(self):"
            },
            "9": {
                "beforePatchRowNumber": 101,
                "afterPatchRowNumber": 101,
                "PatchRowcode": "         pending_task_count = self._queue.qsize()"
            },
            "10": {
                "beforePatchRowNumber": 102,
                "afterPatchRowNumber": 102,
                "PatchRowcode": "         if pending_task_count:"
            },
            "11": {
                "beforePatchRowNumber": 103,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            logger.warning(f'Processing {pending_task_count} pending tasks in the rpc queue \\'{self._name}\\'... '"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 103,
                "PatchRowcode": "+            logger.warning(f'Processing {pending_task_count} pending tasks in the task queue \\'{self._name}\\'... '"
            },
            "13": {
                "beforePatchRowNumber": 104,
                "afterPatchRowNumber": 104,
                "PatchRowcode": "                            f'Please do not kill the process.')"
            },
            "14": {
                "beforePatchRowNumber": 105,
                "afterPatchRowNumber": 105,
                "PatchRowcode": "             self._queue.join()"
            },
            "15": {
                "beforePatchRowNumber": 106,
                "afterPatchRowNumber": 106,
                "PatchRowcode": "         logger.debug('No pending tasks left.')"
            }
        },
        "frontPatchFile": [
            "import time",
            "import queue",
            "import logging",
            "import threading",
            "import weakref",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class RequestQueue(object):",
            "    def __init__(self, name, max_queue_memory=0,",
            "                 retry_count=0, retry_interval=0):",
            "",
            "        self._client = None",
            "",
            "        self.retry_count = retry_count or 1",
            "        self.retry_interval = retry_interval",
            "        self._needs_reconnect = False",
            "",
            "        self.max_memory_usage = max_queue_memory",
            "        self.current_memory_usage = 0",
            "",
            "        self._shutdown = False",
            "        self._queue = queue.Queue()",
            "        self._name = name",
            "",
            "        self._thread = threading.Thread(target=self.worker)",
            "        self._thread.daemon = True",
            "        self._thread.start()",
            "",
            "    def register_task(self, client, task_f, *args):",
            "        if not self._client:",
            "            self._client = weakref.ref(client)",
            "",
            "        if self._shutdown:",
            "            logger.debug('Cannot register task: rpc task queue is stopped.')",
            "            return",
            "",
            "        arg_size = self._calculate_size(args)",
            "        with self._queue.not_full:",
            "            while self.current_memory_usage + arg_size >= self.max_memory_usage:",
            "                self._queue.not_full.wait()",
            "",
            "        with self._queue.mutex:",
            "            self.current_memory_usage += arg_size",
            "",
            "        self._queue.put((task_f, args))",
            "",
            "    def worker(self):",
            "        while True:",
            "            if self._shutdown:",
            "                logger.debug(f'Shutting down worker thread {threading.get_ident()}.')",
            "                break",
            "            task_f, args = self._queue.get()",
            "            if self._try_exec_task(task_f, *args):",
            "                arg_size = self._calculate_size(args)",
            "                with self._queue.mutex:",
            "                    self.current_memory_usage -= arg_size",
            "                # clear the unnecessary references",
            "                task_f, args = None, None",
            "                self._queue.task_done()",
            "            else:",
            "                self._put_front(task_f, args)",
            "",
            "    def _try_exec_task(self, task_f, *args):",
            "        # temporary workaround for M1 build",
            "        from websockets.exceptions import ConnectionClosedError",
            "",
            "        retry = 0",
            "        while retry < self.retry_count:",
            "            if self._needs_reconnect:",
            "                try:",
            "                    self._client().reconnect()",
            "                    self._needs_reconnect = False",
            "                except Exception:",
            "                    retry += 1",
            "                    time.sleep(self.retry_interval)",
            "                    continue",
            "",
            "            try:",
            "                task_f(*args)",
            "                return True",
            "            except ConnectionClosedError as e:",
            "                self._needs_reconnect = True",
            "",
            "                retry += 1",
            "                time.sleep(self.retry_interval)",
            "                logger.warning(f'Remote Server is unavailable, please check network connection: {e}.')",
            "",
            "        return False",
            "",
            "    def _put_front(self, task_f, args):",
            "        with self._queue.not_full:",
            "            self._queue.queue.appendleft((task_f, args))",
            "            self._queue.not_empty.notify()",
            "",
            "    def wait_for_finish(self):",
            "        self._queue.join()",
            "",
            "    def stop(self):",
            "        pending_task_count = self._queue.qsize()",
            "        if pending_task_count:",
            "            logger.warning(f'Processing {pending_task_count} pending tasks in the rpc queue \\'{self._name}\\'... '",
            "                           f'Please do not kill the process.')",
            "            self._queue.join()",
            "        logger.debug('No pending tasks left.')",
            "        self._shutdown = True",
            "",
            "    @staticmethod",
            "    def _calculate_size(args):",
            "        size = 0",
            "        assert type(args) is tuple",
            "        for arg in args[0]:",
            "            assert type(arg) is tuple",
            "            assert len(arg) == 2",
            "            size += len(arg[0]) + len(arg[1])",
            "        return size"
        ],
        "afterPatchFile": [
            "import time",
            "import queue",
            "import logging",
            "import threading",
            "import weakref",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "class RequestQueue(object):",
            "    def __init__(self, name, max_queue_memory=0,",
            "                 retry_count=0, retry_interval=0):",
            "",
            "        self._client = None",
            "",
            "        self.retry_count = retry_count or 1",
            "        self.retry_interval = retry_interval",
            "        self._needs_reconnect = False",
            "",
            "        self.max_memory_usage = max_queue_memory",
            "        self.current_memory_usage = 0",
            "",
            "        self._shutdown = False",
            "        self._queue = queue.Queue()",
            "        self._name = name",
            "",
            "        self._thread = threading.Thread(target=self.worker)",
            "        self._thread.daemon = True",
            "        self._thread.start()",
            "",
            "    def register_task(self, client, task_f, *args):",
            "        if not self._client:",
            "            self._client = weakref.ref(client)",
            "",
            "        if self._shutdown:",
            "            logger.debug('Cannot register task: task queue is stopped.')",
            "            return",
            "",
            "        arg_size = self._calculate_size(args)",
            "        with self._queue.not_full:",
            "            while self.current_memory_usage + arg_size >= self.max_memory_usage:",
            "                self._queue.not_full.wait()",
            "",
            "        with self._queue.mutex:",
            "            self.current_memory_usage += arg_size",
            "",
            "        self._queue.put((task_f, args))",
            "",
            "    def worker(self):",
            "        while True:",
            "            if self._shutdown:",
            "                logger.debug(f'Shutting down worker thread {threading.get_ident()}.')",
            "                break",
            "            task_f, args = self._queue.get()",
            "            if self._try_exec_task(task_f, *args):",
            "                arg_size = self._calculate_size(args)",
            "                with self._queue.mutex:",
            "                    self.current_memory_usage -= arg_size",
            "                # clear the unnecessary references",
            "                task_f, args = None, None",
            "                self._queue.task_done()",
            "            else:",
            "                self._put_front(task_f, args)",
            "",
            "    def _try_exec_task(self, task_f, *args):",
            "        # temporary workaround for M1 build",
            "        from websockets.exceptions import ConnectionClosedError",
            "",
            "        retry = 0",
            "        while retry < self.retry_count:",
            "            if self._needs_reconnect:",
            "                try:",
            "                    self._client().reconnect()",
            "                    self._needs_reconnect = False",
            "                except Exception:",
            "                    retry += 1",
            "                    time.sleep(self.retry_interval)",
            "                    continue",
            "",
            "            try:",
            "                task_f(*args)",
            "                return True",
            "            except ConnectionClosedError as e:",
            "                self._needs_reconnect = True",
            "",
            "                retry += 1",
            "                time.sleep(self.retry_interval)",
            "                logger.warning(f'Remote Server is unavailable, please check network connection: {e}.')",
            "",
            "        return False",
            "",
            "    def _put_front(self, task_f, args):",
            "        with self._queue.not_full:",
            "            self._queue.queue.appendleft((task_f, args))",
            "            self._queue.not_empty.notify()",
            "",
            "    def wait_for_finish(self):",
            "        self._queue.join()",
            "",
            "    def stop(self):",
            "        pending_task_count = self._queue.qsize()",
            "        if pending_task_count:",
            "            logger.warning(f'Processing {pending_task_count} pending tasks in the task queue \\'{self._name}\\'... '",
            "                           f'Please do not kill the process.')",
            "            self._queue.join()",
            "        logger.debug('No pending tasks left.')",
            "        self._shutdown = True",
            "",
            "    @staticmethod",
            "    def _calculate_size(args):",
            "        size = 0",
            "        assert type(args) is tuple",
            "        for arg in args[0]:",
            "            assert type(arg) is tuple",
            "            assert len(arg) == 2",
            "            size += len(arg[0]) + len(arg[1])",
            "        return size"
        ],
        "action": [
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "36": [
                "RequestQueue",
                "register_task"
            ],
            "103": [
                "RequestQueue",
                "stop"
            ]
        },
        "addLocation": []
    }
}