{
    "jupyter_server_proxy/handlers.py": {
        "Patch": {
            "0": {
                "beforePatchRowNumber": 209,
                "afterPatchRowNumber": 209,
                "PatchRowcode": "             return url_path_join(self.base_url, 'proxy', host_and_port)"
            },
            "1": {
                "beforePatchRowNumber": 210,
                "afterPatchRowNumber": 210,
                "PatchRowcode": " "
            },
            "2": {
                "beforePatchRowNumber": 211,
                "afterPatchRowNumber": 211,
                "PatchRowcode": "     def get_client_uri(self, protocol, host, port, proxied_path):"
            },
            "3": {
                "beforePatchRowNumber": 212,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        context_path = self._get_context_path(host, port)"
            },
            "4": {
                "beforePatchRowNumber": 213,
                "afterPatchRowNumber": 212,
                "PatchRowcode": "         if self.absolute_url:"
            },
            "5": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 213,
                "PatchRowcode": "+            context_path = self._get_context_path(host, port)"
            },
            "6": {
                "beforePatchRowNumber": 214,
                "afterPatchRowNumber": 214,
                "PatchRowcode": "             client_path = url_path_join(context_path, proxied_path)"
            },
            "7": {
                "beforePatchRowNumber": 215,
                "afterPatchRowNumber": 215,
                "PatchRowcode": "         else:"
            },
            "8": {
                "beforePatchRowNumber": 216,
                "afterPatchRowNumber": 216,
                "PatchRowcode": "             client_path = proxied_path"
            },
            "9": {
                "beforePatchRowNumber": 217,
                "afterPatchRowNumber": 217,
                "PatchRowcode": " "
            },
            "10": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 218,
                "PatchRowcode": "+        # ensure client_path always starts with '/'"
            },
            "11": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 219,
                "PatchRowcode": "+        if not client_path.startswith(\"/\"):"
            },
            "12": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 220,
                "PatchRowcode": "+            client_path = \"/\" + client_path"
            },
            "13": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 221,
                "PatchRowcode": "+"
            },
            "14": {
                "beforePatchRowNumber": 218,
                "afterPatchRowNumber": 222,
                "PatchRowcode": "         # Quote spaces, \u00e5\u00e4\u00f6 and such, but only enough to send a valid web"
            },
            "15": {
                "beforePatchRowNumber": 219,
                "afterPatchRowNumber": 223,
                "PatchRowcode": "         # request onwards. To do this, we mark the RFC 3986 specs' \"reserved\""
            },
            "16": {
                "beforePatchRowNumber": 220,
                "afterPatchRowNumber": 224,
                "PatchRowcode": "         # and \"un-reserved\" characters as safe that won't need quoting. The"
            },
            "17": {
                "beforePatchRowNumber": 228,
                "afterPatchRowNumber": 232,
                "PatchRowcode": "             protocol=protocol,"
            },
            "18": {
                "beforePatchRowNumber": 229,
                "afterPatchRowNumber": 233,
                "PatchRowcode": "             host=host,"
            },
            "19": {
                "beforePatchRowNumber": 230,
                "afterPatchRowNumber": 234,
                "PatchRowcode": "             port=port,"
            },
            "20": {
                "beforePatchRowNumber": 231,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            path=client_path"
            },
            "21": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 235,
                "PatchRowcode": "+            path=client_path,"
            },
            "22": {
                "beforePatchRowNumber": 232,
                "afterPatchRowNumber": 236,
                "PatchRowcode": "         )"
            },
            "23": {
                "beforePatchRowNumber": 233,
                "afterPatchRowNumber": 237,
                "PatchRowcode": "         if self.request.query:"
            },
            "24": {
                "beforePatchRowNumber": 234,
                "afterPatchRowNumber": 238,
                "PatchRowcode": "             client_uri += '?' + self.request.query"
            },
            "25": {
                "beforePatchRowNumber": 297,
                "afterPatchRowNumber": 301,
                "PatchRowcode": "         client = httpclient.AsyncHTTPClient()"
            },
            "26": {
                "beforePatchRowNumber": 298,
                "afterPatchRowNumber": 302,
                "PatchRowcode": " "
            },
            "27": {
                "beforePatchRowNumber": 299,
                "afterPatchRowNumber": 303,
                "PatchRowcode": "         req = self._build_proxy_request(host, port, proxied_path, body)"
            },
            "28": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 304,
                "PatchRowcode": "+        self.log.debug(f\"Proxying request to {req.url}\")"
            },
            "29": {
                "beforePatchRowNumber": 300,
                "afterPatchRowNumber": 305,
                "PatchRowcode": " "
            },
            "30": {
                "beforePatchRowNumber": 301,
                "afterPatchRowNumber": 306,
                "PatchRowcode": "         try:"
            },
            "31": {
                "beforePatchRowNumber": 302,
                "afterPatchRowNumber": 307,
                "PatchRowcode": "             # Here, \"response\" is a tornado.httpclient.HTTPResponse object."
            },
            "32": {
                "beforePatchRowNumber": 303,
                "afterPatchRowNumber": 308,
                "PatchRowcode": "             response = await client.fetch(req, raise_error=False)"
            },
            "33": {
                "beforePatchRowNumber": 304,
                "afterPatchRowNumber": 309,
                "PatchRowcode": "         except httpclient.HTTPError as err:"
            },
            "34": {
                "beforePatchRowNumber": 305,
                "afterPatchRowNumber": 310,
                "PatchRowcode": "             # We need to capture the timeout error even with raise_error=False,"
            },
            "35": {
                "beforePatchRowNumber": 306,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            # because it only affects the HTTPError raised when a non-200 response "
            },
            "36": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 311,
                "PatchRowcode": "+            # because it only affects the HTTPError raised when a non-200 response"
            },
            "37": {
                "beforePatchRowNumber": 307,
                "afterPatchRowNumber": 312,
                "PatchRowcode": "             # code is used, instead of suppressing all errors."
            },
            "38": {
                "beforePatchRowNumber": 308,
                "afterPatchRowNumber": 313,
                "PatchRowcode": "             # Ref: https://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.AsyncHTTPClient.fetch"
            },
            "39": {
                "beforePatchRowNumber": 309,
                "afterPatchRowNumber": 314,
                "PatchRowcode": "             if err.code == 599:"
            },
            "40": {
                "beforePatchRowNumber": 324,
                "afterPatchRowNumber": 329,
                "PatchRowcode": "         else:"
            },
            "41": {
                "beforePatchRowNumber": 325,
                "afterPatchRowNumber": 330,
                "PatchRowcode": "             # Represent the original response as a RewritableResponse object."
            },
            "42": {
                "beforePatchRowNumber": 326,
                "afterPatchRowNumber": 331,
                "PatchRowcode": "             original_response = RewritableResponse(orig_response=response)"
            },
            "43": {
                "beforePatchRowNumber": 327,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            "
            },
            "44": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 332,
                "PatchRowcode": "+"
            },
            "45": {
                "beforePatchRowNumber": 328,
                "afterPatchRowNumber": 333,
                "PatchRowcode": "             # The function (or list of functions) which should be applied to modify the"
            },
            "46": {
                "beforePatchRowNumber": 329,
                "afterPatchRowNumber": 334,
                "PatchRowcode": "             # response."
            },
            "47": {
                "beforePatchRowNumber": 330,
                "afterPatchRowNumber": 335,
                "PatchRowcode": "             rewrite_response = self.rewrite_response"
            },
            "48": {
                "beforePatchRowNumber": 688,
                "afterPatchRowNumber": 693,
                "PatchRowcode": " def setup_handlers(web_app, serverproxy_config):"
            },
            "49": {
                "beforePatchRowNumber": 689,
                "afterPatchRowNumber": 694,
                "PatchRowcode": "     host_allowlist = serverproxy_config.host_allowlist"
            },
            "50": {
                "beforePatchRowNumber": 690,
                "afterPatchRowNumber": 695,
                "PatchRowcode": "     rewrite_response = serverproxy_config.non_service_rewrite_response"
            },
            "51": {
                "beforePatchRowNumber": 691,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    web_app.add_handlers('.*', ["
            },
            "52": {
                "beforePatchRowNumber": 692,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ("
            },
            "53": {
                "beforePatchRowNumber": 693,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            url_path_join("
            },
            "54": {
                "beforePatchRowNumber": 694,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                web_app.settings['base_url'],"
            },
            "55": {
                "beforePatchRowNumber": 695,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                r'/proxy/([^/]*):(\\d+)(.*)',"
            },
            "56": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 696,
                "PatchRowcode": "+    web_app.add_handlers("
            },
            "57": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 697,
                "PatchRowcode": "+        \".*\","
            },
            "58": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 698,
                "PatchRowcode": "+        ["
            },
            "59": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 699,
                "PatchRowcode": "+            ("
            },
            "60": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 700,
                "PatchRowcode": "+                url_path_join("
            },
            "61": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 701,
                "PatchRowcode": "+                    web_app.settings[\"base_url\"],"
            },
            "62": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 702,
                "PatchRowcode": "+                    r\"/proxy/([^/:@]+):(\\d+)(/.*|)\","
            },
            "63": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 703,
                "PatchRowcode": "+                ),"
            },
            "64": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 704,
                "PatchRowcode": "+                RemoteProxyHandler,"
            },
            "65": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 705,
                "PatchRowcode": "+                {"
            },
            "66": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 706,
                "PatchRowcode": "+                    \"absolute_url\": False,"
            },
            "67": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 707,
                "PatchRowcode": "+                    \"host_allowlist\": host_allowlist,"
            },
            "68": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 708,
                "PatchRowcode": "+                    \"rewrite_response\": rewrite_response,"
            },
            "69": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 709,
                "PatchRowcode": "+                },"
            },
            "70": {
                "beforePatchRowNumber": 696,
                "afterPatchRowNumber": 710,
                "PatchRowcode": "             ),"
            },
            "71": {
                "beforePatchRowNumber": 697,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            RemoteProxyHandler,"
            },
            "72": {
                "beforePatchRowNumber": 698,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            {"
            },
            "73": {
                "beforePatchRowNumber": 699,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'absolute_url': False,"
            },
            "74": {
                "beforePatchRowNumber": 700,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'host_allowlist': host_allowlist,"
            },
            "75": {
                "beforePatchRowNumber": 701,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'rewrite_response': rewrite_response,"
            },
            "76": {
                "beforePatchRowNumber": 702,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            }"
            },
            "77": {
                "beforePatchRowNumber": 703,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ),"
            },
            "78": {
                "beforePatchRowNumber": 704,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ("
            },
            "79": {
                "beforePatchRowNumber": 705,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            url_path_join("
            },
            "80": {
                "beforePatchRowNumber": 706,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                web_app.settings['base_url'],"
            },
            "81": {
                "beforePatchRowNumber": 707,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                r'/proxy/absolute/([^/]*):(\\d+)(.*)',"
            },
            "82": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 711,
                "PatchRowcode": "+            ("
            },
            "83": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 712,
                "PatchRowcode": "+                url_path_join("
            },
            "84": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 713,
                "PatchRowcode": "+                    web_app.settings[\"base_url\"],"
            },
            "85": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 714,
                "PatchRowcode": "+                    r\"/proxy/absolute/([^/:@]+):(\\d+)(/.*|)\","
            },
            "86": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 715,
                "PatchRowcode": "+                ),"
            },
            "87": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 716,
                "PatchRowcode": "+                RemoteProxyHandler,"
            },
            "88": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 717,
                "PatchRowcode": "+                {"
            },
            "89": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 718,
                "PatchRowcode": "+                    \"absolute_url\": True,"
            },
            "90": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 719,
                "PatchRowcode": "+                    \"host_allowlist\": host_allowlist,"
            },
            "91": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 720,
                "PatchRowcode": "+                    \"rewrite_response\": rewrite_response,"
            },
            "92": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 721,
                "PatchRowcode": "+                },"
            },
            "93": {
                "beforePatchRowNumber": 708,
                "afterPatchRowNumber": 722,
                "PatchRowcode": "             ),"
            },
            "94": {
                "beforePatchRowNumber": 709,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            RemoteProxyHandler,"
            },
            "95": {
                "beforePatchRowNumber": 710,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            {"
            },
            "96": {
                "beforePatchRowNumber": 711,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'absolute_url': True,"
            },
            "97": {
                "beforePatchRowNumber": 712,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'host_allowlist': host_allowlist,"
            },
            "98": {
                "beforePatchRowNumber": 713,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'rewrite_response': rewrite_response,"
            },
            "99": {
                "beforePatchRowNumber": 714,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            }"
            },
            "100": {
                "beforePatchRowNumber": 715,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ),"
            },
            "101": {
                "beforePatchRowNumber": 716,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ("
            },
            "102": {
                "beforePatchRowNumber": 717,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            url_path_join("
            },
            "103": {
                "beforePatchRowNumber": 718,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                web_app.settings['base_url'],"
            },
            "104": {
                "beforePatchRowNumber": 719,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                r'/proxy/(\\d+)(.*)',"
            },
            "105": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 723,
                "PatchRowcode": "+            ("
            },
            "106": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 724,
                "PatchRowcode": "+                url_path_join("
            },
            "107": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 725,
                "PatchRowcode": "+                    web_app.settings[\"base_url\"],"
            },
            "108": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 726,
                "PatchRowcode": "+                    r\"/proxy/(\\d+)(/.*|)\","
            },
            "109": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 727,
                "PatchRowcode": "+                ),"
            },
            "110": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 728,
                "PatchRowcode": "+                LocalProxyHandler,"
            },
            "111": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 729,
                "PatchRowcode": "+                {"
            },
            "112": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 730,
                "PatchRowcode": "+                    \"absolute_url\": False,"
            },
            "113": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 731,
                "PatchRowcode": "+                    \"rewrite_response\": rewrite_response,"
            },
            "114": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 732,
                "PatchRowcode": "+                },"
            },
            "115": {
                "beforePatchRowNumber": 720,
                "afterPatchRowNumber": 733,
                "PatchRowcode": "             ),"
            },
            "116": {
                "beforePatchRowNumber": 721,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            LocalProxyHandler,"
            },
            "117": {
                "beforePatchRowNumber": 722,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            {"
            },
            "118": {
                "beforePatchRowNumber": 723,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'absolute_url': False,"
            },
            "119": {
                "beforePatchRowNumber": 724,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'rewrite_response': rewrite_response,"
            },
            "120": {
                "beforePatchRowNumber": 725,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            },"
            },
            "121": {
                "beforePatchRowNumber": 726,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ),"
            },
            "122": {
                "beforePatchRowNumber": 727,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ("
            },
            "123": {
                "beforePatchRowNumber": 728,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            url_path_join("
            },
            "124": {
                "beforePatchRowNumber": 729,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                web_app.settings['base_url'],"
            },
            "125": {
                "beforePatchRowNumber": 730,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                r'/proxy/absolute/(\\d+)(.*)',"
            },
            "126": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 734,
                "PatchRowcode": "+            ("
            },
            "127": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 735,
                "PatchRowcode": "+                url_path_join("
            },
            "128": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 736,
                "PatchRowcode": "+                    web_app.settings[\"base_url\"],"
            },
            "129": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 737,
                "PatchRowcode": "+                    r\"/proxy/absolute/(\\d+)(/.*|)\","
            },
            "130": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 738,
                "PatchRowcode": "+                ),"
            },
            "131": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 739,
                "PatchRowcode": "+                LocalProxyHandler,"
            },
            "132": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 740,
                "PatchRowcode": "+                {"
            },
            "133": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 741,
                "PatchRowcode": "+                    \"absolute_url\": True,"
            },
            "134": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 742,
                "PatchRowcode": "+                    \"rewrite_response\": rewrite_response,"
            },
            "135": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 743,
                "PatchRowcode": "+                },"
            },
            "136": {
                "beforePatchRowNumber": 731,
                "afterPatchRowNumber": 744,
                "PatchRowcode": "             ),"
            },
            "137": {
                "beforePatchRowNumber": 732,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            LocalProxyHandler,"
            },
            "138": {
                "beforePatchRowNumber": 733,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            {"
            },
            "139": {
                "beforePatchRowNumber": 734,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'absolute_url': True,"
            },
            "140": {
                "beforePatchRowNumber": 735,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-                'rewrite_response': rewrite_response,"
            },
            "141": {
                "beforePatchRowNumber": 736,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-            },"
            },
            "142": {
                "beforePatchRowNumber": 737,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-        ),"
            },
            "143": {
                "beforePatchRowNumber": 738,
                "afterPatchRowNumber": "",
                "PatchRowcode": "-    ])"
            },
            "144": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 745,
                "PatchRowcode": "+        ],"
            },
            "145": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 746,
                "PatchRowcode": "+    )"
            },
            "146": {
                "beforePatchRowNumber": "",
                "afterPatchRowNumber": 747,
                "PatchRowcode": "+"
            },
            "147": {
                "beforePatchRowNumber": 739,
                "afterPatchRowNumber": 748,
                "PatchRowcode": " "
            },
            "148": {
                "beforePatchRowNumber": 740,
                "afterPatchRowNumber": 749,
                "PatchRowcode": " # vim: set et ts=4 sw=4:"
            }
        },
        "frontPatchFile": [
            "\"\"\"",
            "Authenticated HTTP proxy for Jupyter Notebooks",
            "",
            "Some original inspiration from https://github.com/senko/tornado-proxy",
            "\"\"\"",
            "",
            "import inspect",
            "import socket",
            "import os",
            "from urllib.parse import urlunparse, urlparse, quote",
            "import aiohttp",
            "from asyncio import Lock",
            "from copy import copy",
            "",
            "from tornado import gen, web, httpclient, httputil, process, websocket, ioloop, version_info",
            "",
            "from jupyter_server.utils import ensure_async, url_path_join",
            "from jupyter_server.base.handlers import JupyterHandler, utcnow",
            "from traitlets.traitlets import HasTraits",
            "from traitlets import Bytes, Dict, Instance, Integer, Unicode, Union, default, observe",
            "",
            "from .utils import call_with_asked_args",
            "from .websocket import WebSocketHandlerMixin, pingable_ws_connect",
            "from simpervisor import SupervisedProcess",
            "",
            "",
            "class RewritableResponse(HasTraits):",
            "    \"\"\"",
            "    A class to hold the response to be rewritten by rewrite_response",
            "    \"\"\"",
            "    # The following should not be modified (or even accessed) by rewrite_response.",
            "    # It is used to initialize the default values of the traits.",
            "    orig_response = Instance(klass=httpclient.HTTPResponse)",
            "",
            "    # The following are modifiable by rewrite_response",
            "    headers = Union(trait_types=[Dict(), Instance(klass=httputil.HTTPHeaders)])",
            "    body = Bytes()",
            "    code = Integer()",
            "    reason = Unicode(allow_none=True)",
            "",
            "    @default('headers')",
            "    def _default_headers(self):",
            "        return copy(self.orig_response.headers)",
            "",
            "    @default('body')",
            "    def _default_body(self):",
            "        return self.orig_response.body",
            "",
            "    @default('code')",
            "    def _default_code(self):",
            "        return self.orig_response.code",
            "",
            "    @default('reason')",
            "    def _default_reason(self):",
            "        return self.orig_response.reason",
            "",
            "    @observe('code')",
            "    def _observe_code(self, change):",
            "        # HTTP status codes are mapped to short descriptions in the",
            "        # httputil.responses dictionary, 200 maps to \"OK\", 403 maps to",
            "        # \"Forbidden\" etc.",
            "        #",
            "        # If code is updated and it previously had a reason matching its short",
            "        # description, we update reason to match the new code's short",
            "        # description.",
            "        #",
            "        if self.reason == httputil.responses.get(change['old'], 'Unknown'):",
            "            self.reason = httputil.responses.get(change['new'], 'Unknown')",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        # Trigger the default value to be set from orig_response on instantiation.",
            "        # Otherwise _observe_code will receive change['old'] == 0.",
            "        self.code",
            "",
            "    def _apply_to_copy(self, func):",
            "        \"\"\"",
            "        Apply a function to a copy of self, and return the copy",
            "        \"\"\"",
            "        new = copy(self)",
            "        func(new)",
            "        return new",
            "",
            "",
            "class AddSlashHandler(JupyterHandler):",
            "    \"\"\"Add trailing slash to URLs that need them.\"\"\"",
            "    @web.authenticated",
            "    def get(self, *args):",
            "        src = urlparse(self.request.uri)",
            "        dest = src._replace(path=src.path + '/')",
            "        self.redirect(urlunparse(dest))",
            "",
            "class ProxyHandler(WebSocketHandlerMixin, JupyterHandler):",
            "    \"\"\"",
            "    A tornado request handler that proxies HTTP and websockets from",
            "    a given host/port combination. This class is not meant to be",
            "    used directly as a means of overriding CORS. This presents significant",
            "    security risks, and could allow arbitrary remote code access. Instead, it is",
            "    meant to be subclassed and used for proxying URLs from trusted sources.",
            "",
            "    Subclasses should implement open, http_get, post, put, delete, head, patch,",
            "    and options.",
            "    \"\"\"",
            "    def __init__(self, *args, **kwargs):",
            "        self.proxy_base = ''",
            "        self.absolute_url = kwargs.pop('absolute_url', False)",
            "        self.host_allowlist = kwargs.pop('host_allowlist', ['localhost', '127.0.0.1'])",
            "        self.rewrite_response = kwargs.pop(",
            "            'rewrite_response',",
            "            tuple(),",
            "        )",
            "        self.subprotocols = None",
            "        super().__init__(*args, **kwargs)",
            "",
            "    # Support/use jupyter_server config arguments allow_origin and allow_origin_pat",
            "    # to enable cross origin requests propagated by e.g. inverting proxies.",
            "",
            "    def check_origin(self, origin=None):",
            "        return JupyterHandler.check_origin(self, origin)",
            "",
            "    # Support all the methods that tornado does by default except for GET which",
            "    # is passed to WebSocketHandlerMixin and then to WebSocketHandler.",
            "",
            "    async def open(self, port, proxied_path):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement open')",
            "",
            "    async def http_get(self, host, port, proxy_path=''):",
            "        '''Our non-websocket GET.'''",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement http_get')",
            "",
            "    def post(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement this post')",
            "",
            "    def put(self, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement this put')",
            "",
            "    def delete(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement delete')",
            "",
            "    def head(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement head')",
            "",
            "    def patch(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement patch')",
            "",
            "    def options(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement options')",
            "",
            "    def on_message(self, message):",
            "        \"\"\"",
            "        Called when we receive a message from our client.",
            "",
            "        We proxy it to the backend.",
            "        \"\"\"",
            "        self._record_activity()",
            "        if hasattr(self, 'ws'):",
            "            self.ws.write_message(message, binary=isinstance(message, bytes))",
            "",
            "    def on_ping(self, data):",
            "        \"\"\"",
            "        Called when the client pings our websocket connection.",
            "",
            "        We proxy it to the backend.",
            "        \"\"\"",
            "        self.log.debug('jupyter_server_proxy: on_ping: {}'.format(data))",
            "        self._record_activity()",
            "        if hasattr(self, 'ws'):",
            "            self.ws.protocol.write_ping(data)",
            "",
            "    def on_pong(self, data):",
            "        \"\"\"",
            "        Called when we receive a ping back.",
            "        \"\"\"",
            "        self.log.debug('jupyter_server_proxy: on_pong: {}'.format(data))",
            "",
            "    def on_close(self):",
            "        \"\"\"",
            "        Called when the client closes our websocket connection.",
            "",
            "        We close our connection to the backend too.",
            "        \"\"\"",
            "        if hasattr(self, 'ws'):",
            "            self.ws.close()",
            "",
            "    def _record_activity(self):",
            "        \"\"\"Record proxied activity as API activity",
            "",
            "        avoids proxied traffic being ignored by the notebook's",
            "        internal idle-shutdown mechanism",
            "        \"\"\"",
            "        self.settings['api_last_activity'] = utcnow()",
            "",
            "    def _get_context_path(self, host, port):",
            "        \"\"\"",
            "        Some applications need to know where they are being proxied from.",
            "        This is either:",
            "        - {base_url}/proxy/{port}",
            "        - {base_url}/proxy/{host}:{port}",
            "        - {base_url}/proxy/absolute/{port}",
            "        - {base_url}/proxy/absolute/{host}:{port}",
            "        - {base_url}/{proxy_base}",
            "        \"\"\"",
            "        host_and_port = str(port) if host == 'localhost' else host + \":\" + str(port)",
            "        if self.proxy_base:",
            "            return url_path_join(self.base_url, self.proxy_base)",
            "        if self.absolute_url:",
            "            return url_path_join(self.base_url, 'proxy', 'absolute', host_and_port)",
            "        else:",
            "            return url_path_join(self.base_url, 'proxy', host_and_port)",
            "",
            "    def get_client_uri(self, protocol, host, port, proxied_path):",
            "        context_path = self._get_context_path(host, port)",
            "        if self.absolute_url:",
            "            client_path = url_path_join(context_path, proxied_path)",
            "        else:",
            "            client_path = proxied_path",
            "",
            "        # Quote spaces, \u00e5\u00e4\u00f6 and such, but only enough to send a valid web",
            "        # request onwards. To do this, we mark the RFC 3986 specs' \"reserved\"",
            "        # and \"un-reserved\" characters as safe that won't need quoting. The",
            "        # un-reserved need to be marked safe to ensure the quote function behave",
            "        # the same in py36 as py37.",
            "        #",
            "        # ref: https://tools.ietf.org/html/rfc3986#section-2.2",
            "        client_path = quote(client_path, safe=\":/?#[]@!$&'()*+,;=-._~\")",
            "",
            "        client_uri = '{protocol}://{host}:{port}{path}'.format(",
            "            protocol=protocol,",
            "            host=host,",
            "            port=port,",
            "            path=client_path",
            "        )",
            "        if self.request.query:",
            "            client_uri += '?' + self.request.query",
            "",
            "        return client_uri",
            "",
            "    def _build_proxy_request(self, host, port, proxied_path, body):",
            "",
            "        headers = self.proxy_request_headers()",
            "",
            "        client_uri = self.get_client_uri('http', host, port, proxied_path)",
            "        # Some applications check X-Forwarded-Context and X-ProxyContextPath",
            "        # headers to see if and where they are being proxied from.",
            "        if not self.absolute_url:",
            "            context_path = self._get_context_path(host, port)",
            "            headers['X-Forwarded-Context'] = context_path",
            "            headers['X-ProxyContextPath'] = context_path",
            "            # to be compatible with flask/werkzeug wsgi applications",
            "            headers['X-Forwarded-Prefix'] = context_path",
            "",
            "        req = httpclient.HTTPRequest(",
            "            client_uri, method=self.request.method, body=body,",
            "            decompress_response=False,",
            "            headers=headers, **self.proxy_request_options())",
            "        return req",
            "",
            "    def _check_host_allowlist(self, host):",
            "        if callable(self.host_allowlist):",
            "            return self.host_allowlist(self, host)",
            "        else:",
            "            return host in self.host_allowlist",
            "",
            "    @web.authenticated",
            "    async def proxy(self, host, port, proxied_path):",
            "        '''",
            "        This serverextension handles:",
            "            {base_url}/proxy/{port([0-9]+)}/{proxied_path}",
            "            {base_url}/proxy/absolute/{port([0-9]+)}/{proxied_path}",
            "            {base_url}/{proxy_base}/{proxied_path}",
            "        '''",
            "",
            "        if not self._check_host_allowlist(host):",
            "            self.set_status(403)",
            "            self.write(\"Host '{host}' is not allowed. \"",
            "                       \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))",
            "            return",
            "",
            "        if 'Proxy-Connection' in self.request.headers:",
            "            del self.request.headers['Proxy-Connection']",
            "",
            "        self._record_activity()",
            "",
            "        if self.request.headers.get(\"Upgrade\", \"\").lower() == 'websocket':",
            "            # We wanna websocket!",
            "            # jupyterhub/jupyter-server-proxy@36b3214",
            "            self.log.info(\"we wanna websocket, but we don't define WebSocketProxyHandler\")",
            "            self.set_status(500)",
            "",
            "        body = self.request.body",
            "        if not body:",
            "            if self.request.method == 'POST':",
            "                body = b''",
            "            else:",
            "                body = None",
            "",
            "        client = httpclient.AsyncHTTPClient()",
            "",
            "        req = self._build_proxy_request(host, port, proxied_path, body)",
            "",
            "        try:",
            "            # Here, \"response\" is a tornado.httpclient.HTTPResponse object.",
            "            response = await client.fetch(req, raise_error=False)",
            "        except httpclient.HTTPError as err:",
            "            # We need to capture the timeout error even with raise_error=False,",
            "            # because it only affects the HTTPError raised when a non-200 response ",
            "            # code is used, instead of suppressing all errors.",
            "            # Ref: https://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.AsyncHTTPClient.fetch",
            "            if err.code == 599:",
            "                self._record_activity()",
            "                self.set_status(599)",
            "                self.write(str(err))",
            "                return",
            "            else:",
            "                raise",
            "",
            "        # record activity at start and end of requests",
            "        self._record_activity()",
            "",
            "        # For all non http errors...",
            "        if response.error and type(response.error) is not httpclient.HTTPError:",
            "            self.set_status(500)",
            "            self.write(str(response.error))",
            "        else:",
            "            # Represent the original response as a RewritableResponse object.",
            "            original_response = RewritableResponse(orig_response=response)",
            "            ",
            "            # The function (or list of functions) which should be applied to modify the",
            "            # response.",
            "            rewrite_response = self.rewrite_response",
            "",
            "            # If this is a single function, wrap it in a list.",
            "            if isinstance(rewrite_response, (list, tuple)):",
            "                rewrite_responses = rewrite_response",
            "            else:",
            "                rewrite_responses = [rewrite_response]",
            "",
            "            # To be passed on-demand as args to the rewrite_response functions.",
            "            optional_args_to_rewrite_function = {",
            "                'request': self.request,",
            "                'orig_response': original_response,",
            "                'host': host,",
            "                'port': port,",
            "                'path': proxied_path",
            "            }",
            "",
            "            # Initial value for rewriting",
            "            rewritten_response = original_response",
            "",
            "            for rewrite in rewrite_responses:",
            "                # The rewrite function is a function of the RewritableResponse object",
            "                # ``response`` as well as several other optional arguments. We need to",
            "                # convert it to a function of only ``response`` by plugging in the",
            "                # known values for all the other parameters. (This is called partial",
            "                # evaluation.)",
            "                def rewrite_pe(rewritable_response: RewritableResponse):",
            "                    return call_with_asked_args(",
            "                        rewrite,",
            "                        {",
            "                            'response': rewritable_response,",
            "                            **optional_args_to_rewrite_function",
            "                        }",
            "                    )",
            "                # Now we can cleanly apply the partially evaulated function to a copy of",
            "                # the rewritten response.",
            "                rewritten_response = rewritten_response._apply_to_copy(rewrite_pe)",
            "",
            "            ## status",
            "            self.set_status(rewritten_response.code, rewritten_response.reason)",
            "",
            "            # clear tornado default header",
            "            self._headers = httputil.HTTPHeaders()",
            "            for header, v in rewritten_response.headers.get_all():",
            "                if header not in ('Content-Length', 'Transfer-Encoding',",
            "                                  'Connection'):",
            "                    # some header appear multiple times, eg 'Set-Cookie'",
            "                    self.add_header(header, v)",
            "",
            "            if rewritten_response.body:",
            "                self.write(rewritten_response.body)",
            "",
            "    async def proxy_open(self, host, port, proxied_path=''):",
            "        \"\"\"",
            "        Called when a client opens a websocket connection.",
            "",
            "        We establish a websocket connection to the proxied backend &",
            "        set up a callback to relay messages through.",
            "        \"\"\"",
            "",
            "        if not self._check_host_allowlist(host):",
            "            self.set_status(403)",
            "            self.log.info(\"Host '{host}' is not allowed. \"",
            "                          \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))",
            "            self.close()",
            "            return",
            "",
            "        if not proxied_path.startswith('/'):",
            "            proxied_path = '/' + proxied_path",
            "",
            "        client_uri = self.get_client_uri('ws', host, port, proxied_path)",
            "        headers = self.proxy_request_headers()",
            "",
            "        def message_cb(message):",
            "            \"\"\"",
            "            Callback when the backend sends messages to us",
            "",
            "            We just pass it back to the frontend",
            "            \"\"\"",
            "            # Websockets support both string (utf-8) and binary data, so let's",
            "            # make sure we signal that appropriately when proxying",
            "            self._record_activity()",
            "            if message is None:",
            "                self.close()",
            "            else:",
            "                self.write_message(message, binary=isinstance(message, bytes))",
            "",
            "        def ping_cb(data):",
            "            \"\"\"",
            "            Callback when the backend sends pings to us.",
            "",
            "            We just pass it back to the frontend.",
            "            \"\"\"",
            "            self._record_activity()",
            "            self.ping(data)",
            "",
            "        async def start_websocket_connection():",
            "            self.log.info('Trying to establish websocket connection to {}'.format(client_uri))",
            "            self._record_activity()",
            "            request = httpclient.HTTPRequest(url=client_uri, headers=headers)",
            "            self.ws = await pingable_ws_connect(request=request,",
            "                on_message_callback=message_cb, on_ping_callback=ping_cb,",
            "                subprotocols=self.subprotocols)",
            "            self._record_activity()",
            "            self.log.info('Websocket connection established to {}'.format(client_uri))",
            "",
            "        # Wait for the WebSocket to be connected before resolving.",
            "        # Otherwise, messages sent by the client before the",
            "        # WebSocket successful connection would be dropped.",
            "        await start_websocket_connection()",
            "",
            "    def proxy_request_headers(self):",
            "        '''A dictionary of headers to be used when constructing",
            "        a tornado.httpclient.HTTPRequest instance for the proxy request.'''",
            "        headers = self.request.headers.copy()",
            "        # Merge any manually configured request headers",
            "        headers.update(self.get_request_headers_override())",
            "        return headers",
            "",
            "    def get_request_headers_override(self):",
            "        '''Add additional request headers. Typically overridden in subclasses.'''",
            "        return {}",
            "",
            "    def proxy_request_options(self):",
            "        '''A dictionary of options to be used when constructing",
            "        a tornado.httpclient.HTTPRequest instance for the proxy request.'''",
            "        return dict(follow_redirects=False, connect_timeout=250.0, request_timeout=300.0)",
            "",
            "    def check_xsrf_cookie(self):",
            "        '''",
            "        http://www.tornadoweb.org/en/stable/guide/security.html",
            "",
            "        Defer to proxied apps.",
            "        '''",
            "        pass",
            "",
            "    def select_subprotocol(self, subprotocols):",
            "        '''Select a single Sec-WebSocket-Protocol during handshake.'''",
            "        self.subprotocols = subprotocols",
            "        if isinstance(subprotocols, list) and subprotocols:",
            "            self.log.debug('Client sent subprotocols: {}'.format(subprotocols))",
            "            return subprotocols[0]",
            "        return super().select_subprotocol(subprotocols)",
            "",
            "",
            "class LocalProxyHandler(ProxyHandler):",
            "    \"\"\"",
            "    A tornado request handler that proxies HTTP and websockets",
            "    from a port on the local system. Same as the above ProxyHandler,",
            "    but specific to 'localhost'.",
            "",
            "    The arguments \"port\" and \"proxied_path\" in each method are extracted from",
            "    the URL as capture groups in the regex specified in the add_handlers",
            "    method.",
            "    \"\"\"",
            "    async def http_get(self, port, proxied_path):",
            "        return await self.proxy(port, proxied_path)",
            "",
            "    async def open(self, port, proxied_path):",
            "        return await self.proxy_open('localhost', port, proxied_path)",
            "",
            "    def post(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def put(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def delete(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def head(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def patch(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def options(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def proxy(self, port, proxied_path):",
            "        return super().proxy('localhost', port, proxied_path)",
            "",
            "class RemoteProxyHandler(ProxyHandler):",
            "    \"\"\"",
            "    A tornado request handler that proxies HTTP and websockets",
            "    from a port on a specified remote system.",
            "",
            "    The arguments \"host\", \"port\" and \"proxied_path\" in each method are",
            "    extracted from the URL as capture groups in the regex specified in the",
            "    add_handlers method.",
            "    \"\"\"",
            "",
            "    async def http_get(self, host, port, proxied_path):",
            "        return await self.proxy(host, port, proxied_path)",
            "",
            "    def post(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def put(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def delete(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def head(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def patch(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def options(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    async def open(self, host, port, proxied_path):",
            "        return await self.proxy_open(host, port, proxied_path)",
            "",
            "    def proxy(self, host, port, proxied_path):",
            "        return super().proxy(host, port, proxied_path)",
            "",
            "# FIXME: Move this to its own file. Too many packages now import this from nbrserverproxy.handlers",
            "class SuperviseAndProxyHandler(LocalProxyHandler):",
            "    '''Manage a given process and requests to it '''",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        self.requested_port = 0",
            "        self.mappath = {}",
            "        super().__init__(*args, **kwargs)",
            "",
            "    def initialize(self, state):",
            "        self.state = state",
            "        if 'proc_lock' not in state:",
            "            state['proc_lock'] = Lock()",
            "",
            "    name = 'process'",
            "",
            "    @property",
            "    def port(self):",
            "        \"\"\"",
            "        Allocate either the requested port or a random empty port for use by",
            "        application",
            "        \"\"\"",
            "        if 'port' not in self.state:",
            "            sock = socket.socket()",
            "            sock.bind(('', self.requested_port))",
            "            self.state['port'] = sock.getsockname()[1]",
            "            sock.close()",
            "        return self.state['port']",
            "",
            "    def get_cwd(self):",
            "        \"\"\"Get the current working directory for our process",
            "",
            "        Override in subclass to launch the process in a directory",
            "        other than the current.",
            "        \"\"\"",
            "        return os.getcwd()",
            "",
            "    def get_env(self):",
            "        '''Set up extra environment variables for process. Typically",
            "           overridden in subclasses.'''",
            "        return {}",
            "",
            "    def get_timeout(self):",
            "        \"\"\"",
            "        Return timeout (in s) to wait before giving up on process readiness",
            "        \"\"\"",
            "        return 5",
            "",
            "    async def _http_ready_func(self, p):",
            "        url = 'http://localhost:{}'.format(self.port)",
            "        async with aiohttp.ClientSession() as session:",
            "            try:",
            "                async with session.get(url, allow_redirects=False) as resp:",
            "                    # We only care if we get back *any* response, not just 200",
            "                    # If there's an error response, that can be shown directly to the user",
            "                    self.log.debug('Got code {} back from {}'.format(resp.status, url))",
            "                    return True",
            "            except aiohttp.ClientConnectionError:",
            "                self.log.debug('Connection to {} refused'.format(url))",
            "                return False",
            "",
            "    async def ensure_process(self):",
            "        \"\"\"",
            "        Start the process",
            "        \"\"\"",
            "        # We don't want multiple requests trying to start the process at the same time",
            "        # FIXME: Make sure this times out properly?",
            "        # Invariant here should be: when lock isn't being held, either 'proc' is in state &",
            "        # running, or not.",
            "        async with self.state['proc_lock']:",
            "            if 'proc' not in self.state:",
            "                # FIXME: Prevent races here",
            "                # FIXME: Handle graceful exits of spawned processes here",
            "                cmd = self.get_cmd()",
            "",
            "                # Set up extra environment variables for process",
            "                server_env = os.environ.copy()",
            "                server_env.update(self.get_env())",
            "",
            "                timeout = self.get_timeout()",
            "",
            "                proc = SupervisedProcess(self.name, *cmd, env=server_env, ready_func=self._http_ready_func, ready_timeout=timeout, log=self.log)",
            "                self.state['proc'] = proc",
            "",
            "                try:",
            "                    await proc.start()",
            "",
            "                    is_ready = await proc.ready()",
            "",
            "                    if not is_ready:",
            "                        await proc.kill()",
            "                        raise web.HTTPError(500, 'could not start {} in time'.format(self.name))",
            "                except:",
            "                    # Make sure we remove proc from state in any error condition",
            "                    del self.state['proc']",
            "                    raise",
            "",
            "",
            "    @web.authenticated",
            "    async def proxy(self, port, path):",
            "        if not path.startswith('/'):",
            "            path = '/' + path",
            "        if self.mappath:",
            "            if callable(self.mappath):",
            "                path = call_with_asked_args(self.mappath, {'path': path})",
            "            else:",
            "                path = self.mappath.get(path, path)",
            "",
            "        await self.ensure_process()",
            "",
            "        return await ensure_async(super().proxy(self.port, path))",
            "",
            "",
            "    async def http_get(self, path):",
            "        return await ensure_async(self.proxy(self.port, path))",
            "",
            "    async def open(self, path):",
            "        await self.ensure_process()",
            "        return await super().open(self.port, path)",
            "",
            "    def post(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def put(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def delete(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def head(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def patch(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def options(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "",
            "def setup_handlers(web_app, serverproxy_config):",
            "    host_allowlist = serverproxy_config.host_allowlist",
            "    rewrite_response = serverproxy_config.non_service_rewrite_response",
            "    web_app.add_handlers('.*', [",
            "        (",
            "            url_path_join(",
            "                web_app.settings['base_url'],",
            "                r'/proxy/([^/]*):(\\d+)(.*)',",
            "            ),",
            "            RemoteProxyHandler,",
            "            {",
            "                'absolute_url': False,",
            "                'host_allowlist': host_allowlist,",
            "                'rewrite_response': rewrite_response,",
            "            }",
            "        ),",
            "        (",
            "            url_path_join(",
            "                web_app.settings['base_url'],",
            "                r'/proxy/absolute/([^/]*):(\\d+)(.*)',",
            "            ),",
            "            RemoteProxyHandler,",
            "            {",
            "                'absolute_url': True,",
            "                'host_allowlist': host_allowlist,",
            "                'rewrite_response': rewrite_response,",
            "            }",
            "        ),",
            "        (",
            "            url_path_join(",
            "                web_app.settings['base_url'],",
            "                r'/proxy/(\\d+)(.*)',",
            "            ),",
            "            LocalProxyHandler,",
            "            {",
            "                'absolute_url': False,",
            "                'rewrite_response': rewrite_response,",
            "            },",
            "        ),",
            "        (",
            "            url_path_join(",
            "                web_app.settings['base_url'],",
            "                r'/proxy/absolute/(\\d+)(.*)',",
            "            ),",
            "            LocalProxyHandler,",
            "            {",
            "                'absolute_url': True,",
            "                'rewrite_response': rewrite_response,",
            "            },",
            "        ),",
            "    ])",
            "",
            "# vim: set et ts=4 sw=4:"
        ],
        "afterPatchFile": [
            "\"\"\"",
            "Authenticated HTTP proxy for Jupyter Notebooks",
            "",
            "Some original inspiration from https://github.com/senko/tornado-proxy",
            "\"\"\"",
            "",
            "import inspect",
            "import socket",
            "import os",
            "from urllib.parse import urlunparse, urlparse, quote",
            "import aiohttp",
            "from asyncio import Lock",
            "from copy import copy",
            "",
            "from tornado import gen, web, httpclient, httputil, process, websocket, ioloop, version_info",
            "",
            "from jupyter_server.utils import ensure_async, url_path_join",
            "from jupyter_server.base.handlers import JupyterHandler, utcnow",
            "from traitlets.traitlets import HasTraits",
            "from traitlets import Bytes, Dict, Instance, Integer, Unicode, Union, default, observe",
            "",
            "from .utils import call_with_asked_args",
            "from .websocket import WebSocketHandlerMixin, pingable_ws_connect",
            "from simpervisor import SupervisedProcess",
            "",
            "",
            "class RewritableResponse(HasTraits):",
            "    \"\"\"",
            "    A class to hold the response to be rewritten by rewrite_response",
            "    \"\"\"",
            "    # The following should not be modified (or even accessed) by rewrite_response.",
            "    # It is used to initialize the default values of the traits.",
            "    orig_response = Instance(klass=httpclient.HTTPResponse)",
            "",
            "    # The following are modifiable by rewrite_response",
            "    headers = Union(trait_types=[Dict(), Instance(klass=httputil.HTTPHeaders)])",
            "    body = Bytes()",
            "    code = Integer()",
            "    reason = Unicode(allow_none=True)",
            "",
            "    @default('headers')",
            "    def _default_headers(self):",
            "        return copy(self.orig_response.headers)",
            "",
            "    @default('body')",
            "    def _default_body(self):",
            "        return self.orig_response.body",
            "",
            "    @default('code')",
            "    def _default_code(self):",
            "        return self.orig_response.code",
            "",
            "    @default('reason')",
            "    def _default_reason(self):",
            "        return self.orig_response.reason",
            "",
            "    @observe('code')",
            "    def _observe_code(self, change):",
            "        # HTTP status codes are mapped to short descriptions in the",
            "        # httputil.responses dictionary, 200 maps to \"OK\", 403 maps to",
            "        # \"Forbidden\" etc.",
            "        #",
            "        # If code is updated and it previously had a reason matching its short",
            "        # description, we update reason to match the new code's short",
            "        # description.",
            "        #",
            "        if self.reason == httputil.responses.get(change['old'], 'Unknown'):",
            "            self.reason = httputil.responses.get(change['new'], 'Unknown')",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        super().__init__(*args, **kwargs)",
            "        # Trigger the default value to be set from orig_response on instantiation.",
            "        # Otherwise _observe_code will receive change['old'] == 0.",
            "        self.code",
            "",
            "    def _apply_to_copy(self, func):",
            "        \"\"\"",
            "        Apply a function to a copy of self, and return the copy",
            "        \"\"\"",
            "        new = copy(self)",
            "        func(new)",
            "        return new",
            "",
            "",
            "class AddSlashHandler(JupyterHandler):",
            "    \"\"\"Add trailing slash to URLs that need them.\"\"\"",
            "    @web.authenticated",
            "    def get(self, *args):",
            "        src = urlparse(self.request.uri)",
            "        dest = src._replace(path=src.path + '/')",
            "        self.redirect(urlunparse(dest))",
            "",
            "class ProxyHandler(WebSocketHandlerMixin, JupyterHandler):",
            "    \"\"\"",
            "    A tornado request handler that proxies HTTP and websockets from",
            "    a given host/port combination. This class is not meant to be",
            "    used directly as a means of overriding CORS. This presents significant",
            "    security risks, and could allow arbitrary remote code access. Instead, it is",
            "    meant to be subclassed and used for proxying URLs from trusted sources.",
            "",
            "    Subclasses should implement open, http_get, post, put, delete, head, patch,",
            "    and options.",
            "    \"\"\"",
            "    def __init__(self, *args, **kwargs):",
            "        self.proxy_base = ''",
            "        self.absolute_url = kwargs.pop('absolute_url', False)",
            "        self.host_allowlist = kwargs.pop('host_allowlist', ['localhost', '127.0.0.1'])",
            "        self.rewrite_response = kwargs.pop(",
            "            'rewrite_response',",
            "            tuple(),",
            "        )",
            "        self.subprotocols = None",
            "        super().__init__(*args, **kwargs)",
            "",
            "    # Support/use jupyter_server config arguments allow_origin and allow_origin_pat",
            "    # to enable cross origin requests propagated by e.g. inverting proxies.",
            "",
            "    def check_origin(self, origin=None):",
            "        return JupyterHandler.check_origin(self, origin)",
            "",
            "    # Support all the methods that tornado does by default except for GET which",
            "    # is passed to WebSocketHandlerMixin and then to WebSocketHandler.",
            "",
            "    async def open(self, port, proxied_path):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement open')",
            "",
            "    async def http_get(self, host, port, proxy_path=''):",
            "        '''Our non-websocket GET.'''",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement http_get')",
            "",
            "    def post(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement this post')",
            "",
            "    def put(self, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement this put')",
            "",
            "    def delete(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement delete')",
            "",
            "    def head(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement head')",
            "",
            "    def patch(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement patch')",
            "",
            "    def options(self, host, port, proxy_path=''):",
            "        raise NotImplementedError('Subclasses of ProxyHandler should implement options')",
            "",
            "    def on_message(self, message):",
            "        \"\"\"",
            "        Called when we receive a message from our client.",
            "",
            "        We proxy it to the backend.",
            "        \"\"\"",
            "        self._record_activity()",
            "        if hasattr(self, 'ws'):",
            "            self.ws.write_message(message, binary=isinstance(message, bytes))",
            "",
            "    def on_ping(self, data):",
            "        \"\"\"",
            "        Called when the client pings our websocket connection.",
            "",
            "        We proxy it to the backend.",
            "        \"\"\"",
            "        self.log.debug('jupyter_server_proxy: on_ping: {}'.format(data))",
            "        self._record_activity()",
            "        if hasattr(self, 'ws'):",
            "            self.ws.protocol.write_ping(data)",
            "",
            "    def on_pong(self, data):",
            "        \"\"\"",
            "        Called when we receive a ping back.",
            "        \"\"\"",
            "        self.log.debug('jupyter_server_proxy: on_pong: {}'.format(data))",
            "",
            "    def on_close(self):",
            "        \"\"\"",
            "        Called when the client closes our websocket connection.",
            "",
            "        We close our connection to the backend too.",
            "        \"\"\"",
            "        if hasattr(self, 'ws'):",
            "            self.ws.close()",
            "",
            "    def _record_activity(self):",
            "        \"\"\"Record proxied activity as API activity",
            "",
            "        avoids proxied traffic being ignored by the notebook's",
            "        internal idle-shutdown mechanism",
            "        \"\"\"",
            "        self.settings['api_last_activity'] = utcnow()",
            "",
            "    def _get_context_path(self, host, port):",
            "        \"\"\"",
            "        Some applications need to know where they are being proxied from.",
            "        This is either:",
            "        - {base_url}/proxy/{port}",
            "        - {base_url}/proxy/{host}:{port}",
            "        - {base_url}/proxy/absolute/{port}",
            "        - {base_url}/proxy/absolute/{host}:{port}",
            "        - {base_url}/{proxy_base}",
            "        \"\"\"",
            "        host_and_port = str(port) if host == 'localhost' else host + \":\" + str(port)",
            "        if self.proxy_base:",
            "            return url_path_join(self.base_url, self.proxy_base)",
            "        if self.absolute_url:",
            "            return url_path_join(self.base_url, 'proxy', 'absolute', host_and_port)",
            "        else:",
            "            return url_path_join(self.base_url, 'proxy', host_and_port)",
            "",
            "    def get_client_uri(self, protocol, host, port, proxied_path):",
            "        if self.absolute_url:",
            "            context_path = self._get_context_path(host, port)",
            "            client_path = url_path_join(context_path, proxied_path)",
            "        else:",
            "            client_path = proxied_path",
            "",
            "        # ensure client_path always starts with '/'",
            "        if not client_path.startswith(\"/\"):",
            "            client_path = \"/\" + client_path",
            "",
            "        # Quote spaces, \u00e5\u00e4\u00f6 and such, but only enough to send a valid web",
            "        # request onwards. To do this, we mark the RFC 3986 specs' \"reserved\"",
            "        # and \"un-reserved\" characters as safe that won't need quoting. The",
            "        # un-reserved need to be marked safe to ensure the quote function behave",
            "        # the same in py36 as py37.",
            "        #",
            "        # ref: https://tools.ietf.org/html/rfc3986#section-2.2",
            "        client_path = quote(client_path, safe=\":/?#[]@!$&'()*+,;=-._~\")",
            "",
            "        client_uri = '{protocol}://{host}:{port}{path}'.format(",
            "            protocol=protocol,",
            "            host=host,",
            "            port=port,",
            "            path=client_path,",
            "        )",
            "        if self.request.query:",
            "            client_uri += '?' + self.request.query",
            "",
            "        return client_uri",
            "",
            "    def _build_proxy_request(self, host, port, proxied_path, body):",
            "",
            "        headers = self.proxy_request_headers()",
            "",
            "        client_uri = self.get_client_uri('http', host, port, proxied_path)",
            "        # Some applications check X-Forwarded-Context and X-ProxyContextPath",
            "        # headers to see if and where they are being proxied from.",
            "        if not self.absolute_url:",
            "            context_path = self._get_context_path(host, port)",
            "            headers['X-Forwarded-Context'] = context_path",
            "            headers['X-ProxyContextPath'] = context_path",
            "            # to be compatible with flask/werkzeug wsgi applications",
            "            headers['X-Forwarded-Prefix'] = context_path",
            "",
            "        req = httpclient.HTTPRequest(",
            "            client_uri, method=self.request.method, body=body,",
            "            decompress_response=False,",
            "            headers=headers, **self.proxy_request_options())",
            "        return req",
            "",
            "    def _check_host_allowlist(self, host):",
            "        if callable(self.host_allowlist):",
            "            return self.host_allowlist(self, host)",
            "        else:",
            "            return host in self.host_allowlist",
            "",
            "    @web.authenticated",
            "    async def proxy(self, host, port, proxied_path):",
            "        '''",
            "        This serverextension handles:",
            "            {base_url}/proxy/{port([0-9]+)}/{proxied_path}",
            "            {base_url}/proxy/absolute/{port([0-9]+)}/{proxied_path}",
            "            {base_url}/{proxy_base}/{proxied_path}",
            "        '''",
            "",
            "        if not self._check_host_allowlist(host):",
            "            self.set_status(403)",
            "            self.write(\"Host '{host}' is not allowed. \"",
            "                       \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))",
            "            return",
            "",
            "        if 'Proxy-Connection' in self.request.headers:",
            "            del self.request.headers['Proxy-Connection']",
            "",
            "        self._record_activity()",
            "",
            "        if self.request.headers.get(\"Upgrade\", \"\").lower() == 'websocket':",
            "            # We wanna websocket!",
            "            # jupyterhub/jupyter-server-proxy@36b3214",
            "            self.log.info(\"we wanna websocket, but we don't define WebSocketProxyHandler\")",
            "            self.set_status(500)",
            "",
            "        body = self.request.body",
            "        if not body:",
            "            if self.request.method == 'POST':",
            "                body = b''",
            "            else:",
            "                body = None",
            "",
            "        client = httpclient.AsyncHTTPClient()",
            "",
            "        req = self._build_proxy_request(host, port, proxied_path, body)",
            "        self.log.debug(f\"Proxying request to {req.url}\")",
            "",
            "        try:",
            "            # Here, \"response\" is a tornado.httpclient.HTTPResponse object.",
            "            response = await client.fetch(req, raise_error=False)",
            "        except httpclient.HTTPError as err:",
            "            # We need to capture the timeout error even with raise_error=False,",
            "            # because it only affects the HTTPError raised when a non-200 response",
            "            # code is used, instead of suppressing all errors.",
            "            # Ref: https://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.AsyncHTTPClient.fetch",
            "            if err.code == 599:",
            "                self._record_activity()",
            "                self.set_status(599)",
            "                self.write(str(err))",
            "                return",
            "            else:",
            "                raise",
            "",
            "        # record activity at start and end of requests",
            "        self._record_activity()",
            "",
            "        # For all non http errors...",
            "        if response.error and type(response.error) is not httpclient.HTTPError:",
            "            self.set_status(500)",
            "            self.write(str(response.error))",
            "        else:",
            "            # Represent the original response as a RewritableResponse object.",
            "            original_response = RewritableResponse(orig_response=response)",
            "",
            "            # The function (or list of functions) which should be applied to modify the",
            "            # response.",
            "            rewrite_response = self.rewrite_response",
            "",
            "            # If this is a single function, wrap it in a list.",
            "            if isinstance(rewrite_response, (list, tuple)):",
            "                rewrite_responses = rewrite_response",
            "            else:",
            "                rewrite_responses = [rewrite_response]",
            "",
            "            # To be passed on-demand as args to the rewrite_response functions.",
            "            optional_args_to_rewrite_function = {",
            "                'request': self.request,",
            "                'orig_response': original_response,",
            "                'host': host,",
            "                'port': port,",
            "                'path': proxied_path",
            "            }",
            "",
            "            # Initial value for rewriting",
            "            rewritten_response = original_response",
            "",
            "            for rewrite in rewrite_responses:",
            "                # The rewrite function is a function of the RewritableResponse object",
            "                # ``response`` as well as several other optional arguments. We need to",
            "                # convert it to a function of only ``response`` by plugging in the",
            "                # known values for all the other parameters. (This is called partial",
            "                # evaluation.)",
            "                def rewrite_pe(rewritable_response: RewritableResponse):",
            "                    return call_with_asked_args(",
            "                        rewrite,",
            "                        {",
            "                            'response': rewritable_response,",
            "                            **optional_args_to_rewrite_function",
            "                        }",
            "                    )",
            "                # Now we can cleanly apply the partially evaulated function to a copy of",
            "                # the rewritten response.",
            "                rewritten_response = rewritten_response._apply_to_copy(rewrite_pe)",
            "",
            "            ## status",
            "            self.set_status(rewritten_response.code, rewritten_response.reason)",
            "",
            "            # clear tornado default header",
            "            self._headers = httputil.HTTPHeaders()",
            "            for header, v in rewritten_response.headers.get_all():",
            "                if header not in ('Content-Length', 'Transfer-Encoding',",
            "                                  'Connection'):",
            "                    # some header appear multiple times, eg 'Set-Cookie'",
            "                    self.add_header(header, v)",
            "",
            "            if rewritten_response.body:",
            "                self.write(rewritten_response.body)",
            "",
            "    async def proxy_open(self, host, port, proxied_path=''):",
            "        \"\"\"",
            "        Called when a client opens a websocket connection.",
            "",
            "        We establish a websocket connection to the proxied backend &",
            "        set up a callback to relay messages through.",
            "        \"\"\"",
            "",
            "        if not self._check_host_allowlist(host):",
            "            self.set_status(403)",
            "            self.log.info(\"Host '{host}' is not allowed. \"",
            "                          \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))",
            "            self.close()",
            "            return",
            "",
            "        if not proxied_path.startswith('/'):",
            "            proxied_path = '/' + proxied_path",
            "",
            "        client_uri = self.get_client_uri('ws', host, port, proxied_path)",
            "        headers = self.proxy_request_headers()",
            "",
            "        def message_cb(message):",
            "            \"\"\"",
            "            Callback when the backend sends messages to us",
            "",
            "            We just pass it back to the frontend",
            "            \"\"\"",
            "            # Websockets support both string (utf-8) and binary data, so let's",
            "            # make sure we signal that appropriately when proxying",
            "            self._record_activity()",
            "            if message is None:",
            "                self.close()",
            "            else:",
            "                self.write_message(message, binary=isinstance(message, bytes))",
            "",
            "        def ping_cb(data):",
            "            \"\"\"",
            "            Callback when the backend sends pings to us.",
            "",
            "            We just pass it back to the frontend.",
            "            \"\"\"",
            "            self._record_activity()",
            "            self.ping(data)",
            "",
            "        async def start_websocket_connection():",
            "            self.log.info('Trying to establish websocket connection to {}'.format(client_uri))",
            "            self._record_activity()",
            "            request = httpclient.HTTPRequest(url=client_uri, headers=headers)",
            "            self.ws = await pingable_ws_connect(request=request,",
            "                on_message_callback=message_cb, on_ping_callback=ping_cb,",
            "                subprotocols=self.subprotocols)",
            "            self._record_activity()",
            "            self.log.info('Websocket connection established to {}'.format(client_uri))",
            "",
            "        # Wait for the WebSocket to be connected before resolving.",
            "        # Otherwise, messages sent by the client before the",
            "        # WebSocket successful connection would be dropped.",
            "        await start_websocket_connection()",
            "",
            "    def proxy_request_headers(self):",
            "        '''A dictionary of headers to be used when constructing",
            "        a tornado.httpclient.HTTPRequest instance for the proxy request.'''",
            "        headers = self.request.headers.copy()",
            "        # Merge any manually configured request headers",
            "        headers.update(self.get_request_headers_override())",
            "        return headers",
            "",
            "    def get_request_headers_override(self):",
            "        '''Add additional request headers. Typically overridden in subclasses.'''",
            "        return {}",
            "",
            "    def proxy_request_options(self):",
            "        '''A dictionary of options to be used when constructing",
            "        a tornado.httpclient.HTTPRequest instance for the proxy request.'''",
            "        return dict(follow_redirects=False, connect_timeout=250.0, request_timeout=300.0)",
            "",
            "    def check_xsrf_cookie(self):",
            "        '''",
            "        http://www.tornadoweb.org/en/stable/guide/security.html",
            "",
            "        Defer to proxied apps.",
            "        '''",
            "        pass",
            "",
            "    def select_subprotocol(self, subprotocols):",
            "        '''Select a single Sec-WebSocket-Protocol during handshake.'''",
            "        self.subprotocols = subprotocols",
            "        if isinstance(subprotocols, list) and subprotocols:",
            "            self.log.debug('Client sent subprotocols: {}'.format(subprotocols))",
            "            return subprotocols[0]",
            "        return super().select_subprotocol(subprotocols)",
            "",
            "",
            "class LocalProxyHandler(ProxyHandler):",
            "    \"\"\"",
            "    A tornado request handler that proxies HTTP and websockets",
            "    from a port on the local system. Same as the above ProxyHandler,",
            "    but specific to 'localhost'.",
            "",
            "    The arguments \"port\" and \"proxied_path\" in each method are extracted from",
            "    the URL as capture groups in the regex specified in the add_handlers",
            "    method.",
            "    \"\"\"",
            "    async def http_get(self, port, proxied_path):",
            "        return await self.proxy(port, proxied_path)",
            "",
            "    async def open(self, port, proxied_path):",
            "        return await self.proxy_open('localhost', port, proxied_path)",
            "",
            "    def post(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def put(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def delete(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def head(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def patch(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def options(self, port, proxied_path):",
            "        return self.proxy(port, proxied_path)",
            "",
            "    def proxy(self, port, proxied_path):",
            "        return super().proxy('localhost', port, proxied_path)",
            "",
            "class RemoteProxyHandler(ProxyHandler):",
            "    \"\"\"",
            "    A tornado request handler that proxies HTTP and websockets",
            "    from a port on a specified remote system.",
            "",
            "    The arguments \"host\", \"port\" and \"proxied_path\" in each method are",
            "    extracted from the URL as capture groups in the regex specified in the",
            "    add_handlers method.",
            "    \"\"\"",
            "",
            "    async def http_get(self, host, port, proxied_path):",
            "        return await self.proxy(host, port, proxied_path)",
            "",
            "    def post(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def put(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def delete(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def head(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def patch(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    def options(self, host, port, proxied_path):",
            "        return self.proxy(host, port, proxied_path)",
            "",
            "    async def open(self, host, port, proxied_path):",
            "        return await self.proxy_open(host, port, proxied_path)",
            "",
            "    def proxy(self, host, port, proxied_path):",
            "        return super().proxy(host, port, proxied_path)",
            "",
            "# FIXME: Move this to its own file. Too many packages now import this from nbrserverproxy.handlers",
            "class SuperviseAndProxyHandler(LocalProxyHandler):",
            "    '''Manage a given process and requests to it '''",
            "",
            "    def __init__(self, *args, **kwargs):",
            "        self.requested_port = 0",
            "        self.mappath = {}",
            "        super().__init__(*args, **kwargs)",
            "",
            "    def initialize(self, state):",
            "        self.state = state",
            "        if 'proc_lock' not in state:",
            "            state['proc_lock'] = Lock()",
            "",
            "    name = 'process'",
            "",
            "    @property",
            "    def port(self):",
            "        \"\"\"",
            "        Allocate either the requested port or a random empty port for use by",
            "        application",
            "        \"\"\"",
            "        if 'port' not in self.state:",
            "            sock = socket.socket()",
            "            sock.bind(('', self.requested_port))",
            "            self.state['port'] = sock.getsockname()[1]",
            "            sock.close()",
            "        return self.state['port']",
            "",
            "    def get_cwd(self):",
            "        \"\"\"Get the current working directory for our process",
            "",
            "        Override in subclass to launch the process in a directory",
            "        other than the current.",
            "        \"\"\"",
            "        return os.getcwd()",
            "",
            "    def get_env(self):",
            "        '''Set up extra environment variables for process. Typically",
            "           overridden in subclasses.'''",
            "        return {}",
            "",
            "    def get_timeout(self):",
            "        \"\"\"",
            "        Return timeout (in s) to wait before giving up on process readiness",
            "        \"\"\"",
            "        return 5",
            "",
            "    async def _http_ready_func(self, p):",
            "        url = 'http://localhost:{}'.format(self.port)",
            "        async with aiohttp.ClientSession() as session:",
            "            try:",
            "                async with session.get(url, allow_redirects=False) as resp:",
            "                    # We only care if we get back *any* response, not just 200",
            "                    # If there's an error response, that can be shown directly to the user",
            "                    self.log.debug('Got code {} back from {}'.format(resp.status, url))",
            "                    return True",
            "            except aiohttp.ClientConnectionError:",
            "                self.log.debug('Connection to {} refused'.format(url))",
            "                return False",
            "",
            "    async def ensure_process(self):",
            "        \"\"\"",
            "        Start the process",
            "        \"\"\"",
            "        # We don't want multiple requests trying to start the process at the same time",
            "        # FIXME: Make sure this times out properly?",
            "        # Invariant here should be: when lock isn't being held, either 'proc' is in state &",
            "        # running, or not.",
            "        async with self.state['proc_lock']:",
            "            if 'proc' not in self.state:",
            "                # FIXME: Prevent races here",
            "                # FIXME: Handle graceful exits of spawned processes here",
            "                cmd = self.get_cmd()",
            "",
            "                # Set up extra environment variables for process",
            "                server_env = os.environ.copy()",
            "                server_env.update(self.get_env())",
            "",
            "                timeout = self.get_timeout()",
            "",
            "                proc = SupervisedProcess(self.name, *cmd, env=server_env, ready_func=self._http_ready_func, ready_timeout=timeout, log=self.log)",
            "                self.state['proc'] = proc",
            "",
            "                try:",
            "                    await proc.start()",
            "",
            "                    is_ready = await proc.ready()",
            "",
            "                    if not is_ready:",
            "                        await proc.kill()",
            "                        raise web.HTTPError(500, 'could not start {} in time'.format(self.name))",
            "                except:",
            "                    # Make sure we remove proc from state in any error condition",
            "                    del self.state['proc']",
            "                    raise",
            "",
            "",
            "    @web.authenticated",
            "    async def proxy(self, port, path):",
            "        if not path.startswith('/'):",
            "            path = '/' + path",
            "        if self.mappath:",
            "            if callable(self.mappath):",
            "                path = call_with_asked_args(self.mappath, {'path': path})",
            "            else:",
            "                path = self.mappath.get(path, path)",
            "",
            "        await self.ensure_process()",
            "",
            "        return await ensure_async(super().proxy(self.port, path))",
            "",
            "",
            "    async def http_get(self, path):",
            "        return await ensure_async(self.proxy(self.port, path))",
            "",
            "    async def open(self, path):",
            "        await self.ensure_process()",
            "        return await super().open(self.port, path)",
            "",
            "    def post(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def put(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def delete(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def head(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def patch(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "    def options(self, path):",
            "        return self.proxy(self.port, path)",
            "",
            "",
            "def setup_handlers(web_app, serverproxy_config):",
            "    host_allowlist = serverproxy_config.host_allowlist",
            "    rewrite_response = serverproxy_config.non_service_rewrite_response",
            "    web_app.add_handlers(",
            "        \".*\",",
            "        [",
            "            (",
            "                url_path_join(",
            "                    web_app.settings[\"base_url\"],",
            "                    r\"/proxy/([^/:@]+):(\\d+)(/.*|)\",",
            "                ),",
            "                RemoteProxyHandler,",
            "                {",
            "                    \"absolute_url\": False,",
            "                    \"host_allowlist\": host_allowlist,",
            "                    \"rewrite_response\": rewrite_response,",
            "                },",
            "            ),",
            "            (",
            "                url_path_join(",
            "                    web_app.settings[\"base_url\"],",
            "                    r\"/proxy/absolute/([^/:@]+):(\\d+)(/.*|)\",",
            "                ),",
            "                RemoteProxyHandler,",
            "                {",
            "                    \"absolute_url\": True,",
            "                    \"host_allowlist\": host_allowlist,",
            "                    \"rewrite_response\": rewrite_response,",
            "                },",
            "            ),",
            "            (",
            "                url_path_join(",
            "                    web_app.settings[\"base_url\"],",
            "                    r\"/proxy/(\\d+)(/.*|)\",",
            "                ),",
            "                LocalProxyHandler,",
            "                {",
            "                    \"absolute_url\": False,",
            "                    \"rewrite_response\": rewrite_response,",
            "                },",
            "            ),",
            "            (",
            "                url_path_join(",
            "                    web_app.settings[\"base_url\"],",
            "                    r\"/proxy/absolute/(\\d+)(/.*|)\",",
            "                ),",
            "                LocalProxyHandler,",
            "                {",
            "                    \"absolute_url\": True,",
            "                    \"rewrite_response\": rewrite_response,",
            "                },",
            "            ),",
            "        ],",
            "    )",
            "",
            "",
            "# vim: set et ts=4 sw=4:"
        ],
        "action": [
            "0",
            "0",
            "0",
            "1",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "0",
            "0",
            "0",
            "0",
            "0",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "2",
            "0",
            "0"
        ],
        "dele_reviseLocation": {
            "212": [
                "ProxyHandler",
                "get_client_uri"
            ],
            "231": [
                "ProxyHandler",
                "get_client_uri"
            ],
            "306": [
                "ProxyHandler"
            ],
            "327": [
                "ProxyHandler"
            ],
            "691": [
                "setup_handlers"
            ],
            "692": [
                "setup_handlers"
            ],
            "693": [
                "setup_handlers"
            ],
            "694": [
                "setup_handlers"
            ],
            "695": [
                "setup_handlers"
            ],
            "697": [
                "setup_handlers"
            ],
            "698": [
                "setup_handlers"
            ],
            "699": [
                "setup_handlers"
            ],
            "700": [
                "setup_handlers"
            ],
            "701": [
                "setup_handlers"
            ],
            "702": [
                "setup_handlers"
            ],
            "703": [
                "setup_handlers"
            ],
            "704": [
                "setup_handlers"
            ],
            "705": [
                "setup_handlers"
            ],
            "706": [
                "setup_handlers"
            ],
            "707": [
                "setup_handlers"
            ],
            "709": [
                "setup_handlers"
            ],
            "710": [
                "setup_handlers"
            ],
            "711": [
                "setup_handlers"
            ],
            "712": [
                "setup_handlers"
            ],
            "713": [
                "setup_handlers"
            ],
            "714": [
                "setup_handlers"
            ],
            "715": [
                "setup_handlers"
            ],
            "716": [
                "setup_handlers"
            ],
            "717": [
                "setup_handlers"
            ],
            "718": [
                "setup_handlers"
            ],
            "719": [
                "setup_handlers"
            ],
            "721": [
                "setup_handlers"
            ],
            "722": [
                "setup_handlers"
            ],
            "723": [
                "setup_handlers"
            ],
            "724": [
                "setup_handlers"
            ],
            "725": [
                "setup_handlers"
            ],
            "726": [
                "setup_handlers"
            ],
            "727": [
                "setup_handlers"
            ],
            "728": [
                "setup_handlers"
            ],
            "729": [
                "setup_handlers"
            ],
            "730": [
                "setup_handlers"
            ],
            "732": [
                "setup_handlers"
            ],
            "733": [
                "setup_handlers"
            ],
            "734": [
                "setup_handlers"
            ],
            "735": [
                "setup_handlers"
            ],
            "736": [
                "setup_handlers"
            ],
            "737": [
                "setup_handlers"
            ],
            "738": [
                "setup_handlers"
            ]
        },
        "addLocation": []
    }
}